{"posts":[{"title":"斜堆","text":"斜堆一、什么是斜堆？斜堆（Skew Heap），也称斜树（Skew Tree），自适应堆(Self-Adjusting Heap)，是一种自平衡二叉堆数据结构。 斜堆是左倾堆（Leftist Heap）的一个变种，只是斜堆的节点中没有 NPL 这个属性而已。 斜堆的主要特点包括： 不平衡性：整体是不平衡的，并且在任何操作中都不会显式执行旋转操作来维持平衡 自平衡性：每次操作后，仅通过互换左右子树来调整结构，从而达到自平衡的效果 简单性：因为不需要执行显式的平衡操作，所以实现起来相对简单 斜堆最主要的特点就是，不执行显式的平衡操作，而是通过交换左右子树来维护自平衡性。 下面是斜堆的一个例子： 1234567 1 / \\ 2 3 / \\ 4 6 /5 单从结构上看，斜堆和普通堆差不多，感受不到区别。 不过实际上它和左倾堆是类似的，整体结构具有左倾性。 二、为什么用斜堆？斜堆在某些场景下，具有一些特定的应用和优点： 实现简单：没有复杂的平衡操作，实现简单 合并高效：合并操作非常高效，没有额外的平衡操作，仅需要互换左右子树 自适应性：经常被访问的元素会被提升到根节点，从而提高了对这些元素的访问速度 空间效率：节点不需要保存额外的平衡信息，比如 左倾堆、AVL、红黑树等 尽管斜堆具有上述优点，但它也有一些缺点，最坏情况下的性能不如其他一些堆结构。 斜堆通常适用于需要高效的合并操作和自适应性的场景，且不太依赖最坏情况性能保证的情况。 比如 Prim 算法、Kruskal 算法、优先级队列等需要频繁合并操作的场景。 三、怎么实现斜堆？合并操作是斜堆的重点，合并两个堆的步骤如下： 如果两个堆中有一个为空，则直接返回另一个堆 如果两个堆都不为空，则比较两个堆的根节点，将较小的根节点作为新堆的根节点 将较小根节点的右子树和较大根节点合并，然后将合并后的树作为新堆的右子树 最后交换左右子树 其实和左倾堆差不多，就是少了 NPL 属性判断而已，伪代码如下： 123456789101112131415161718192021merge(h1, h2) { // 1. 返回非空堆 if (h1 == null) { return h2; } if (h2 == null) { return h1; } // 2. 以小根节点作为新堆的根节点 min = h1.val &lt; h2.val ? h1 : h2; max = h1.val &gt; h2.val ? h1 : h2; // 3. 小根节点的右子节点和大根节点合并 min.right = merge(min.right, max); // 4. 交换左右子节点 swap(min.left, min.right); return min;} 下面给出一个合并操作的例子： 12345 堆1 堆2 2 1 / \\ / \\6 4 3 5 1）首先，取小根节点 1 作为新堆的根节点，然后合并小根右孩子与大根堆 12345 新堆1 待合并 1 5 2 / / \\3 6 4 2）同样地，取小根节点 2 作为新堆的根节点，合并小根右孩子与大根堆 12345 新堆1 新堆2 待合并 1 2 5 4 / / 3 6 3）同上，取小根节点 4 作为新堆根节点，合并小根右孩子（null 节点）与大根堆 12345 新堆1 新堆2 新堆3 1 2 4 / / \\3 6 5 4）接着交换 4 的左右孩子 12345 新堆1 新堆2 新堆3 1 2 4 / / /3 6 5 5）接着开始递归往上合并，4 返回给 2 的右孩子 1234567 新堆1 新堆2 1 2 / / \\3 6 4 / 5 6）接着交换 2 的左右孩子 1234567 新堆1 新堆2 1 2 / / \\3 4 6 / 5 7）继续往上合并，2 返回给 1 的右孩子 123456789 新堆1 1 / \\3 2 / \\ 4 6 /5 8）接着交换 1 的左右孩子 123456789 新堆1 1 / \\ 2 3 / \\ 4 6 /5 至此，合并操作就完成了。 至于其他的操作，比如删除和插入，实际上都是通过合并操作实现的： 删除最小元素：相当于删除根节点，然后合并左右子树 插入新元素：相当于将新元素作为一个新的斜堆，然后两个堆合并 下面是它们的伪代码： 123456removeFirst() { temp = root; root = merge(root.left, root.right); temp.left = temp.right = null; return temp.val;} 123insert(val) { root = merge(root, new Node&lt;&gt;(val));} 总的来说，斜堆和左倾堆差不多，实现也是比较简单的。 参考 https://www.cnblogs.com/skywang12345/p/3638552.html 附录斜堆接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 斜堆（Skew Heap） * &lt;p&gt; * 左倾堆（Leftist Heap）的变种，只是斜堆没有 NPL 这个属性 * * @author weijiaduo * @since 2023/9/26 */public interface SkewHeap&lt;T&gt; { /** * 合并另外一个堆 * * @param other 另外一个堆 */ void merge(SkewHeap&lt;T&gt; other); /** * 插入新值 * * @param val 新值 */ void insert(T val); /** * 移除根节点 * * @return 根节点值 */ T removeFirst(); /** * 根节点值 * * @return 根节点值 */ T first(); /** * 堆大小 * * @return 堆大小 */ int size(); /** * 是否为空 * * @return true/false */ boolean isEmpty();} 斜堆实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104/** * 斜堆（Skew Heap）实现类 * &lt;p&gt; * 左倾堆（Leftist Heap）的变种，只是斜堆没有 NPL 这个属性 * * @author weijiaduo * @since 2023/9/26 */public class SkewHeapImpl&lt;T extends Comparable&lt;T&gt;&gt; implements SkewHeap&lt;T&gt; { /** * 堆根节点 */ private SkewHeapNode&lt;T&gt; root; /** * 节点数量 */ private int size; @Override public void merge(SkewHeap&lt;T&gt; other) { if (!(other instanceof SkewHeapImpl&lt;T&gt;)) { return; } root = merge(root, ((SkewHeapImpl&lt;T&gt;) other).root); size += other.size(); } @Override public void insert(T val) { root = merge(root, new SkewHeapNode&lt;&gt;(val)); size++; } @Override public T removeFirst() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap is Empty!&quot;); } SkewHeapNode&lt;T&gt; node = root; root = merge(root.left, root.right); node.left = node.right = null; size--; return node.val; } @Override public T first() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap is Empty!&quot;); } return root.val; } @Override public int size() { return size; } @Override public boolean isEmpty() { return size &lt;= 0; } /** * 合并 2 个堆，并返回新堆的根节点 * * @param h1 堆1 根节点 * @param h2 堆2 根节点 * @return 新堆的根节点 */ private SkewHeapNode&lt;T&gt; merge(SkewHeapNode&lt;T&gt; h1, SkewHeapNode&lt;T&gt; h2) { if (h1 == null) { return h2; } if (h2 == null) { return h1; } // 以小根节点作为新堆的根节点 SkewHeapNode&lt;T&gt; min, max; if (h1.val.compareTo(h2.val) &lt;= 0) { min = h1; max = h2; } else { min = h2; max = h1; } // 小根节点的右子节点和大根节点合并 min.right = merge(min.right, max); // 交换左右子节点 SkewHeapNode&lt;T&gt; tmp = min.left; min.left = min.right; min.right = tmp; return min; }}","link":"/datastructure/heap/skewheap/"},{"title":"左倾堆","text":"左倾堆一、什么是左倾堆？左倾堆（Leftist Heap），也称为左偏树（Leftist Tree）、左偏堆，最左堆等。 和二叉堆（即常见的堆，基于数组实现的完全堆）一样，左倾堆也是优先队列的一种实现方式。 只不过左倾堆具有一些特殊的性质： 左倾性：左倾堆中左子树的深度（或高度）都不小于右子树的深度 最小堆性：左倾堆通常用于实现最小堆，所以根节点通常都是最小值 为了实现左倾性，左倾堆的节点都有一个 NPL（Null Path Length）属性： NPL：节点到一个“最近的不满节点”的最短路径的长度。空节点的 NPL = -1 其中，“不满节点”是指左右子节点中至少有一个为 null 的节点。 而左倾堆的结构中，也有几个基本性质： 节点的键值 &lt;= 它的左右子节点的键值 节点的左孩子的 NPL &gt;= 节点右孩子的 NPL 节点的 NPL = 它的右孩子的 NPL + 1 下面是左倾堆的一个例子： 1234567 2(1) / \\ 3(1) 4(0) / \\5(0) 7(0) / 9(0) 其中，括号中的数字表示 NPL。 像 4，5，7，9 这几个节点都有 null 子节点，所以它们的 NPL 都是 0。 而 2，3 的 NPL 则等于它们右孩子的 NPL + 1。 另外，有一点需要说明的是：根节点的 NPL 不一定比子节点的大。 二、为什么用左倾堆？左倾堆和二叉堆的作用是一样的，只是在结构上有所区别： 二叉堆是用数组实现，堆结构是一棵完全二叉树 左倾堆是用树实现，结构就是一棵普通的二叉树 二叉堆和左倾堆都能用于优先队列的实现，区别不是很大。 但是在涉及“合并操作”时，二叉堆的效率会比较低，而左倾堆的性能更好 而左倾堆也有自己的缺点，就是在删除最小元素操作上可能表现略差一些 所以，左倾堆适用于某些特殊场景下，特别是需要频繁执行合并操作的情况。 三、怎么实现左倾堆？合并操作是左倾堆的重点，合并两个堆的步骤如下： 如果两个堆中有一个为空，则直接返回另一个堆 如果两个堆都不为空，则比较两个堆的根节点，将较小的根节点作为新堆的根节点 将较小根节点的右子树和较大根节点合并，然后将合并后的树作为新堆的右子树 如果新堆的右子树的 NPL &gt; 左子树的 NPL，则交换左右子树 新堆的 NPL = 右子树的 NPL + 1 步骤看起来挺多的，但是其实逻辑很简单，伪代码如下： 1234567891011121314151617181920212223242526merge(h1, h2) { // 1. 返回非空堆 if (h1 == null) { return h2; } if (h2 == null) { return h1; } // 2. 以小根节点作为新堆的根节点 min = h1.val &lt; h2.val ? h1 : h2; max = h1.val &gt; h2.val ? h1 : h2; // 3. 小根节点的右子节点和大根节点合并 min.right = merge(min.right, max); // 4. 交换左右子节点 if (npl(min.right) &gt; npl(min.left)) { swap(min.left, min.right); } // 5. 根节点距离 = 右子节点距离 + 1 min.npl = npl(min.right) + 1; return min;} 下面给出一个合并操作的例子： 12345 堆1 堆2 2(1) 1(1) / \\ / \\6(0) 4(0) 3(0) 5(0) 1）首先，取小根节点 1(1) 作为新堆的根节点，然后合并小根右孩子与大根堆 12345 新堆1 待合并 1(1) 5(0) 2(1) / / \\3(0) 6(0) 4(0) 2）同样地，取小根节点 2(1) 作为新堆的根节点，合并小根右孩子与大根堆 12345 新堆1 新堆2 待合并 1(1) 2(1) 5(0) 4(0) / / 3(0) 6(0) 3）同上，取小根节点 4(0) 作为新堆根节点，合并小根右孩子（null 节点）与大根堆 12345 新堆1 新堆2 新堆3 1(1) 2(1) 4(0) / / \\3(0) 6(0) 5(0) 4）此时 4 的右孩子 5(0) 大于左孩子 NULL(-1) 的 NPL，需要交换左右孩子 12345 新堆1 新堆2 新堆3 1(1) 2(1) 4(0) / / /3(0) 6(0) 5(0) 同时更新 4 的 NPL = NPL(null) + 1 = -1 + 1 = 0。 5）接着，完成后开始递归往上合并，4 返回给 2 的右孩子 1234567 新堆1 新堆2 1(1) 2(1) / / \\3(0) 6(0) 4(0) / 5(0) 由于 4(0) 并不比 6(0) 的 NPL 大，所以不需要交换左右子节点。 同时更新 2 的 NPL = NPL(4) + 1 = 0 + 1 = 1。 6）继续合并完成后开始递归往上，2 返回给 1 的右孩子 123456789 新堆 1(1) / \\3(0) 2(1) / \\ 6(0) 4(0) / 5(0) 7）由于 2(1) 比 3(0) 的 NPL 大，所以需要交换左右子节点 123456789 新堆 1(1) / \\ 2(1) 3(0) / \\6(0) 4(0) / 5(0) 同时更新 1 的 NPL = NPL(3) + 1 = 0 + 1 = 1。 至此，合并操作就完成了。 至于其他的操作，比如删除和插入，实际上都是通过合并操作实现的： 删除最小元素：相当于删除根节点，然后合并左右子树 插入新元素：相当于将新元素作为一个新的左倾堆，然后两个堆合并 下面是它们的伪代码： 123456removeFirst() { temp = root; root = merge(root.left, root.right); temp.left = temp.right = null; return temp.val;} 123insert(val) { root = merge(root, new Node&lt;&gt;(val));} 总体来说，左倾堆的实现还是比较简单的。 参考 https://www.cnblogs.com/skywang12345/p/3638384.html 附录左倾堆接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 左倾堆（Leftist Heap） * &lt;p&gt; * 基本性质： * &lt;p&gt; * 1. 节点的键值小于或等于它的左右子节点的键值 * &lt;p&gt; * 2. 节点的左孩子的NPL &gt;= 右孩子的NPL * &lt;p&gt; * 3. 节点的NPL = 它的右孩子的NPL + 1 * * @author weijiaduo * @since 2023/9/26 */public interface LeftistHeap&lt;T&gt; { /** * 合并另外一个堆 * * @param other 另外一个堆 */ void merge(LeftistHeap&lt;T&gt; other); /** * 插入新值 * * @param val 新值 */ void insert(T val); /** * 移除根节点 * * @return 根节点值 */ T removeFirst(); /** * 根节点值 * * @return 根节点值 */ T first(); /** * 堆大小 * * @return 堆大小 */ int size(); /** * 是否为空 * * @return true/false */ boolean isEmpty();} 左倾堆实现1234567891011121314151617181920212223242526272829303132333435/** * 左倾堆节点 * * @author weijiaduo * @since 2023/9/26 */public class LeftistHeapNode&lt;T&gt; { /** * 节点值 */ public T val; /** * 零距离（Null Path Length） */ public int npl; /** * 左子节点 */ public LeftistHeapNode&lt;T&gt; left; /** * 右子节点 */ public LeftistHeapNode&lt;T&gt; right; public LeftistHeapNode(T val) { this.val = val; } @Override public String toString() { return val.toString() + &quot;(&quot; + npl + &quot;)&quot;; }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127/** * 左倾堆（Leftist Heap）实现类 * &lt;p&gt; * 基本性质： * &lt;p&gt; * 1. 节点的键值小于或等于它的左右子节点的键值 * &lt;p&gt; * 2. 节点的左孩子的NPL &gt;= 右孩子的NPL * &lt;p&gt; * 3. 节点的NPL = 它的右孩子的NPL + 1 * * @author weijiaduo * @since 2023/9/26 */public class LeftistHeapImpl&lt;T extends Comparable&lt;T&gt;&gt; implements LeftistHeap&lt;T&gt; { /** * 根节点 */ private LeftistHeapNode&lt;T&gt; root; /** * 节点数量 */ private int size; @Override public void merge(LeftistHeap&lt;T&gt; other) { if (!(other instanceof LeftistHeapImpl&lt;T&gt;)) { return; } root = merge(root, ((LeftistHeapImpl&lt;T&gt;) other).root); size += other.size(); } @Override public void insert(T val) { root = merge(root, new LeftistHeapNode&lt;&gt;(val)); size++; } @Override public T removeFirst() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap is Empty!&quot;); } LeftistHeapNode&lt;T&gt; node = root; root = merge(root.left, root.right); node.left = node.right = null; size--; return node.val; } @Override public T first() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap is Empty!&quot;); } return root.val; } @Override public int size() { return size; } @Override public boolean isEmpty() { return size &lt;= 0; } /** * 合并 2 个堆，并返回新堆的根节点 * * @param h1 堆1 根节点 * @param h2 堆2 根节点 * @return 新堆的根节点 */ private LeftistHeapNode&lt;T&gt; merge(LeftistHeapNode&lt;T&gt; h1, LeftistHeapNode&lt;T&gt; h2) { if (h1 == null) { return h2; } if (h2 == null) { return h1; } // 以小根节点作为新堆的根节点 LeftistHeapNode&lt;T&gt; min, max; if (h1.val.compareTo(h2.val) &lt;= 0) { min = h1; max = h2; } else { min = h2; max = h1; } // 小根节点的右子节点和大根节点合并 min.right = merge(min.right, max); // 右子节点距离 &gt; 左子节点距离，交换左右子节点 if (npl(min.right) &gt; npl(min.left)) { LeftistHeapNode&lt;T&gt; tmp = min.left; min.left = min.right; min.right = tmp; } // 根节点距离 = 右子节点距离 + 1 min.npl = npl(min.right) + 1; return min; } /** * 节点的 NPL 距离 * * @param node 节点 * @return NPL 距离 */ private int npl(LeftistHeapNode&lt;T&gt; node) { // null 节点的距离为 -1 return node != null ? node.npl : -1; }}","link":"/datastructure/heap/leftistheap/"},{"title":"KMP 算法","text":"KMP 算法KMP 算法是一种字符串匹配算法，可以在 O(n+m) 的时间复杂度内实现两个字符串的匹配。 KMP 算法是根据三位作者（D.E.Knuth，J.H.Morris 和 V.R.Pratt）的名字来命名的，全称是 Knuth-Morris-Pratt 算法。 一、暴力：一次滑一位最简单的方式就是暴力逐位匹配，比如： 123// 第1轮a b c a b c a b da b c a b d 123// 第2轮a b c a b c a b d a b c a b d 123// 第3轮a b c a b c a b d a b c a b d 123// 第4轮a b c a b c a b d a b c a b d 暴力匹配的思路很简单，就是： 每次匹配失败，模式串就往后移动一位，再重新开始匹配 这种方式非常慢，复杂度超高，不适合大规模文本的匹配。 二、想法：一次滑几位既然暴力匹配失败后，一位一位地滑动很慢，那如果： 利用之前的匹配信息，匹配失败后，尽量一次滑多几位 这样的匹配方式是否能够提升性能？ 比如： 123// 第1轮a b c a b c a b da b c a b d 很明显后面2位（bc）都不是 a，所以不用匹配了，直接滑过： 123// 第2轮a b c a b c a b d a b c a b d 如果每次都能滑多几位，那么就能减少匹配的轮数，速度会大大提升。 不过，假如能滑多几位，那么能滑多远呢？ 滑到下一个可能匹配成功的位置 比如上面的例子，下一个可能匹配的位置（开头是 a）是： 12345 -----T: a b c | a b | c a b dP: a b c | a b | d P: -&gt; | a b | c a b d ----- 观察发现： 上一轮已经匹配好的子串是：abcab 下一轮开始：abcab 的前缀子串（ab）和后缀子串（ab）刚好有交集的位置 其滑动效果就类似这样： 1234567前缀子串 后缀子串 ---- ----| ab | c | ab | ---- ---- ---- ---- --&gt; | ab | c | ab | ---- ---- 这个滑动，实际就是将「前缀子串」滑到「后缀子串」的位置，即 ab 的位置。 也就是说，只要找到这种相等前后缀子串，每次匹配失败后就能一次往后滑多几位。 三、实现：Pmt 数组的匹配Pmt 数组，全称是：Partial Match Table，即部分匹配表。 Pmt 数组记录了模式串每个子串的最长相等前后缀的长度 Pmt 数组本质上是利用了相等前后缀子串的性质，来加快字符串的匹配 比如，模式串 abcabd 的 Pmt 数组为： 12P: a b c a b dPmt: 0 0 0 1 2 0 其中， Pmt[3] = 1 表示，abca 的最长相等前后缀的长度为 1，即 a Pmt[4] = 2 表示，abcab 的最长相等前后缀的长度为 2，即 ab 利用 Pmt 数组，字符串匹配过程可以这样： 1234567891011121314if (T[i] == P[j]) { // 匹配成功，i 和 x 同时向后移动一位 i++; j++;} else { // 匹配失败 if (j &gt; 0) { // 模式串滑到最长相等前后缀的位置重新开始 j = Pmt[j - 1]; } else { // 第一个字符就匹配失败，i 向后移动一位 i++; }} 其中，j = pmt[j - 1] 实际上就是将模式串滑动到最长相等前后缀的位置。 Pmt 数组的匹配过程类似这样： 123456 匹配失败 | vT: a b c a b c a b dP: a b c a b dPmt: 0 0 0 1 2 0 此时，j = 5，pmt[j - 1] = 2。 然后保持主串位置不变，模式串往后滑动，从索引 2 开始重新匹配： 123456 重新开始 | vT: a b c a b c a b dP: a b c a b dPmt: 0 0 0 1 2 0 按照这种方式不断匹配下去，直到匹配结束为止。 匹配过程中，主串索引只会不断递增，而不会回头 所以，相比于暴力的逐位匹配，Pmt 数组可以极大地提升匹配速度： 时间复杂度：暴力匹配是 O(m * n)；而 Pmt 的是 O(m + n) 空间复杂度：暴力匹配是 O(1)；而 Pmt 的是 O(m) 虽然空间复杂度从 O(1) 升到了 O(m)，但是模式串 m 一般都比较小，所以也不是很大的问题。 而对于大文本匹配来说，时间复杂度从 O(m * n) 降到了 O(m + n)，则是一个非常大的提升。 四、关键：Pmt 数组的构造Pmt 数组确实可以提升匹配速度，那么如何求得 Pmt 数组呢？ 利用动态规划，通过 Pmt[0] … Pmt[i] 来求 Pmt[i + 1] 假设已经知道了 Pmt[i-1] = k，即意味着模式串：P[0..k-1] == P[i-k..i-1]： 123456 ----------相等---------- | | v v ------------ --------------P: | 0 .. k-1 | k ... | i-k .. i-1 | i ------------ -------------- 那么对于 Pmt[i] 而言，可分为 2 种情况： (1) P[k] == P[i] 很明显，这种情况下 Pmt[i] 只需要在上一个的基础上扩展一位就行了，即： Pmt[i] = k + 1 扩展后的效果是这样的： 123456 ----------相等---------- | | v v --------------- -----------------P: | 0 .. k-1 k | ... | i-k .. i-1 i | --------------- ----------------- (2) P[k] != P[i] 这个时候，为了使得前后缀相等，就需要缩短前后缀长度，直到找到 P[x] == P[i] 为止： 123456 ------------------相等----------------- | | v v ------------ --------------P: | 0 .. x-1 | x ... k-1 ... i-k ... | i-x .. i-1 | i ------------ -------------- 其中，每次缩短，新的前后缀都要求满足这样的关系： P[0..x-1] == P[i-x..i-1] P[0..x-1] 是 P[0..k-1] 的前缀 P[i-x..i-1] 是 P[i-k..i-1] 的后缀 而且由于前提条件中 P[0..k-1] == P[i-k..i-1]，因此： P[0..x-1] 是 P[0..k-1] 的前缀 P[i-x..i-1] 是 P[0..k-1] 的后缀 简单来说就是： P[0..x-1] 是 P[0..k-1] 的一个相等前后缀 为了求最长的相等前后缀，x 应该尽量地大，否则找到的就不是最长的相等前后缀了。 要保证 x 尽量地大，因此 P[0..x-1] 实际上就是 P[0..k-1] 最长相等前后缀 所以，找 P[x] == P[i] 的过程类似这样： 123while (x &gt; 0 &amp;&amp; P[x] != P[i]) { x = pmt[x - 1];} 就是一个不断递归寻找上一级最长相等前后缀，再匹配的过程。 综合上面的 2 种情况，Pmt 数组构造对应的代码就是这样的： 123456789101112131415if (P[j] == P[i]) { // 最长相等前后缀长度 pmt[i] = j + 1; i++; j++;} else { if (j != 0) { // 找次长相等前后缀递归匹配 j = pmt[j - 1]; } else { // 一开始就匹配失败了 pmt[i] = 0; i++; }} 至此，Pmt 数组的构造就完成了。 五、改进：Next 数组在 Pmt 算法中，一旦第 j 位匹配失败，就会用 Pmt[j-1] 进行回溯，所以： 为了编程方便，直接将 Pmt 数组向右移动 1 位，得到 Next 数组 Next 数组的结果类似这样： 123P: a b c a b dPmt: 0 0 0 1 2 0Next: 0 0 0 1 2 至于第 0 位的值，可以赋值为 -1，这样做只是为了编程方面，并无其他意义。 123P: a b c a b dPmt: 0 0 0 1 2 0Next: -1 0 0 0 1 2 基于 Next 数组的算法和基于 Pmt 的算法是一样的，只是在编程上更加方便了。 Next 数组的匹配算法如下： 12345678if (j == -1 || P[j] == P[i]) { // 匹配主串和模式串的下一个字符 i++; j++;} else { // 一次性滑到最长相等前后缀的位置开始匹配 j = next[j];} 构造 Next 数组的算法如下： 123456789if (j == -1 || P[j] == P[i]) { i++; j++; // 最长相等前后缀长度，索引右移了1位 next[i] = j;} else { // 找次长相等前后缀递归匹配 j = next[j];} Next 数组和 Pmt 数组并没有本质区别，算法复杂度是一样的。 Next 数组改变的仅仅是编程的便利性，在实际中，Next 数组会更常用一些。 参考 https://time.geekbang.org/column/article/71845 https://www.zhihu.com/question/21923021 https://zhuanlan.zhihu.com/p/83334559 https://oi-wiki.org/string/kmp/ 附录基于 Pmt 数组的 KMP 算法实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * KMP(Partial Match Table) 算法 * * @author weijiaduo * @since 2023/3/28 */public class PmtKMP { public int search(String pat, String txt) { int[] pmt = getPmt(pat); int i = 0, j = 0; int m = pat.length(), n = txt.length(); while (i &lt; n &amp;&amp; j &lt; m) { if (txt.charAt(i) == pat.charAt(j)) { // 匹配成功，匹配下一个字符 i++; j++; } else { // 匹配失败 if (j != 0) { // 模式串滑到最长相等前后缀的位置重新开始 j = pmt[j - 1]; } else { // 第一个字符就匹配失败了 i++; } } } // 匹配成功 if (j == m) { return i - j; } return -1; } /** * 获取 Partial Match Table * &lt;p&gt; * pmt[i] 表示 pat[0...i] 的最长相等前后缀的长度 * * @param pat 模式串 * @return pmt 数组 */ private int[] getPmt(String pat) { int m = pat.length(); int[] pmt = new int[m]; pmt[0] = 0; int i = 1, j = 0; while (i &lt; m) { if (pat.charAt(i) == pat.charAt(j)) { // 最长相等前后缀长度 pmt[i] = j + 1; i++; j++; } else { if (j != 0) { // 找次长相等前后缀递归匹配 j = pmt[j - 1]; } else { // 一开始就匹配失败了 pmt[i] = 0; i++; } } } return pmt; }} 基于 Next 数组的 KMP 算法实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * KMP(Next Match Table) 算法 * * @author weijiaduo * @since 2023/3/28 */public class NextKMP { public int search(String pat, String txt) { int[] next = getNext(pat); int i = 0, j = 0; int m = pat.length(), n = txt.length(); while (i &lt; n &amp;&amp; j &lt; m) { if (j == -1 || txt.charAt(i) == pat.charAt(j)) { // 匹配主串和模式串的下一个字符 i++; j++; } else { // 一次性滑到最长相等前后缀的位置开始匹配 j = next[j]; } } // 匹配成功 if (j == m) { return i - j; } return -1; } /** * 获取 Next Match Table * &lt;p&gt; * next[i] 表示模式串下一次进行比较的索引位置 * &lt;p&gt; * next[i] 也表示 pat[0...j-1] 的最长相等前后缀的长度 * &lt;p&gt; * next 数组实际就是 pmt 数组往右移动一位得到的 * * @param pat 模式串 * @return next 数组 */ private int[] getNext(String pat) { int m = pat.length(); int[] next = new int[m]; next[0] = -1; int i = 0, j = -1; while (i &lt; m - 1) { if (j == -1 || pat.charAt(i) == pat.charAt(j)) { i++; j++; // 最长相等前后缀长度，索引右移了1位 next[i] = j; } else { // 找次长相等前后缀递归匹配 j = next[j]; } } return next; }}","link":"/algorithm/strings/match/kmp/"},{"title":"BF 算法","text":"BF 算法BF 算法，即 Brute Force，暴力匹配算法，也叫朴素匹配算法。 一、原理所谓的暴力匹配，就是： 检查主串的所有子串，看是否与模式串匹配 比如，主串是 ababababca，模式串是 abababca。 从前往后，依次检查主串的每一个子串是否跟模式串匹配 第 1 轮（比较第 1 个子串）： 12345 匹配失败 | vababababcaabababca 第 2 轮（比较第 2 个子串）： 12345匹配失败 | vababababca abababca 第 3 轮（比较第 3 个子串）： 12345 匹配成功 | vababababca abababca BF 算法就是通过匹配全部子串的方式，来实现字符串匹配。 二、分析假设主串长度是 n，模式串长度是 m。 那么匹配次数（即主串中长度为 m 的子串个数）是： 1n - m + 1 每次匹配的时间复杂度是 O(m)，所以总的时间复杂度是： 1O((n - m + 1) * m), 即 O(n * m) 三、应用虽然 BF 算法的时间复杂度比较高，但是它在实际应用中还是会经常用到： 很多场景下，主串和模式串的长度都不会太长，所以时间复杂度也不会太高 BF 算法思想简单，实现起来也比较简单，代码不容易出错，调试起来也简单 所以，大部分的简单场景下，BF 算法是可以满足需求的。 参考 https://time.geekbang.org/column/article/71187 https://www.zhihu.com/question/21923021 附录12345678910111213141516171819202122232425262728/** * 暴力搜索法 * * @author weijiaduo * @since 2023/3/28 */public class BruteForceSearch implements Search { @Override public int search(String pat, String txt) { int n = txt.length(); int m = pat.length(); for (int i = 0; i &lt;= n - m; i++) { int j = 0; for (; j &lt; m; j++) { if (txt.charAt(i + j) != pat.charAt(j)) { break; } } // 匹配成功 if (j == m) { return i; } } return -1; }}","link":"/algorithm/strings/match/bf/"},{"title":"堆排序","text":"堆排序一、什么是堆排序？ 基于堆的排序算法 二、为什么要用堆排序？ 唯一能够同时最优地利用空间和时间的排序算法 缺点是很少和相邻元素比较，导致无法利用缓存 三、怎么实现堆排序？ 堆排序可以分为 2 步： 构建堆：将数组构建成堆 堆排序：一直移除堆顶元素，直到堆为空为止 3.1 构建堆因为每次都是移除堆顶，而堆顶一直都是最大/最小值，所以移除堆元素就是排序的过程。 比如说，数组 [2, 7, 1, 4, 3, 6, 5]，要从小到大排序。 第一步是构建堆，将数组构建出大顶堆的结构： 1234567 1=&gt;6 7 2=&gt;7=&gt;4 2 2 2 7 / \\ / \\ / \\ / \\ 7 1 7 6 7 6 4 6 / \\ / \\ / \\ / \\ / \\ / \\ / \\ / \\ 4 3 6 5 4 3 1 5 4 3 1 5 2 3 1 5 构建完堆以后，数组变成了这样： 12345678 7 / \\ 4 6 -- 逻辑结构 / \\ / \\ 2 3 1 5 ___ ___ ___ ___ ___ ___ ___| 7 | 4 | 6 | 2 | 3 | 1 | 5 | -- 物理结构 3.2 堆排序接下来是排序，一直移除堆顶元素，被移除的堆顶元素放到数组的末尾空位： 1234567 7 6 / \\ / \\ 4 6 =&gt; 4 5 / \\ / \\ / \\ / 2 3 1 5 2 3 1 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 7 | 4 | 6 | 2 | 3 | 1 | 5 | | 6 | 4 | 5 | 2 | 3 | 1 | | 7 | 1234567 6 5 / \\ / \\ 4 5 =&gt; 4 1 / \\ / / \\ 2 3 1 2 3 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 6 | 4 | 5 | 2 | 3 | 1 | | 7 | | 5 | 4 | 1 | 2 | 3 | | 6 | 7 | 1234567 5 4 / \\ / \\ 4 1 =&gt; 3 1 / \\ / 2 3 2 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 5 | 4 | 1 | 2 | 3 | | 6 | 7 | | 4 | 3 | 1 | 2 | | 5 | 6 | 7 | 1234567 4 3 / \\ / \\ 3 1 =&gt; 2 1 / 2 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 4 | 3 | 1 | 2 | | 3 | 6 | 7 | | 3 | 2 | 1 | | 4 | 5 | 6 | 7 | 12345 3 2 / \\ =&gt; \\ 2 1 1 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 3 | 2 | 1 | | 4 | 5 | 6 | 7 | | 2 | 1 | | 3 | 4 | 5 | 6 | 7 | 12345 2 =&gt; 1 \\ 1 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 2 | 1 | | 3 | 4 | 5 | 6 | 7 | | 1 | | 2 | 3 | 4 | 5 | 6 | 7 | 至此，堆排序就完成了，数据已经排好序了。 总结 基于堆的排序算法 优缺点 唯一能够同时最优地利用空间和时间的排序算法 缺点是很少和相邻元素比较，导致无法利用缓存 堆排序步骤 构建堆：将数组构建成堆 堆排序：一直移除堆顶元素，直到堆为空为止 参考 《算法（第4版）》 附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 堆排序 * * @author weijiaduo * @since 2023/2/26 */public class HeapSort implements Sort { @Override public void sort(int[] arr) { // 建堆 int n = arr.length; for (int i = (n - 1) / 2; i &gt;= 0; i--) { sink(arr, i, n); } // 排序 for (int i = n; i &gt; 0; i--) { swap(arr, 0, i - 1); sink(arr, 0, i - 1); } } /** * 下沉 * * @param arr 数组 * @param i 当前索引 i * @param n 数组长度 */ private void sink(int[] arr, int i, int n) { while (i &lt; n - 1) { int m = i; // 左子节点 int l = 2 * i + 1; if (l &lt; n &amp;&amp; arr[l] &gt; arr[m]) { m = l; } // 右子节点 int r = 2 * i + 2; if (r &lt; n &amp;&amp; arr[r] &gt; arr[m]) { m = r; } if (m == i) { break; } swap(arr, i, m); i = m; } }}","link":"/algorithm/sort/heapsort/"},{"title":"索引堆","text":"索引堆一、什么是索引堆？索引堆（Index Heap）是二叉堆的一个变种，是二叉堆的一种增强。 相比于二叉堆只能访问堆顶元素，索引堆可以通过索引访问堆中的任意元素。 比如下面的索引堆： 12345 1(30) / \\ 4(28) 3(16) \\ / 5(22) 2(12) 除了可以直接访问堆顶元素 30，还可以通过索引访问其他元素： 1: 30 2: 12 3: 16 4: 28 5: 22 这相当于给堆元素增加了索引，因此称为索引堆。 二、为什么用索引堆？二叉堆，每次只能操作堆顶元素，没办法操作其他的元素。 在某些场景下，有时候需要操作一下非堆顶的元素，这种二叉堆就做不到了。 索引堆就是专门为了解决操作非堆顶元素问题而设计的。 三、索引堆如何实现？一种简单的方式是给元素加上索引属性，但是这需要重新实现一套新代码。 但另一种常见方式是，基于现有的二叉堆来改造实现： 使用额外一个数组记录元素索引，将索引数组建成堆 其结构类似这样子： 123456789101112 6(30) / \\ 4(28) 3(16) -- 索引堆结构 / \\ / 2(18) 5(22) 1(12) ___ ____ ____ ____ ____ ____ ____| | 6 | 4 | 3 | 2 | 5 | 1 | -- 索引堆数组 ___ ____ ____ ____ ____ ____ ____| | 12 | 18 | 16 | 28 | 22 | 30 | -- 元素数组 其中，6(30) 表示索引为 6 的元素，对应的值为 30。 元素数组：按照元素索引保存，元素位置会一直保持不变 索引堆数组：保存的是元素索引，会按照堆的结构来调整位置 有了这两个数组，就能随意获取堆里面的元素了： 获取堆顶元素时，可通过索引堆数组获取 根据索引获取元素时，可通过元素数组获取 这其实相当于在二叉堆的基础上，加了一个中间层，用索引数组来替代元素数组建堆而已。 不过利用这种方式，就可以通过直接改造二叉堆的代码来实现索引堆了。 四、实际案例问题描述： 多路归并问题，将多个有序的输入流，合并成一个有序的输出流。 解决方案： 这个问题，就可以使用索引堆来解决。 每个堆元素表示一路输入流，堆顶元素就是当前最小的那一路输入流。 12345678910111213141516171819202122232425// 创建一个最小索引堆（会同时记录输入流的索引和值）IndexHeap&lt;Integer&gt; indexHeap = new MinIndexHeap&lt;&gt;(n);// 初始化多路数据for (int i = 0; i &lt; n; i++) { int num = ins[i].readInt(); indexHeap.insert(i, num);}// 对多路数据进行排序while (indexHeap.size() &gt; 0) { // 移除堆顶记录，追加到输出流 int index = indexHeap.firstIndex(); int num = indexHeap.removeFirst(); out.write(num); // 某一路数据已经读完了 if (ins[index] == null) { continue; } // 从被移除的那一路补充数据 num = ins[index].readInt(); indexHeap.insert(index, num);} 合并多路输入流时，需要操作非堆顶的元素。 如果用普通的二叉堆就不好实现了，而索引堆则正好解决这个问题。 参考 《算法（第4版）》 附录索引堆接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 索引堆接口 * * @author weijiaduo * @since 2023/2/25 */public interface IndexHeap&lt;T&gt; { /** * 插入新值 * * @param index 指定索引 * @param val 新值 */ void insert(int index, T val); /** * 移除第一个节点 * * @return 第一个节点值 */ T removeFirst(); /** * 删除指定索引的元素 * * @param index 指定索引 * @return 被删除元素 */ T remove(int index); /** * @return 第一个元素 */ T first(); /** * 根节点元素的索引 * * @return 索引 */ int firstIndex(); /** * 指定索引的元素是否存在 * * @param index 指定索引 * @return true/false */ boolean containsIndex(int index); /** * @return 元素数量 */ int size();} 索引堆实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257/** * 索引堆 * * @author weijiaduo * @since 2023/2/25 */public class IndexHeapImpl&lt;T extends Comparable&lt;T&gt;&gt; implements IndexHeap&lt;T&gt; { /** * 元素数组 */ private final T[] elements; /** * 堆数组，堆元素 -&gt; 元素数组索引 * &lt;p&gt; * 另外，heap[0] 不用 */ private final int[] heap; /** * 元素数组索引 -&gt; 堆数组索引 */ private final int[] idxMap; /** * 元素比较器 */ private final Comparator&lt;T&gt; cmp; /** * 元素数量 */ private int size; public IndexHeapImpl(int capacity) { this(capacity, Comparator.reverseOrder()); } public IndexHeapImpl(int capacity, Comparator&lt;T&gt; cmp) { this.cmp = cmp; //noinspection unchecked elements = (T[]) new Comparable[capacity]; heap = new int[capacity + 1]; idxMap = new int[capacity]; Arrays.fill(heap, -1); Arrays.fill(idxMap, -1); } @Override public void insert(int idx, T val) { if (idx &lt; 0 || idx &gt;= elements.length) { throw new IllegalStateException(String.format(&quot;size: %d, index: %d&quot;, elements.length, idx)); } if (containsIndex(idx)) { // 更新元素 elements[idx] = val; int hp = idxMap[idx]; siftUp(hp); siftDown(hp); } else { // 插入元素 elements[idx] = val; int hp = ++size; heap[hp] = idx; idxMap[idx] = hp; siftUp(hp); } } @Override public T removeFirst() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap isEmpty!&quot;); } int hp = 1; int idx = heap[hp]; T val = elements[idx]; swap(hp, size); heap[size] = -1; idxMap[idx] = -1; elements[idx] = null; size--; siftDown(hp); return val; } @Override public T remove(int idx) { if (!containsIndex(idx)) { throw new IllegalStateException(String.format(&quot;size: %d, index: %d&quot;, elements.length, idx)); } int hp = idxMap[idx]; T val = elements[idx]; swap(hp, size); heap[size] = -1; idxMap[idx] = -1; elements[idx] = null; size--; // 删除最后一个元素无需处理 if (hp &lt;= size) { siftUp(hp); siftDown(hp); } return val; } @Override public T first() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap isEmpty!&quot;); } return elements[heap[1]]; } @Override public int firstIndex() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap isEmpty!&quot;); } return heap[1]; } @Override public boolean containsIndex(int idx) { if (idx &lt; 0 || idx &gt;= elements.length) { return false; } return idxMap[idx] != -1; } @Override public int size() { return size; } /** * 从上往下调整 * * @param hp 当前节点，堆数组索引 */ private void siftDown(int hp) { int i = hp; while (i &lt; size) { int m = i; int l = left(i); if (l &lt;= size &amp;&amp; prior(l, m)) { m = l; } int r = right(i); if (r &lt;= size &amp;&amp; prior(r, m)) { m = r; } if (m == i) { break; } swap(i, m); i = m; } } /** * 从下往上调整 * * @param hp 当前节点，堆数组索引 */ private void siftUp(int hp) { int i = hp; while (i &gt; 1) { int p = parent(i); if (p &gt; 0 &amp;&amp; prior(i, p)) { swap(i, p); i = p; } else { break; } } } /** * 父节点索引 * * @param hp 当前节点，堆数组索引 * @return 父节点索引 */ private int parent(int hp) { return hp / 2; } /** * 左子节点索引 * * @param hp 当前节点，堆数组索引 * @return 左子节点索引 */ private int left(int hp) { return 2 * hp; } /** * 右子节点索引 * * @param hp 当前节点，堆数组索引 * @return 右子节点索引 */ private int right(int hp) { return 2 * hp + 1; } /** * elements[heap[hp]] 是否优先于 elements[heap[hq]] * * @param hp 堆数组索引 hp * @param hq 堆数组索引 hq * @return true/false */ private boolean prior(int hp, int hq) { return cmp.compare(elements[heap[hp]], elements[heap[hq]]) &lt; 0; } /** * 交换 2 个元素的位置 * * @param hp 堆数组索引 hp * @param hq 堆数组索引 hq */ private void swap(int hp, int hq) { if (hp == hq) { return; } int t = heap[hp]; heap[hp] = heap[hq]; heap[hq] = t; idxMap[heap[hp]] = hp; idxMap[heap[hq]] = hq; } @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(&quot;[&quot;); for (int i = 1; i &lt;= size; i++) { if (i &gt; 1) { sb.append(&quot;, &quot;); } sb.append(&quot;(&quot;) .append(heap[i]) .append(&quot;, &quot;) .append(elements[heap[i]]) .append(&quot;)&quot;); } sb.append(&quot;]&quot;); return sb.toString(); }}","link":"/datastructure/heap/indexheap/"},{"title":"堆","text":"堆一、是什么？在逻辑意义上，堆是一棵二叉树，类似这样： 1234567 大值堆 小值堆 30 14 / \\ / \\ 28 16 22 16 \\ / / / 22 12 24 26 堆的特性： 是一棵二叉树 节点是局部有序的（不像 BST 那样整体有序） 局部有序的意思是： 大值堆：父节点的值总比子节点的值大 小值堆：父节点的值总比子节点的值小 兄弟节点之间不存在大小关系 即，局部有序是指的父子之间有序，兄弟之间无序。 二、为什么？2.1 场景 每次只需要最优先的数据，而不必所有数据都排好序，比如任务调度 需要从大量数据中找出 TopN 的数据 2.2 目的 想要实现一种按优先级排列的数据结构 并且能保证较高的操作效率（插入和删除） 2.3 对比 有序表的插入和删除复杂度都是 O(n)，性能较差 BST 的插入和删除复杂度是 O(logn)，但结构不稳定 AVL 和红黑树可以满足条件，但是实现复杂 三、怎么做？3.1 存储结构堆是二叉树，按照一般实现，会使用节点链接的方式实现。 但是使用链接形式的二叉树来实现堆，过于浪费空间 如果把堆做成一棵完全二叉树，那就会相对简单很多： 以数组作为堆的底层物理存储结构 将堆树的节点按照层级顺序放入数组中 虽然堆的存储结构是数组，但是逻辑上是棵完全二叉树。 以大值堆为例，物理结构和逻辑结构的对应关系如下： 12345678 30 / \\ 28 16 -- 逻辑结构 / \\ / 18 22 12 ___ ____ ____ ____ ____ ____ ____| | 30 | 28 | 16 | 18 | 22 | 12 | -- 物理结构 堆使用数组存储时的性质： 堆节点的位置从索引 1 开始 左子节点索引是 2*i，右子节点索引是 2*i+1 父节点索引是 i/2 索引从 1 开始是为了减少父子索引计算时的 +/- 次数。 3.2 建堆建堆方式： 方式 1：将每个元素逐个插入堆中 方式 2：对分支节点，按照从下往上、从右往左的顺序调整 从理论上说，方案 2 的效率更高，因为它只需要处理 n/2 个元素。 比如，构建大值堆，构建的过程如下： 1234567 16=&gt;30 22=&gt;28 12=&gt;30=&gt;16 12 12 12 30 / \\ 16 / \\ 22 / \\ 12 / \\ 22 16 =====&gt; 22 30 =====&gt; 28 30 =====&gt; 28 16 / \\ / / \\ / / \\ / / \\ / 18 28 30 18 28 16 18 22 16 18 22 12 这里的最后一个分支节点是 16，所以按照 16 -&gt; 22 -&gt; 12 的顺序来调整。 从最后一个分支节点开始，从下往上、从右往左逐个执行 sift down，就能构建出一个堆。 3.3 插入插入过程： 先将插入元素放到数组最后，对应到堆树就是最后一个叶子节点 然后对插入元素从下往上递归调整父子节点的位置 比如，给下面例子的堆插入新元素 40，插入过程如下： 1234567 要插入40 插入40 40=&gt;16 40=&gt;30 30 30 30 40 / \\ 40 / \\ / \\ / \\ 28 16 =====&gt; 28 16 =====&gt; 28 40 =====&gt; 28 30 / \\ / / \\ / \\ / \\ / \\ / \\ / \\ 18 22 12 18 22 12 40 18 22 12 16 18 22 12 16 插入过程是从下往上执行 sift up，直到结构稳定或抵达根节点为止。 3.4 删除堆的删除，一般都是删除根节点。所以删除过程是这样的： 交换根节点和数组最后一个元素的位置 删除最后一个元素（原根节点） 对新根节点（原最后一个元素）从上往下调整位置 比如，下面例子要删除根节点 30，过程是这样的： 1234567 要移除30 交换30-12 移除30 调整12 调整12 30 12 12 28 28 / \\ / \\ / \\ / \\ / \\ 28 16 =====&gt; 28 16 =====&gt; 28 16 =====&gt; 12 16 =====&gt; 22 16 / \\ / / \\ / / \\ / \\ / \\ 18 22 12 18 22 30 18 22 18 22 18 12 删除是从上往下执行 siftdown 方法，直到结构稳定或抵达叶子节点为止。 四、实际案例问题描述： TopN 问题，从一个不知道长度的数据流中，统计 TopN 的数据 对应的伪代码如下： 12345678910// 创建一个最小值堆Heap&lt;Integer&gt; minHeap = new MinHeap&lt;&gt;(n + 1);while ((num = in.readInt()) != -1) { minHeap.intsert(num); // 堆中只保留 n 个元素 if (minHeap.size() &gt; n) { // 删除最小的元素值 minHeap.removeFirst(); }} 最终堆里只会保留 n 个最大值，即 TopN 数据。 总结堆的性质： 堆是一棵二叉树（使用数组实现的堆才是完全二叉树） 节点是局部有序的（不像 BST 那样整体有序） 大值堆：父节点的值总比子节点的值大 小值堆：父节点的值总比子节点的值小 兄弟节点之间不存在大小关系 堆的存储： 以数组作为堆的底层物理存储结构 将堆树的节点按照层级顺序放入数组中 使用数组存储的堆，是一棵完全二叉树 堆节点的位置从索引 1 开始 左子节点索引是 2*i，右子节点索引是 2*i+1 父节点索引是 i/2 索引从 1 开始是为了减少父子索引计算时的 +/- 次数 堆的操作： 建堆方式 方式 1：将每个元素逐个插入堆中 方式 2（更好）：对分支节点，按照从下往上、从右往左的顺序调整 插入过程 先将插入元素放到数组最后，对应到堆树就是最后一个叶子节点 然后对插入元素从下往上递归调整父子节点的位置 删除过程 交换根节点和数组最后一个元素的位置 删除最后一个元素（原根节点） 对新根节点（原最后一个元素）从上往下调整位置 参考 《数据结构与算法设计（第三版）》 《算法（第4版）》 附录堆接口123456789101112131415161718192021222324252627282930313233/** * 堆接口 * * @author weijiaduo * @since 2023/2/24 */public interface Heap&lt;T&gt; { /** * 插入新值 * * @param val 新值 */ void insert(T val); /** * 移除第一个节点 * * @return 第一个节点值 */ T removeFirst(); /** * @return 第一个元素 */ T first(); /** * @return 元素数量 */ int size();} 堆实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199/** * 堆实现 * * @author weijiaduo * @since 2023/2/24 */public class HeapImpl&lt;T extends Comparable&lt;T&gt;&gt; implements Heap&lt;T&gt; { /** * 堆，从 1 开始 */ private final T[] elements; /** * 堆大小 */ private int size; /** * 值比较器 */ private final Comparator&lt;T&gt; cmp; public HeapImpl(int capacity) { //noinspection unchecked elements = (T[]) new Comparable[capacity + 1]; cmp = Comparator.reverseOrder(); size = 0; } public HeapImpl(T[] elements) { this(elements, Comparator.reverseOrder()); } public HeapImpl(T[] elements, Comparator&lt;T&gt; cmp) { this.cmp = cmp; size = elements.length; //noinspection unchecked this.elements = (T[]) new Comparable[size + 1]; System.arraycopy(elements, 0, this.elements, 1, size); build(); } /** * 构建堆 */ private void build() { for (int i = size / 2; i &gt; 0; i--) { siftDown(i); } } @Override public void insert(T val) { if (size + 1 &gt;= elements.length) { throw new IllegalStateException(&quot;Heap isFull!&quot;); } elements[++size] = val; siftUp(size); } @Override public T removeFirst() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap isEmpty!&quot;); } T val = elements[1]; swap(1, size--); siftDown(1); return val; } @Override public T first() { if (size &lt;= 0) { throw new IllegalStateException(&quot;Heap isEmpty!&quot;); } return elements[1]; } @Override public int size() { return size; } /** * 从上往下调整 * * @param index 指定开始索引 */ private void siftDown(int index) { int i = index; while (i &lt; size) { int m = i; int l = left(i); if (l &lt;= size &amp;&amp; prior(l, m)) { m = l; } int r = right(i); if (r &lt;= size &amp;&amp; prior(r, m)) { m = r; } if (m == i) { break; } swap(i, m); i = m; } } /** * 从下往上调整 * * @param index 指定开始索引 */ private void siftUp(int index) { int i = index; while (i &gt; 0) { int p = parent(i); if (p &gt; 0 &amp;&amp; prior(i, p)) { swap(i, p); i = p; } else { break; } } } /** * 父节点索引 * * @param i 当前节点索引 * @return 父节点索引 */ private int parent(int i) { return i / 2; } /** * 左子节点索引 * * @param i 当前节点索引 * @return 左子节点索引 */ private int left(int i) { return 2 * i; } /** * 右子节点索引 * * @param i 当前节点索引 * @return 右子节点索引 */ private int right(int i) { return 2 * i + 1; } /** * elements[i] 是否小于 elements[j] * * @param i 索引 i * @param j 索引 j * @return true/false */ private boolean prior(int i, int j) { return cmp.compare(elements[i], elements[j]) &lt; 0; } /** * 交换2个元素的位置 * * @param i 索引 i * @param j 索引 j */ private void swap(int i, int j) { if (i == j) { return; } T t = elements[i]; elements[i] = elements[j]; elements[j] = t; } @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(&quot;[&quot;); for (int i = 0; i &lt;= size; i++) { if (i &gt; 0) { sb.append(&quot;, &quot;); } sb.append(elements[i]); } sb.append(&quot;]&quot;); return sb.toString(); }}","link":"/datastructure/heap/heap/"},{"title":"红黑树","text":"红黑树一、什么是红黑树？红黑树是一棵只有红色节点和黑色节点的平衡二叉搜索树。 其结构类似这样： 1234567 b4 / \\ r2 r6 / \\ / \\b1 b3 b5 b7 \\ r9 其中，b 表示黑色，r 表示红色。 1.1 红黑树的特性在《算法导论》里，红黑树是这样定义的： 每个结点或是红色的，或是黑色的 根节点是黑色的 每个叶结点（NIL）是黑色的 如果一个节点是红色的，则它的两个儿子都是黑色的 对于每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑色结点 前 4 点好理解，第 5 点需要说明一下，它的意思是： 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点 其中，黑节点的数目称为黑高（black-height）。 比如上面的红黑树，从 b4 节点开始的路径有 4 条： b4 -&gt; r2 -&gt; b1：2 个黑色节点 [b4, b1] b4 -&gt; r2 -&gt; b3：2 个黑色节点 [b4, b3] b4 -&gt; r6 -&gt; b5：2 个黑色节点 [b4, b5] b4 -&gt; r6 -&gt; b7：2 个黑色节点 [b4, b7] 每条路径包含的黑色节点数量是一样的。所以， 红黑树并不是“高度”平衡的二叉树，而是“黑高”平衡的二叉树 至于为什么是“黑高”平衡，这和红黑树的起源有关。 二、红黑树的起源2.1 与 4-阶 B-树的关系红黑树本质上是由 4 阶 B-树演化而来的，节点之间的对应关系是： 1）节点有 1 个元素 12344 阶 B-树节点 红黑树节点 ___ ___ ___| 1 | | | =&gt; b1 2）节点有 2 个元素 123454 阶 B-树节点 红黑树节点 ___ ___ ___ b1 b2| 1 | 2 | | =&gt; \\ 或 / r2 r1 3）节点有 3 个元素 123454 阶 B-树节点 红黑树节点 ___ ___ ___ b2| 1 | 2 | 3 | =&gt; / \\ r1 r3 需要说明的是： 1 个 4 阶 B-树节点对应的红黑树结构，只会有 1 个黑色节点 4 阶 B-树节点有 3 个元素时，对应的红黑树节点只有 1 种情况 合法的 4 阶 B-树 3 元素节点对应的红色节点只能在左右子节点中 所以下面这些情况都是不合法的： 12345 b3 b3 b1 b1 / / \\ \\ r2 r1 r3 r2 / \\ / \\r1 r2 r2 r3 简单点说，就是： 先有黑色节点，才有红色节点 红色节点不能单独存在，总是与黑色节点绑定的 红色节点的父节点只能是黑色 2 个红色节点不能够相邻 这些全都是红黑树的特性，总之就是： 将红色节点和它的黑色父节点，看成是 1 个节点就行了 1 个节点最多带有 3 个元素，最多时只能是“1黑色 + 2红色” 上面说红黑树是“黑高”平衡的，是因为 1 个 4 阶 B-树节点对应到红黑树上只会有 1 个黑色节点。 而 B-树是高度平衡的，所以对应到红黑树时，就变成了“黑高”平衡。 2.2 为什么不直接用 4 阶 B-树？实际上，相对于 4 阶 B-树，红黑树会有一些优势： 空间利用率 B-树有空间浪费，空间利用率不高 红黑树的空间利用率总是 100% 二分查找 B-树是多叉树，采用的是多路搜索，没有二分查找那么方便 红黑树本身就是二叉搜索树 比如，上面的 1 元素节点： 12344 阶 B-树节点 红黑树节点 ___ ___ ___| 1 | | | =&gt; b1 对于 B-树而言，空间利用率只有 33%，而红黑树的空间利用率就是 100%。 除了这些优点，还有一点： B-树是多叉树，代码实现比红黑树要复杂得多 红黑树本身是二叉树，代码再复杂也不会比多叉树复杂 综合各种情况，还是红黑树会比 4阶 B-树更优一些。 2.3 为什么是红色和黑色？为什么是红黑树，而不是黑白树？黄绿树？ 目前发现有 2 种说法： 红色和黑色是激光打印机最好找到的颜色 红色和黑色是最容易获得的笔色 不管是哪种说法都差不多，大概就是： 因为平时常用红色和黑色来作图，所以才称之为红黑树 红黑色的来源确实贴近生活，符合实际。 三、为什么用红黑树？红黑树的优略势： 相比于 BST 树，红黑树结构更加平衡，稳定性更好 相比于 AVL 树，红黑树在插入和删除过程中的旋转更少 相比于 B-树，红黑树结构更简单，空间利用率更高 红黑树的适用场景： 频繁的插入、删除，采用红黑树 频繁的搜索，采用 AVL 树 四、如何实现红黑树？声明，下面默认是将红黑树节点看成是 4 阶 B-树节点： 将红色节点和它的黑色父节点，看成是 1 个节点 1 个节点最多带有 3 个元素，最多时只能是“1黑色 + 2红色” 这样是为了简化理解，从 B-树的角度去理解红黑树为什么要这么调整。 4.1 检索红黑树本身就是 BST 树，所以检索也是采用的二分查找。 伪代码如下： 123456789101112131415private RBTNode get(RBTNode h, int val) { // 没有找到 if (h == null) { return null; } // 找到对应的节点 if (h.val == val) { return h; } if (h.val &gt; val) { return get(h.left, val); } else { return get(h.right, val); }} 红黑树的检索时间复杂度是 O(logn)。 4.2 插入红黑树是一棵平衡树，所以插入节点后可能会需要调整，维持平衡。 红黑树插入新节点的原则： 新节点总是在叶子节点处插入 新节点的颜色总是红色 根据这 2 个原则，插入新节点后可能出现的情况有 6 种： 123456黑色父节点 红色父节点 b b / \\ / \\ r r / \\ / \\ 其中，在插入红色节点后，6 种情况里： 父节点是黑色的 2 种情况，不影响红黑树的“黑高”平衡，不需要调整 只有父节点是红色的 4 种情况，需要调整红黑树的结构，以维持平衡 所以，需要特殊处理的只是父节点是红色的 4 种情况。 4.2.1 Left-Left-RedLeft-Left-Red 表示的红黑树类似这样（新插入节点是 r1）： 12345 b3 / r2 /r1 由于 2 个红色节点相邻了，不符合红黑树的定义，需要调整。 调整方式很简单，只需要做 2 步处理： 1234567 红色节点右旋 父子节点反色 b3 / b2 r2 r2 =&gt; / \\ =&gt; / \\ / r1 r3 b1 b3r1 做完处理后，父节点变成了红色，此时还可能会出现连续 2 个红色节点的情况。 父节点变红后，可以将父节点 r2 当作新插入的节点，继续往上递归调整 往上递归调整一直到结构平衡，或者根节点为止。 4.2.2 Left-Right-RedLeft-Right-Red 表示的红黑树类似这样（新插入节点是 r2）： 12345 b3 /r1 \\ r2 平衡的调整过程如下： 1234567 红色节点左旋 b3 b3 / /r1 =&gt; r2 \\ / r2 r1 旋转后，Left-Right-Red 就变成了 Left-Left-Red，按照上面的处理即可。 4.2.3 Right-Right-RedRight-Right-Red 表示的红黑树类似这样（新插入节点是 r3）： 12345b1 \\ r2 \\ r3 平衡的调整过程如下： 1234567 红色节点左旋 父子节点反色 b1 \\ b2 r2 r2 =&gt; / \\ =&gt; / \\ \\ r1 r3 b1 b3 r3 做完处理后，父节点变成了红色，此时还可能会出现连续 2 个红色节点的情况。 这个和 Left-Left-Red 差不多，因为红黑树的对称的二叉树，按照和它一样的方式处理即可。 4.2.4 Right-Left-RedLeft-Right-Red 表示的红黑树类似这样（新插入节点是 r2）： 12345b1 \\ r3 /r2 平衡的调整过程如下： 1234567 红色节点右旋 b1 b1 \\ \\ r3 =&gt; r2 / \\r2 r3 旋转后，Right-Left-Red 就变成了 Right-Right-Red，按照上面的处理即可。 小结综合上述的 6 种情况，插入的伪代码如下： 1234567891011 public void insert(int val) { // 插入新节点 RBTNode h = new RBTNode(val); root = insertNode(root, h); // 调整树结构 balanceInsertion(h); // 根节点始终是黑色 setColor(root, BLACK);} 插入新节点后，调整红黑树结构以维持平衡： 123456789101112131415161718192021222324252627282930313233private void balanceInsertion(RBTNode h) { // 父节点是黑色时，不用调整 RBTNode p = parent(h); if (!isRed(p)) { return; } // 父节点是红色的 4 种情况 RBTNode gp = parent(p); if (p == gp.left) { // Left-Right-Red if (h == p.right) { rotateLeft(p); } // Left-Left-Red p = rotateRight(gp); } else { // Right-Left-Red if (h == p.left) { rotateRight(p); } // Right-Right-Red p = rotateLeft(gp); } // 父子节点反色 setColor(p, RED); setColor(p.left, BLACK); setColor(p.right, BLACK); // 父节点递归往上处理 balanceInsertion(p);} 另外，红黑树根节点始终黑色的，但是插入调整往上递归时，有可能把根节点变成红色了。 所以在最终的插入完成后，一般都要将根节点的颜色设置成黑色。 4.3 删除红黑树的删除大致可以分为几个步骤： 替代删除节点：寻找替代当前节点的节点，如果没有，就直接删除当前节点 删除平衡调整：删除前先调整树结构，保证删除节点后，红黑树的结构依旧是稳定的 真正删除节点 下面详细说明这几个步骤。 4.3.1 替代删除节点替换删除节点，是 BST 树删除都要做的事情，因为要保证 BST 树的有序性。 红黑树也是 BST 树，所以一开始也是要寻找替代的节点： 12345删除 r1 叶子节点 没有替代 b2 b2 / \\ =&gt; / \\ r1 r3 r1 r3 12345删除 b2 内部单子节点 b2 和前继 r1 交换 b2 b1 / =&gt; / r1 r2 12345删除 b2 内部单子节点 b2 和后继 r3 交换 b2 b3 \\ =&gt; \\ r3 r2 1234567删除 b2 内部双子节点 b2 和后继 r3 交换 b2 b3 / \\ / \\ b1 b4 =&gt; b1 b4 / / r3 r2 除删除叶子节点外，其余情况都使用前继/后继节点替换。 4.3.2 删除平衡调整红黑树是由 B-树演化而来的，所以可以参考 B-树的删除平衡调整。 B-树的删除平衡调整可以分为 3 种情况： 当前节点元素充足，可以直接删除，且不需要调整树结构 当前节点元素不足，兄弟节点有多余元素，从兄弟节点借一个元素 当前节点元素不足，兄弟节点也不能借，就将父节点下溢，合并父子节点为新节点 红黑树和 B-树是对应的，红黑树的平衡调整也可以分为这 3 种情况。 4.3.2.1 红色节点直接删除当被删除的 B-树节点元素充足时，可以直接删除，不用调整： 1234 无需调整树结构 ___ ___ ___ remove 1 ___ ___ ___ | 1 | 2 | 3 | =&gt; | 2 | 3 | | 这种情况对应到红黑树就是： 删除节点是 1 个黑色节点 + 1/2 个红色节点 删除红黑树的红色节点时，可以直接删除，不用调整树结构 但不能是删除黑色节点，因为删除黑色节点相当于删除了所有相关节点，情况不同 删除红色节点的过程就类似这样： 12345删除红色节点 删除后 b2 remove r1 b2 / \\ =&gt; \\ r1 r3 r3 12345删除红色节点 删除后 b2 remove r1 / =&gt; b2 r1 删除红色节点的情况就是直接删除即可，也不需要调整结构，比较简单。 4.3.2.2 从兄弟借红色节点当被删除的 B-树节点元素不足时，会先从兄弟节点借一个元素： 123456789 左旋，从右兄弟借一个元素 ___ ___ ___ ___ ___ ___ | 2 | | | | 3 | | | | | ------------------- remove 1 ------------------- | | =&gt; | | ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ | 1 | | | | 3 | 5 | | | 2 | | | | 5 | | | 这种情况对应到红黑树就是： 删除节点是黑色节点，而兄弟则是 1 个黑色节点 + 1/2 个红色节点（子节点） 删除黑色节点时，如果兄弟附带有红色节点（即红色子节点），就可以从兄弟那边借一个红色节点 这种情况的处理过程就类似这样： 12345 b2 borrow right b3 remove b1 b3 / \\ =&gt; / \\ =&gt; / \\b1 b3 b2 b5 b2 b5 \\ / r5 b1 12345 b2 rotate right b2 / \\ =&gt; / \\ =&gt; 按照上面的处理b1 b5 b1 b3 / \\ r3 r5 先从兄弟借一个红色节点，再删除元素，这样就不会损坏树平衡。不过， 当兄弟附带有红色子节点时才可以借，所以兄弟必须是黑色节点才行 如果兄弟是红色节点，需要先旋转一次，将兄弟变成黑色才行，类似这样： 123456789 删除1 6 左旋 b2 b6 / \\ rotate left / \\b1 r6 =&gt; r2 b7 =&gt; 按照上面的处理 / \\ / \\ b4 b7 b1 b4 / \\ / \\ r3 r5 r3 r5 旋转以后，删除节点的兄弟由红色 r6 变成黑色 b4，此时就能从兄弟借元素了。 4.3.2.3 父节点下溢合并当被删除的 B-树节点元素不足，并且兄弟也没办法借时，父节点就会产生下溢，并和左右子节点合并： 123456789 父节点下溢，合并父子节点 ___ ___ ___ | 2 | | | | ------------------- remove 1 ___ ___ ___ | | =&gt; | 2 | 3 | | ___ ___ ___ ___ ___ ___ | 1 | | | | 3 | | | 这种情况对应到红黑树就是： 删除节点是黑色节点，并且兄弟也只是 1 个黑色节点 删除黑色节点时，如果兄弟没附带有红色节点（即红色子节点），就需要父节点下溢，和子节点合并 这种情况的处理过程就类似这样： 12345 父节点下溢 b2 remove 1 b2 / \\ =&gt; \\b1 b3 r3 不过由于父节点下溢了，就可能会产生新的不平衡，比如这样： 1234567 要删除1 2变黑，3变红 删除1 b4 b4 b4 / \\ merge b2 / \\ remove r1 / \\ b2 b6 =&gt; b2 r6 =&gt; b2 b6 / \\ / \\ / \\ / \\ \\ / \\b1 b3 b5 b7 r1 r3 b5 b7 r3 b5 b7 假如这样删除 1 节点，那么最后左子树的黑高是 2，而右子树的黑高是 3，这其实是不平衡的结构。 和 B-树的一样，对于这种情况，就需要递归调整不平衡结构，将父节点当作删除节点再往上递归调整： 1234567 要删除1 2变黑，3变红 4变黑，6变红 删除1 b4 b4 b4 b4 / \\ merge b2 / \\ merge b4 / \\ remove r1 / \\ b2 b6 =&gt; b2 r6 =&gt; b2 r6 =&gt; b2 r6 / \\ / \\ / \\ / \\ / \\ / \\ \\ / \\b1 b3 b5 b7 r1 r3 b5 b7 r1 r3 b5 b7 r3 b5 b7 按照这种方式一直往上递归，直到结构平衡或者抵达根节点为止。 为了避免产生级联下溢，应该优先选择红色父节点下溢 所以，如果父节点有红色节点（即兄弟是红色），先将红色节点转到删除节点这边，然后再操作： 1234567 要删除2 6左旋 b4 b6 / \\ rotate left / \\b2 r6 =&gt; r4 b7 =&gt; 按照上面的处理 / \\ / \\ b5 b7 b2 b5 旋转过后，删除节点的父节点由黑色 b4 变成了红色 r4，这样就不会产生级联下溢了。 4.3.3 真正删除节点删除平衡调整完成后，就开始真正地删除节点了。 由于第 1 步使用后继节点替代了删除节点，所以最后被删除节点的结构是很简单的： 被删除节点至多只有 1 个子节点 直接删除节点，然后返回它的非空子节点即可 最后的删除节点过程类似这样： 12345删除 b2 节点 返回非空子节点 b2 remove b2 / =&gt; r1 r1 12345删除 b2 节点 返回非空子节点 b2 remove b2 \\ =&gt; r3 r3 1234删除 b2 节点 返回非空子节点 remove b2 b2 =&gt; nil 最后的删除节点最简单，难的是前面的删除平衡调整。 小结提取“从兄弟借红节点”和“父节点下溢合并”的公共行为： 删除节点的兄弟是红色，就先将红色节点转到删除节点这一边 然后再根据上面说明的几种情况，删除的伪代码类似这样： 123456789101112131415161718public void remove(int val) { RBTNode h = get(root, val); if (h == null) { return; } // 替换节点（前继/后继） h = swapReplacer(h); // 先调整树结构 balanceDeletion(h); // 真正删除节点 removeNode(h); // 根节点始终是黑色 setColor(root, BLACK);} 删除前调整树平衡： 12345678910111213141516171819202122232425262728private void balanceDeletion(RBTNode h) { // 1. 删除红色节点，不需要调整 RBTNode p = parent(h); if (p == null || isRed(h)) { return; } // 2. 兄弟是红色，先转成黑色 RBTNode s = sibling(h); if (isRed(s)) { rotateOpposite(h); s = sibling(h); } // 3. 看兄弟是否有红色节点可以借一个 if (hasRedChild(s)) { borrowSiblingRed(h); return; } // 4. 兄弟没有红色，父节点下溢合并 boolean balanced = underflow(h); // 视情况往上递归调整 if (!balanced) { balanceDeletion(p); }} 和插入一样，删除平衡调整后，最后也要将根节点重新设为黑色。 总结红黑树的定义： 红黑树是一棵只有红色节点和黑色节点的平衡二叉搜索树 每个结点或是红色的，或是黑色的 根节点是黑色的 每个叶结点（NIL）是黑色的 如果一个节点是红色的，则它的两个儿子都是黑色的 对于每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑色结点 红黑树并不是“高度”平衡的二叉树，而是“黑高”平衡的二叉树 红黑树的来源： 红黑树实际上是由 4 阶 B-树演化而来的，是互相对应的 因为平时常用红色和黑色来作图，所以才称之为红黑树 红黑树的优略势： 相比于 BST 树，红黑树结构更加平衡，稳定性更好 相比于 AVL 树，红黑树在插入和删除过程中的旋转更少 相比于 B-树，红黑树结构更简单，空间利用率更高 红黑树的适用场景： 频繁的插入、删除，采用红黑树 频繁的搜索，采用 AVL 树 红黑树的检索： 采用的二分查找 红黑树的插入： 新节点总是在叶子节点处插入 新节点的颜色总是红色 插入新节点后可能出现的情况有 6 种 父节点是黑色 新插入节点是左子节点 新插入节点是右子节点 父节点是红色 父节点是左子节点 新插入节点是左子节点 新插入节点是右子节点 父节点是右子节点 新插入节点是左子节点 新插入节点是右子节点 父节点是黑色的 2 种情况，不影响红黑树的“黑高”平衡，所以不需要调整 只有父节点是红色的 4 种情况需要调整红黑树结构，以维持平衡 红黑树的删除： 通用的删除步骤 替代删除节点：寻找替代当前节点的后继节点，如果没有，就直接删除当前节点 删除平衡调整：删除前先调整树结构，保证删除节点后，红黑树的结构依旧是稳定的 真正删除节点 删除平衡调整 红色节点直接删除 从兄弟借红色节点 父节点下溢合并 参考 《算法》（第4版） 《数据结构与算法分析（第三版）》 https://blog.csdn.net/zzy893037505/article/details/115177354 http://events.jianshu.io/p/48331a5a11f4 https://wenku.baidu.com/view/225ca967cb50ad02de80d4d8d15abe23492f037b.html?_wkts_=1675956297191 https://en.wikipedia.org/wiki/Red%E2%80%93black_tree https://www.cnblogs.com/nullzx/p/6192984.html https://blog.csdn.net/Sun_TTTT/article/details/65445754 https://blog.csdn.net/cy973071263/article/details/122543826 附录红黑树接口12345678910111213141516171819202122232425262728293031/** * 红黑树接口 * * @author weijiaduo * @since 2022/12/21 */public interface RBTree { /** * 获取指定值的节点 * * @param val 指定值 * @return val对应的节点/null */ Integer get(int val); /** * 插入新节点 * * @param val 新值 */ void insert(int val); /** * 删除指定值的节点 * * @param val 指定值 */ void remove(int val);} 红黑树实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410/** * 双偏向（Both-Leaning）红黑树（2-3-4树） * &lt;p&gt; * 1. 红色节点可以出现在左右两边 * * @author weijiaduo * @since 2023/2/2 */public class BLRBTree implements RBTree { /** * 红色 */ private static final boolean RED = true; /** * 黑色 */ private static final boolean BLACK = false; /** * 根节点 */ private RBTNode root; @Override public Integer get(int val) { RBTNode node = get(root, val); return node != null ? node.val : null; } /** * 查找指定值对应的节点 * * @param h 当前节点 * @param val 指定值 * @return 指定值的节点 */ private RBTNode get(RBTNode h, int val) { // 没有找到 if (h == null) { return null; } // 找到对应的节点 if (h.val == val) { return h; } if (h.val &gt; val) { return get(h.left, val); } else { return get(h.right, val); } } @Override public void insert(int val) { if (get(val) != null) { return; } // 插入新节点 RBTNode h = new RBTNode(val); root = insertNode(root, h); // 调整树结构 balanceInsertion(h); // 根节点始终是黑色 setColor(root, BLACK); } /** * 插入新节点 * * @param h 当前节点 * @param newNode 新节点 * @return 新当前节点 */ private RBTNode insertNode(RBTNode h, RBTNode newNode) { if (h == null) { return newNode; } if (newNode.val &lt; h.val) { h.left = insertNode(h.left, newNode); h.left.parent = h; } else { h.right = insertNode(h.right, newNode); h.right.parent = h; } return h; } /** * 修正插入后的红黑树结构 * * @param h 新插入的节点 */ private void balanceInsertion(RBTNode h) { // 父节点是黑色时，不用调整 RBTNode p = h.parent; if (!isRed(p)) { return; } // 父节点是红色 RBTNode gp = p.parent; if (p == gp.left) { // LR 双红节点 if (h == p.right) { rotateLeft(p); } // LL 双红节点 p = rotateRight(gp); } else { // RL 双红节点 if (h == p.left) { rotateRight(p); } // RR 双红节点 p = rotateLeft(gp); } // 父子反色 setColor(p, RED); setColor(p.left, BLACK); setColor(p.right, BLACK); // 递归往上处理 balanceInsertion(p); } @Override public void remove(int val) { RBTNode h = get(root, val); if (h == null) { return; } // 替换节点（后继/前继） h = swapReplacer(h); // 先调整树结构 balanceDeletion(h); // 真正删除节点 removeNode(h); // 根节点始终是黑色 setColor(root, BLACK); } /** * 交换当前节点到后继/前继节点 * * @param h 当前节点 * @return 替换节点 */ private RBTNode swapReplacer(RBTNode h) { RBTNode replacer = h; if (h.left != null &amp;&amp; h.right != null) { replacer = h.right; while (replacer.left != null) { replacer = replacer.left; } } else if (h.right != null) { replacer = h.right; } else if (h.left != null) { replacer = h.left; } // TODO: 简单点，仅替换值，节点不变 int val = h.val; h.val = replacer.val; replacer.val = val; return replacer; } /** * 移除节点（后继最小值/前继最大值） * * @param h 被移除节点，确保没有孩子或只有1个孩子 */ private void removeNode(RBTNode h) { RBTNode p = h.parent; if (p == null) { if (h.left == null) { root = h.right; } else { root = h.left; } } else { if (h == p.left) { // 后继最小值 p.left = h.right; } else { // 前继最大值 p.right = h.left; } } h.parent = h.left = h.right = null; } /** * 修正删除节点前的红黑树结构 * * @param h 被删除节点 */ private void balanceDeletion(RBTNode h) { // 删除红色节点，不影响平衡性 RBTNode p = h.parent; if (p == null || isRed(h)) { return; } // 删除黑色节点 if (h == p.left) { // 1. 兄弟是红色，先转成黑色 RBTNode s = p.right; if (isRed(s)) { rotateLeft(p); } // 2. 从兄弟借红色孩子 if (borrowRight(h)) { return; } // 3. 父节点下溢合并 if (underflow(h)) { return; } } else { // 镜像处理 RBTNode s = p.left; if (isRed(s)) { rotateRight(p); } if (borrowLeft(h)) { return; } if (underflow(h)) { return; } } // 递归向上调整 balanceDeletion(p); } /** * 父节点下溢，父子节点合并 * * @param h 当前节点 * @return true下溢后已平衡/false下溢后未平衡 */ private boolean underflow(RBTNode h) { RBTNode p = h.parent; RBTNode s; if (p.left == h) { s = p.right; } else { s = p.left; } boolean balanced = isRed(p); setColor(p, BLACK); setColor(s, RED); return balanced; } /** * 从右兄弟借一个红色节点过来 * * @param h 当前节点 * @return true借用成功/false借用失败 */ private boolean borrowRight(RBTNode h) { RBTNode p = h.parent; RBTNode s = p.right; RBTNode sl = s.left, sr = s.right; if (!isRed(sl) &amp;&amp; !isRed(sr)) { // 没有红色节点可借 return false; } // 远侄子是黑色，近侄子是红色 if (!isRed(sr)) { rotateRight(s); } // 远侄子是红色 p = rotateLeft(p); setColor(p.left, BLACK); setColor(p.right, BLACK); return true; } /** * 从左兄弟借一个红色节点过来 * * @param h 当前节点 * @return true借用成功/false借用失败 */ private boolean borrowLeft(RBTNode h) { RBTNode p = h.parent; RBTNode s = p.left; RBTNode sl = s.left, sr = s.right; if (!isRed(sl) &amp;&amp; !isRed(sr)) { // 没有红色节点可借 return false; } // 远侄子是黑色，近侄子是红色 if (!isRed(sl)) { rotateLeft(s); } // 远侄子是红色 p = rotateRight(p); setColor(p.left, BLACK); setColor(p.right, BLACK); return true; } /** * 左旋，将红色节点转到左边 * * @param h 当前节点 * @return 新当前节点 */ private RBTNode rotateLeft(RBTNode h) { if (h == null || h.right == null) { return h; } RBTNode p = h.parent; RBTNode r = h.right; r.parent = p; if (p == null) { root = r; r.color = BLACK; } else { r.color = p.color; if (h == p.left) { p.left = r; } else { p.right = r; } } h.right = r.left; if (h.right != null) { h.right.parent = h; } h.parent = r; r.left = h; h.color = RED; return r; } /** * 右旋，将红色节点转到右边 * * @param h 当前节点 * @return 新当前节点 */ private RBTNode rotateRight(RBTNode h) { if (h == null || h.left == null) { return h; } RBTNode p = h.parent; RBTNode l = h.left; l.parent = p; if (p == null) { root = l; l.color = BLACK; } else { l.color = p.color; if (h == p.left) { p.left = l; } else { p.right = l; } } h.left = l.right; if (h.left != null) { h.left.parent = h; } h.parent = l; l.right = h; h.color = RED; return l; } /** * 设置节点颜色 * * @param h 节点 * @param color 颜色 */ private void setColor(RBTNode h, boolean color) { if (h != null) { h.color = color; } } /** * 是否是红色 * * @param h 节点 * @return true/false */ private boolean isRed(RBTNode h) { return h != null &amp;&amp; h.color == RED; }}","link":"/datastructure/tree/red_black_tree/"},{"title":"B+树","text":"B+树一、什么是 B+ 树？B+ 树是 B-树的变种。 其结构类似这样： 123456789101112 ____ ___ ___ | 24 | | | | -------------------------------------------------------- | | ____ ____ ___ ____ ___ ___ | 15 | 20 | | | 33 | | | | | -------------------------------------------- ----------------------- | | | | | ____ ____ ___ ____ ____ ___ ____ ____ ___ ____ ____ ___ ____ ____ ___| 10 | 12 | | &lt;=&gt; | 15 | 18 | | &lt;=&gt; | 20 | 21 | | &lt;=&gt; | 30 | 31 | | &lt;=&gt; | 34 | 38 | | B+ 树和 B-树的主要区别在于： 内部节点只是索引，只有叶子节点才保存数据 叶子节点之间构成了一条双向链表 叶子节点包含了所有关键码值，而内部节点仅包含用于索引的关键码值 B+ 树和 B-树的区别主要在于叶子节点，它们的内部节点基本是一样的。 二、为什么用 B+ 树？ B+ 树特别适合范围查询，因为叶子节点之间是双向连接，可以顺着双向链表寻找数据 B+ 树只会在叶子节点上插入和删除数据，相对于 B-树来说，实现会简单一些 三、如何实现 B+ 树？和 B-树差不多，B+ 树也包含了几种操作： 检索元素：在树中搜索指定的元素 插入元素：往树中插入新的元素 删除元素：从树中删除指定的元素 其中，插入和删除会对 B+ 树的结构产生影响，稍微麻烦。 3.1 检索元素B+ 树的检索和 B-树的差不多： 基于多路查找，找到对应的节点 需要一直找到叶子节点，因为只有叶子节点有数据 比如，上面的 B+ 树中，要寻找元素 20，它的搜索路线就是： 123456789101112 ____ ___ ___ | 24 | | | | -------------------------------------------------------- | | ____ ____ ___ ____ ___ ___ | | 20 | | | | | | | | -------------------------------------------- ----------------------- | | | | | ____ ____ ___ ____ ____ ___ ____ ____ ___ ____ ____ ___ ____ ____ ___| | | | &lt;=&gt; | | | | &lt;=&gt; | 20 | | | &lt;=&gt; | | | | &lt;=&gt; | | | | 注意：虽然内部节点也有 20 这个关键码值，但是它没有保存数据，仅仅是作为索引，所以还是要一直搜索到叶子节点。 这个检索过程对应的伪代码： 123456789101112131415161718/**- 检索元素 -*/private V get(BPTNode&lt;K, V&gt; root, K key) { int index = root.findIndex(key); if (root.isLeaf()) { // 叶子节点 if (key.equals(root.getKey(index))) { // 找到 key 对应的节点 BPTLeaf&lt;K, V&gt; leaf = (BPTLeaf&lt;K, V&gt;) root; return leaf.getValue(index); } else { // 没有找到对应的节点 return null; } } else { // 内部节点，往子树继续找 key 对应的节点 return get(root.getChild(index), key); }} B+ 树的检索要一直到达叶子节点才行。 3.2 插入元素B+ 树和 B-树一样： 插入节点总是在叶子节点插入 B-树节点的分裂实际只有 2 种情况，但是 B+ 树的叶子节点分裂会有点特殊： 叶子节点分裂后，新的左右叶子节点会保留所有的关键码值 分裂出来的父节点的关键码值，等于右叶子节点中的最小关键码值 这是因为，B+ 树的数据都在叶子中保存，不能将其上溢到父节点中，要保持这种规则。 由于 B+ 树叶子节点和内部节点的分裂不同，所以会分为 4 种情况： 叶子节点空间足够，直接插入元素 叶子节点空间不足，1 个节点分裂成 3 个节点，执行上溢操作 内部节点空间足够，直接插入元素 内部节点空间不足，1 个节点分裂成 3 个节点，执行上溢操作 这 4 种情况的效果如下。 3.2.1 叶子节点-直接插入当叶子节点空间足够时，可以直接插入新元素： 1234567891011121314 ____ ____ ___ | 12 | | | | 插入 20 v ____ ____ ___ | 12 | 20 | | | 插入 9 v ____ ____ ____ | 9 | 12 | 20 | 此时的叶子节点空间足够时，直接插入元素就行了。 3.2.2 叶子节点-分裂上溢当叶子节点空间不足时，再插入新元素，会导致节点分裂，产生上溢： 12345678910111213 ___ ____ ____ | 9 | 12 | 20 | | 插入 25 v ____ ___ ___ | 20 | | | | --------------------- | | ___ ____ ___ ____ ____ ____ | 9 | 12 | | &lt;=&gt; | 20 | 25 | | 节点空间不足以插入新元素，所以 1 个节点会分裂成 3 个节点。其中， 叶子分裂后，新的叶子节点会保留所有的关键码值 [9, 12]、[20, 25] 父节点的关键码值，等于右叶子节点的最小关键码值 [20] 叶子节点之间，还需要补充上双向链接 在叶子节点分裂上溢这一点上，B+ 树和 B-树有所不同。 3.2.3 内部节点-直接插入为了保持 B+ 树的高度平衡，叶子节点会将分裂后的父节点，往上插入之前的父节点： 12345678910111213141516171819 ____ ___ ___ | 20 | | | | ------------------------ | | ___ ____ ____ ____ ____ ____ | 9 | 12 | 18 | &lt;=&gt; | 20 | 25 | | | 插入 10 v ____ ____ ___ | 12 | 20 | | | ----------------------------------------------- | | | ___ ____ ____ ____ ____ ____ ____ ____ ____ | 9 | 10 | | &lt;=&gt; | 12 | 18 | | &lt;=&gt; | 20 | 25 | | 左子节点 [9, 12, 18] 插入新元素 10 后会产生上溢，12 会上溢父节点 [20] 中。 因为内部节点 [20] 的空间足够，所以 12 直接插入即可。 3.2.4 内部节点-分裂上溢节点上溢后，如果父节点空间也满了，那么父节点也会出现分裂上溢： 123456789101112131415161718192021222324 ____ ____ ____ | 12 | 20 | 45 | | ------------------------------------------------------------------ | | | | ___ ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ | 8 | 9 | 10 | | 12 | 18 | | | 20 | 25 | | | 45 | 85 | | | 插入 11 v ____ ____ ____ | 20 | | | | ------------------------------------------------------------ | | ____ ____ ___ ____ ___ ___ | 10 | 12 | | | 45 | | | | | ---------------------------------------------- ------------------------- | | | | | ___ ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____| 8 | 9 | | &lt;=&gt; | 10 | 11 | | &lt;=&gt; | 12 | 18 | | &lt;=&gt; | 20 | 25 | | &lt;=&gt; | 45 | 85 | | 插入元素 11 之后，会传递性地导致节点 [8, 9, 10] 和节点 [12, 20, 45] 都产生分裂上溢。 注意，内部节点的分裂和叶子节点是不同的： 内部节点分裂后，子节点不会出现和父节点一样的关键码值 新分裂父节点的关键码值，等于插入新元素后的中间关键码值 这种分裂上溢可以一直持续到根节点，最后可能会导致 B+ 树提升一层（如上）。 上述的 4 种情况，对应的伪代码差不多是这样： 1234567891011121314151617/**- 插入新元素 -*/private BPTNode&lt;K, V&gt; put(BPTNode&lt;K, V&gt; root, K key, V value) { int index = root.findIndex(key); if (root.isLeaf()) { // 叶子节点，有可能发生了分裂 BPTLeaf&lt;K, V&gt; leaf = (BPTLeaf&lt;K, V&gt;) root; return leaf.add(key, value); } else { // 内部节点，添加到子树的叶子节点中 BPTInternal&lt;K, V&gt; node = (BPTInternal&lt;K, V&gt;) root; BPTNode&lt;K, V&gt; child = node.getChild(index); child = put(child, key, value); // 添加到子树中，有可能发生了分裂 return node.overflow(index, child); }} 12345678910111213/**- 叶子节点的上溢 -*/public BPTNode&lt;K, V&gt; add(K key, V value) { int index = findIndex(key); // 1. 空间足够，可以直接插入新元素 if (!this.isFull()) { insertEntry(index + 1, new Entry&lt;&gt;(key, value)); return this; } // 2. 空间不足，需要分裂节点 return splitNodes(index, new Entry&lt;&gt;(key, value));} 12345678910111213/**- 内部节点的上溢 -*/public BPTNode&lt;K, V&gt; overflow(int index, BPTNode&lt;K, V&gt; node) { // 1. 当前空间足够，可以直接插入新节点 if (size + node.size() &lt; m) { for (Entry&lt;K, V&gt; entry : node.entries()) { insertEntry(++index, entry); } return this; } // 2. 当前空间不够，需要分裂成 3 个节点 return splitNodes(index, node);} 3.3 删除元素删除元素，和插入一样，由于叶子节点的特殊性，所以实际上会有 6 种情况： 叶子节点元素足够，直接删除 叶子节点元素不足，看兄弟节点是否可以借一个过来（和内部节点不同） 叶子节点兄弟节点不能借，那就和兄弟合并，删除父节点（和内部节点不同） 内部节点元素足够，直接删除 内部节点元素不足，看兄弟节点是否可以借一个过来（和叶子节点不同） 内部节点兄弟节点不能借，那就和兄弟合并，删除父节点（和叶子节点不同） 这几种情况如下。 3.3.1 叶子节点-直接删除如果是叶子节点，且删除元素后，元素数量仍然处于半满状态，则可以直接删除： 123456789101112131415161718 ____ ___ ___ | 20 | | | | ----------------------- | | ___ ____ ___ ____ ____ ____ | 9 | 12 | | &lt;=&gt; | 20 | 25 | | | 删除 20 v ____ ___ ___ | 20 | | | | ----------------------- | | ___ ____ ___ ____ ____ ____ | 9 | 12 | | &lt;=&gt; | 25 | | | 叶子节点 [20, 25] 删除 20 以后，元素数量依旧满足半满状态，则可以直接删除并返回。 注意：直接删除叶子节点元素 20 后，并不会改变父节点的关键码值 20。 3.3.2 叶子节点-从兄弟借如果删除元素后，元素数量少于一半，不满足要求，则先看一下兄弟节点能不能借个元素过来： 123456789101112131415161718 ____ ___ ___ | 20 | | | | ----------------------- | | ___ ____ ___ ____ ____ ____ | 9 | 12 | | &lt;=&gt; | 25 | | | | 删除 25 v ____ ___ ___ | 12 | | | | ----------------------- | | ___ ____ ___ ____ ____ ____ | 9 | | | &lt;=&gt; | 12 | | | 右子节点 [25] 删除 25 以后，元素数量不满足要求了，找兄弟节点 [9, 12] 借一个元素。 和 B-树的旋转不同，B+ 树叶子节点的借用是这样的： 叶子节点直接从兄弟节点借一个元素过来 同时还要更新叶子节点对应的父节点关键码值 删除 25 以后，除了借 12 过来，还要更新父节点的关键码值为 12。 上面是从左兄弟借，从右兄弟借也是一样的，要更新父节点的关键码值： 123456789101112131415161718 ____ ___ ___ | 20 | | | | ----------------------- | | ___ ____ ___ ____ ____ ____ | 9 | | | &lt;=&gt; | 20 | 25 | | | 删除 9 v ____ ___ ___ | 25 | | | | ----------------------- | | ____ ___ ___ ____ ____ ____ | 20 | | | &lt;=&gt; | 25 | | | 3.3.3 叶子节点-合并下溢如果兄弟节点借不了元素，那就将左子节点 + 右子节点合并在一起，并删除父节点元素： 12345678910111213 ____ ___ ___ | 25 | | | | ----------------------- | | ____ ___ ___ ____ ____ ____ | 20 | | | &lt;=&gt; | 30 | | | | 删除 30 v ____ ____ ___ | 20 | | | 注意：叶子节点的合并下溢，并不包括父节点元素值，只是左右叶子兄弟合并，因为内部节点不是数据节点。 3.3.4 内部节点-直接删除叶子节点合并下溢后，父节点需要删除对应的父节点元素，如果父节点空间足够，就可以直接删除： 123456789101112131415161718 ____ ____ ___ | 12 | 20 | | | ----------------------------------------------- | | | ___ ____ ____ ____ ____ ____ ____ ____ ____ | 9 | 10 | | &lt;=&gt; | 12 | 18 | | &lt;=&gt; | 20 | | | | 删除 20 v ____ ____ ___ | 12 | | | | ------------------------ | | ___ ____ ____ ____ ____ ___ | 9 | 10 | | &lt;=&gt; | 12 | 18 | | 删除 20 以后，会造成叶子节点合并下溢，父节点元素 20 被删除。 由于父节点 [12, 20] 空间足够，删除 20 后依旧满足要求，所以直接删除即可。 3.3.5 内部节点-从兄弟借如果内部节点删除时，发现空间不足，则先考虑从兄弟节点借一个元素： 12345678910111213141516171819202122232425262728 ____ ____ ____ | 20 | | | | ------------------------------------------------------------ | | ____ ____ ___ ____ ___ ___ | 10 | 12 | | | 45 | | | | | ---------------------------------------------- ------------------------- | | | | | ___ ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____| 8 | 9 | | &lt;=&gt; | 10 | | | &lt;=&gt; | 12 | 18 | | &lt;=&gt; | 20 | 25 | | &lt;=&gt; | 85 | | | | 删除 85 v ____ ____ ____ | 12 | | | | ----------------------------------------------- | | ____ ____ ___ ____ ___ ___ | 10 | | | | 20 | | | | | ------------------------ ------------------------ | | | | ___ ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ | 8 | 9 | | &lt;=&gt; | 10 | | | &lt;=&gt; | 12 | 18 | | &lt;=&gt; | 20 | 25 | | 删除元素 85，会造成叶子节点 [20, 25]、[85] 合并，并删除父节点元素 45。 但是内部节点 [45] 由于空间不足，就需要从兄弟节点 [10, 12] 借一个元素过来才行。 不过，内部节点的借用和叶子节点的借用不同： 内部节点借用，实际上是旋转操作，将兄弟节点旋到父节点，父节点旋到当前节点 上面借用的元素 12，实际会旋转到父节点，然后父节点 20 再旋转到右子节点中。 3.3.6 内部节点-合并下溢如果内部节点的兄弟节点借不了元素，只能将父子节点进行合并，产生下溢： 1234567891011121314151617181920212223 ____ ____ ____ | 12 | | | | ----------------------------------------------- | | ____ ____ ___ ____ ___ ___ | 10 | | | | 20 | | | | | ------------------------ ------------------------ | | | | ___ ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____| 8 | 9 | | &lt;=&gt; | 10 | | | &lt;=&gt; | 12 | 18 | | &lt;=&gt; | 20 | | | | 删除 20 v ____ ____ ___ | 10 | 12 | | | ------------------------------------------- | | | ___ ___ ____ ____ ____ ____ ____ ____ ____ | 8 | 9 | | &lt;=&gt; | 10 | | | &lt;=&gt; | 12 | 18 | | 删除元素 20，会造成叶子节点 [12, 18]、[20] 合并，并删除父节点元素 20。 删除内部节点元素 20 时，由于其空间不足，且兄弟节点无法借用，只能合并父子节点，产生下溢了。 注意，内部节点的合并和叶子节点的合并不同： 内部节点的合并下溢，包括了 父节点 + 左子节点 + 右子节点 即上面的父子节点 [12]、[10]、[20] 会合并起来，形成一个新节点。 下溢和上溢一样，也可能会持续下溢，一直持续到根节点，最终导致树的层级下降。 上述情况的伪代码如下： 1234567891011121314151617181920/**- 删除元素 -*/private BPTNode&lt;K, V&gt; remove(BPTNode&lt;K, V&gt; root, K key) { int index = root.findIndex(key); if (root.isLeaf()) { BPTLeaf&lt;K, V&gt; leaf = (BPTLeaf&lt;K, V&gt;) root; if (key.equals(root.getKey(index))) { // 找到对应节点后移除元素 return leaf.delete(index); } else { // 没找到对应节点，直接返回 return leaf; } } else { BPTInternal&lt;K, V&gt; node = (BPTInternal&lt;K, V&gt;) root; // 在子树内递归移除元素 remove(node.getChild(index), key); // 移除后可能需要父节点下溢 return node.underflow(index); }} 123456789101112131415161718/**- 叶子节点的下溢 -*/public BPTNode&lt;K, V&gt; delete(K key, V value) { int index = findIndex(key); // 1. 空间足够，可以直接删除元素 if (this.isEnough()) { removeEntry(index); return this; } // 2. 从兄弟节点借一个元素 if (borrowLeft(index) || borrowRight(index)) { return this; } // 3. 合并左右兄弟节点 return mergeNodes(index);} 12345678910111213141516/**- 内部节点的下溢 -*/public BPTNode&lt;K, V&gt; underflow(int index) { // 1. 空间足够，可以直接删除元素 if (this.isEnough()) { removeEntry(index); return this; } // 2. 从兄弟节点借一个元素 if (borrowLeft(index) || borrowRight(index)) { return this; } // 3. 合并父元素 + 左右子节点 return mergeNodes(index);} 总结 性质 内部节点只是索引，只有叶子节点才保存数据 叶子节点之间构成了一条双向链表 叶子节点包含了所有关键码值，而内部节点仅包含用于索引的关键码值 检索 多路查找：一直找到叶子节点 插入 叶子节点空间足够，直接插入 叶子节点空间不足，分裂上溢（父节点关键码值等于右叶子节点的最小关键码值） 内部节点空间足够，直接插入 内部节点空间不足，分裂上溢（节点的关键码值都不一样） 删除 叶子节点空间足够，直接删除 叶子节点空间不足，从兄弟借（移动） 叶子节点兄弟节点无法借用，合并左右叶子节点，删除父元素，执行下溢（仅合并兄弟叶子节点） 内部节点空间足够，直接删除 内部节点空间不足，从兄弟借（旋转） 内部节点兄弟节点无法借用，合并父子节点，执行下溢（合并父子节点） 参考 《数据结构与算法分析（第三版）》 https://www.cnblogs.com/nullzx/p/8729425.html 附录B+ 树接口1234567891011121314151617181920212223242526272829303132/** * B+ 树接口定义 * * @author weijiaduo * @since 2023/1/9 */public interface BPTree&lt;K extends Comparable&lt;K&gt;, V&gt; { /** * 查找指定 key 的值 * * @param key key * @return value */ V get(K key); /** * 添加指定 key-value 的节点 * * @param key key * @param value value */ void put(K key, V value); /** * 删除指定 key 的节点 * * @param key key */ void remove(K key);} B+ 树实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143/** * B+ 树实现类 * * @author weijiaduo * @since 2023/1/9 */public class BPTreeImpl&lt;K extends Comparable&lt;K&gt;, V&gt; implements BPTree&lt;K, V&gt; { /** * 根节点 */ private BPTNode&lt;K, V&gt; root; /** * m 阶 B+ 树 */ private final int m; /** * B+树构造器 * * @param m 指定 m 阶 B+ 树 */ public BPTreeImpl(int m) { this.m = m; } @Override public V get(K key) { return get(root, key); } /** * 从当前节点开始找指定 key 的值 * * @param root 当前根节点 * @param key key * @return value */ private V get(BPTNode&lt;K, V&gt; root, K key) { if (root == null) { return null; } // 查找当前 key 所在的位置 int index = root.findIndex(key); if (root.isLeaf()) { if (key.equals(root.getKey(index))) { BPTLeaf&lt;K, V&gt; leaf = (BPTLeaf&lt;K, V&gt;) root; return leaf.getValue(index); } else { return null; } } else { // 往子树继续找 key 对应的节点 return get(root.getChild(index), key); } } @Override public void put(K key, V value) { root = put(root, key, value); } /** * 在当前树内添加指定的 key-value * * @param root 当前根节点 * @param key key * @param value value * @return 新的根节点 */ private BPTNode&lt;K, V&gt; put(BPTNode&lt;K, V&gt; root, K key, V value) { // 1. 整棵树为空时，插入新节点 if (root == null) { BPTLeaf&lt;K, V&gt; leaf = new BPTLeaf&lt;&gt;(m); return leaf.add(key, value); } int index = root.findIndex(key); if (root.isLeaf()) { // 2. 叶子节点 BPTLeaf&lt;K, V&gt; leaf = (BPTLeaf&lt;K, V&gt;) root; // 验证是否已存在，存在则只需更新值 if (key.equals(leaf.getKey(index))) { leaf.setValue(index, value); return leaf; } // 添加到叶子节点中，有可能发生了分裂 return leaf.add(key, value); } else { // 3. 内部节点，添加到子树的叶子节点中 BPTInternal&lt;K, V&gt; node = (BPTInternal&lt;K, V&gt;) root; BPTNode&lt;K, V&gt; child = node.getChild(index); child = put(child, key, value); // 添加到子树中，有可能发生了分裂 return node.overflow(index, child); } } @Override public void remove(K key) { root = remove(root, key); if (root != null &amp;&amp; root.isEmpty()) { // 树的高度下降 root = root.firstChild(); } } /** * 在当前树内删除指定 key 的节点 * * @param root 当前根节点 * @param key key * @return 新的根节点 */ private BPTNode&lt;K, V&gt; remove(BPTNode&lt;K, V&gt; root, K key) { if (root == null) { return null; } int index = root.findIndex(key); if (root.isLeaf()) { BPTLeaf&lt;K, V&gt; leaf = (BPTLeaf&lt;K, V&gt;) root; if (key.equals(root.getKey(index))) { // 找到对应节点后移除元素 return leaf.delete(index); } else { // 没找到对应节点，直接返回 return leaf; } } else { BPTInternal&lt;K, V&gt; node = (BPTInternal&lt;K, V&gt;) root; // 在子树内递归移除元素 remove(node.getChild(index), key); // 移除后可能需要父节点下溢 return node.underflow(index); } }} B+ 节点定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363/** * B+树基类节点 * * @author weijiaduo * @since 2023/1/10 */public abstract class BPTNode&lt;K extends Comparable&lt;K&gt;, V&gt; { /** * m 阶 B 树 */ protected final int m; /** * 节点元素阈值 */ protected final int threshold; /** * 节点元素数组 * &lt;p&gt; * 元素的第 0 位始终是一个占位元素，专门用于存放最左子节点 * &lt;p&gt; * 所以一个节点能拥有的元素个数最多是 m - 1 */ protected final Object[] elements; /** * 实际元素数量 * &lt;p&gt; * 取值范围是 [0, m - 1] */ protected int size; public BPTNode(int m) { this.m = m; this.threshold = half(m); elements = new Object[m]; // 最左元素占位，用于存放最左子节点指针 elements[0] = new Entry&lt;K, V&gt;(null, null); size = 0; } /** * @return 元素数量 */ public int size() { return size; } /** * 半数阈值 ceil(m / 2) - 1 * * @param m 当前值 * @return 半数阈值 */ protected int half(int m) { return (m + 1) / 2 - 1; } /** * 是否已满 * * @return true已满/false未满 */ public boolean isFull() { return size == m - 1; } /** * 是否为空 * * @return true为空/false非空 */ public boolean isEmpty() { return size == 0; } /** * 节点是否合法 * &lt;p&gt; * 节点的元素数量要求大于等于阈值 * * @return true合法/false非法 */ public boolean isLegal() { return size &gt;= threshold; } /** * 是否可借用元素给别的节点 * &lt;p&gt; * 当节点的元素数量大于阈值时，才可以外借元素 * * @return true可借用/false不可借用 */ protected boolean canBorrow() { return size &gt; threshold; } /** * 是否是叶子节点 * &lt;p&gt; * 没有任何一个非空子节点时才是叶子节点 * * @return true叶子节点/false内部节点 */ public abstract boolean isLeaf(); /** * 获取所有的元素 * * @return 元素集合 */ protected List&lt;Entry&lt;K, V&gt;&gt; entries() { List&lt;Entry&lt;K, V&gt;&gt; entries = new ArrayList&lt;&gt;(size); // 元素从索引 1 开始 for (int i = 1; i &lt;= size; i++) { entries.add(getEntry(i)); } return entries; } /** * 获取所有的 key * * @return key 集合 */ public List&lt;K&gt; keys() { List&lt;K&gt; keys = new ArrayList&lt;&gt;(size); // 元素从索引 1 开始 for (int i = 1; i &lt;= size; i++) { keys.add(getKey(i)); } return keys; } /** * 获取指定位置的 key * * @param index 索引 * @return key */ public K getKey(int index) { return getEntry(index).key; } /** * 获取所有的子节点 * &lt;p&gt; * 注意：是所有可能的子节点，也包括了 null 子节点 * * @return 子节点集合 */ public List&lt;BPTNode&lt;K, V&gt;&gt; children() { List&lt;BPTNode&lt;K, V&gt;&gt; children = new ArrayList&lt;&gt;(size + 1); // 子节点从索引 0 开始 for (int i = 0; i &lt;= size; i++) { children.add(getChild(i)); } return children; } /** * 返回第一个子节点 * &lt;p&gt; * 注意：不是第一个非空子节点，而是第 1 个元素的左子节点 * * @return 第一个子节点 */ public BPTNode&lt;K, V&gt; firstChild() { return getChild(0); } /** * 返回最后一个子节点 * &lt;p&gt; * 注意：不是最后一个非空子节点，而是最后 1 个元素的右子节点 * * @return 最后一个子节点 */ public BPTNode&lt;K, V&gt; lastChild() { return getChild(size); } /** * 获取指定位置的下一层子节点 * * @param index 指定位置 * @return 下一层子树根节点 */ public BPTNode&lt;K, V&gt; getChild(int index) { return getEntry(index).pointer; } /** * 更新指定位置的子节点 * * @param index 索引 * @param node 子节点 */ public void setChild(int index, BPTNode&lt;K, V&gt; node) { getEntry(index).pointer = node; } /** * 查找指定 key 的位置 * &lt;p&gt; * 返回最后一个小于等于 key 的位置 * * @param key key * @return key 的位置 */ public int findIndex(K key) { // 第 0 位是占位元素，还没算在内 return 1 + binaryle(keys(), key); } /** * 二分查找，返回最后一个小于等于 key 的位置 * * @param keys key 集合 * @param key 指定 key * @return 最后一个小于等于 key 的位置/-1 */ protected int binaryle(List&lt;K&gt; keys, K key) { int size = keys.size(); int l = 0, r = size - 1; while (l &lt;= r) { int m = l + (r - l) / 2; K k = keys.get(m); if (k.compareTo(key) &lt;= 0) { if (m == size - 1 || keys.get(m + 1).compareTo(key) &gt; 0) { return m; } l = m + 1; } else { r = m - 1; } } return -1; } /** * 获取指定位置的元素 * * @param index 索引 * @return 元素 */ protected Entry&lt;K, V&gt; getEntry(int index) { return (Entry&lt;K, V&gt;) elements[index]; } /** * 更新指定位置的元素 * &lt;p&gt; * 要求原始元素必须存在，否则应该使用 {@code insertEntry()} * * @param index 索引 * @param entry 元素 */ protected void setEntry(int index, Entry&lt;K, V&gt; entry) { Entry&lt;K, V&gt; oldEntry = getEntry(index); if (oldEntry == null || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } // 保留子节点，只替换元素的 key-value elements[index] = entry; entry.pointer = oldEntry.pointer; } /** * 追加新元素 * &lt;p&gt; * 此方法不会产生节点分裂，需要分裂时应调用 {@code overflow()} 方法 * * @param entry 元素 */ protected void addEntry(Entry&lt;K, V&gt; entry) { if (isFull()) { throw new IllegalStateException(String.format(&quot;size: %d&quot;, size)); } elements[++size] = entry; } /** * 插入新元素 * &lt;p&gt; * 此方法不会产生节点分裂，需要分裂时应调用 {@code overflow()} 方法 * * @param index 插入索引 * @param entry 元素 */ protected void insertEntry(int index, Entry&lt;K, V&gt; entry) { if (isFull() || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } if (size &gt;= index) { System.arraycopy(elements, index, elements, index + 1, size - index + 1); elements[index] = entry; size++; } else { elements[index] = entry; size = index; } } /** * 移除指定位置的元素 * * @param index 索引 */ protected void removeEntry(int index) { if (isEmpty() || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } if (size &gt; index) { System.arraycopy(elements, index + 1, elements, index, size - index); } elements[size] = null; size--; } @Override public String toString() { String[] s = new String[size]; for (int i = 1; i &lt;= size; i++) { s[i - 1] = elements[i].toString(); } return &quot;[&quot; + String.join(&quot;, &quot;, s) + &quot;]&quot;; } /** * 单个元素 */ public static class Entry&lt;K extends Comparable&lt;K&gt;, V&gt; { /** * key */ K key; /** * value */ V value; /** * 右子节点指针，即大于 key 的子树 */ BPTNode&lt;K, V&gt; pointer; public Entry(K key, V value) { this.key = key; this.value = value; pointer = null; } @Override public String toString() { return &quot;{&quot; + key + &quot; : &quot; + value + &quot;}&quot;; } }} B+ 树内部节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255/** * B+树内部节点 * * @author weijiaduo * @since 2023/1/10 */public class BPTInternal&lt;K extends Comparable&lt;K&gt;, V&gt; extends BPTNode&lt;K, V&gt; { public BPTInternal(int m) { super(m); } @Override public boolean isLeaf() { return false; } /** * 节点上溢处理 * &lt;p&gt; * 子树添加新元素后，可能会分裂成新节点，替代原有的子节点 * * @param index 索引 * @param node 新节点 * @return 添加后的当前节点 */ public BPTNode&lt;K, V&gt; overflow(int index, BPTNode&lt;K, V&gt; node) { if (node == null || node.isEmpty()) { return this; } // 还是旧节点，说明子节点没有上溢，无需处理 BPTNode&lt;K, V&gt; cur = getChild(index); if (cur == node) { return this; } // 1. 当前空间足够，可以直接插入新节点 if (size + node.size() &lt; m) { // 新子节点的左子节点替代旧子节点的位置 setChild(index, node.firstChild()); for (Entry&lt;K, V&gt; entry : node.entries()) { insertEntry(++index, entry); } return this; } // 2. 当前空间不够，需要分裂成 3 个节点 return splitNodes(index, node); } /** * 子节点上溢后，父节点已满，则需要分裂节点，将 1 个节点拆分成 3 个节点 * * @param index 上溢子节点的父元素索引 * @param newNode 上溢的子节点 * @return 分裂后新的父节点 */ private BPTNode&lt;K, V&gt; splitNodes(int index, BPTNode&lt;K, V&gt; newNode) { // 新子节点的左子节点替代旧子节点的位置 setChild(index, newNode.firstChild()); int newSize = size + newNode.size(); List&lt;Entry&lt;K, V&gt;&gt; allEntries = new ArrayList&lt;&gt;(newSize); List&lt;Entry&lt;K, V&gt;&gt; curEntries = entries(); for (int i = 0; i &lt; index &amp;&amp; i &lt; size; i++) { allEntries.add(curEntries.get(i)); } allEntries.addAll(newNode.entries()); for (int i = index; i &lt; size; i++) { allEntries.add(curEntries.get(i)); } // 根节点 int mid = newSize / 2; BPTInternal&lt;K, V&gt; root = new BPTInternal&lt;&gt;(m); for (int i = mid; i &lt;= mid; i++) { root.addEntry(allEntries.get(i)); } // 左子节点 BPTInternal&lt;K, V&gt; left = new BPTInternal&lt;&gt;(m); for (int i = 0; i &lt; mid; i++) { left.addEntry(allEntries.get(i)); } // 右子节点（和叶子节点不同，右子节点不包括根节点元素） BPTInternal&lt;K, V&gt; right = new BPTInternal&lt;&gt;(m); for (int i = mid + 1; i &lt; newSize; i++) { right.addEntry(allEntries.get(i)); } // 更新边界指针 left.setChild(0, firstChild()); right.setChild(0, root.lastChild()); root.setChild(0, left); root.setChild(root.size, right); return root; } /** * 节点下溢处理 * &lt;p&gt; * 存在非法子节点时，可能需要对父节点进行下溢操作 * * @param index 父节点索引 * @return 根节点 */ public BPTNode&lt;K, V&gt; underflow(int index) { // 验证子节点是否合法，合法就不用下溢 BPTNode&lt;K, V&gt; cur = getChild(index); if (cur == null || cur.isLegal()) { return this; } // 1. 从兄弟节点借一个元素 BPTNode&lt;K, V&gt; left = null; if (index &gt; 0) { left = getChild(index - 1); if (left != null &amp;&amp; left.canBorrow()) { return borrowLeft(index); } } BPTNode&lt;K, V&gt; right = null; if (index &lt; size) { right = getChild(index + 1); if (right != null &amp;&amp; right.canBorrow()) { return borrowRight(index); } } if (left == null &amp;&amp; right == null) { return this; } // 2. 合并父元素 + 左右子节点 // 始终把当前节点作为合并时的右子节点 return mergeNodes(left != null ? index : index + 1); } /** * 借用左子节点的值 * &lt;p&gt; * 实际就是右旋，将父节点转到右子节点，左子节点的元素转到父节点 * * @param index 父节点索引 */ private BPTNode&lt;K, V&gt; borrowLeft(int index) { BPTNode&lt;K, V&gt; left = getChild(index - 1); BPTNode&lt;K, V&gt; right = getChild(index); if (left.isLeaf()) { // 叶子节点，父元素不是数据，不能旋转到叶子节点里面 // 左叶子节点转移到右叶子节点（叶子节点的子节点都为空，不需要更新） Entry&lt;K, V&gt; leftEntry = left.getEntry(left.size); left.removeEntry(left.size); right.insertEntry(1, leftEntry); // 更新父节点索引 setEntry(index, new Entry&lt;&gt;(leftEntry.key, null)); setChild(index, right); } else { // 内部节点，都是索引元素，直接旋转 Entry&lt;K, V&gt; parentEntry = getEntry(index); Entry&lt;K, V&gt; leftEntry = left.getEntry(left.size); BPTNode&lt;K, V&gt; leftRight = left.lastChild(); // 父节点转到右子节点 right.insertEntry(1, parentEntry); right.setChild(1, right.firstChild()); // 左子节点转到父节点 left.removeEntry(left.size); setEntry(index, leftEntry); setChild(index, right); right.setChild(0, leftRight); } return this; } /** * 借用右子节点的值 * &lt;p&gt; * 实际就是左旋，将父元素转到左子节点，右子节点的元素转到父节点 * * @param index 父节点索引 */ private BPTNode&lt;K, V&gt; borrowRight(int index) { BPTNode&lt;K, V&gt; right = getChild(index + 1); BPTNode&lt;K, V&gt; left = getChild(index); if (right.isLeaf()) { // 叶子节点，父元素不是数据，不能旋转到叶子节点里面 // 右叶子节点转移到左叶子子节点（叶子节点的子节点都为空，不需要更新） Entry&lt;K, V&gt; rightEntry = right.getEntry(1); right.removeEntry(1); left.addEntry(rightEntry); // 更新父节点索引 Entry&lt;K, V&gt; newRightEntry = right.getEntry(1); setEntry(index + 1, new Entry&lt;&gt;(newRightEntry.key, null)); setChild(index + 1, right); } else { // 内部节点，都是索引元素，直接旋转 Entry&lt;K, V&gt; parentEntry = getEntry(index + 1); Entry&lt;K, V&gt; rightEntry = right.getEntry(1); BPTNode&lt;K, V&gt; rightLeft = right.firstChild(); // 父节点转到左子节点 left.addEntry(parentEntry); // 右子节点转到父节点 right.setChild(0, right.getChild(1)); right.removeEntry(1); setEntry(index + 1, rightEntry); setChild(index + 1, right); left.setChild(left.size, rightLeft); } return this; } /** * 父节点元素 + 右子节点，全都合并到左子节点 * &lt;p&gt; * 因为父节点元素和右子节点是一一对应的，所以都是按照“父 + 右 --&gt; 左”进行合并 * &lt;p&gt; * 方便同时删除父节点元素和右子节点 * * @param index 父节点索引 */ private BPTNode&lt;K, V&gt; mergeNodes(int index) { BPTNode&lt;K, V&gt; left = getChild(index - 1); BPTNode&lt;K, V&gt; right = getChild(index); // 父节点元素合并到左子节点 if (!left.isLeaf()) { // 子节点是叶子节点时，合并不要加上父元素 Entry&lt;K, V&gt; parentEntry = getEntry(index); left.addEntry(parentEntry); } // 右子节点合并到左子节点 left.setChild(left.size, right.firstChild()); for (Entry&lt;K, V&gt; entry : right.entries()) { left.addEntry(entry); } // 移除父节点元素 removeEntry(index); // 更新叶子节点双向链表的指针 if (left.isLeaf()) { BPTLeaf&lt;K, V&gt; leftLeaf = (BPTLeaf&lt;K, V&gt;) left; BPTLeaf&lt;K, V&gt; rightLeaf = (BPTLeaf&lt;K, V&gt;) right; BPTLeaf&lt;K, V&gt; rightNext = rightLeaf.getNext(); if (rightNext != null) { rightNext.setPrev(leftLeaf); } leftLeaf.setNext(rightNext); } return this; }} B+ 树叶子节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159/** * B+树叶子节点 * * @author weijiaduo * @since 2023/1/10 */public class BPTLeaf&lt;K extends Comparable&lt;K&gt;, V&gt; extends BPTNode&lt;K, V&gt; { /** * 双向链表，上一个节点 */ private BPTLeaf&lt;K, V&gt; prev; /** * 双向链表，下一个节点 */ private BPTLeaf&lt;K, V&gt; next; public BPTLeaf(int m) { super(m); } @Override public boolean isLeaf() { return true; } /** * 添加新元素 * * @param key key * @param value value */ public BPTNode&lt;K, V&gt; add(K key, V value) { int index = findIndex(key); // 1. 空间足够，可以直接插入新元素 if (!this.isFull()) { insertEntry(index + 1, new Entry&lt;&gt;(key, value)); return this; } // 2. 空间不足，需要分裂节点 return splitNodes(index, new Entry&lt;&gt;(key, value)); } /** * 叶子节点已满，无法插入新元素时，需分裂成 3 个节点 * * @param index 元素插入位置 * @param newEntry 新元素 * @return 分裂后的父节点 */ private BPTNode&lt;K, V&gt; splitNodes(int index, Entry&lt;K, V&gt; newEntry) { List&lt;Entry&lt;K, V&gt;&gt; curEntries = entries(); curEntries.add(index, newEntry); int newSize = curEntries.size(); int mid = newSize / 2; // 根节点（内部节点只需要索引就够了，不需要数据） BPTNode&lt;K, V&gt; root = new BPTInternal&lt;&gt;(m); Entry&lt;K, V&gt; entry = curEntries.get(mid); root.addEntry(new Entry&lt;&gt;(entry.key, null)); // 左子节点 BPTLeaf&lt;K, V&gt; left = new BPTLeaf&lt;&gt;(m); for (int i = 0; i &lt; mid; i++) { left.addEntry(curEntries.get(i)); } // 右子节点（和内部节点不同，右子节点包括了根节点元素） BPTLeaf&lt;K, V&gt; right = new BPTLeaf&lt;&gt;(m); for (int i = mid; i &lt; newSize; i++) { right.addEntry(curEntries.get(i)); } // 设置父子节点关系 root.setChild(0, left); root.setChild(root.size, right); // 更新叶子节点双向链表指针 left.prev = this.prev; if (this.prev != null) { this.prev.next = left; } left.next = right; right.prev = left; if (this.next != null) { this.next.prev = right; } right.next = this.next; this.prev = this.next = null; return root; } /** * 删除指定位置的元素 * &lt;p&gt; * 删除元素后，节点可能会产生下溢，从而返回了一个空元素节点 * * @param index 索引 * @return 删除后的根节点 */ public BPTNode&lt;K, V&gt; delete(int index) { // 叶子节点直接删除元素，删除后可能会变成元素为空的空节点 // 空节点会由内部节点处理掉，或者由根节点处理掉 removeEntry(index); return this; } /** * 获取指定位置的 value * * @param index 索引 * @return value */ public V getValue(int index) { return getEntry(index).value; } /** * 设置指定位置的 value * * @param index 索引 * @param value 值 */ public void setValue(int index, V value) { getEntry(index).value = value; } /** * @return 上一个叶子节点 */ public BPTLeaf&lt;K, V&gt; getPrev() { return prev; } /** * @return 下一个叶子节点 */ public BPTLeaf&lt;K, V&gt; getNext() { return next; } /** * 更新上一个叶子节点 * * @param prev 上一个叶子节点 */ protected void setPrev(BPTLeaf&lt;K, V&gt; prev) { this.prev = prev; } /** * 更新下一个叶子节点 * * @param next 下一个叶子节点 */ protected void setNext(BPTLeaf&lt;K, V&gt; next) { this.next = next; }}","link":"/datastructure/tree/bplus_tree/"},{"title":"B-树","text":"B-树一、B-树是什么？B-树是一棵所有叶子节点高度都相同的平衡多叉树。 其结构类似这样： 123456789101112 ____ ___ ___ | 24 | | | | --------------------------------------------- | | ____ ____ ___ ____ ___ ___ | 15 | 20 | | | 33 | | | | | ----------------------------------- ------------------- | | | | | ____ ____ ___ ____ ___ ___ ____ ____ ___ ____ ____ ___ ____ ___ ___| 10 | 12 | | | 18 | | | | 21 | 23 | | | 30 | 31 | | | 38 | | | B-树的一些性质： 树节点中，子节点数量的最大值称为B-树的阶 m 阶B-树的节点，最多拥有 m - 1 个元素 B-树的所有叶子节点都在同一层，是高度平衡的 除根节点外，所有节点的元素个数不少于 Math.ceil(m/2) - 1，也即子节点数量不少于 Math.ceil(m/2） 节点的大小，始终满足 左子节点 &lt; 父节点 &lt; 右子节点，即和二叉查找树类似 简单来说，B-树的结构是节点的子节点数量要半满，叶子节点的高度要始终一样。 二、为什么要用B-树？ B-树或B-树变体被广泛应用于需要进行插入、删除、范围检索等的应用程序，比如 MySQL 数据库索引 更新和检索操作只影响部分节点，对于基于磁盘的检索，可以减少 I/O 请求，提升性能 B-树保证至少有一定比例的节点是满的，能改进空间利用率 三、怎么实现一棵B-树？B-树主要包含几种操作： 检索元素：在树中搜索指定的元素 插入元素：往树中插入新的元素 删除元素：从树中删除指定的元素 其中插入和删除会对B-树的结构产生影响，稍微麻烦亿点。 3.1 检索元素B-树和二叉搜索树类似，二叉搜索树使用的是二分查找，而B-树也是类似的： B-树检索元素采用的是二分查找的升级版本 —— 多路查找 比如说，上面的B-树中，要寻找元素 23，那么它的搜索路线就是： 24 -&gt; 20 -&gt; 23 在B-树中查找的话，就是这样子： 123456789101112 ____ ___ ___ | 24 | | | | --------------------------------------------- | | ____ ____ ___ ____ ___ ___ | | 20 | | | | | | | | ----------------------------------- ------------------- | | | | | ____ ____ ___ ____ ___ ___ ____ ____ ___ ____ ____ ___ ____ ___ ___| | | | | | | | | | 23 | | | | | | | | | | 对应到伪代码的话，差不多是这样的： 12345678910private V get(BTNode&lt;K, V&gt; root, K key) { int index = root.findIndex(key); if (key.equals(root.getKey(index))) { // 找到 key 对应的节点 return root.getValue(index); } else { // 往子树继续找 key 对应的节点 return get(root.getChild(index), key); }} 实际就是从上往下多路递归查找元素。 3.2 插入元素B-树和二叉搜索树的插入类似： B-树插入新元素，始终是在叶子节点插入 插入元素，可以分为 2 种情况处理： 节点空间足够，直接插入元素 节点空间不足，1 个节点分裂成 3 个节点，执行上溢操作 这 2 种情况的效果如下。 3.2.1 叶子节点-直接插入当叶子节点空间足够时，可以直接插入新元素，而且不会影响到B-树的高度平衡： 1234567891011121314 ____ ____ ___ | 12 | | | | 插入 20 v ____ ____ ___ | 12 | 20 | | | 插入 9 v ____ ____ ____ | 9 | 12 | 20 | 空间足够时，直接插入元素就行了。 3.2.2 叶子节点-上溢分裂当叶子节点空间不足时，此时再插入新元素，会导致节点空间上溢，然后分裂： 12345678910111213 ___ ____ ____ | 9 | 12 | 20 | | 插入 25 v ____ ___ ___ | 20 | | | | --------------------- | | ___ ____ ___ ____ ____ ____ | 9 | 12 | | | 25 | | | 节点元素上溢后，1 个节点会分裂成 3 个节点。 3.2.3 内部节点-直接插入为了保持B-树的高度平衡，叶子节点会将分裂后的父节点，往上插入之前的父节点： 12345678910111213141516171819 ____ ___ ___ | 20 | | | | ---------------------- | | ___ ____ ____ ____ ____ ____ | 9 | 12 | 18 | | 25 | | | | 插入 10 v ____ ____ ___ | 12 | 20 | | | -------------------------------------------- | | | ___ ____ ____ ____ ____ ____ ____ ____ ____ | 9 | 10 | | | 18 | | | | 25 | | | 左子节点 [9, 12, 18] 插入新节点 10 会产生上溢，节点 12 会上溢父节点中。 因为内部节点 [20] 空间足够，所以 12 直接插入即可。 3.2.4 内部节点-分裂上溢子节点上溢后，如果父节点空间也满了，那么父节点也会出现分裂上溢： 123456789101112131415161718192021222324 ____ ____ ____ | 20 | 30 | 45 | | ------------------------------------------------------------------- | | | | ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ | 9 | 12 | 18 | | 25 | | | | 37 | 39 | | | 62 | 85 | | | 插入 10 v ____ ____ ____ | 30 | | | | ---------------------------------------------------------- | | ____ ____ ___ ____ ___ ___ | 12 | 20 | | | 45 | | | | | -------------------------------------------- ------------------------ | | | | | ___ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____| 9 | 10 | | | 18 | | | | 25 | | | | 37 | 39 | | | 62 | 85 | | 插入元素 10 之后，会传递性地导致节点 [9, 12, 18] 和节点 [20, 30, 45] 都产生分裂上溢。 这种分裂上溢可以一直持续到根节点，最后可能会导致B-树提升一层（如上）。 上述的 4 种情况，实际就 2 种： 空间足够时，直接插入 空间不足时，分裂上溢 对应的伪代码类似这样： 12345678910111213141516/**- 插入新元素 -*/private BTNode&lt;K, V&gt; put(BTNode&lt;K, V&gt; root, K key, V value) { int index = root.findIndex(key); // 叶子节点 if (root.isLeaf()) { // 叶子节点添加元素后，可能发生了分裂 return root.add(key, value); } // 内部节点 BTNode&lt;K, V&gt; child = root.getChild(index); child = put(child, key, value); // 子树添加元素后，可能发生了分裂 return root.overflow(index, child);} 12345678910111213141516/**- 直接插入和分裂上溢（叶子节点和内部节点的插入逻辑一样） -*/public BTNode&lt;K, V&gt; overflow(int index, BTNode&lt;K, V&gt; node) { // 子节点没上溢 if (getChild(index) == node) { return this; } // 子节点上溢了 // 1. 空间足够，直接插入 if (size + node.size() &lt; m) { return insertNode(index, node); } // 2. 空间不足，分裂节点 return splitNodes(index, node);} 3.3 删除元素删除元素，可以分为 3 种情况： 删除后元素数量仍然满足要求，直接删除 删除后元素数量不满足要求，看兄弟节点是否可以借一个过来 兄弟节点不能借，那就将父子节点合并成 1 个节点，产生下溢 这几种情况如下。 3.3.1 直接删除如果节点删除元素后，元素数量仍然处于半满状态，则直接返回即可： 12345678910111213141516171819 ____ ___ ___ | 20 | | | | ---------------------- | | ___ ____ ____ ____ ____ ____ | 9 | 12 | 18 | | 25 | | | | 删除 12 v ____ ___ ___ | 20 | | | | ---------------------- | | ___ ____ ____ ____ ____ ____ | 9 | 18 | | | 25 | | | 叶子节点 [9, 12, 18] 删除 12 以后，元素数量依旧满足半满状态，则可以直接删除并返回。 3.3.2 从兄弟借如果删除元素后，元素数量少于一半，不满足要求，则看一下兄弟节点能不能借一下： 12345678910111213141516171819 ____ ___ ___ | 20 | | | | ---------------------- | | ___ ____ ____ ____ ____ ____ | 9 | 12 | 18 | | 25 | | | | 删除 25 v ____ ___ ___ | 18 | | | | ---------------------- | | ___ ____ ____ ____ ____ ____ | 9 | 12 | | | 20 | | | 右子节点 [25] 删除 25 以后，元素数量不满足要求了，找兄弟节点 [9, 12, 18] 借一个。 但是不能直接把左子节点的元素移到右子节点中，因为B-树是要求满足 左子节点 &lt; 父节点 &lt; 右子节点。 所以“借用”实际上是一种旋转操作，父节点转到需要借用元素的节点，而兄弟节点元素则转到父节点中。 3.3.3 父子合并如果兄弟节点借不了元素，那就将父节点 + 左子节点 + 右子节点合并在一起： 1234567891011121314 ____ ___ ___ | 20 | | | | ---------------------- | | ___ ____ ____ ____ ____ ____ | 9 | | | | 25 | | | | 删除 25 v ___ ____ ___ | 9 | 20 | | 删除元素 25 后，由于兄弟节点没办法借用，所以将父子节点都合并成 1 个节点，这个合并称为下溢。 下溢和上溢一样，也可能会持续下溢，一直持续到根节点，最终导致树的层级下降。 上述情况的伪代码如下： 123456789101112131415/**- 删除元素 -*/private BTNode&lt;K, V&gt; remove(BTNode&lt;K, V&gt; root, K key) { int index = root.findIndex(key); // 找到对应节点后移除元素 if (key.equals(root.getKey(index))) { // 直接删除元素后，可能导致父节点下溢 return root.delete(index); } // 在子树内递归移除元素 remove(root.getChild(index), key); // 子树删除元素后，可能导致父节点下溢 return root.underflow(index);} 12345678910111213141516/** 从兄弟借和父子合并（叶子节点和内部节点的下溢逻辑是一样的） */public BTNode&lt;K, V&gt; underflow(int index) { // 子节点合法，无需下溢 if (isLegal(getChild(index))) { return this; } // 子节点不合法，需修正 // 1. 从兄弟节点借一个元素 if (borrowLeft(index) || borrowRight(index)) { return this; } // 2. 合并父元素 + 左右子节点 return mergeNodes(index);} 总结 性质 m 阶B-树的节点，最多拥有 m - 1 个元素 B-树的所有叶子节点都在同一层，是高度平衡的 除根节点外，所有节点的元素个数不少于 Math.ceil(m/2) - 1，也即子节点数量不少于 Math.ceil(m/2） 节点的大小，始终满足 左子节点 &lt; 父节点 &lt; 右子节点 检索 多路查找：二分查找的升级版本 插入 空间足够，直接插入 空间不足，分裂上溢 删除 元素够多，直接删除 元素不够，从兄弟借 兄弟节点无法借用，合并父子节点，执行下溢 参考 《数据结构与算法分析（第三版）》 https://www.cnblogs.com/nullzx/p/8729425.html https://github.com/LiuXianghai-coder/Test-Repo/blob/master/DataStructure/BTree.java https://blog.csdn.net/u011711997/article/details/80420392 https://blog.csdn.net/c630843901/article/details/121423196 https://blog.csdn.net/oooooorz/article/details/112297554 https://blog.csdn.net/cdnight/article/details/11772621 附录B-树接口1234567891011121314151617181920212223242526272829303132/** * B-树 * * @author weijiaduo * @since 2023/1/2 */public interface BTree&lt;K extends Comparable&lt;K&gt;, V&gt; { /** * 查找指定 key 的值 * * @param key key * @return value */ V get(K key); /** * 添加指定 key-value 的节点 * * @param key key * @param value value */ void put(K key, V value); /** * 删除指定 key 的节点 * * @param key key */ void remove(K key);} B-树实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/** * B-树实现类 * * @author weijiaduo * @since 2023/1/2 */public class BTreeImpl&lt;K extends Comparable&lt;K&gt;, V&gt; implements BTree&lt;K, V&gt; { /** * 根节点 */ private BTNode&lt;K, V&gt; root; /** * m 阶 B 树 */ private final int m; public BTreeImpl(int m) { this.m = m; } @Override public V get(K key) { return get(root, key); } /** * 从当前节点开始找指定 key 的值 * * @param root 当前根节点 * @param key key * @return value */ private V get(BTNode&lt;K, V&gt; root, K key) { if (root == null) { return null; } // 查找当前 key 所在的位置 int index = root.findIndex(key); if (key.equals(root.getKey(index))) { // 找到 key 对应的节点 return root.getValue(index); } else { // 往子树继续找 key 对应的节点 return get(root.getChild(index), key); } } @Override public void put(K key, V value) { root = put(root, key, value); } /** * 在当前树内添加指定的 key-value * * @param root 当前根节点 * @param key key * @param value value * @return 新的根节点 */ private BTNode&lt;K, V&gt; put(BTNode&lt;K, V&gt; root, K key, V value) { // 1. 整棵树为空时，插入新节点 if (root == null) { BTNode&lt;K, V&gt; node = new BTNode&lt;&gt;(m); return node.add(key, value); } // 验证是否已存在，存在则只需更新 int index = root.findIndex(key); if (key.equals(root.getKey(index))) { // 更新节点 root.setValue(index, value); return root; } // 2. 叶子节点，直接添加 if (root.isLeaf()) { // 添加到叶子节点中，有可能发生分裂 return root.add(key, value); } // 3. 内部节点，添加到子树的叶子节点中 BTNode&lt;K, V&gt; child = root.getChild(index); child = put(child, key, value); // 添加元素后子树可能发生了分裂 return root.overflow(index, child); } @Override public void remove(K key) { root = remove(root, key); if (root != null &amp;&amp; root.isEmpty()) { // 树的高度下降 root = root.firstChild(); } } /** * 在当前树内删除指定 key 的节点 * * @param root 当前根节点 * @param key key * @return 新的根节点 */ private BTNode&lt;K, V&gt; remove(BTNode&lt;K, V&gt; root, K key) { if (root == null) { return null; } // 找到对应节点后移除元素 int index = root.findIndex(key); if (key.equals(root.getKey(index))) { return root.delete(index); } // 在子树内递归移除元素 remove(root.getChild(index), key); // 移除后可能需要父节点下溢 return root.underflow(index); }} B-树节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767/** * B-树节点 * * @author weijiaduo * @since 2023/1/2 */public class BTNode&lt;K extends Comparable&lt;K&gt;, V&gt; { /** * m 阶 B 树 */ private final int m; /** * 节点元素阈值 */ private final int threshold; /** * 节点元素数组 * &lt;p&gt; * 元素的第 0 位始终是一个占位元素，专门用于存放最左子节点 * &lt;p&gt; * 所以一个节点能拥有的元素个数最多是 m - 1 */ private final Object[] elements; /** * 实际元素数量 * &lt;p&gt; * 取值范围是 [0, m - 1] */ private int size; public BTNode(int m) { this.m = m; this.threshold = half(m); elements = new Object[m]; // 最左元素占位，用于存放最左子节点指针 elements[0] = new Entry&lt;K, V&gt;(null, null); size = 0; } /** * @return 元素数量 */ public int size() { return size; } /** * 半数阈值 ceil(m / 2) - 1 * * @param m 当前值 * @return 半数阈值 */ private int half(int m) { return (m + 1) / 2 - 1; } /** * 是否已满 * * @return true已满/false未满 */ public boolean isFull() { return size == m - 1; } /** * 是否为空 * * @return true为空/false非空 */ public boolean isEmpty() { return size == 0; } /** * 节点是否合法 * &lt;p&gt; * 节点的元素数量要求大于等于阈值 * * @return true合法/false非法 */ public boolean isLegal() { return size &gt;= threshold; } /** * 是否可借用元素给别的节点 * &lt;p&gt; * 当节点的元素数量大于阈值时，才可以外借元素 * * @return true可借用/false不可借用 */ private boolean canBorrow() { return size &gt; threshold; } /** * 是否是叶子节点 * &lt;p&gt; * 没有任何一个非空子节点时才是叶子节点 * * @return true叶子节点/false内部节点 */ public boolean isLeaf() { for (int i = 0; i &lt;= size; i++) { if (getChild(i) != null) { return false; } } return true; } /** * 获取所有的元素 * * @return 元素集合 */ public List&lt;Entry&lt;K, V&gt;&gt; entries() { List&lt;Entry&lt;K, V&gt;&gt; entries = new ArrayList&lt;&gt;(size); // 元素从索引 1 开始 for (int i = 1; i &lt;= size; i++) { entries.add(getEntry(i)); } return entries; } /** * 获取所有的 key * * @return key 集合 */ public List&lt;K&gt; keys() { List&lt;K&gt; keys = new ArrayList&lt;&gt;(size); // 元素从索引 1 开始 for (int i = 1; i &lt;= size; i++) { keys.add(getKey(i)); } return keys; } /** * 获取所有的 value * * @return value 集合 */ public List&lt;V&gt; values() { List&lt;V&gt; values = new ArrayList&lt;&gt;(size); // 元素从索引 1 开始 for (int i = 1; i &lt;= size; i++) { values.add(getValue(i)); } return values; } /** * 获取指定位置的 key * * @param index 索引 * @return key */ public K getKey(int index) { return getEntry(index).key; } /** * 获取指定位置的 value * * @param index 索引 * @return value */ public V getValue(int index) { return getEntry(index).value; } /** * 设置指定位置的 value * * @param index 索引 * @param value 值 */ public void setValue(int index, V value) { getEntry(index).value = value; } /** * 获取所有的子节点 * &lt;p&gt; * 注意：是所有可能的子节点，也包括了 null 子节点 * * @return 子节点集合 */ public List&lt;BTNode&lt;K, V&gt;&gt; children() { List&lt;BTNode&lt;K, V&gt;&gt; children = new ArrayList&lt;&gt;(size + 1); // 子节点从索引 0 开始 for (int i = 0; i &lt;= size; i++) { children.add(getChild(i)); } return children; } /** * 返回第一个子节点 * &lt;p&gt; * 注意：不是第一个非空子节点，而是第 1 个元素的左子节点 * * @return 第一个子节点 */ public BTNode&lt;K, V&gt; firstChild() { return getChild(0); } /** * 返回最后一个子节点 * &lt;p&gt; * 注意：不是最后一个非空子节点，而是最后 1 个元素的右子节点 * * @return 最后一个子节点 */ public BTNode&lt;K, V&gt; lastChild() { return getChild(size); } /** * 获取指定位置的下一层子节点 * * @param index 指定位置 * @return 下一层子树根节点 */ public BTNode&lt;K, V&gt; getChild(int index) { return getEntry(index).pointer; } /** * 更新指定位置的子节点 * * @param index 索引 * @param node 子节点 */ public void setChild(int index, BTNode&lt;K, V&gt; node) { getEntry(index).pointer = node; } /** * 查找指定 key 的位置 * &lt;p&gt; * 返回最后一个小于等于 key 的位置 * * @param key key * @return key 的位置 */ public int findIndex(K key) { // 第 0 位是占位元素，还没算在内 return 1 + binaryle(keys(), key); } /** * 二分查找，返回最后一个小于等于 key 的位置 * * @param keys key 集合 * @param key 指定 key * @return 最后一个小于等于 key 的位置/-1 */ private int binaryle(List&lt;K&gt; keys, K key) { int size = keys.size(); int l = 0, r = size - 1; while (l &lt;= r) { int m = l + (r - l) / 2; K k = keys.get(m); if (k.compareTo(key) &lt;= 0) { if (m == size - 1 || keys.get(m + 1).compareTo(key) &gt; 0) { return m; } l = m + 1; } else { r = m - 1; } } return -1; } /** * 添加新元素 * * @param key key * @param value value */ public BTNode&lt;K, V&gt; add(K key, V value) { BTNode&lt;K, V&gt; node = new BTNode&lt;&gt;(m); node.addEntry(new Entry&lt;&gt;(key, value)); int index = findIndex(key); return overflow(index, node); } /** * 节点上溢处理 * &lt;p&gt; * 子树添加新元素后，可能会分裂成新节点，替代原有的子节点 * * @param index 索引 * @param node 新节点 * @return 添加后的当前节点 */ public BTNode&lt;K, V&gt; overflow(int index, BTNode&lt;K, V&gt; node) { if (node == null || node.isEmpty()) { return this; } // 还是旧节点，说明子节点没有上溢，无需处理 BTNode&lt;K, V&gt; cur = getChild(index); if (cur == node) { return this; } // 1. 当前空间足够插入 if (size + node.size() &lt; m) { // 新子节点的左子节点替代旧子节点的位置 setChild(index, node.firstChild()); for (Entry&lt;K, V&gt; entry : node.entries()) { insertEntry(++index, entry); } return this; } // 2. 当前空间不够，需要分裂成 3 个节点 return splitNodes(index, node); } /** * 子节点上溢后，父节点已满，则需要分裂节点，将 1 个节点拆分成 3 个节点 * * @param index 上溢子节点的父元素索引 * @param newNode 上溢的子节点 * @return 分裂后新的父节点 */ private BTNode&lt;K, V&gt; splitNodes(int index, BTNode&lt;K, V&gt; newNode) { // 新子节点的左子节点替代旧子节点的位置 setChild(index, newNode.firstChild()); int newSize = size + newNode.size(); List&lt;Entry&lt;K, V&gt;&gt; allEntries = new ArrayList&lt;&gt;(newSize); List&lt;Entry&lt;K, V&gt;&gt; curEntries = entries(); for (int i = 0; i &lt; index &amp;&amp; i &lt; size; i++) { allEntries.add(curEntries.get(i)); } allEntries.addAll(newNode.entries()); for (int i = index; i &lt; size; i++) { allEntries.add(curEntries.get(i)); } // 根节点 int mid = newSize / 2; BTNode&lt;K, V&gt; root = new BTNode&lt;&gt;(m); for (int i = mid; i &lt;= mid; i++) { root.addEntry(allEntries.get(i)); } // 左子节点 BTNode&lt;K, V&gt; left = new BTNode&lt;&gt;(m); for (int i = 0; i &lt; mid; i++) { left.addEntry(allEntries.get(i)); } // 右子节点 BTNode&lt;K, V&gt; right = new BTNode&lt;&gt;(m); for (int i = mid + 1; i &lt; newSize; i++) { right.addEntry(allEntries.get(i)); } // 边界指针 left.setChild(0, firstChild()); right.setChild(0, root.lastChild()); root.setChild(0, left); root.setChild(root.size, right); return root; } /** * 删除指定位置的元素 * &lt;p&gt; * 删除元素后，节点可能会产生下溢，从而返回了一个空元素节点 * * @param index 索引 * @return 删除后的根节点 */ public BTNode&lt;K, V&gt; delete(int index) { if (isEmpty() || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } if (isLeaf()) { // 叶子节点 // 直接删除，删除后可能会变成元素为空的空节点 // 空节点将由父节点的 underflow 处理掉，或者由根节点处理掉 removeEntry(index); return this; } // 内部节点 // 使用前驱或后驱进行替换 int rpIndex = getReplacer(this, index); BTNode&lt;K, V&gt; child = getChild(rpIndex); BTNode&lt;K, V&gt; newChild; if (rpIndex &lt; index) { // 前驱元素替换 Entry&lt;K, V&gt; max = max(child); newChild = removeMax(child); setChild(rpIndex, newChild); setEntry(index, max); } else { // 后驱元素替换 Entry&lt;K, V&gt; min = min(child); newChild = removeMin(child); setChild(rpIndex, newChild); setEntry(index, min); } // 移除后可能需要父节点下溢 return underflow(rpIndex); } /** * 节点下溢处理 * &lt;p&gt; * 存在非法子节点时，可能需要对父节点进行下溢操作 * * @param index 父节点索引 * @return 根节点 */ public BTNode&lt;K, V&gt; underflow(int index) { // 验证子节点是否合法 BTNode&lt;K, V&gt; cur = getChild(index); if (cur == null || cur.isLegal()) { return this; } // 1. 从兄弟节点借一个元素 BTNode&lt;K, V&gt; left = null; if (index &gt; 0) { left = getChild(index - 1); if (left != null &amp;&amp; left.canBorrow()) { return borrowLeft(index); } } BTNode&lt;K, V&gt; right = null; if (index &lt; size) { right = getChild(index + 1); if (right != null &amp;&amp; right.canBorrow()) { return borrowRight(index); } } if (left == null &amp;&amp; right == null) { return this; } // 2. 合并父元素 + 左右子节点 // 始终把当前节点作为合并时的右子节点 return mergeNodes(left != null ? index : index + 1); } /** * 借用左子节点的值 * &lt;p&gt; * 实际就是右旋，将父节点转到右子节点，左子节点的元素转到父节点 * * @param index 父节点索引 */ private BTNode&lt;K, V&gt; borrowLeft(int index) { BTNode&lt;K, V&gt; left = getChild(index - 1); BTNode&lt;K, V&gt; right = getChild(index); Entry&lt;K, V&gt; parentEntry = getEntry(index); Entry&lt;K, V&gt; leftEntry = left.getEntry(left.size); BTNode&lt;K, V&gt; leftRight = left.lastChild(); // 父节点转到右子节点 right.insertEntry(1, parentEntry); right.setChild(1, right.firstChild()); // 左子节点转到父节点 left.removeEntry(left.size); setEntry(index, leftEntry); setChild(index, right); right.setChild(0, leftRight); return this; } /** * 借用右子节点的值 * &lt;p&gt; * 实际就是左旋，将父元素转到左子节点，右子节点的元素转到父节点 * * @param index 父节点索引 */ private BTNode&lt;K, V&gt; borrowRight(int index) { BTNode&lt;K, V&gt; right = getChild(index + 1); BTNode&lt;K, V&gt; left = getChild(index); Entry&lt;K, V&gt; parentEntry = getEntry(index + 1); Entry&lt;K, V&gt; rightEntry = right.getEntry(1); BTNode&lt;K, V&gt; rightLeft = right.firstChild(); // 父节点转到左子节点 left.addEntry(parentEntry); // 右子节点转到父节点 right.setChild(0, right.getChild(1)); right.removeEntry(1); setEntry(index + 1, rightEntry); setChild(index + 1, right); left.setChild(left.size, rightLeft); return this; } /** * 父节点元素 + 右子节点，全都合并到左子节点 * &lt;p&gt; * 因为父节点元素和右子节点是一一对应的，所以都是按照“父 + 右 --&gt; 左”进行合并 * &lt;p&gt; * 方便同时删除父节点元素和右子节点 * * @param index 父元素索引 */ private BTNode&lt;K, V&gt; mergeNodes(int index) { BTNode&lt;K, V&gt; left = getChild(index - 1); BTNode&lt;K, V&gt; right = getChild(index); // 父节点元素合并到左子节点 Entry&lt;K, V&gt; parentEntry = getEntry(index); left.addEntry(parentEntry); // 右子节点合并到左子节点 left.setChild(left.size, right.firstChild()); for (Entry&lt;K, V&gt; entry : right.entries()) { left.addEntry(entry); } // 移除父节点元素 removeEntry(index); return this; } /** * 获取可替换子节点索引（前驱/后驱） * * @param root 当前根节点 * @param index 当前索引 * @return 可替换子节点索引 */ private int getReplacer(BTNode&lt;K, V&gt; root, int index) { BTNode&lt;K, V&gt; right = null; if (index &lt;= root.size) { right = root.getChild(index); } if (right == null) { return index - 1; } BTNode&lt;K, V&gt; left = null; if (index &gt; 0) { left = root.getChild(index - 1); } if (left == null) { return index; } if (left.canBorrow()) { return index - 1; } else { return index; } } /** * 获取最大值 * * @param root 当前根节点 * @return 最大值 */ private Entry&lt;K, V&gt; max(BTNode&lt;K, V&gt; root) { if (root == null) { return null; } if (root.isLeaf()) { return root.getEntry(root.size); } return max(root.lastChild()); } /** * 移除最大值 * * @param root 当前根节点 * @return 移除后的根节点 */ private BTNode&lt;K, V&gt; removeMax(BTNode&lt;K, V&gt; root) { if (root == null) { return null; } if (root.isLeaf()) { root.removeEntry(root.size); return root; } int index = root.size; removeMax(root.getChild(index)); return root.underflow(index); } /** * 获取最小值 * * @param root 当前根节点 * @return 最小值 */ private Entry&lt;K, V&gt; min(BTNode&lt;K, V&gt; root) { if (root == null) { return null; } if (root.isLeaf()) { return root.getEntry(1); } return min(root.firstChild()); } /** * 移除最小值 * * @param root 当前根节点 * @return 移除值后的根节点 */ private BTNode&lt;K, V&gt; removeMin(BTNode&lt;K, V&gt; root) { if (root == null) { return null; } if (root.isLeaf()) { root.removeEntry(1); return root; } int index = 0; removeMin(root.getChild(index)); return root.underflow(index); } /** * 获取指定位置的元素 * * @param index 索引 * @return 元素 */ private Entry&lt;K, V&gt; getEntry(int index) { return (Entry&lt;K, V&gt;) elements[index]; } /** * 更新指定位置的元素 * &lt;p&gt; * 要求原始元素必须存在，否则应该使用 {@code insertEntry()} * * @param index 索引 * @param entry 元素 */ private void setEntry(int index, Entry&lt;K, V&gt; entry) { Entry&lt;K, V&gt; oldEntry = getEntry(index); if (oldEntry == null || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } // 保留子节点，只替换元素的 key-value elements[index] = entry; entry.pointer = oldEntry.pointer; } /** * 追加新元素 * &lt;p&gt; * 此方法不会产生节点分裂，需要分裂时应调用 {@code overflow()} 方法 * * @param entry 元素 */ private void addEntry(Entry&lt;K, V&gt; entry) { if (isFull()) { throw new IllegalStateException(String.format(&quot;size: %d&quot;, size)); } elements[++size] = entry; } /** * 插入新元素 * &lt;p&gt; * 此方法不会产生节点分裂，需要分裂时应调用 {@code overflow()} 方法 * * @param index 插入索引 * @param entry 元素 */ private void insertEntry(int index, Entry&lt;K, V&gt; entry) { if (isFull() || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } if (size &gt;= index) { System.arraycopy(elements, index, elements, index + 1, size - index + 1); elements[index] = entry; size++; } else { elements[index] = entry; size = index; } } /** * 移除指定位置的元素 * * @param index 索引 */ private void removeEntry(int index) { if (isEmpty() || index == 0) { throw new IllegalStateException(String.format(&quot;index: %d, size: %d&quot;, index, size)); } if (size &gt; index) { System.arraycopy(elements, index + 1, elements, index, size - index); } elements[size] = null; size--; } @Override public String toString() { String[] s = new String[size]; for (int i = 1; i &lt;= size; i++) { s[i - 1] = elements[i].toString(); } return &quot;[&quot; + String.join(&quot;, &quot;, s) + &quot;]&quot;; } /** * 单个元素 */ static class Entry&lt;K extends Comparable&lt;K&gt;, V&gt; { /** * key */ K key; /** * value */ V value; /** * 右子节点指针，即大于 key 的子树 */ BTNode&lt;K, V&gt; pointer; public Entry(K key, V value) { this.key = key; this.value = value; pointer = null; } @Override public String toString() { return &quot;{&quot; + key + &quot; : &quot; + value + &quot;}&quot;; } }}","link":"/datastructure/tree/b_tree/"},{"title":"设计原则总结","text":"设计原则总结“单一职责原则”、“接口隔离原则”、“迪米特法则”的区别从目的上来说，它们都是为了实现高内聚、低耦合，只是不同角度而已： 单一职责 角度：自身 方式：相关功能应该聚合在一起 侧重点：高内聚 接口隔离 角度：调用者 方式：不需要的功能不应该依赖 侧重点：低耦合 迪米特法则 角度：关系 方式：依赖关系尽可能地少 侧重点：低耦合 大部分设计模式的目的都差不多，很多只是思考的角度不同而已。","link":"/design_pattern/principle/principles/"},{"title":"迪米特法则","text":"迪米特法则迪米特法则（Law of Demeter，LOD），或者 The Least Knowledge Principle。 英文描述： 12Each unit should have only limited knowledge about other units: only units “closely” related to the current unit.Or: Each unit should only talk to its friends; Don’t talk to strangers. 中文翻译： 12每个模块（unit）只应该了解那些与它关系密切的模块的有限知识（knowledge）。或者说，每个模块只和自己的朋友“说话”（talk），不和陌生人“说话”（talk）。 一、如何理解迪米特法则？不和陌生人说话，其含义就是： 每个模块与其他模块的关系尽可能地少 每个模块只需要依赖必要的模块 简单点说就是： 模块之间的关系尽可能地少 要尽可能地减少模块依赖关系。 比如，用户模块的接口： 123456public interface UserService { boolean register(String userName, String password); boolean login(String userName, String password); User getUser(String userId); boolean deleteUser(String userId);} 假如有某一个模块需要登录功能，但又不需要其他的用户功能。 如果用 UserService 接口的话，就会显得依赖的东西比较多。 这个时候可以将接口拆分出一个登录接口 LoginService： 1234public interface LoginService { boolean register(String userName, String password); boolean login(String userName, String password);} 需要登录的模块只需要 LoginService 这个接口就足够了。 迪米特法则要求模块之间的依赖关系要尽可能地少。 二、为什么要迪米特法则？ 依赖关系越少，模块之间就越符合高内聚、低耦合 依赖关系越少，改动单个模块时就越不容易影响其他模块，整体就越稳定 三、如何做到迪米特法则？迪米特法则目的就是要减少模块之间的依赖关系。 因此只要能减少依赖关系，就是符合迪米特法则的： 面向接口编程，模块之间只调用对外的接口 不要设计大而全的接口，接口粒度尽可能小，满足业务需求即可 … 总而言之，迪米特法则的目的还是为了实现低耦合，只要能降低耦合度就行。","link":"/design_pattern/principle/lod/"},{"title":"DRY 原则","text":"DRY 原则DRY 英文描述： 1Don’t Repeat Yourself 中文翻译： 1不要重复自己 一、如何理解 “DRY”？从编程的角度去理解的话，其含义就是： 不要编写重复的代码 这个概念很简单，就是不要做重复的事情。 DRY 原则实际上是要求尽量复用代码，而不要重复造轮子。 什么样的代码，才算是重复？ 实现逻辑重复：不同的方法里面，写了多份一样的代码 功能语义重复：同样的功能，采用了不同的实现方式（比如正则判断、字符串对比） 代码执行重复：在一个方法里面，执行了多次同一个方法 这几种情况都违反了 DRY 原则吗？ 实现逻辑重复：不算违反 DRY 原则，因为是属于不同的功能里面，只是逻辑有点类似而已 功能语义重复：算是违反了 DRY 原则，同样的功能却弄了多个不同的实现 代码执行重复：也算是违反了 DRY 原则，一次执行里面没必要调用多次同一个方法 那这几种情况一般要怎么处理呢？ 实现逻辑重复：只能说代码没有复用到，可以把公共代码提取到一个新方法里，供不同地方调用 功能语义重复：只保留一份实现就可以了，其他的都删掉 代码执行重复：应该将多次调用的方法结果保存到局部变量，避免多次执行 不管有没有违反 DRY 原则，在编写代码时，都应该尽量复用已有代码。 二、为什么要 “DRY”？ 降低维护成本，去掉重复代码后，就不需要修改多个地方 避免逻辑不一致，这种问题的原因往往是因为漏改了其中一个地方的代码 提高代码可读性，重复代码的实现可能是不一样的，会让人感到疑惑 三、如何实现 “DRY”？DRY 原则要求尽量复用已有代码，这就要求代码要有可复用性，否则就没办法复用了。 所以要实现 DRY，首先就要提高代码的可复用性。 常见的提供代码复用性的方法： 减少代码耦合 满足单一职责原则 模块化 业务与非业务逻辑分离 通用代码下沉 抽象、封装、继承、多态 应用设计模式 如何识别什么时候要执行 DRY 原则呢？ 多次在不同地方看到同样的代码（Rule of Three） 多次是多少次？一般来说，超过 2 次都算是多次了。 一旦发现多个地方有重复代码，就应该用上面的方法进行重构，改造成可复用的代码。","link":"/design_pattern/principle/dry/"},{"title":"YAGNI 原则","text":"YAGNI 原则YAGNI 的英文描述： 1You Ain’t Gonna Need It 中文翻译： 1你不会需要它 一、如何理解 “YAGNI”？从开发方面去理解的话，其含义是： 不要去设计当前用不到的功能 不要去编写当前用不到的代码 核心思想是： 不要做过度设计 实际执行时，就是：不要做多余的事。 二、为什么要 “YAGNI”？ 过度设计会导致结构复杂，代码难以理解 多余的代码会影响阅读理解，因为分散了注意力 提前实现在未来未必会用到，白费功夫 三、如何做到 “YAGNI”？遵循 YAGNI 原则，很简单，只要做到： 不要过度设计 不要提前实现 但是不要过度设计，不代表着不考虑扩展性。 在实践时，应该考虑这么做： 设计时留出扩展点，但是不需要立即实现 等后面有需求推动了，再实现对应的扩展 如果未来需求变动了，大不了只是放弃这个扩展点而已 总之，在设计时尽量考虑扩展性，但是可以先不实现，留待未来。","link":"/design_pattern/principle/yagni/"},{"title":"KISS 原则","text":"KISS 原则KISS 的英文描述： 123Keep It Simple and Stupid.Keep It Short and Simple.Keep It Simple and Straightforward. 中文意思： 1尽量保持简单 一、如何理解 “KISS”？KISS 的设计理念就是： 保持方案尽可能的简单、易于理解 简单的含义是： 结构清晰 可读性强 易于理解 易于维护 KISS 原则要求把复杂问题简单化，大问题拆分成小问题去解决。 KISS 原则是侧重于可读性和可维护性设计的。 二、为什么要 “KISS”？ 越简单，就越容易理解方案的设计思路，更容易看懂 越简单，越不容易出现问题，维护起来就越轻松 即使出现问题，修改起来也很容易 三、如何做到 “KISS”？怎么样才算是简单，并没有一个明确的标准。 代码越少，就是简单？ 性能越好，就是简单？ 这两个问题的答案都是否定的。 由于没有一个标准，所以只能尽量避免违反 KISS 原则的情况： 不要过度设计，适应当前需求和基本满足近期未来需求即可 不要使用奇淫技巧，难以理解的实现（除非是性能优化需要） 不要重复造轮子，尽量使用已有的工具类 正常来说，除了性能优化比较特殊以外，代码都应该尽量简单和可读。 在工作上实践 KISS 原则时，就应该做到： 尽量缩短方法，每个方法解决一个问题就可以了 控制类的大小，不要太肥了 删除无用和多余的代码 保持代码的整洁、风格统一 先拆分问题，再根据步骤实现","link":"/design_pattern/principle/kiss/"},{"title":"依赖反转原则","text":"依赖反转原则依赖反转原则（Dependency Inversion Principle，DIP），也称为依赖倒置原则。 英文描述： 12High-level modules shouldn’t depend on low-level modules. Both modules should depend on abstractions. In addition, abstractions shouldn’t depend on details. Details depend on abstractions. 中文翻译： 12高层模块（high-level modules）不要依赖低层模块（low-level）。高层模块和低层模块应该通过抽象（abstractions）来互相依赖。除此之外，抽象（abstractions）不要依赖具体实现细节（details），具体实现细节（details）依赖抽象（abstractions）。 一、如何理解“依赖反转”？依赖反转原则的设计理念： 相对于细节的多变性，抽象的东西要稳定的多 现实中，经常存在这么一种场景： 整体流程是基本不变的，但是细节实现可能会发生变化 比如说，Tomcat 容器和部署的应用程序。 从调用上来说，Tomcat 会调用应用程序，所以 Tomcat 依赖于应用程序： 1Tomcat ---&gt; 应用程序 但是如果 Tomcat 依赖于某个应用程序的具体实现，它就不可能是一个通用的容器。 所以现实中，Tomcat 和应用程序实际是依赖于同一个抽象 Servlet： 1Tomcat ---&gt; Servlet &lt;--- 应用程序 这种将低层抽象出来一层，作为公共依赖的方式，就是依赖反转。 低层的应用程序反过来依赖了 Servlet 这个中间层。 反转的意思是： 低层根据高层的调用方式，抽象出调用接口，提供给高层 这是一种反向思考的方式： 正常来说，都是先设计的低层接口，然后高层去调用低层接口 但依赖反转的思想则是，根据高层的调用，从低层抽象出一层 依赖反转实际是低层反转依赖公共中间层的意思。 二、为什么要“依赖反转”？依赖反转的目的和作用： 低层次模块更加通用，适用性更广 高层次模块没有依赖低层次模块的具体实现，方便低层次模块的替换 一般来说，依赖反转原则主要用于指导框架的设计。 框架属于高层，实现细节则是属于低层。 三、如何实现“依赖反转”？很多时候，不需要用到依赖反转原则。 像平时的业务开发，高层代码直接调用低层代码是很常见的事情。 依赖反转原则主要适用于这样的场景： 高层的结构和流程基本不变，但是低层是可变的 或者说整体流程是固定不变的，但是细节实现是可变的 依赖反转原则在设计框架时尤其有用，其他的普通情况反而不怎么用到。 依赖反转的实现也很简单： 将低层抽象出一层中间层，然后高低层都依赖于这个中间层 这种实现方式，在重构代码时可能会经常用到。","link":"/design_pattern/principle/dip/"},{"title":"接口隔离原则","text":"接口隔离原则接口隔离原则（Interface Segregation Principle，ISP）。 英文描述： 1Clients should not be forced to depend upon interfaces that they do not use 中文翻译： 1客户端不应该被强迫依赖它不需要的接口 其中的“客户端”，可以理解为接口的调用者或者使用者。 一、如何理解“接口隔离”？接口含义： 对外开放的 提供给别人调用的 比如说 API 接口，类的 public 方法等，都属于接口。 接口隔离： 将不同业务或功能的接口分离，拆分成更细粒度的接口 客户端不应该调用大而全的接口，而是细粒度的接口 接口隔离原则实际上是要求服务提供者限制对外开放的接口。 比如说，用户服务对外提供了几个接口： 123456public class UserService { boolean register(String userName, String password); boolean login(String userName, String password); User getUser(String userId); boolean deleteUser(String userId);} 其中 deleteUser 接口需要相应的删除权限。 最简单的方式就是在 deleteUser 里面或代理这个接口来实现权限管理。 不过还可以从接口设计层面来处理，将接口隔离开来设计，比如说： 123456789public class UserService { boolean register(String userName, String password); boolean login(String userName, String password); User getUser(String userId);}public class RestrictedUserService { boolean deleteUser(String userId);} 这种方式就是接口隔离，服务提供者将不同业务的接口分离开来，限制客户端的调用。 二、为什么要“接口隔离”? 防止对外暴露不应该开放的接口，比如权限限制 减少对外开放的无用接口，比如大型接口服务提供了很多接口，但是很多接口很少用 避免实现类依赖多余的接口，比如类接口很多，但是很多是子类不需要实现的 提供更灵活的接口搭配，比如不同业务的子类可以实现通用的接口 三、如何判断“接口隔离”？判断是否满足“接口隔离原则”，可以通过调用者使用接口的方式来判断： 经常是集中调用了部分接口，接口调用频率不一样 有些接口相比于其他接口，需要额外的处理某些逻辑，比如权限控制之类的 部分接口调用后直接抛异常，提示不支持 这些情况，说明接口可能存在业务或逻辑不一样的部分，可以考虑一下做接口隔离。 四、如何实现“接口隔离”？接口是否要隔离，可以从这几个方面去检查： 按照业务功能进行接口分类，不同业务的应该隔离 隔离必要接口和非必要接口，子类不用实现非必要接口 分析常用接口和不常用接口，可以考虑做接口隔离 实际上接口是否要隔离，还是和业务挂钩的，如果没有需求推动，有时候也不一定要做接口隔离。 一般来说，设计接口时， 一开始提供少量接口，随着业务发展，逐渐添加新接口 然后等到某一天有需求驱动了，再将业务接口进行隔离 所以不一定要在一开始就完全设计好接口隔离，视情况而做。","link":"/design_pattern/principle/isp/"},{"title":"里氏替换原则","text":"里氏替换原则里式替换原则（Liskov Substitution Principle，LSP）。 英文描述： 1Functions that use pointers of references to base classes must be able to use objects of derived classes without knowing it 中文翻译： 1子类对象（`object of subtype`/`derived class`）能够替换程序中父类对象（`object of base`/`parent class`）出现的任何地方，并且保证原来程序的逻辑行为不变及正确性不被破坏。 一、如何理解“里式替换原则”？里式替换是一种设计原则，是用来指导继承关系中子类该如何设计的。 子类的设计要保证在替换父类的时候，不改变原有程序的逻辑以及不破坏原有程序的正确性 里式替换原则还有一个更实在的描述： “Design By Contract”，即“按照协议来设计” 协议的意思就是，当父类定义了函数的行为约定时， 子类可以改变函数的内部实现逻辑，但不能改变父类函数原有的行为约定 一般来说，父类设计的行为约定包括： 父类函数声明要实现的功能 父类对输入、输出、异常的约定 父类注释中所罗列的任何特殊说明，比如范围、格式等 子类设计不遵循这些约定时，都算是违反了里氏替换原则。 二、如何判断是否违反了 LSP？判断子类的设计违反了里氏替换原则的几种情况： 子类违背父类声明要实现的功能 子类违背父类对输入、输出、异常的约定 子类违背父类注释中所罗列的任何特殊说明 额外的小窍门： 拿父类的单元测试去验证子类的代码，如果运行失败，那就是违反了里氏替换原则 可能的情况就是，子类的实现没有完全地遵守父类的约定。","link":"/design_pattern/principle/lsp/"},{"title":"开闭原则","text":"开闭原则开闭原则（Open Closed Principle，OCP）。 英文描述： 1software entities (modules, classes, functions, etc.) should be open for extension , but closed for modification 中文翻译： 1软件实体（模块、类、方法等）应该“对扩展开放、对修改关闭” 扩展性是代码质量最重要的衡量标准之一。 在 23 种经典设计模式中，大部分设计模式都是为了解决代码的扩展性问题而存在的，主要遵从的设计原则就是开闭原则。 一、如何理解“对扩展开放、对修改关闭”添加一个新的功能时，应该做到： 在已有代码基础上扩展代码（新增模块、类、方法等） 而非修改已有代码（修改模块、类、方法等） 尽量避免修改已有的代码，而是追加新代码。 二、为什么要“对扩展开放、对修改关闭”？ 对扩展开放是为了应对变化(需求) 对修改关闭是为了保证已有代码的稳定性 最终结果是为了让系统更有弹性 三、修改代码就意味着违背开闭原则吗？ 添加一个新功能，不可能任何模块、类、方法的代码都不“修改”，这个是做不到的 要做的是尽量让修改操作更集中、更少、更上层 尽量让最核心、最复杂的那部分逻辑代码满足开闭原则 四、如何做到“对扩展开放、对修改关闭”？开闭原则讲的就是代码的扩展性问题，写出扩展性好的代码就是遵循开闭原则： 要时刻具备扩展意识、抽象意识、封装意识 多思考未来需求，猜测未来可能出现的扩展点，在设计时预先留好这些扩展点 尽量识别出可变部分和不可变部分，将可变部分封装起来，隔离变化，同时提供抽象化的不可变接口 常用来提高代码扩展性的方法有： 多态 依赖注入 基于接口而非实现编程 大部分的设计模式（比如，装饰、策略、模板、职责链、状态等） 这些方式实际上都是同一种设计思路，只是从不同的角度、不同的层面来阐述而已。 五、如何在项目中灵活应用开闭原则？要想识别出尽可能多的扩展点，就要对业务有足够的了解： 了解当下以及未来可能要支持的业务需求 它们会被如何使用？ 今后打算添加哪些功能？ 未来会有哪些更多的功能需求？ 了解需求以后，就可以去设计扩展点，但是要辨别出可扩展设计和过度设计。 可做的扩展设计： 比较确定的、短期内就可能会扩展的 需求改动对代码结构影响比较大的 实现成本不高的扩展点 过度设计的情况： 不确定未来是否要支持的需求 实现起来比较复杂的扩展点 过度设计的情况，可以等到有需求驱动的时候，再重构代码来支持扩展需求。 六、开闭原则可能带来的弊端 有些情况下，代码的扩展性会跟可读性相冲突，理解起来比以前难一些 重构之后的代码要比之前的代码，在结构上可能会复杂很多","link":"/design_pattern/principle/ocp/"},{"title":"单一职责原则","text":"单一职责原则单一职责原则（Single Responsibility Principle，SRP）。 英文描述： 1A class or module should have a single responsibility 中文翻译： 1一个类或者模块只负责一个职责（或者功能） 一、如何理解单一职责原则（SRP）？单一职责原则的含义： 一个类只负责完成一个职责或者功能 不要设计大而全的类，而是设计粒度小、功能单一的类 比如，一个类里既包含订单的一些操作，又包含用户的一些操作。 订单和用户是两个独立的业务领域，将它们的功能都放在同一个类中，那就违反了单一职责原则。 需要将这个类拆分成两个粒度更细、功能更加单一的两个类：订单类和用户类。 二、为什么要用单一职责原则？ 实现代码高内聚、低耦合 提高代码的复用性、可读性、可维护性 三、如何判定类的职责是否足够单一？大部分情况下，类里的方法是否归为同一类，并不是那么容易判定的。 1234567891011121314public class UserInfo { private long userId; private String username; private String email; private String telephone; private long createTime; private long lastLoginTime; private String avatarUrl; private String provinceOfAddress; // 省 private String cityOfAddress; // 市 private String regionOfAddress; // 区 private String detailedAddress; // 详细地址 // ...省略其他属性和方法...} UserInfo 类的设计是否满足单一职责原则呢？ 对于这个问题，有两种不同的观点： UserInfo 类中都是跟用户相关的信息，都隶属于用户这样一个业务模型，满足单一职责原则 地址信息所占的比重较高，可以拆分成独立的 UserAddress 类，拆分后的两个类的职责更单一 这 2 种观点都可以说是正确的。 类的职责是否足够单一，实际上并没有一个明确的、可量化的标准： 不同应用场景下，对同一个类的职责是否单一的判定，可能都是不一样的 在某种应用场景下，一个类的设计可能已经满足单一职责原则了，但如果换个应用场景，可能就不满足了。 可以用一些侧面指标，来判定类的设计是否满足单一职责原则： 类中的代码行数、函数或者属性过多，多到不知道用哪个的时候 类依赖的其他类过多，或者依赖类的其他类过多 私有方法过多，就要考虑能否将私有方法独立到新的类中 比较难给类起一个合适的名字，或者只能用一些笼统的 Manager、Context 之类的词语来命名 经常集中操作类中的某几个属性，可以考虑将这几个属性单独抽出来做成一个类 满足这些情况之一，就说明类设计不符合单一职责原则，需要拆分。 但是也不必过于未雨绸缪，刚开始时不必过度设计： 可以先写一个粗粒度的类，暂时满足业务需求 随着业务的发展，代码越来越多，再考虑拆分成几个更细粒度的类 这种方式就是所谓的持续重构。 四、类的职责是否越单一越好？单一职责原则通过避免设计大而全的类，避免将不相关的功能耦合在一起，来提高类的内聚性。 但是如果拆分得过细，可能会适得其反，反倒会降低内聚性，也会影响代码的可维护性 比如，序列化这个功能可以拆分成2个类（一个序列化类，一个反序列化类），但是： 拆分成 2 个类，那序列化这整个功能就有点违反了“高内聚”的原则 序列化算法发生了改变，需要同时修改 2 个类的实现，在“可维护性”上也变差了 所以不是拆分得越细越好，要恰到好处的均衡。 不管怎么样，最终目的还是为了提高代码的可读性、可扩展性、复用性、可维护性等 在考虑应用某一个设计原则是否合理的时候，也可以以此作为最终的考量标准。","link":"/design_pattern/principle/srp/"},{"title":"树状数组","text":"树状数组一、什么是树状数组树状数组，其英文是 Binary Indexed Tree（简称 BIT），也称为 二叉索引树/二叉下标树。 树状数组虽然名称后缀是数组，但实际上是一棵由数组实现的树 最基本的树状数组支持 2 种操作： 单点修改：更新数组 nums 中任意单个元素值 区间查询：求数组 nums 中任意区间的元素和 并且在复杂度上能够满足： 树状数组对于单点修改和区间查询的时间复杂度都是 O(logn) 比如说，数组 [3, 2, 1, 3]，它对应的树状数组结构类似这样： 123456789101112131415161718 ___ ___ ___ ___| 3 | | 5 | | 1 | | 9 | -- 树状数组 ___ | 9 | / | / /| / / | / / | / / | ___ / | | 5 | / | /| / | / | / | / | / | / | / | ___ ___ ___ ___| 3 | | 2 | | 1 | | 3 | -- 树状结构 树状数组是一种专门用于高效计算前缀和、区间和数据结构。 二、为什么用树状数组？2.1 背景引入 事项说明：下面的所有数组区间设定不是 [0, n - 1]，而是 [1, n] 一开始的问题是需要实现 2 种操作： 单点修改：更新数组 nums 中任意单个元素值 区间查询：求数组 nums 中任意区间的元素和 要同时实现这 2 种操作，有 2 种办法： 普通数组：nums[i] 单点修改；sum(nums[i]) 区间查询 前缀和数组：sum(ps[i]) 单点修改；ps[i] 区间查询 比如说，普通数组和前缀和数组的实现分别是： (1) 普通数组实现 123456789101112// 单点修改void update(int index, int val) { nums[index] += val;}// 区间查询int query(int l, int r) { int sum = 0; for (int i = l; i &lt;= r; i++) { sum += nums[i]; } return sum;} (2) 前缀和数组实现 12345678910111213// 单点修改void update(int index, int val) { for (int i = index; i &lt; n; i++) { ps[i] += val; }}// 区间查询int query(int l, int r) { if (l == 0) { return ps[r]; } return ps[r] - ps[l - 1];} 两种方式都能实现，然后它们的时间复杂度分别是： 时间复杂度 单点修改 区间查询 普通数组 O(1) O(n) 前缀和数组 O(n) O(1) 不管哪种实现方式，总有一种操作的时间复杂度为 O(n)。 O(n) 还是比较慢的，还有其他办法可以优化吗？ 2.2 问题分析分析前，先看一下普通数组和前缀和数组的区间情况。 普通数组的每个元素都可以看成一个区间： 1234567 ___ ___ ___ ___ |1,1| |2,2| |3,3| |4,4| -- 区间------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 这种情况下执行区间查询，需要将多个区间合并起来。 所以普通数组区间查询时间复杂度为 O(n) 的原因是： 区间范围太小，区间较多，合并区间比较慢 前缀和数组的区间是连续元素区间： 123456789101112131415 ____________________________________ |1, 4| -- 区间 _________________________ |1, 3| -- 区间 ______________ |1, 2| -- 区间 ___ |1,1| -- 区间------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 5 | | 6 | | 9 | -- 前缀和数组 ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 这种情况下执行单点修改，多个区间会受到影响，需要同时修改。 所以，前缀和数组单点修改时间复杂度为 O(n) 的原因是： 单个元素影响了太多区间，导致区间都要修改 要是能能解决这 2 个问题，理论上就能优化掉 O(n) 的复杂度。 2.3 区间划分区间太离散，或者区间太连续，都会出现 O(n) 的时间复杂度。 那么是否可以局部建立区间？不至于太散，也不会很连续。 比如说相邻区间两两合并，层层叠加起来，最终形成一棵二叉树： 1234567891011 _______________________________________ | 9 | -- 区间(0,4] _______________ _______________ | 5 | | 4 | -- 区间(0,2]和(2,4] ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 区间(i-1,i]------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 这样的话，单点修改和区间查询的时间复杂度如何了？ (1) 单点修改 比如修改元素 2，改成 1，那么更新的区间（二叉树从下往上）包括： (1,2]：2 -&gt; 1 (0,2]：5 -&gt; 4 (0,4]：9 -&gt; 8 更新的区间数量就是树的高度 h，所以时间复杂度是 O(logn)。 (2) 区间查询 比如查询区间 [2,3]，那么它查询过程（二叉树从上往下）包括： (0,4] (0,2] 和 (2,4] (1,2] 和 (2,3] 查询的区间数量也是树的高度，时间复杂度也是 O(logn)。 利用这种二叉树的区间划分结构，确实可以做到： 单点修改和区间查询的时间复杂度都是 O(logn) 不过这实际上是利用空间换时间得到的，空间复杂度变成了 O(n)。 2.4 结构优化为了达到 O(logn) 的时间复杂度，需要耗费 O(n) 空间建一棵二叉树，有点麻烦。 还有没有其他办法可以优化？尝试一下二叉树剪枝？ 可以采用前缀和差的思路，来剪掉二叉树中一些不必要的节点 比如，区间 [2,3] 实际上是区间 (0,3] - (0,1] 得到的。 再看上面的二叉树结构： 1234567891011 _______________________________________ | 9 | -- 区间(0,4] _______________ _______________ | 5 | | 4 | -- 区间(0,2]和(2,4] ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 区间(i-1,i]------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 考虑利用前缀和差的推断方式，可以有： 区间 (1,2] 可以由区间 (0,2] - (0,1] 得到 区间 (3,4] 可以由区间 (2,4] - (2,3] 得到 那么区间 (1,2] 和 区间 (3,4] 这 2 个节点其实可以去掉： 1234567891011 _______________________________________ | 9 | -- 区间(0,4] _______________ _______________ | 5 | | 4 | -- 区间(0,2]和(2,4] ___ ___ | 3 | | 1 | -- 区间(i-1,i]------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 同理，(2,4] 可以由区间 (0,4] - (0,2] 得到： 1234567891011 _______________________________________ | 9 | -- 区间(0,4] _______________ | 5 | -- 区间(0,2] ___ ___ | 3 | | 1 | -- 区间(i-1,i]------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 删除掉一些不必要的区间节点后，二叉树的节点数量就少了很多。 此时再调整一下图形，改成这样子（5 和 9 的位置移动了一下）： 1234567891011 _______________________________________ | 9 | -- 区间(0,4] _______________ | 5 | -- 区间(0,2] ___ ___ | 3 | | 1 | -- 区间(i-1,i]------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 再把区间节点值都收集起来，发现剩余节点，刚好能凑成一个大小为 n 的数组： 12345678910111213 _______________________________________ | 9 | -- 区间(0,4] _______________ | 5 | -- 区间(0,2] ___ ___ | 3 | | 1 | -- 区间(i-1,i]------------------------------------------------------------------ ___ ___ ___ ___ | 3 | | 5 | | 1 | | 9 | -- 树状数组 ___ ___ ___ ___ | 3 | | 2 | | 1 | | 3 | -- 原始数组 1 2 3 4 -- 区间索引 这个得到的数组 [3, 5, 1, 9] 就是树状数组。 树状数组虽然是一个数组形式，但实际上表示的是一棵经过剪枝的二叉树 通过前缀和差剪枝的方式，将二叉树结构变成了数组，结构简单多了。 三、如何实现树状数组？3.1 不依赖于数值在上面的构建二叉树中，并没有用到数组数据，因此： 树状结构不依赖于具体的数据，只和数据量有关 也就是说，不管数组内的数据如何，大小一样的数组建立起来的树状结构一定是一样的。 比如说，数组大小为 9 的树状结构肯定是这样的： 12345678910111213 _______________________________| 8 | _______________| 4 | _______ _______ | 2 | | 6 | ___ ___ ___ ___ ___| 1 | | 3 | | 5 | | 7 | | 9 | -- 树状结构 ___ ___ ___ ___ ___ ___ ___ ___ ___| | | | | | | | | | -- 原始数组 1 2 3 4 5 6 7 8 9 -- 索引下标 注意，这里面树状结构中的数字分别是树状数组中的下标，并不是值。 所以，现在只要知道树状数组中，每个下标的对应的是二叉树中的什么节点即可。 3.2 从左往右两两向上合并仔细看树状结构，就会发现： 树状结构的节点是从左往右，相邻节点两两向上合并 比如数组大小为 9，节点从左到右两两向上合并的效果就是： 1234 8 -- 3层 4 8 -- 2层 2 4 6 8 -- 1层1 2 3 4 5 6 7 8 9 -- 0层 其中， 节点 1 和 2 向上合并，得到父节点 2 节点 3 和 4 向上合并，得到父节点 4 … 节点 2 和 4 向上合并，得到父节点 4 树状结构就是这样从左往右，节点两两向上合并建起来的。 3.3 单点修改树状结构的单点修改，需要从下往上更新树节点，所以要知道子节点对应的父节点。 为了方便分析父节点的位置，首先给出一个大小为 18 的树状数组： 12345 16 -- 4层 8 16 -- 3层 4 8 12 16 -- 2层 2 4 6 8 10 12 14 16 18 -- 1层1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- 0层 其中，里面的数字表示的是下标（注意不是值）： 2 是 1 父节点 4 是 2、3 的父节点 8 是 4、6、7 的父节点 16 是 8、12、14、15 的父节点 观察每一层的节点，可以看到： 上一层都是从下一层节点中，按 2 取 1 的方式获取 因此，可以知道每层的节点规律： 0层：起始下标 2^0，间隔 2^0 1层：起始下标 2^1，间隔 2^1 2层：起始下标 2^2，间隔 2^2 3层：起始下标 2^3，间隔 2^3 … k层：起始下标 2^k，间隔 2^k 因为是每隔 1 个节点作为上一层节点，所以可以总结出： 父节点下标 = 等于当前节点下标 + 节点所在层级的间隔 所以找父节点的下标可以这样做： 找到当前节点所在层级 k 父节点下标 = 当前节点的下标 + 2^k 比如说： 5 所在层级是 0，父节点下标 = 5 + 2^0 = 6 12 所在层级是 2，父节点下标 = 12 + 2^2 = 16 不过这里面的当前节点所在层级如何计算？ 节点层级，等于当前索引值的因数中 2 的数量 比如说： 5 = 5，2 的数量有 0 个，所以层级是 0 12 = 2*2*3，2 的数量有 2 个，所以是层级 2 这样就能算出父节点的下标了，就可以不断往上更新父节点了。 所以单点修改的代码最终是这样的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 单点修改void update(int index, int val) { if (index &lt; 0 || index &gt;= n) { return; } // 更新当前节点 tree[index] += val; // 父节点下标 int p = nextP(index); // 往上更新父节点 update(p, val);}// 计算父节点的下标int nextP(int index) { // 当前层级 int k = level(index); // 层级间隔 2^k int g = gap(k); // 父节点下标 int p = index + g; return p;}// 计算当前层级int level(int index) { int k = 0; while (index % 2 == 0) { index &gt;&gt;= 1; k++; } return l;}// 计算层级间隔int gap(int k) { int g = 1; while (k &gt; 0) { gap &lt;&lt;= 1; k--; } return g;} 树状结构的节点取的很有规律，所以很容易算出父节点的位置。 3.4 区间查询首先说明，区间 [l, r] 实际上可以通过前缀和差来计算： [l, r] = (0, r] - (0, l - 1] 所以只要计算出 (0, r] 和 (0, l - 1] 的值，就能知道任意区间和了。 还是大小 18 的树状数组为例： 12345 16 -- 4层 8 16 -- 3层 4 8 12 16 -- 2层 2 4 6 8 10 12 14 16 18 -- 1层1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- 0层 在树状结构定义中，可以知道： 高层级节点 = 它之前的所有低层级节点之和 比如说： 8 表示的是 (0, 8] 的区间和 12 表示的是 (8, 12] 的区间和，因为 8 层级比 12 大 想要计算某个节点的区间和，可以通过前面的高层节点快速得到结果。 比如说，要寻找 (0, 14] 的区间和，按照层级可以分为几部分： (0, 8] (8, 12] (12, 14] 这几个区间加起来，实际上就等于 (0,14] 的区间和了。 只要不断往前找高层级节点，累加起来，就能得到区间和 怎么往前找高层级节点呢？借鉴单点修改的过程： 找到当前节点所在层级 k 前面的高层节点下标 = 当前节点的下标 - 2^k 所以区间查询的代码最终是这样的： 12345678910111213141516171819202122232425262728293031// 区间查询int query(int l, int r) { return query(r) - query(l - 1);}// 区间和 (0, index]void query(int index) { if (index &lt; 0 || index &gt;= n) { return 0; } int sum = 0; // 当前节点值 sum += tree[index]; tree[index] += val; // 前一个高层节点 int p = prevP(index); sum += query(p); return sum;}// 计算前一个高层节点的下标int prevP(int index) { // 当前层级 int k = level(index); // 层级间隔 2^k int g = gap(k); // 前一个高层节点下标 int p = index - g; return p;} 3.5 lowbit 的妙用在前面的处理中，单点更新和查询区间的过程差不多： 单点更新，从下往上，从左至右，寻找高层级节点 区间查询，从下往上，从右至左，寻找高层级节点 单点修改和区间查询都是通过当前层级和层级间隔来找的下一个节点。 然而层级和相邻的高层节点计算有点麻烦，有没有办法优化？ (1) 层级计算 123456789// 计算当前层级int level(int index) { int k = 0; while (index % 2 == 0) { index &gt;&gt;= 1; k++; } return l;} 计算过程就是不断去判断是否能对 2 整除，实际上： 计算层级的过程，等于在找 index 的二进制表示中末尾的 0 的数量 比如说，12 的二进制表示是 1100，对它不断整除 2： 123110011011 所以，不需要整除 2，而是： 只要知道二进制值末尾的 0 数量，就能直接知道层级了 怎么计算二进制值末尾的 0 数量？ 可以通过位运算来处理： 12345678910// 计算当前层级int level(int index) { int l = 0; int m = index &amp; (-index); while (m &gt; 1) { m &gt;&gt;= 1; l++; } return l;} 其中，index &amp; (-index) 可以保留二进制值得最低位 1。 比如 12 的就是 1100 &amp; 0100 = 0100。 (2) 层级间隔 123456789// 计算层级间隔int gap(int k) { int g = 1; while (k &gt; 0) { gap &lt;&lt;= 1; k--; } return g;} 实际上，计算层级间隔的过程就是计算层级的反过程： 计算层级，一直整除 2 计算间隔，一直乘以 2 如果把 level(index) 和 gap(k) 合并起来 gap(index)。 就会发现，两者的位移动会互相抵消掉，最终： 1234// 计算层级间隔int gap(int index) { return index &amp; (-index);} 层级间隔，就等于下标的 index &amp; (-index) 位运算结果。 所以最终获取相邻高层级节点的代码就变成这样了： 123456789101112131415161718192021// 计算后一个高层节点的下标int nextP(int index) { // 层级间隔 2^k int g = gap(index); // 父节点下标 return index + g;}// 计算前一个高层节点的下标int prevP(int index) { // 层级间隔 2^k int g = gap(index); // 前一个高层节点下标 return index - g;}// 计算层级间隔int gap(int index) { return index &amp; (-index);} 在树状数组中，gap(index) 方法一般用 lowBit(index) 表示。 因为 lowBit(index) 刚好取的是 index 的最低位 1 的结果。 总结 树状数组的存储形式是数组，但是实际表示的结构是一棵树 树状数组是为了优化 O(n) 复杂度，提出的一种利用空间换时间的树结构 树状数组主要用于 2 方面操作： 单点修改：时间复杂度 O(logn) 区间查询：时间复杂度 O(logn) 树状数组是利用前缀和差的思想来对树进行剪枝，剪枝后才能保存到数组中 查找前后高层节点时，采用的是一种 lowBit 方法 参考 https://zhuanlan.zhihu.com/p/93795692 https://blog.csdn.net/qq_40941722/article/details/104406126 https://www.jianshu.com/p/7cd5ad2f449a https://leetcode.cn/circle/discuss/qGREiN/ https://oi-wiki.org/ds/fenwick/ 附录完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * 树状数组（二叉索引树） * * @author weijiaduo * @since 2022/10/1 */public class BinaryIndexTree { /** * 树状数组 */ int[] tree; /** * 数组大小 */ int n; public BinaryIndexTree(int n) { this.n = n; tree = new int[this.n]; } /** * 单点修改 * * @param index 指定下标 * @param val 增量修改值 */ public void update(int index, int val) { while (index &lt; n) { tree[index] += val; index = nextP(index); } } /** * 区间查询 * * @param l [l, r] * @param r [l, r] * @return [l, r] 的区间和 */ public int query(int l, int r) { return query(r) - query(l - 1); } /** * 区间查询 * * @param index (0, index] * @return (0, 1] 的区间和 */ private int query(int index) { int sum = 0; while (index &gt; 0) { sum += tree[index]; index = prevP(index); } return sum; } /** * 计算后一个高层节点的下标 * * @param index 当前下标 * @return 后一个高层节点的下标 */ int nextP(int index) { // 层级间隔 2^k int g = lowBit(index); // 父节点下标 return index + g; } /** * 计算前一个高层节点的下标 * * @param index 当前下标 * @return 前一个高层节点的下标 */ int prevP(int index) { // 层级间隔 2^k int g = lowBit(index); // 前一个高层节点下标 return index - g; } /** * index 只剩余最低位 1 的值 * * @param index 值 * @return 只剩余最低位 1 的值 */ private int lowBit(int index) { return index &amp; (-index); }}","link":"/datastructure/tree/binary_index_tree/"},{"title":"并查集","text":"并查集一、什么是并查集？并查集是一种简单的集合表示。 它支持以下 3 种操作： Initial(S)：将集合 S 中的所有元素初始化为一个个单元素集合 Union(S, Root1, Root2)：把集合 S 中的子集合 Root2 并入子集合 Root1 中 Find(S, x)：查找集合 S 中单元素 x 所在的子集合，并返回子集合的名字 通常用树表示每个子集合，子集合的合并就是树的合并。 子集合 Root2 合并到子集合 Root1，只需要把 Root2 的根节点指向 Root1 的根节点即可。 二、为什么要用并查集？ 并查集主要用于解决一些元素分组的问题 并查集可用于管理一系列不相交的集合，执行集合的合并以及搜索元素所在集合 三、如何实现并查集？3.1 集合初始化 Initial(S)12345void initial (int[] s) { for (int i = 0; i &lt; s.length; i++) { s[i] = i; }} 初始化后单个元素就是一个集合 123456789集合 S 存储：[0, 1, 2, 3, 4]------------------------------------------集合示意图： ___ ___ ___ ___ ___| 0 | | 1 | | 2 | | 3 | | 4 | 3.2 子集合合并 Union(S, Root1, Root2)123void union(int[] s, int root1, int root2) { s[root2] = root1;} 比如合并 0 和 1 得到子集合 0： 12345678910111213集合 S 存储：[0, 0, 2, 3, 4]------------------------------------------集合示意图： ___ ___ ___ ___| 0 | | 2 | | 3 | | 4 | ^ | ___| 1 | 再合并 3 和 4 得到子集合 3： 12345678910111213集合 S 存储：[0, 0, 2, 3, 3]------------------------------------------集合示意图： ___ ___ ___| 0 | | 2 | | 3 | ^ ^ | | ___ ___| 1 | | 4 | 还可以把子集合 0 和子集合 3 也合并起来： 123456789101112131415161718集合 S 存储：[0, 0, 2, 0, 3]------------------------------------------集合示意图： ___ ___ | 0 | | 2 | ^ / \\ / \\ ___ ___ | 1 | | 3 | ^ | ___ | 4 | 3.3 查找子集合 Find(S, x)123456int find(int[] s, int x) { while (s[x] != x) { x = s[x]; } return x;} 比如查找 4 所在集合时，过程是这样的： 12345 ___________________ _____ | | | | v | v |[0, 0, 2, 0, 3] 一直往上找，直到根节点为止，就能得到 4 所在的集合。 3.4 元素合并 Union(S, X1, X2)判断两个元素是否属于同一个集合，只需要看它们的根节点是否相同即可。 合并两个元素时，找到它们的根节点合并即可 所以上面的子集合合并代码可以改成这样： 123void union(int[] s, int x1, int x2) { s[find(x2)] = find(x1);} 四、路径压缩简单的并查集，在某些场景下的性能是比较差的，例如： 链条变得越来越长的时候，查找根节点也变得越来越耗时 比如，下面查找元素 5 所在的子集合时，每次都需要经过好几个节点： 1234567891011121314 ___| 1 | ^ | ___| 3 | ^ | ___| 4 | ^ | ___| 5 | 在并查集链比较长的时候，每次搜索元素的根节点，都比较耗时。 那怎么解决这个问题呢？ 并查集中只关注根节点，因此可以采用路径压缩，将元素直接指向根节点 而实现的方法也很简单，就是： 在查询时，把路径上所有节点的父节点都指向根节点 代码上实现的话，可以采用递归，类似这样： 12345678int find(int[] s, int x) { if (s[x] == x) { return x; } else { s[x] = find(s, s[x]); return s[x]; }} 相当于把上面的一条直链，变成了多叉树： 12345678 ___ | 1 | ^ / | \\ / | \\ / | \\ ___ ___ ___| 3 | | 4 | | 5 | 经过路径压缩后，就基本解决了链条过长引起的性能问题。 五、按秩合并路径压缩虽然能解决查询时链条过长的问题，但是路径压缩是在查询时才做的。 当没有查询时，路径不会压缩，还是会出现链路很长的情况 每次查询时，只压缩一条路径，其他路径的链路还是很长 这种情况要如何避免呢？ 在两个子集合进行合并时，只要尽量满足： 把简单的树往复杂的树上合并 就能避免并查集的树深度过大，影响查询的效率。 比如说，2 个子集合长这样： 12345678910 ___ ___| 0 | | 3 | ^ | ___| 1 | ^ | ___ | 4 | 子集合的合并可分为 2 种情况： 3 合并到 0，树深度是还是 2，深度不变 0 合并到 3，树深度变成了 3，深度加深了 所以肯定是把深度小的 3 合并到深度大的 0 更好一些，因为这样可以避免节点深度变得更大。 那怎么知道哪个集合的深度更高呢？ 采用一个额外的数组，记录每个根节点的深度，合并子集合时同时更新 比如说，采用数组 rank 记录节点深度： 初始化时，把所有元素的 rank（秩）设为默认值 1 合并子集合时，比较两个根节点，把 rank 较小合并到较大的上面 代码实现的话就类似这样： 初始化： 123456void initial (int[] s, int[] rank) { for (int i = 0; i &lt; s.length; i++) { s[i] = i; rank[i] = 1; }} 合并子集合： 12345678910111213void union(int[] s, int[] rank, int x1, int x2) { int root1 = find(x1); int root2 = find(x2); if (rank[root1] &gt;= rank[root2]) { s[root2] = root1; // 两棵树深度一样的时候，合并起来会加深一层 if (rank[root1] == rank[root2] &amp;&amp; root1 != root2) { rank[root1]++; } } else { s[root1] = root2; }} 两棵树深度一样的时候，合并起来会加深一层： 123456 ___ ___| 0 | | 3 | ^ ^ | | ___ ___| 1 | | 4 | 1234567891011 ___ | 0 | ^ / \\ / \\ ___ ___| 1 | | 3 | ^ | ___ | 4 | 按秩合并和路径压缩一起用的时候，路径压缩会影响到 rank 值，导致它不准确。 虽然 rank 值不准确，但是不影响 2 者结合一起用。 总结并查集是一种简单的集合表示，包括 3 种操作： Initial(S)：将集合 S 中的所有元素初始化为一个个单元素集合 Union(S, Root1, Root2)：把集合 S 中的子集合 Root2 并入子集合 Root1 中 Find(S, x)：查找集合 S 中单元素 x 所在的子集合，并返回子集合的名字 并查集的作用： 并查集主要用于解决一些元素分组的问题 并查集可用于管理一系列不相交的集合，执行集合的合并以及搜索元素所在集合 并查集有 2 种方法优化方式： 路径压缩：查询时压缩节点路径，直接指向根节点 按秩合并：合并时，深度小的合并到深度大的树上面 按秩合并和路径压缩一起用： 路径压缩会影响到按秩合并的 rank 值，导致它不准确 虽然 rank 值不准确了，但是不影响 2 者结合一起用 参考 《数据结构》王道考研系列 https://zhuanlan.zhihu.com/p/93647900 https://blog.csdn.net/weixin_38279101/article/details/112546053 https://blog.csdn.net/qq_40378034/article/details/103224445 https://destiny1020.blog.csdn.net/article/details/7655764 附录完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 并查集-路径压缩 + 按秩合并 */public class UnionFind { /** * 父节点存储 */ private int[] parent; /** * 节点深度 */ private int[] rank; public UnionFind(int n) { parent = new int[n]; rank = new int[n]; init(n); } /** * 初始化并查集 * * @param n 元素个数 */ private void init(int n) { for (int i = 0; i &lt; n; i++) { parent[i] = i; rank[i] = 1; } } /** * 查找元素 * * @param x 指定元素 * @return 元素根节点 */ public int find(int x) { if (parent[x] == x) { return x; } else { // 路径压缩，会导致 rank 有误差 parent[x] = find(parent[x]); return parent[x]; } } /** * 合并元素子集合 * * @param x1 元素 * @param x2 元素 */ public void union(int x1, int x2) { int root1 = find(x1); int root2 = find(x2); if (root1 == root2) { return; } // 按秩合并 if (rank[root1] &gt; rank[root2]) { parent[root2] = root1; } else if (rank[root1] &lt; rank[root2]) { parent[root1] = root2; } else { // 深度一样的时候，合并起来会加深一层 parent[root2] = root1; rank[root1]++; } }}","link":"/datastructure/tree/union_find/"},{"title":"排序算法的选择","text":"排序算法的选择一、算法汇总 算法 时间复杂度 空间复杂度 是否原地排序 是否稳定排序 冒泡排序 O(n^2) O(1) 是 是 插入排序 O(n^2) O(1) 是 是 选择排序 O(n^2) O(1) 是 否 归并排序 O(nlogn) O(n) 否 是 快速排序 O(nlogn) O(1) 是 否 桶排序 O(n) O(n) 否 是 计数排序 O(n) O(n) 否 是 基数排序 O(n) O(n) 否 是 二、算法分析 算法 适用场景 不适用场景 冒泡排序 数据量小；稳定排序；原地排序 数据量大 插入排序 数据量小；稳定排序；原地排序 数据量大 选择排序 数据量小；原地排序 数据量大；稳定排序 归并排序 数据量小；稳定排序 数据量大；原地排序 快速排序 数据量大；原地排序 稳定排序 桶排序 数据总体分散局部聚集；稳定排序 原地排序 计数排序 数据量大但数值范围小 原地排序 基数排序 数据高低位有递进关系 原地排序 排序算法的一些数据和性能分析： 线性排序算法适用场景比较少，对数据要求比较高 归并排序需要 O(n) 的空间，不适用于大数据量的排序 选择排序是一种不稳定的排序算法 冒泡排序在性能上不如插入排序 不同算法都有各自的优缺点，应该根据实际情况选择不同的算法。 三、算法优化3.1 插入排序插入排序的优化，可以参考希尔排序。 3.2 快速排序如果数据本身就是接近有序的，那么快速排序的复杂度可能会退化为 O(n^2)。 复杂度退化是由于分区点的选择不对，导致每次都不能很好地分成 2 部分数据。 分区点选择的优化方式有几种： 三数取中法 随机法 (1) 三数取中法 分别取左中右三个值，选择三个值中的中间值作为分区点。 这种方式可以较大程度上避免分区不合理的问题。 不过如当数据量比较大时，取 3 个数可能不太够，可以改成取 5 个、10 个等。 (2) 随机法 随机取一个元素作为分区点，随机的话基本上不容易出现最糟糕的情况。 四、综合优化综上，快速排序和插入排序可能是比较好的选择： 在数据量比较小时，可以考虑插入排序和归并排序 在数据量比较大时，使用快速排序 选择算法时，应当根据实际的数据情况来选择。","link":"/algorithm/sort/how_to_select_sort/"},{"title":"希尔排序","text":"希尔排序一、什么是希尔排序？ 希尔排序是一种基于插入排序进行了优化后的排序算法 希尔排序比普通插入排序更适用于大规模数组排序 二、为什么要用希尔排序？普通的插入排序存在一个问题： 对于大规模乱序数组排序很慢 而它这么慢的原因是： 插入排序只是交换相邻元素，因此元素只能一点点从一端移动到另一端 比如说，数组 [7, 2, 3, 5, 6, 4, 1]，插入排序只能一点点地将 1 移动到最前面。 希尔排序为了加快这种情况的排序速度，对插入排序进行了优化： 对数组元素按照指定间隔进行跳跃式的分组 对分组内进行局部排序，交换不相邻的元素 最终用插入排序将局部有序数组进行排序 比如说，数组 [7, 2, 3, 5, 6, 4, 1]。 希尔排序会将其划分为多个组，假设分为 3 组： 1234 ------------------------------------------------- | | | ___ ___ ___ ___ ___ ___ ___| 7 | | 2 | | 3 | | 5 | | 6 | | 4 | | 1 | 1234 ------------------------- | | ___ ___ ___ ___ ___ ___ ___| 7 | | 2 | | 3 | | 5 | | 6 | | 4 | | 1 | 1234 ------------------------- | | ___ ___ ___ ___ ___ ___ ___| 7 | | 2 | | 3 | | 5 | | 6 | | 4 | | 1 | 然后分别对每个组内进行排序： 1234 ------------------------------------------------- | | | ___ ___ ___ ___ ___ ___ ___| 1 | | 2 | | 3 | | 5 | | 6 | | 4 | | 7 | 1234 ------------------------- | | ___ ___ ___ ___ ___ ___ ___| 1 | | 2 | | 3 | | 5 | | 6 | | 4 | | 7 | 1234 ------------------------- | | ___ ___ ___ ___ ___ ___ ___| 1 | | 2 | | 3 | | 5 | | 6 | | 4 | | 7 | 可以看到，1 已经直接移动到最前面了，从一端移动到另一端的速度很快。 而且，在局部有序的情况下，整个数组看起来也基本是有序的了。 希尔排序就是采用间隔分组排序的方式，来优化对大规模的数组排序。 三、如何实现希尔排序？希尔排序的基本思想是按照间隔进行跳跃式分组，并对组内进行排序。 其排序过程是这样： 按照间隔 h 对数组进行跳跃式分组 对每个分组内的元素进行排序 缩小间隔 h，重新回到第 1 步，直到 h = 1 为止 这里面有 2 个核心的点： 分组内的排序 间隔 h 的选择和缩小 3.1 分组内排序一般来说，希尔排序的实现中，分组内排序采用的是插入排序。 比如对这个分组进行插入排序： 1234 ------------------------------------------------- | | | ___ ___ ___ ___ ___ ___ ___| 7 | | 2 | | 3 | | 5 | | 6 | | 4 | | 1 | 1234 ------------------------------------------------- | | | ___ ___ ___ ___ ___ ___ ___| 5 | | 2 | | 3 | | 7 | | 6 | | 4 | | 1 | -- (5 插到 7 前) 1234 ------------------------------------------------- | | | ___ ___ ___ ___ ___ ___ ___| 1 | | 2 | | 3 | | 5 | | 6 | | 4 | | 7 | -- (1 插到 5 前) 所以说希尔排序本质就是插入排序，只是插入的方式有点不同。 3.2 增量序列希尔排序中的间隔 h 变化序列，一般称为增量序列。 比如说，开始间隔 h = n / 2，后面以 h = h / 2 缩小增量： 1n/2 n/4 n/8 ... 1 那么这样的一个序列，就称为增量序列。 目前来说，希尔排序的增量序列的选择还没有最优的方案 因为增量序列的选择和证明还是一个数学难题。 除了上面取中的增量序列，在《算法》一书中还给出了 2 种增量序列： 11, 4, 13, 40, 121, 364 ... (h = 3 * h + 1) 11, 5, 19, 41, 109, 209, 505, 929, 2161, 3905, 8929, 16001, 36289, 64769, 146305, 260609 希尔排序的性能会受到增量序列的影响，但是目前暂时没有办法证明哪个增量序列是最优的。 四、参考代码123456789101112131415161718192021222324252627282930313233/** * 希尔排序 * &lt;p&gt; * 时间复杂度：暂时无法分析，但是达不到 O(n^2) * &lt;p&gt; * 空间复杂度：O(1) * &lt;p&gt; * 稳定性：不稳定 */public void shellSort(int[] arr) { int n = arr.length; // 递增序列：1, 4, 13, 40, 121, ... int h = 1; while (h &lt; n / 3) { h = 3 * h + 1; } // 增量序列倒序递减至 1 while (h &gt;= 1) { // 局部插入排序 for (int i = h; i &lt; n; i++) { int x = arr[i]; int j = i; for (; j &gt;= h &amp;&amp; x &lt; arr[j - h]; j -= h) { arr[j] = arr[j - h]; } arr[j] = x; } // 递减 h 间隔 h /= 3; }} 总结 希尔排序是一种基于插入排序进行了优化后的排序算法 希尔排序比普通插入排序更适用于大规模数组排序 希尔排序的关键点包括增量序列的选择和分组内排序 目前还没有找到最优的增量序列 暂时无法证明希尔排序的时间复杂度 参考 https://www.cnblogs.com/chengxiao/p/6104371.html","link":"/algorithm/sort/shellsort/"},{"title":"散列表","text":"散列表一、什么是散列表？1.1 定义散列表，也称为哈希表，其定义如下： 散列表是一种能够根据关键字，直接访问到值的数据结构 散列表建立了关键字和存储地址之间的一种直接映射关系 通常，关键字称为 Key，对应的值称为 Value。 因此散列表也可以说是： 将 Key 直接“映射”到一张“记录表”上，以此找到 Value 的地址 其中，“映射”方式，称为散列函数，存储记录的表就称为哈希表。 哈希表的映射逻辑类似这样： 12345678910111213141516Key 散列函数 散列表 ________ -------&gt; | value4 | | ________ key1 --------- | | | | | ________ key2 --------- -------&gt; | value1 | | | ________ key3 --------------&gt; hash(key) ----------&gt; | value5 | | | ________key4 --------- | | | | | ________key5 --------- -------&gt; | value2 | | _________ -------&gt; | value3 | 一般来说： 散列表底层存储结构是数组 散列函数负责将 Key 映射到数组索引，即 Value 地址 映射的地址，取决于散列函数，不同散列函数可能会不一样。 1.2 结构常见的散列表结构（数组 + 链表）如下： 1234567891011121314 ___ 0 | | ___ ___ ____1 | 8 | ---&gt; | 1 | ---&gt; | 22 | ___ 2 | 9 | ___ ____ 3 | 3 | ---&gt; | 17 | ___ ____ ____ ____ 4 | 4 | ---&gt; | 32 | ---&gt; | 18 | ---&gt; | 46 | ___5 | | ___ 6 | 6 | 这里的散列函数是取余 key % 7，将关键字（整数）映射到了数组索引。 比如说 22 % 7 = 1，那么 22 就放在了数组索引为 1 的位置上。 1.3 例子举个更具体的例子来说。 手机通讯录中，联系人是按照拼音的首字母排序的，暂记为通讯录 [A - Z]。 假如要找张三，其首字母是 Z，那么就能直接定位到通讯录中以 Z 开头的地方，再开始查找。 通讯录 [A - Z] 实际上就是散列表，将关键字（张三），映射到地址（Z）。 二、为什么要用散列表？2.1 “比较”和“映射”线性的数组、链表，非线性的树、图等，一般都是基于“比较”来查找的。 对于这些数据结构，查找的效率取决于“比较”的次数 如果要找某个值，就必须遍历结构中的数据，逐个“比较”直到找到结果。 这种基于“比较”的查找方法，数据量越大，性能就会越差 因为数据量变大会导致“比较”次数变多，耗时就更长了。 而散列表则是用了另一种方式，不是基于“比较”寻值，而是从键直接“映射”到数据地址 理想情况下，散列表的查找与数据量无关，不会因为数据量变大而导致性能降低 所以散列表的一个主要作用就是： 解决大数据量情况下，快速定位值的问题 散列表带来的性能提升，不是凭空得来的，而是一种用空间换时间的实现方式。 三、如何实现散列表？3.1 快速地址访问散列表是通过 Key 得到 Value 地址后，访问地址才能拿到数据。 比如说，Key = 22，通过计算得到了索引地址 22 % 7 = 1。 但是 1 只是一个索引地址，不是数据，实际上真正的数据是 arr[1]。 如果不能通过地址快速访问到数据，那散列表就没有意义了 所以散列表的一个基本要求就是： 通过映射地址能快速定位到对应的数据 而数组刚好有这个功能： 数组支持通过索引随机访问，提供了快速访问地址数据的手段 所以，散列表基本都是基于数组实现的： 散列表底层用数组作为存储结构 实际是利用了数组的随机访问特性 散列表不一定都是数组实现，只是数组刚好能够完美地实现。 实际上只要能够快速访问地址的数据结构，都可以用到散列表里。 3.2 散列设计散列就是将关键字映射到地址，所以散列的设计至关重要。 散列必须能够映射所有可能的关键字 散列对于同一个关键字，映射地址应该保持一致 散列应该尽可能的把映射地址均匀分布开来 散列应该尽量简单，能够短时间计算出来 这是散列的几个基本要求，另外还包括： 散列设计还要包括散列冲突的解决策略 3.3 散列冲突散列是将关键字映射到地址，而地址就是数组的索引。 因为是映射到索引，所以要明确一点： 不同关键字，映射的索引地址可能存在冲突 这是因为数组空间是有限的，而关键字可能是无限的： 不管怎么设计散列，都不可避免的会出现冲突 所以，要求散列设计的时候，要同时考虑： 散列冲突了怎么解决？ 散列冲突的处理有多种方式，可以视实际情况选择。 3.4 负载扩容当数组内的空间基本都用完时，散列冲突的概率会非常高。 这个时候要怎么办？因为是空间不足，所以需要做的就是： 对散列表的数组进行扩容 那什么时候进行扩容呢？等到数组空间用完的时候吗？ 等到用完空间再扩容的话，就太晚了，所以一般是： 在数组空间被占用了大部分的时候，才开始扩容 如何判断空间被占用了大部分？一般使用负载因子判断： 负载因子 = 散列表中的元素 / 散列表的数组大小 比如说，散列表数组大小是 10， 此时散列表元素数量是 7： 那么负载因子就是 7 / 10 = 0.7。 负载因子越大，表明散列表越满，空间越少 所以，可以根据负载因子判断是否要数组扩容： 只要负载因子达到某个阈值，就可以认为要对数组扩容了 四、散列函数构造散列函数，就是将关键字映射到地址的函数。可以记为： 1Hash(key) = Addr 散列函数的构造要求，遵循的就是散列设计的要求。 常见的散列函数有： 4.1 直接定址法直接取关键字的某个线性函数值，作为散列地址。 1H(key) = a * key + b 线性映射不会造成散列冲突，适合关键字连续的情况。 若是关键字不连续，则会导致空位较多，浪费空间。 4.2 除留余数法取关键字被某个不大于散列表表长 m 的数 p 除后所得的余数为散列地址。 1H(key) = key % p 其中 q &lt; m。 这种方式简单，最常用，但是因为对数数值取余的原因，有可能会出现散列冲突。 关键在于选好 p，不同的 p 对空间的利用是不同的。 4.3 数字分析法取数码分布较为均匀的若干位作为散列地址。 1H(key) = key &amp; mask 比如说关键字是 10 位数，类似这样的： 123100123456710023456781003456789 关键字中有些数位的码字是分布不均匀的，比如前 3 位 100 都是一样的。 这个时候就不要用 100 作为散列地址了，因为很容易就散列冲突了。 应该取比较均匀的其他数位作为散列地址，比如这里的后 7 位。 这种方法适合关键字集合已知的情况，如果关键字的分布情况变了，散列函数也需要重新构造。 4.4 平方取中法取关键字的平方值的中间几位作为散列地址。 1H(key) = (key * key) &amp; mask 具体取多少位，视情况而定。 适用于关键字每一位取值都不够均匀，或者小于散列地址所需位数的情况。 这种方法得到的散列地址与关键字的每一位都有关系，使得散列地址分布比较均匀。 4.5 折叠法将关键字分割成位数相同的几部分，然后取这几部分的叠加和作为散列地址。 123H(key) = (key &amp; mask1) | (key &amp; mask2) | (key &amp; mask3)mask2 = mask1 &lt;&lt; k, mask3 = mask2 &lt;&lt; k 适用于关键字位数较多，且每一位的数字分布大致均匀的情况。 五、散列冲突处理散列冲突是不可避免的，那一般怎么处理散列冲突呢？ 常见的解决方法分为 2 种： 开放寻址法 拉链法 下面分别说明这 2 种方法。 5.1 开放寻址法开放寻址法，指的是在其他散列地址空闲的位置，插入冲突的数据。 这就意味着，关键字散列到的地址，对应的数据不一定是它的，有可能是别人占用了。 其数学递推公式是： 1hi = (H(key) + di) % m 其中，i = 1,2,3…，m 表示散列表长，di 为增量序列。 当选定某一增量序列后，对应的处理方法就确定了，常见的增量序列有以下几种。 5.1.1 线性探测线性探测，就是增量为 1 的序列 d = 1, 2, 3, … 探测过程就是，如果出现冲突，就按顺序查看表中下一个单元，找到第一个空闲位置（直到遍历完整张表）。 比如散列函数是取余 H(key) = key % 5，当前数组是这样的： 12345678910 ___ 0 | | ___1 | 1 | ___ 2 | | ___3 | | ___ 4 | 4 | 此时插入一个 6，6 % 5 = 1，对应地址是 1，但是此时已经有人占用了。 按顺序往下找一个空位，找到了 2 的位置，然后插入： 12345678910 ___ 0 | | ___1 | 1 | ___ 2 | 6 | ___3 | | ___ 4 | 4 | 接着再插入一个 15，11 % 5 = 1，还是地址 1。 按顺序往下找，直至找到了 3，最后放进去： 12345678910 ____ 0 | | ____1 | 1 | ____ 2 | 8 | ____3 | 11 | ____ 4 | 4 | 这种情况下，散列地址 1 实际上是占用了 2 和 3 的空间。 线性探测会导致同一个地址的数据聚集在一起，而且占用相邻地址的空间。 5.1.2 平方探测平方探测，就是增量为平方的序列 d = 1^2, 2^2, 3^2, 4^2, … 线性探测会导致数据堆积，所以增量步长换成了它的平方，避免堆积问题。 缺点是不能探测到散列表上的所有位置，但至少能探测到一半。 5.1.3 再散列再散列，就是增量序列是用另一个散列函数生成的 d = H2(key)。 再散列的增量序列就是： 12345d1 = H2(H(key))d2 = H2(d1)d3 = H2(d2)d4 = H2(d3)... 比如说，再散列函数是 H2(d) = (4 * d + 3) % 5。 假如散列值地址是 H(key) = 1，那么它对应的增量序列就是： 12H2(1) = (4 * 1 + 3) % 5 = 2H2(2) = (4 * 2 + 3) % 5 = 1 也即是，冲突探测地址分别是 [1, 1 + 2, 1 + 2 + 1] = [1, 3, 2]。 再散列就是用额外的散列函数生成增量序列，达到寻找空位的目的。 5.1.4 伪随机序列伪随机序列，就是使用伪随机数作为增量序列。 为什么是伪随机数？因为散列函数的一个要求是： 同一个关键字，对应的地址必须相等 如果使用了真的随机数，那么同一个关键字映射的地址就不确定了。 所以只能用伪随机数。 5.2 拉链法开放寻址法，是用别的地址来存储自己地址的数据，这就很容易导致冲突。 拉链法，不占用别人的空间，而是将相同地址的数据放到一条链表里。 其大概结构如下： 123456789101112 ___ 0 | | ___ ___ ____1 | 8 | ---&gt; | 1 | ---&gt; | 22 | ___ 2 | 9 | ___ ____ 3 | 3 | ---&gt; | 17 | ___ ____ ____ ____ 4 | 4 | ---&gt; | 32 | ---&gt; | 18 | ---&gt; | 46 | ___5 | | 相同地址冲突的数据，会形成一条链表，这样就可以避免冲突的问题。 拉链法适用于经常进行插入和删除的情况。 小结开放寻址法： 使用原本的数组空间，会占用到别的地址来存放同地址的数据 不能直接删除，否则会导致冲突寻址序列中断 适合当数据量比较小、装载因子小的情况 拉链法： 新开额外的链表空间，存放同地址的数据 适合存储大对象、大数据量的情况 适合经常进行插入和删除的情况 六、散列表的性能分析散列表的查找效率取决于 3 个因素： 散列函数：散列函数直接关系到冲突的概率，冲突概率越高，查询效率就越低 处理冲突的方法：不同的处理冲突的方法，也会导致查询长度变化，从而影响查询效率 负载因子：直观上看，负载因子越大，散列表越满，冲突也就也多，查找的效率也就越低 散列表的查询性能，是实时变化的，随着数据分布情况和数据量而变化。 一般来说，散列表的平均查找长度依赖于负载因子，负载因子越大，平均查找长度就越大。 所以应该尽量避免负载因子过大。 七、散列表的特点 查找速度快：正常情况下是 O(1) 的查找效率 额外空间浪费：很难做到用完数组的空间，总是会有一些剩余空位 数据无序：散列表是通过关键字直接映射的地址，不保证数据在数组中的顺序 产生冲突：很难设计一个没有冲突的散列函数 八、散列表的应用场景 适合大数据量下快速查找 适合缓存，快速定位 总结设计散列表时，有几个关键的地方： 散列函数的设计 散列冲突的处理 动态的负载扩容 散列函数的设计要求： 散列必须能够映射所有可能的关键字 散列对于同一个关键字，映射地址应该保持一致 散列应该尽可能的把映射地址均匀分布开来 散列应该尽量简单，能够短时间计算出来 散列冲突的处理： 开放寻址法： 使用原本的数组空间，会占用到别的地址来存放同地址的数据 不能直接删除，否则会导致冲突寻址序列中断 适合当数据量比较小、装载因子小的情况 拉链法： 新开额外的链表空间，存放同地址的数据 适合存储大对象、大数据量的情况 适合经常进行插入和删除的情况 参考 http://data.biancheng.net/view/107.html https://zhuanlan.zhihu.com/p/537528259 http://t.zoukankan.com/Yunrui-blogs-p-11967732.html 附录散列表-开放寻址法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198/** * 散列表-开放寻址法 * &lt;p&gt; * 散列函数：折叠法 + 取余 * &lt;p&gt; * 散列冲突：线性探测法 */public class OpenHashTable implements HashTable { /** * 散列表数组 */ Node[] table; /** * 元素数量 */ int size; /** * 负载因子 */ double factory; static class Node { final int key; int value; boolean deleted; public Node(int key, int value) { this.key = key; this.value = value; } } public OpenHashTable() { this(16); } public OpenHashTable(int capacity) { this(capacity, 0.75); } public OpenHashTable(int capacity, double factory) { if (capacity &lt;= 0) { capacity = 16; } table = new Node[capacity]; size = 0; this.factory = factory; } @Override public void put(int key, int value) { boolean succeed = false; int length = table.length; int index = hash(key); for (int i = 0; i &lt; length; i++) { Node node = table[index]; // 插入节点 if (node == null || node.deleted) { node = new Node(key, value); table[index] = node; size++; succeed = true; break; } // 更新节点 if (node.key == key) { node.value = value; succeed = true; break; } index = conflict(index); } // 验证添加结果 if (!succeed) { // 没有添加成功，扩容后再尝试 resize(); put(key, value); } else { // 添加成功后，检查是否需要扩容 checkResize(); } } @Override public int remove(int key) { int index = findIndex(key); if (index &lt; 0) { return -1; } // 只标记删除，不清除节点 Node node = table[index]; node.deleted = true; size--; return node.value; } @Override public int get(int key) { int index = findIndex(key); if (index &lt; 0) { return -1; } return table[index].value; } @Override public boolean contains(int key) { return findIndex(key) != -1; } @Override public int size() { return size; } /** * 查找指定key的索引位置 * * @param key 关键字 * @return 对应的索引/-1表示不存在 */ protected int findIndex(int key) { int length = table.length; int index = hash(key); for (int i = 0; i &lt; length; i++) { Node node = table[index]; if (node == null) { return -1; } // key 值存在，且没有删除标记 if (node.key == key &amp;&amp; !node.deleted) { return index; } index = conflict(index); } return -1; } /** * 散列函数 * &lt;p&gt; * 关键字低 16 位和高 16 位进行异或运算，然后取余 * * @param key 关键字 * @return 散列地址 */ protected int hash(int key) { return ((key ^ (key &gt;&gt;&gt; 16)) &amp; 0xFFFF) % table.length; } /** * 散列冲突的下一个序列值 * &lt;p&gt; * 线性探测法 * * @param index 索引 * @return 冲突的下一个索引 */ protected int conflict(int index) { return (index + 1) % table.length; } /** * 检查并进行数组扩容 */ protected void checkResize() { // 大于负载因子时，进行扩容 if (1.0 * size / table.length &gt; factory) { resize(); } } /** * 动态扩容 */ protected synchronized void resize() { // 数组进行 2 倍扩容 Node[] oldTable = table; int newLength = oldTable.length &lt;&lt; 1; table = new Node[newLength]; // 重新映射数组元素 for (Node node : oldTable) { if (node.deleted) { continue; } int index = hash(node.key); while (table[index] != null) { index = conflict(index); } table[index] = node; } }} 散列表-拉链法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215/** * 散列表-拉链法 * &lt;p&gt; * 散列函数：折叠法 + 取余 * &lt;p&gt; * 散列冲突：双向拉链法 */public class LinkedHashTable implements HashTable { /** * 散列表数组 */ Node[] table; /** * 元素数量 */ int size; /** * 负载因子 */ double factory; static class Node { final int key; int value; Node prev; Node next; public Node(int key, int value) { this.key = key; this.value = value; } } public LinkedHashTable() { this(16); } public LinkedHashTable(int capacity) { this(capacity, 0.75); } public LinkedHashTable(int capacity, double factory) { if (capacity &lt;= 0) { capacity = 16; } table = new Node[capacity]; size = 0; this.factory = factory; } @Override public void put(int key, int value) { int index = hash(key); Node head = table[index]; if (head == null) { // 数组链表头节点 table[index] = new Node(key, value); } else { // 查找 key 值是否存在 Node node = head, prev = null; while (node != null &amp;&amp; node.key != key) { prev = node; node = node.next; } // 更新节点 if (node != null) { node.value = value; return; } // 追加节点 node = new Node(key, value); prev.next = node; node.prev = prev; } size++; // 检查是否需要扩容 checkResize(); } @Override public int remove(int key) { int index = hash(key); Node head = table[index]; if (head == null) { return -1; } // 查找 key 的节点 Node node = head; while (node != null &amp;&amp; node.key != key) { node = node.next; } if (node == null) { return -1; } // 移除链表节点 if (node.prev == null) { // 数组链表头节点 table[index] = node.next; node.next = null; } else if (node.next == null) { // 链表尾节点 node.prev.next = null; node.prev = null; } else { // 链表中间节点 node.next.prev = node.prev; node.prev.next = node.next; node.prev = node.next = null; } size--; return node.value; } @Override public int get(int key) { Node node = find(key); if (node == null) { return -1; } return node.value; } @Override public boolean contains(int key) { return find(key) != null; } @Override public int size() { return size; } /** * 查找指定key的索引位置 * * @param key 关键字 * @return 对应的索引/-1表示不存在 */ protected Node find(int key) { int index = hash(key); Node node = table[index]; if (node == null) { return null; } while (node != null &amp;&amp; node.key != key) { node = node.next; } return node; } /** * 散列函数 * &lt;p&gt; * 关键字低 16 位和高 16 位进行异或运算，然后取余 * * @param key 关键字 * @return 散列地址 */ protected int hash(int key) { return ((key ^ (key &gt;&gt;&gt; 16)) &amp; 0xFFFF) % table.length; } /** * 检查并进行数组扩容 */ protected void checkResize() { // 大于负载因子时，进行扩容 if (1.0 * size / table.length &gt; factory) { resize(); } } /** * 动态扩容 */ protected synchronized void resize() { // 数组进行 2 倍扩容 Node[] oldTable = table; int newLength = oldTable.length &lt;&lt; 1; table = new Node[newLength]; // 重新映射数组元素 for (Node head : oldTable) { for (Node node = head; node != null; ) { Node next = node.next; // 从旧链表断开 node.prev = node.next = null; // 连接到新链表 int index = hash(node.key); if (table[index] == null) { // 链表头节点 table[index] = node; } else { // 添加到链表尾部 Node tail = table[index]; while (tail.next != null) { tail = tail.next; } tail.next = node; node.prev = tail; } node = next; } } }}","link":"/datastructure/hash/hashtable/"},{"title":"跳表","text":"跳表一、什么是跳表？跳表，又叫做跳跃表、跳跃列表。 是一种对有序链式线性表的优化 在原始链表的基础上添加了多级索引链表 分为多层，从下往上分别是原始链表、一级索引、二级索引… 搜索时从上往下，实现了类似“二分查找”的功能 它的结构大概是这样的： 12345678 ___ ___| 1 | ----------------------------&gt; | 5 | -- 二级索引 | | ___ ___ ___| 1 | ----------&gt; | 3 | ----------&gt; | 5 | -- 一级索引 | | | ___ ___ ___ ___ ___ ___| 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | -- 原始链表 跳表就是对有序链表的一种优化，通过添加多级索引来提升性能。 跳表本质上是一种利用空间来换时间的数据结构。 二、为什么要用跳表？2.1 引入背景对于链表来说，查找某个值，只能通过遍历的方式实现，时间复杂度是 O(n)。 即使链表是有序的，依旧也只能是从头到尾遍历，完全没有用到数据的有序性。 12 ___ ___ ___ ___ ___ ___| 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | 在这种情况下，有没有办法用到链表的有序性？ 给链表建立索引，方便快速定位数据的区间范围 比如说，链表的每2个节点就提取出一个索引节点： 12345 ___ ___ ___| 1 | ----------&gt; | 3 | ----------&gt; | 5 | -- 索引 | | | ___ ___ ___ ___ ___ ___| 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | -- 原始链表 通过索引先快速定位到区间 [1, 3]、[3, 5] 以及 [5, +]，缩小范围，再小范围遍历搜索。 比如说，查找数值 4： 首先在索引层遍历判断，发现 4 是在区间 [3, 5] 内的 然后找到了原始链表的 3，再从 3 开始往右遍历，直到找到 4 4 的搜索链路就是：1 -&gt; 3 -&gt; 4，这定位速度就比遍历快多了。 有时候建第一层索引后，遍历范围还是很大（第一层索引的节点数量是 n/2）。 这个时候还可以再往上多建几层索引： 12345678 ___ ___| 1 | ----------------------------&gt; | 5 | -- 二级索引 | | ___ ___ ___| 1 | ----------&gt; | 3 | ----------&gt; | 5 | -- 一级索引 | | | ___ ___ ___ ___ ___ ___| 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | -- 原始链表 这种在原始链表上建多层索引，实现快速查找的数据结构，就是跳表。 2.2 算法分析原始有序链表的算法复杂度是： 搜索：时间 O(n)，空间 O(1) 删除：时间 O(n)，空间 O(1) 插入：时间 O(n)，空间 O(1) 跳表的算法复杂度如何呢？以 2 个节点 1 个索引的跳表为例。 1）空间复杂度 跳表的多层索引，从下往上数的话，节点数量分别是： 1n/2, n/4, n/8, ..., 2 总共是 n/2 + n/4 + ... + 2 = n - 2，也就是说： 跳表结构本身的空间复杂度是 O(n) 2）时间复杂度 根据上面的结构，跳表的层级数量很容易知道： 跳表的索引层级数量是 logn 链表的插入和删除，实际上是依赖于搜索，所以只要分析搜索的时间复杂度即可。 因为每 2 个节点对应 1 个索引节点，所以每一层的搜索节点数量不会超过 3。 比如上一层索引确定了区间 [3, 5]，那么往下一层搜索，搜索只能是 3,4,5。 因此跳表的时间复杂度，依赖于每层遍历的节点数量： 搜索：时间 O(m * logn) 删除：时间 O(m * logn) 插入：时间 O(m * logn) 其中 m 是每层最多遍历的节点数量。 跳表将原始链表的时间复杂度从 O(n) 提升到了 O(logn) 级别。 当然，这是利用空间换时间才得到的，空间消耗变多了。 三、跳表如何实现？跳表的实现方式可以分为2种： 数组实现：由一个数组实现，数组内部包含多层索引指针 链表实现：有多条链表实现，每条链表一层索引 它们的区别只在于底层存储不同，对外是一致的。 下面以链表实现为例，说明跳表的实现。 3.1 跳表的定义3.1.1 结构定义为了减少代码中的判空，采用了一个哨兵头节点，所以实际的跳表结构是这样的： 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | | ___ ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 顶层的 head 节点单独一层，并且这一层只有它一个非空节点。 3.1.2 接口定义1234567891011121314151617181920212223242526public interface SkipList&lt;T extends Comparable&lt;T&gt;&gt; { /** * 搜索指定值是否存在 * * @param value 指定值 * @return true存在/false不存在 */ boolean search(T value); /** * 添加新值 * * @param value 新值 */ void add(T value); /** * 删除指定值 * * @param value 指定值 * @return true删除成功/false删除失败 */ boolean erase(T value);} 3.1.3 链式跳表的定义123456789101112131415161718public class LinkedSkipList&lt;T extends Comparable&lt;T&gt;&gt; implements SkipList&lt;T&gt; { class Node { // 节点值 T value; // 同一层的右侧节点指针 Node right; // 下一层的同值节点指针 Node down; public Node(T value, Node right, Node down) { this.value = value; this.right = right; this.down = down; } }} 3.2 跳表的搜索3.2.1 代码实现跳表的搜索，就是从顶层的索引开始，一层一层往下找，直到找对对应的节点为止。 123456789101112131415public boolean search(T value) { Node p = head, q = null; // 从上往下一直找，直到最底层的原始链表为止 while (p != null) { // 在当前层遍历搜索，直到找到 value 所在区间 while (p.right != null &amp;&amp; value.compareTo(p.right.value) &gt; 0) { p = p.right; } // 搜索下一层 q = p; p = p.down; } // 验证节点值是否相等 return q != null &amp;&amp; q.right != null &amp;&amp; q.right.value.equals(value);} 3.2.2 结构示意搜索过程就类似下面这样（暂时忽略其他线）： 123456789101112head ___| | | ___ ___ ___| | -&gt; | 1 | | 5 | | ___ ___ ___ ___| | | 1 | ----------&gt; | 3 | | 5 | | ___ ___ ___ ___ ___ ___ ___| | | 1 | | 2 | | 3 | -&gt; | 4 | | 5 | | 6 | 很简单，就是一层一层找符合范围的区间，直到最底层的原始链表。 3.3 跳表的插入3.3.1 代码实现插入节点，除了要知道插入点的位置，还要知道上一层跳到下一层的转折节点。 因为插入节点，不仅仅是插入最底层，上面的索引层也需要一起更新。 12345678910111213141516171819202122232425262728/** * 查找指定值的前置路径 * * @param value 指定值 * @return 前置路径 */private List&lt;Node&gt; findProcessors(T value) { Deque&lt;Node&gt; stack = new ArrayDeque&lt;&gt;(); Node p = head; // 从上往下一直找，直到最底层的原始链表为止 while (p != null) { // 在当前层遍历搜索，直到找到 value 所在区间 while (p.right != null &amp;&amp; value.compareTo(p.right.value) &gt; 0) { p = p.right; } // 记录上一层节点 stack.push(p); // 搜索下一层 p = p.down; } // 路径是倒序摆放的，最接近值 value 的在索引 0 的位置 List&lt;Node&gt; path = new ArrayList&lt;&gt;(stack.size()); while (!stack.isEmpty()) { path.add(stack.pop()); } return path;} 查找返回的是目标节点的前置路径： 前置路径是搜索过程中上一层跳到下一层的那个转折节点列表 比如上面搜索 4 时，搜索路径是 1-&gt;3-&gt;4，那么得到的前置路径就是 [3, 1]。 为什么前置路径是倒序的？ 因为插入节点是从下往上插入的，为了方便就倒序返回了 找到前置路径后，就可以准备插入节点了： 12345678910111213141516171819202122public void add(T value) { List&lt;Node&gt; processors = findProcessors(value); int levels = processors.size(); Node newNode = null; boolean insertUp = true; for (int i = 0; i &lt; levels &amp;&amp; insertUp; i++) { Node processor = processors.get(i); // 新节点指向下一层的同值节点 newNode = new Node(value, processor.right, newNode); // 在当前层插入新节点 processor.right = newNode; // 是否要继续往上一层插入节点 insertUp = random.nextDouble() &lt; FACTOR; } // 更新层级 if (insertUp) { levelUp(); }} 3.3.2 结构示意比如插入前跳表的结构是这样的： 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | ----------&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 此时插入一个 3，插入过程是从下往上的： 1）第一次插入 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 2）第二次插入 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | | ___ ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 至于需要插入多少层，这个是通过随机数控制的。 采用了随机数 random.nextDouble() &lt; FACTOR，来判断要不要往上一层插入节点。 为什么采用随机数？ 为了减少算法代码的复杂度 同时又尽量确保跳表的结构平衡 跳表本身代码就比较简单，如果为了维持结构而引入其他复杂算法，显得得不偿失。 随机数就很合适，使用不复杂，而且能大概率保证跳表结构不会严重退化。 3.3.3 提升层级如果节点被插入到了顶层，这个时候需要提升整个跳表的层级。 比如 3 节点被插入到顶层后，跳表结构变成了这样： 123456789101112head ___ ___| | -------------------&gt; | 3 | ------------------------------&gt; null | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | | ___ ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 为了维持跳表头节点在单独一层的结构，就需要提升层级： 1234567/** * 提升层级 */private void levelUp() { // 最上层只有一个头节点 head = new Node(null, null, head);} 提升层级后，跳表的结构就恢复正常了： 123456789101112131415head ___| | ---------------------------------------------------------&gt; null | ___ ___| | -------------------&gt; | 3 | ------------------------------&gt; null | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | | ___ ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | -&gt; | 3 | -&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 3.4 跳表的删除3.4.1 代码实现删除和插入过程是一样的，都是先找到前置路径后，再处理节点： 123456789101112131415161718192021222324public boolean erase(T value) { List&lt;Node&gt; processors = findProcessors(value); // 验证删除节点是否存在，没有找到则直接返回 Node target = processors.get(0).right; if (target == null || !value.equals(target.value)) { return false; } // 从下往上，逐层删除指定节点 for (Node processor : processors) { // 指定 value 值的节点在每一层都删完了，就跳出循环 Node delNode = processor.right; if (delNode == null || !delNode.value.equals(value)) { break; } processor.right = delNode.right; } // 更新层级 levelDown(); return true;} 3.4.2 结构示意删除也和插入一样，是从下往上的。比如删除 3： 1）第一次删除 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___| | -&gt; | 1 | ----------&gt; | 3 | ----------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | ----------&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 2）第二次删除 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___| | -&gt; | 1 | ----------------------------&gt; | 5 | ------------&gt; null | | | ___ ___ ___ ___ ___ ___| | -&gt; | 1 | -&gt; | 2 | ----------&gt; | 4 | -&gt; | 5 | -&gt; | 6 | ---&gt; null 3.4.3 降低层级删除节点后，有可能导致跳表的上层节点变得比较少，此时需要降低层级。 比如把 1 和 5 都删掉后： 123456789101112head ___| | ---------------------------------------------------------&gt; null | ___ | | ---------------------------------------------------------&gt; null | ___ | | ---------------------------------------------------------&gt; null | ___ ___ ___ ___| | ----------&gt; | 2 | ----------&gt; | 4 | ----------&gt; | 6 | ---&gt; null 上面几层链表都空了，浪费空间，这个时候需要将这些节点很少的层级删除： 1234567891011121314/** * 降低层级 */private void levelDown() { while (head.down != null) { // 连续 2 层为空时，才降低层级，因为最上层只有 1 个头节点 if (head.right != null || head.down.right != null) { break; } Node p = head; head = head.down; p.down = null; }} 删除后，跳表又恢复成正常的结构了： 123456head ___| | ---------------------------------------------------------&gt; null | ___ ___ ___ ___| | ----------&gt; | 2 | ----------&gt; | 4 | ----------&gt; | 6 | ---&gt; null 四、跳表的应用场景跳表设计的目的，是为了快速查找。所以它比较适合这些场景： 是有序链表，无序链表用不了 多次查询链表，注意是多次，只查一次的话不如直接遍历 较少的插入和删除，虽然跳表的插入删除性能不差，但是其目的不在于此 其实本质上， 跳表就是二分查找的链表实现版本 所以有序数组二分查找适用的场景，基本适用于有序链表的跳表。 参考 https://leetcode.cn/problems/design-skiplist/ https://blog.csdn.net/yjw123456/article/details/105159817/ https://blog.csdn.net/weixin_45480785/article/details/116293416 https://baijiahao.baidu.com/s?id=1710441201075985657&amp;wfr=spider&amp;for=pc 附录跳表接口1234567891011121314151617181920212223242526272829303132/** * 跳表接口 * * @author weijiaduo * @since 2022/7/28 */public interface SkipList&lt;T extends Comparable&lt;T&gt;&gt; { /** * 搜索指定值是否存在 * * @param value 指定值 * @return true存在/false不存在 */ boolean search(T value); /** * 添加新值 * * @param value 新值 */ void add(T value); /** * 删除指定值 * * @param value 指定值 * @return true删除成功/false删除失败 */ boolean erase(T value);} 链表实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171/** * 跳表（链表） * * @author weijiaduo * @since 2022/7/28 */public class LinkedSkipList&lt;T extends Comparable&lt;T&gt;&gt; implements SkipList&lt;T&gt; { class Node { T value; Node right; Node down; public Node(T value, Node right, Node down) { this.value = value; this.right = right; this.down = down; } } /** * 默认最大层级 */ static final int DEFAULT_MAX_LEVEL = 32; /** * 随机因子 */ static final double FACTOR = 0.25; /** * 哨兵头节点 */ Node head; /** * 最大层级 */ int maxLevels; /** * 随机数 */ Random random = new Random(); public LinkedSkipList() { this(DEFAULT_MAX_LEVEL); } public LinkedSkipList(int maxLevels) { this.maxLevels = maxLevels; this.head = new Node(null, null, null); } @Override public boolean search(T value) { Node p = head, q = null; // 从上往下一直找，直到最底层的原始链表为止 while (p != null) { // 在当前层遍历，直到找到 value 所在区间 while (p.right != null &amp;&amp; value.compareTo(p.right.value) &gt; 0) { p = p.right; } // 记录上一层的转折点 q = p; // 搜索下一层 p = p.down; } return q != null &amp;&amp; q.right != null &amp;&amp; q.right.value.equals(value); } @Override public void add(T value) { List&lt;Node&gt; processors = findProcessors(value); int levels = processors.size(); Node newNode = null; boolean insertUp = true; for (int i = 0; i &lt; levels &amp;&amp; insertUp; i++) { Node processor = processors.get(i); // 新节点指向下一层的同值节点 newNode = new Node(value, processor.right, newNode); // 在当前层插入新节点 processor.right = newNode; // 是否要继续往上一层插入节点 insertUp = random.nextDouble() &lt; FACTOR; } // 更新层级 if (insertUp) { levelUp(); } } @Override public boolean erase(T value) { List&lt;Node&gt; processors = findProcessors(value); // 验证删除节点是否存在，没有找到则直接返回 Node target = processors.get(0).right; if (target == null || !value.equals(target.value)) { return false; } // 从下往上，逐层删除指定节点 for (Node processor : processors) { // 指定 value 值的节点在每一层都删完了，就跳出循环 Node delNode = processor.right; if (delNode == null || !delNode.value.equals(value)) { break; } processor.right = delNode.right; } // 更新层级 levelDown(); return true; } /** * 提升层级 */ private void levelUp() { // 最上层只有一个头节点 head = new Node(null, null, head); } /** * 降低层级 */ private void levelDown() { while (head.down != null) { // 连续 2 层为空时，才降低层级，因为最上层只有 1 个头节点 if (head.right != null || head.down.right != null) { break; } Node p = head; head = head.down; p.down = null; } } /** * 查找指定值的前置路径 * * @param value 指定值 * @return 前置路径 */ private List&lt;Node&gt; findProcessors(T value) { Deque&lt;Node&gt; stack = new ArrayDeque&lt;&gt;(); Node p = head; // 从上往下一直找，直到最底层的原始链表为止 while (p != null) { // 在当前层遍历，直到找到 value 所在区间 while (p.right != null &amp;&amp; value.compareTo(p.right.value) &gt; 0) { p = p.right; } // 记录上一层的转折点 stack.push(p); // 搜索下一层 p = p.down; } // 路径是倒序摆放的，最接近值 value 的在索引 0 的位置 List&lt;Node&gt; path = new ArrayList&lt;&gt;(stack.size()); while (!stack.isEmpty()) { path.add(stack.pop()); } return path; }} 数组实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168/** * 跳表（数组实现） * * @author weijiaduo * @since 2022/7/27 */public class ArraySkipList&lt;T extends Comparable&lt;T&gt;&gt; implements SkipList&lt;T&gt; { class Node { T value; List&lt;Node&gt; forwards; Node(T value, int levels) { this.value = value; forwards = new ArrayList&lt;&gt;(levels); for (int i = 0; i &lt; levels; i++) { forwards.add(null); } } } /** * 默认最大层级 */ static final int DEFAULT_MAX_LEVEL = 32; /** * 随机因子 */ static final double FACTOR = 0.25; /** * 哨兵头节点 */ Node head; /** * 当前层级 */ int levels = 0; /** * 最大层级 */ int maxLevels; /** * 随机数 */ Random random = new Random(); public ArraySkipList() { this(DEFAULT_MAX_LEVEL); } public ArraySkipList(int maxLevels) { this.maxLevels = maxLevels; head = new Node(null, maxLevels); } /** * {@inheritDoc} */ @Override public boolean search(T value) { Node p = head, q = null; // 从上往下一直找，直到最底层的原始链表为止 for (int i = levels - 1; i &gt;= 0; i--) { // 在当前层遍历，直到找到 value 所在区间 Node right = p.forwards.get(i); while (right != null &amp;&amp; value.compareTo(right.value) &gt; 0) { p = right; right = p.forwards.get(i); } // 记录上一层的转折点 q = p; } if (q != null) { Node target = q.forwards.get(0); return target != null &amp;&amp; value.equals(target.value); } return false; } /** * {@inheritDoc} */ @Override public void add(T value) { List&lt;Node&gt; processors = findProcessors(value); int lv = randomLevel(); levels = Math.max(levels, lv); Node newNode = new Node(value, levels); for (int i = 0; i &lt; lv; i++) { Node processor = processors.get(i); newNode.forwards.set(i, processor.forwards.get(i)); processor.forwards.set(i, newNode); } } /** * {@inheritDoc} */ @Override public boolean erase(T value) { List&lt;Node&gt; processors = findProcessors(value); Node target = processors.get(0).forwards.get(0); if (target == null || !value.equals(target.value)) { return false; } // 从下往上，逐层删除指定节点 for (int i = 0; i &lt; levels; i++) { Node processor = processors.get(i); Node delNode = processor.forwards.get(i); if (delNode == null || delNode != target) { break; } processor.forwards.set(i, delNode.forwards.get(i)); } // 降低层级，最顶层只有头节点时 for (; levels &gt; 1; levels--) { if (head.forwards.get(levels - 1) != null) { break; } } return true; } /** * 查找指定值的前置路径 * * @param value 指定值 * @return 前置路径 */ private List&lt;Node&gt; findProcessors(T value) { List&lt;Node&gt; path = new ArrayList&lt;&gt;(maxLevels); for (int i = 0; i &lt; maxLevels; i++) { path.add(head); } Node p = head; for (int i = levels - 1; i &gt;= 0; i--) { // 在当前层遍历，直到找到 value 所在区间 Node right = p.forwards.get(i); while (right != null &amp;&amp; value.compareTo(right.value) &gt; 0) { p = right; right = p.forwards.get(i); } // 记录上一层的转折点 path.set(i, p); } return path; } /** * 随机层级 * &lt;p&gt; * 这个随机有点影响时间 * * @return 随即层级 */ private int randomLevel() { int lv = 1; while (lv &lt; maxLevels &amp;&amp; random.nextDouble() &lt; FACTOR) { lv++; } return lv; }}","link":"/datastructure/list/skiplist/"},{"title":"线段树","text":"线段树一、线段树是什么？ 线段树本质上是一种缓存，它缓存的是区间值 线段树一棵平衡二叉树 线段树的节点表示的是一个区间，节点值表示区间值 二、为什么要用线段树？线段树的常见用途有： 缓存区间值，提高多次查询区间值的性能 懒更新区间，减少修改的次数，提高多次修改区间的性能 简单点说就是： 通过缓存，提高多次区间查询和区间修改的性能 重点在于多次，多次，多次！！！ 下面说明线段树如何通过缓存提高性能。 一般情况下，当需要修改一个区间内的所有值时，只能通过遍历的方式实现： 123for (int i = start; i &lt; end; i++) { nums[i] = val;} 包括获取查询某个区间内的最大值、最小值、区间和时，也只能遍历整个区间： 1234int sum = 0;for (int i = start; i &lt; end; i++) { sum += nums[i];} 像这种区间查询和区间修改，没有其他办法，也只能通过遍历来实现了。 但是，如果说会多次执行区间查询，每次都要遍历一遍的话，性能会比较差。 能不能把区间查询的结果缓存下来，下次查询时直接返回缓存？ 比如，在区间之上缓存一个区间和结果： 1234567 ____ | 28 | -- 缓存区间值 | _______________________ | | ___ ___ ___ ___ ___ ___ ___| 1 | 6 | 7 | 2 | 5 | 4 | 3 | -- 原始数组（已排除索引 0，从 1 开始） 下次查询 [1, 7] 的区间和时，就可以直接从缓存节点返回结果 28。 这样貌似可行，但是只缓存一个够了吗？不够，如果要查询区间 [2 ,4]，还是要遍历。 所以需要把各个区间的结果都缓存了，最终缓存结构就变成了一棵二叉树： 1234567891011121314151617 ____ | 28 | ([1, 7]) | ____________________________________ | | ____ ____ | 16 | ([1, 4]) | 12 | ([5, 7]) | | ___________________ ______________ | | | | ___ ___ ___ | | 7 | ([1, 2]) | 9 | ([3, 4]) | 9 | ([5, 6]) | | | | | _________ _________ _________ | | | | | | | | ___ ___ ___ ___ ___ ___ ___| 1 | | 6 | | 7 | | 2 | | 5 | | 4 | | 3 | 这个二叉树结构就是线段树，每个节点表示一个区间，节点值就是区间值。 线段树实际就是一个二叉树缓存结构，上一层缓存着下一层节点的区间值。 有了线段树，区间的查询就变简单了，比如查询区间 [3, 7]： 从根节点出发，利用二分法逐层往下寻找查询区间 最后找到了满足要求的区间节点 [3, 4] 和 [5, 7] 区间节点 [3, 4] 的值是 9，区间节点 [5, 7] 的值是 12 所以 [3, 7] 的区间和等于 9 + 12 = 21 有了线段树以后，无需再遍历所有节点，而是通过上层的缓存节点就能拿到结果。 区间查询的复杂度从 O(n) 降为了 O(logn) 线段树就是利用空间换时间，通过缓存来提高区间查询的性能。 线段树本质就是缓存，父节点就是子节点的缓存 至于父节点缓存的是什么数据，视情况而定。比如说： 区间最大值 区间最小值 区间和 … 使用线段树前，应该想清楚，缓存的数据究竟是什么？ 三、线段树如何实现？线段树的实现方式主要分为 2 种类型： 静态线段树：所有节点一开始就构建好了，和区间范围有关 动态线段树：节点是动态创建的，随数据变化而变化 静态线段树包括： 简单线段树：基于数组实现的满二叉树结构 动态线段树包括： 动态估点线段树：基于数组实现的动态二叉树 动态开点线段树：基于指针实现的动态二叉树 下面分别介绍这几种线段树。 3.1 简单线段树3.1.1 基本思路 采用数组存储线段树节点 数组存储的是一棵满二叉树，其中有些节点是多余的 根节点的数组索引是 1 左子节点索引 2 * i；右子节点索引 2 * i + 1 总节点数量，一般取区间 [1, n] 的 4 倍，即 4n 3.1.2 存储结构线段树是一棵平衡二叉树，也就是左右子树节点数量相差不超过 1。 但是平衡二叉树在数组上的存储、构造和取数都不方便，所以数组存储的是满二叉树结构。 满二叉树在数组中的父子节点索引关系刚好是： 根节点索引是 1 左子节点索引 2 * i 右子节点索引 2 * i + 1 利用满二叉树的性质，很容易在数组上实现线段树。 3.1.3 节点数量二叉树的节点数量，从上往下统计的话： 12345672 ^ 0 -- 第1层2 ^ 1 -- 第2层2 ^ 2 -- 第3层2 ^ 3 -- 第4层...2 ^ (h - 1) -- 第h层... 如果区间范围 n = 2 ^ k 的话，那么刚好是满二叉树，节点总数就是 S = 2n - 1。 但如果区间范围是 n = 2 ^ k + c 的话，多出了几个，二叉树的最后一层就没有满。 满二叉树有一个特点，下一层的节点数量等于前面所有层级的节点数量总和 + 1 所以，如果填满了最后一层构成满二叉树的话，总节点数量就满足： 2n - 1 &lt;= S &lt; (2n - 1) + 2n = 4n - 1 所以，在初始化线段树时： 总节点数量一般取区间范围的 4 倍 但里面不是所有节点都会用到，有些多余的节点。 3.1.4 构建过程简单线段树的构建步骤如下： 计算出区间 [1, n] 的总节点数量 4n 初始化所有树节点 递归构建二叉树结构 比如构建“区间和”线段树的过程，类似这样： (1) 初始化区间节点 12345678public SegmentTree(int n) { // 总节点数量 4n tree = new Node[4 * n]; // 初始化所有节点 for (int i = 0; i &lt; tree.length; i++) { tree[i] = new Node(); }} (2) 递归构建二叉树 1234567891011121314151617181920212223242526272829public void buildTree(int root, int start, int end) { // 叶子节点 if (start == end) { tree[root].val = arr[start]; return ; } // 左子节点索引 int left = 2 * root; // 右子节点索引 int right = 2 * root + 1; // 递归构建树 int mid = start + (end - start) / 2; buildTree(left, start, mid); buildTree(right, mid + 1, end); // 向上更新父节点缓存 pushUp(node);}private void pushUp(int root) { // 左子节点索引 int left = 2 * root; // 右子节点索引 int right = 2 * root + 1; // 更新父节点的区间值 tree[root].val = tree[left].val + tree[right].val;} 比如，数组 arr = [, 1, 8, 2, 7, 4]（注意数组 0 的位置不用）： 1234567891011121314151617 ____ | 18 | ([1, 5]) | _______________________________________ | | ____ ___ | 11 | ([1, 3]) | 7 | ([4, 5]) | | ___________________ ___________________ | | | | ___ ___ ___ ___ | 9 | ([1, 2]) | 2 | | 3 | | 4 | | _________ | | ___ ___| 1 | | 8 | 假设区间范围就是 [1, 5]，也就是 n = 5，所以需申请 4 * 5 = 20 个节点空间。 但是实际上只用了 9 个空间，不过为了按照满二叉树结构存储数据，也需要 15 个节点了。 至于其他还多出来的节点，是由于 4n 的误差引起的，毕竟 4n 并不是精确的节点数量值。 3.2 动态估点线段树3.2.1 基本思路 根据数据情况，预估可能会访问到的区间范围，从而估计节点数量 根节点的数组索引是 1 子节点索引不确定，父节点内维护有左右子节点的索引 l 和 r 维护有一个 size 大小，表示当前节点数量，也可用于计算下一个节点的索引 动态开点时，新节点的索引就等于 size + 1，比如 node.lp = ++size 不算是完全动态，数组一开始就已经申请好空间了，动态的只有创建 Node 节点而已 3.2.2 区间估点静态线段树的数组长度是按照满二叉树的节点数量来设置的。 但是在实际上未必会用到这么多节点，所以可能会采用一种估点的方式来简化。 估点：就是估计线段树会用到实际区间范围，来替代理论上的区间范围 比如说，线段树的区间范围定义是 [1, 1000]，但是实际查询数据范围只用到了 [1, 200]。 在这种情况下，完全没必要为线段树创建 4 * 1000 个节点，因为很多节点实际上根本访问不到。 可以根据实际数据的查询范围，估计一个合理的节点数量 在线段树初始化数组时，就采用估点值来初始化数组长度 网上提供了一些公式，比如 6 * m * logn，其中，m 是查询次数，n 是区间值域大小。 3.2.3 动态建点动态线段树的节点是动态创建的，所以不再维护满二叉树的结构了。 新创建的节点都放在数组末尾 父节点内保存指向左右子节点的索引 节点的结构定义如下： 12345class Node { int val; // 区间值 int left; // 左子节点索引 int right; // 右子节点索引} 新节点的创建就类似这样，添加到数组末尾： 1234// 更新父节点中的左子节点索引node.left = ++size;// 创建左子节点tree[node.left] = new Node(); 3.2.4 构建过程动态估点线段树的构建步骤如下： 估计区间节点范围 根据估点值初始化数组长度 初始化根节点 访问时动态创建其他节点 比如构建“区间和”线段树的过程，类似这样： (1) 区间估点 + 初始化 12345678910111213public SegmentTree(int low, int high) { // 理论上的区间范围 this.low = low; this.high = high; // 估点区间范围 6 * m * logn int n = (int) (6 * 10000 * Math.log(high)); // 按照估点创建数组 tree = new Node[n]; // 初始化根节点 tree[1] = new Node();} (2) 访问节点时动态建点 12345678910111213141516171819202122232425262728293031public int query(Node node, int start, int end, int l, int r) { ... // 访问节点前，先向下推送更新 pushDown(node, start, end); ...}public int update(Node node, int start, int end, int l, int r) { ... // 访问节点前，先向下推送更新 pushDown(node, start, end); ...}private void pushDown(Node node, int start, int end) { // 动态开点，新节点总是添加到数组末尾 if (node.left == 0) { node.left = ++size; tree[node.left] = new Node(); } if (node.right == 0) { node.right = ++size; tree[node.right] = new Node(); } ...} 3.3 动态开点线段树3.3.1 基本思路 父子节点间采用指针进行链接 维护有一个根节点 每个节点维护有左右子节点的指针 left 和 right 动态开点时，直接创建新节点，比如 node.left = new Node() 3.3.2 动态建点基于指针的动态建点再简单不过了，就是平常的树结构： 12345class Node { int val; // 区间值 Node left; // 左子节点 Node right; // 右子节点} 在访问到节点前，动态创建节点： 12// 创建左子节点node.left = new Node(); 3.3.3 构建过程动态开点线段树的构建步骤如下： 初始化根节点 访问时动态创建其他节点 比如构建“区间和”线段树的过程，类似这样： (1) 初始化根节点 + 初始化区间 12345public SegmentTree(int low, int high) { this.root = new Node(); this.low = low; this.high = high;} (2) 访问时动态创建其他节点 1234567891011121314151617181920212223242526272829public int query(Node node, int start, int end, int l, int r) { ... // 动态向下更新 pushDown(node, start, end); ...}public int update(Node node, int start, int end, int l, int r) { ... // 动态向下更新 pushDown(node, start, end); ...}private void pushDown(Node node, int start, int end) { // 动态开点 if (node.left == null) { node.left = new Node(); } if (node.right == null) { node.right = new Node(); } ...} 3.4 小结静态线段树的特点： 一开始就要申请全部空间，以及构建好线段树结构 占用空间比较大，初始化会比较慢 有些节点未必会访问到，空间利用率低 所以又引申出了动态线段树： 用到这个节点时，再申请节点空间以及初始化 动态线段树的实现方式有 2 种： 动态估点：基于数组 动态开点：基于指针 视不同的情况可以选择不同的线段树。 四、线段树的优化4.1 懒标记更新4.1.1 懒更新引入线段树本质是一棵缓存树，在数据没有修改的情况下，查询性能确实高。 但是如果频繁对区间数据进行修改，就可能会对性能造成影响。 比如说，要把区间 [1, 5] 内的值都更新为 1，且此时在线段树中找到了 [1, 3] 和 [4, 5] 这 2 个区间。 按正常逻辑，需要把以 [1, 3] 和 [4, 5] 为根节点的 2 棵子树的所有节点值都更新为 1。 但是子树里面包括了很多节点，比如 [1, 1]、[2, 2]、[1, 2] … [5, 5] 等等。 这些节点不一定都会被访问到，也许永远没人访问，白更新了 每次更新区间都把所有相关子节点都更新一遍的话，势必会影响性能 为此，提出了一种懒更新的方式： 更新区间时，先标记根节点被更新了，但是暂时不要同步到子节点里面 下次访问子节点前，先从父节点上把上次的数据同步到子节点里面 使用懒更新后，只需要更新 [1, 3] 和 [4, 5] 这 2 个节点就够了，速度就很快。 等到下次查询区间 [1, 2] 时，才会从 [1, 3] 区间上同步之前的更新下来。 4.1.2 懒标记实现在节点中引入懒标记，同时用于保存更新值： 123456class Node { int val; // 区间值 Node left; // 左子节点 Node right; // 右子节点 int add; // 懒标记，0 时表示无更新，其他表示有更新} 然后在更新区间时，只需要更新父节点就行了。 等下次访问子节点前，再从父节点同步数据到子节点中： 1234567891011121314151617181920212223242526272829303132public void update(Node node, int start, int end, int l, int r, int val) { if (l &lt;= start &amp;&amp; end &lt;= r) { // 更新区间节点值 node.val = val; // 更新懒标记 node.add = val; return; } // 动态向下更新 pushDown(node, start, end); ...}private void pushDown(Node node, int start, int end) { ... // 父节点没有更新 if (node.add == 0) { return; } // 同步到子节点 node.left.val = node.add; node.left.add = node.add; node.right.val = node.add; node.right.add = node.add; // 重置父节点的懒标记 node.add = 0;} 原理很简单，就是尽量不往下面更新，减少更新时间。 五、线段树模板线段树有 2 个主要操作： 区间查询 区间更新 因此接口只定义了这 2 个。 5.1 接口定义123456789101112131415161718192021public interface SegmentTree { /** * 查询指定区间的值 * * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @return 区间值 */ int query(int l, int r); /** * 更新指定区间的值 * * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @param val 更新的值 */ void update(int l, int r, int val);} 5.1 动态估点（数组）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208public abstract class ArraySegmentTree implements SegmentTree { public static class Node { /** * 节点值 */ public int val; /** * 懒惰标记 */ public int add; /** * 左右节点数组下标 */ public int left, right; } /** * 树节点数组 */ protected final Node[] tree; /** * 区间最小值 */ protected final int low; /** * 区间最大值 */ protected final int high; /** * 当前节点数量 */ protected int size; public ArraySegmentTree(int low, int high) { this.low = low; this.high = high; // 区间估点 4n int n = 4 * high; tree = new Node[n]; // 初始化根节点 tree[1] = new Node(); size = 1; } @Override public int query(int l, int r) { return query(tree[1], low, high, l, r); } /** * 查询指定区间的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @return 区间值 */ protected int query(Node node, int start, int end, int l, int r) { if (l &lt;= start &amp;&amp; end &lt;= r) { return node.val; } // 访问节点前，先向下推送更新 pushDown(node, start, end); // 分别取左右子区间的值 Integer lResult = null, rResult = null; int mid = middle(start, end); if (l &lt;= mid) { lResult = query(tree[node.left], start, mid, l, r); } if (r &gt; mid) { rResult = query(tree[node.right], mid + 1, end, l, r); } // 合并子区间的查询结果 return mergeQuery(node, start, end, lResult, rResult); } @Override public void update(int l, int r, int val) { update(tree[1], low, high, l, r, val); } /** * 更新指定区间的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @param val 更新的值 */ protected void update(Node node, int start, int end, int l, int r, int val) { if (l &lt;= start &amp;&amp; end &lt;= r) { // 更新符合区间要求的节点值 writeDown(node, start, end, val); return; } // 访问节点前，先向下推送更新 pushDown(node, start, end); // 递归更新左右子区间 int mid = middle(start, end); if (l &lt;= mid) { update(tree[node.left], start, mid, l, r, val); } if (r &gt; mid) { update(tree[node.right], mid + 1, end, l, r, val); } // 子节点更新后，向上推送更新 pushUp(node, start, end); } /** * 子节点的值上推到父节点 * * @param node 父节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 */ protected void pushUp(Node node, int start, int end) { writeUp(node, start, end); } /** * 父节点的值下推到子节点 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 */ protected void pushDown(Node node, int start, int end) { // 动态开点，新节点总是添加到数组末尾 if (node.left == 0) { node.left = ++size; tree[node.left] = new Node(); } if (node.right == 0) { node.right = ++size; tree[node.right] = new Node(); } // 没有懒标记，无需再往下推 if (node.add == 0) { return; } // 把懒标记下推给子节点 int mid = middle(start, end); writeDown(tree[node.left], start, mid, node.add); writeDown(tree[node.right], mid + 1, end, node.add); // 懒标记已处理 node.add = 0; } /** * 合并指定区间的查询结果 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param lVal 左区间的查询结果 * @param rVal 右区间的查询结果 * @return 区间值 */ protected abstract int mergeQuery(Node node, int start, int end, Integer lVal, Integer rVal); /** * 向上更新节点的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 */ protected abstract void writeUp(Node node, int start, int end); /** * 向下更新节点的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param val 更新的值 */ protected abstract void writeDown(Node node, int start, int end, int val); /** * 划分左右区间的中点 * * @param start 左边界[start, end] * @param end 右边界[start, end] * @return 中点 */ protected int middle(int start, int end) { return start + (end - start) / 2; }} 5.3 动态开点（指针）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209public abstract class LinkSegmentTree implements SegmentTree { public static class Node { /** * 节点值 */ public int val; /** * 懒惰标记 */ public int add; /** * 左右节点 */ public Node left, right; } /** * 根节点 */ protected final Node root; /** * 区间最小值 */ protected final int low; /** * 区间最大值 */ protected final int high; public LinkSegmentTree(int low, int high) { this.low = low; this.high = high; this.root = new Node(); } /** * 查询指定区间的值 * * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @return 区间值 */ @Override public int query(int l, int r) { return query(root, low, high, l, r); } /** * 查询指定区间的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @return 区间值 */ protected int query(Node node, int start, int end, int l, int r) { if (l &lt;= start &amp;&amp; end &lt;= r) { return node.val; } // 访问节点前，先向下推送更新 pushDown(node, start, end); // 分别取左右子区间的值 Integer lResult = null, rResult = null; int mid = middle(start, end); if (l &lt;= mid) { lResult = query(node.left, start, mid, l, r); } if (r &gt; mid) { rResult = query(node.right, mid + 1, end, l, r); } // 合并子区间的查询结果 return mergeQuery(node, start, end, lResult, rResult); } /** * 更新指定区间的值 * * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @param val 更新的值 */ @Override public void update(int l, int r, int val) { update(root, low, high, l, r, val); } /** * 更新指定区间的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param l 目标区间[l, r]的左边界 * @param r 目标区间[l, r]的右边界 * @param val 更新的值 */ protected void update(Node node, int start, int end, int l, int r, int val) { if (l &lt;= start &amp;&amp; end &lt;= r) { // 更新符合区间要求的节点值 writeDown(node, start, end, val); return; } // 访问节点前，先向下推送更新 pushDown(node, start, end); // 递归更新左右子区间 int mid = middle(start, end); if (l &lt;= mid) { update(node.left, start, mid, l, r, val); } if (r &gt; mid) { update(node.right, mid + 1, end, l, r, val); } // 子节点更新后，向上推送更新 pushUp(node, start, end); } /** * 子节点的值上推到父节点 * * @param node 父节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 */ protected void pushUp(Node node, int start, int end) { writeUp(node, start, end); } /** * 父节点的值下推到子节点 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 */ protected void pushDown(Node node, int start, int end) { // 动态开点，指向动态创建的对象 if (node.left == null) { node.left = new Node(); } if (node.right == null) { node.right = new Node(); } // 没有懒标记，无需再往下推 if (node.add == 0) { return; } // 把懒标记下推给子节点 int mid = middle(start, end); writeDown(node.left, start, mid, node.add); writeDown(node.right, mid + 1, end, node.add); // 懒标记已处理 node.add = 0; } /** * 合并指定区间的查询结果 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param lVal 左区间的查询结果 * @param rVal 右区间的查询结果 * @return 区间值 */ protected abstract int mergeQuery(Node node, int start, int end, Integer lVal, Integer rVal); /** * 向上更新节点的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 */ protected abstract void writeUp(Node node, int start, int end); /** * 向下更新节点的值 * * @param node 当前节点 * @param start 当前区间[start, end]的左边界 * @param end 当前区间[start, end]的右边界 * @param val 更新的值 */ protected abstract void writeDown(Node node, int start, int end, int val); /** * 划分左右区间的中点 * * @param start 左边界[start, end] * @param end 右边界[start, end] * @return 中点 */ protected int middle(int start, int end) { return start + (end - start) / 2; }} 六、实际案例6.1 LC 307. 区域和检索 题目描述 给你一个数组 nums ，请你完成两类查询。 其中一类查询要求 更新 数组 nums 下标对应的值 另一类查询要求返回数组 nums 中索引 left 和索引 right 之间（ 包含 ）的nums元素的 和 ，其中 left &lt;= right 实现 NumArray 类： NumArray(int[] nums) 用整数数组 nums 初始化对象 void update(int index, int val) 将 nums[index] 的值 更新 为 val int sumRange(int left, int right) 返回数组 nums 中索引 left 和索引 right 之间（ 包含 ）的&gt; nums元素的 和 （即，nums[left] + nums[left + 1], …, nums[right] 提示： 1 &lt;= nums.length &lt;= 3 * 104 -100 &lt;= nums[i] &lt;= 100 0 &lt;= index &lt; nums.length -100 &lt;= val &lt;= 100 0 &lt;= left &lt;= right &lt; nums.length 调用 update 和 sumRange 方法次数不大于 3 * 104 问题分析 问题中涉及了 2 个操作： 单点更新 区间求和 单点更新，可以当成是长度为 1 区间更新，所以这 2 种操作都可认为是区间操作。 线段树正好可以用来解决这 2 个问题。 首先分析一下： 区间节点需要缓存什么数据？ 从题目可知，区间查询的结果是区间和，所以： 父节点缓存的应该是子节点的区间和 确定节点缓存的数据之后，套用模板修改代码即可。 代码实现 这可能用简单线段树会好一些，因为区间范围只有 3 * 10^4，不是很大，直接构建线段树也很快。 不过这里是采用了动态开点线段树来作为例子演示。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 区间和线段树 * * 父节点缓存的是子树所有节点的和 */public class SumLinkSegmentTree extends LinkSegmentTree { public SumLinkSegmentTree(int low, int high) { super(low, high); } @Override protected int mergeQuery(Node node, int start, int end, Integer lVal, Integer rVal) { // 合并子树节点的区间和 int sum = 0; if (lVal != null) { sum += lVal; } if (rVal != null) { sum += rVal; } return sum; } @Override protected void writeUp(Node node, int start, int end) { // 子树的区间和发生变化后，父节点也要更新 node.val = node.left.val + node.right.val; } @Override protected void writeDown(Node node, int start, int end, int val) { // end - start + 1 表示子树中叶子节点的数量 // 区间内所有叶子节点都设为 val 的话 // 那么父节点应该等于所有叶子节点的 val 总和 node.val = (end - start + 1) * val; node.add = val; }} 区间和线段树实现好了，下面直接按题目要求调用： 123456789101112131415161718192021class NumArray { SumSegmentTree segmentTree; int low = 0; int high = (int) 3e4; public NumArray(int[] nums) { segmentTree = new SumSegmentTree(low, high); for (int i = 0; i &lt; nums.length; i++) { this.update(i, nums[i]); } } public void update(int index, int val) { segmentTree.update(index, index, val); } public int sumRange(int left, int right) { return segmentTree.query(left, right); }} 这道题的解决方案还有其他方法，线段树的性能并不是最优的。 这里只是举例子说明一下线段树的用途。 6.2 LC 699. 掉落的方块 题目描述 在二维平面上的 x 轴上，放置着一些方块。 给你一个二维整数数组 positions ，其中 positions[i] = [lefti, sideLengthi] 表示：第 i 个方块边长为 sideLengthi ，其左侧边与 x 轴上坐标点 lefti 对齐。 每个方块都从一个比目前所有的落地方块更高的高度掉落而下。方块沿 y 轴负方向下落，直到着陆到 另一个正方形的顶边 或者是 x 轴上 。一个方块仅仅是擦过另一个方块的左侧边或右侧边不算着陆。一旦着陆，它就会固定在原地，无法移动。 在每个方块掉落后，你必须记录目前所有已经落稳的 方块堆叠的最高高度 。 返回一个整数数组 ans ，其中 ans[i] 表示在第 i 块方块掉落后堆叠的最高高度。 提示： 1 &lt;= positions.length &lt;= 1000 1 &lt;= lefti &lt;= 108 1 &lt;= sideLengthi &lt;= 106 问题分析 问题中出现的 2 个行为： 方块掉落在坐标轴上，占用了一个区间，这实际上就是区间更新 查询所有方块堆叠的最高高度，实际就是在查找区间内的最大值 所以也可以用线段树来实现区间更新和区间求最大值。 首先分析一下： 区间节点需要缓存什么数据？ 从题目可知，查询的是区间最大值，所以： 父节点缓存的应该是子节点的区间最大值 确定节点缓存的数据之后，开始套用模板修改代码。 代码实现 这里的区间范围有 10^8，比较大，不适合用简单线段树，采用动态开点会更好一些。 123456789101112131415161718192021222324252627282930313233343536373839/** * 区间最大值线段树 * * 父节点缓存的是子树的最大值 */public class MaxLinkSegmentTree extends LinkSegmentTree { public MaxLinkSegmentTree(int low, int high) { super(low, high); } @Override protected int mergeQuery(Node node, int start, int end, Integer lVal, Integer rVal) { // 取左右子树中的最大值 int max = Integer.MIN_VALUE; if (lVal != null) { max = lVal; } if (rVal != null) { max = Math.max(rVal, max); } return max; } @Override protected void writeUp(Node node, int start, int end) { // 子节点更新后，父节点也要更新最大值 node.val = Math.max(node.left.val, node.right.val); } @Override protected void writeDown(Node node, int start, int end, int val) { // 子节点都更新为 val 的话，那么所有值都会相等 // 此时区间最大值就是 val node.val = val; node.add = val; }} 接着按题目要求实现调用代码即可： 1234567891011121314151617public List&lt;Integer&gt; fallingSquares(int[][] positions) { List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(positions.length); int low = 1, high = (int) 1e8; MaxLinkSegmentTree segmentTree = new MaxLinkSegmentTree(low, high); for (int[] position : positions) { int x = position[0]; int w = position[1]; // 找到区间内的最大值 int maxH = segmentTree.query(x, x + w - 1); // 堆叠新落下的方块高度 segmentTree.update(x, x + w - 1, maxH + w); ans.add(segmentTree.query(low, high)); } return ans;} 6.3 LC 715. Range 模块 题目描述 Range模块是跟踪数字范围的模块。 设计一个数据结构来跟踪表示为 半开区间 的范围并查询它们。 半开区间 [left, right) 表示所有 left &lt;= x &lt; right 的实数 x 。 实现 RangeModule 类: RangeModule() 初始化数据结构的对象。 void addRange(int left, int right) 添加 半开区间 [left, right)，跟踪该区间中的每个实数。添加与当前跟踪的数字部分重叠的区间时，应当添加在区间 [left, right) 中尚未跟踪的任何数字到该区间中。 boolean queryRange(int left, int right) 只有在当前正在跟踪区间 [left, right) 中的每一个实数时，才返回 true ，否则返回 false 。 void removeRange(int left, int right) 停止跟踪 半开区间 [left, right) 中当前正在跟踪的每个实数。 提示： 1 &lt;= left &lt; right &lt;= 10^9 在单个测试用例中，对 addRange 、queryRange 和 removeRange 的调用总数不超过 104 次 问题分析 问题已经说的很清楚了，就是区间查询和区间更新。 现在还需要确认一下： 区间节点需要缓存什么样的数据？ 跟踪区间，可以理解为区间被标记了。那么可以这样来标记： 区间值为 1 时：表示被跟踪了 区间值小于 1 时：表示未跟踪 这个时候，只要查出区间内的最小值，就能知道区间是否被跟踪了。所以， 父节点缓存的应该是子节点的区间最小值 确定节点缓存的数据之后，开始套用模板修改。 代码实现 这里的区间范围有 10^9，比较大，不适合用简单线段树，采用动态开点会更好一些。 123456789101112131415161718192021222324252627282930313233343536373839/** * 区间最小值线段树 * * 父节点缓存的是子树的最小值 */public class MaxLinkSegmentTree extends LinkSegmentTree { public MaxLinkSegmentTree(int low, int high) { super(low, high); } @Override protected int mergeQuery(Node node, int start, int end, Integer lVal, Integer rVal) { // 取左右子树中的最小值 int min = Integer.MAX_VALUE; if (lVal != null) { min = lVal; } if (rVal != null) { min = Math.min(rVal, min); } return min; } @Override protected void writeUp(Node node, int start, int end) { // 子节点更新后，父节点也要更新最小值 node.val = Math.min(node.left.val, node.right.val); } @Override protected void writeDown(Node node, int start, int end, int val) { // 子节点都更新为 val 的话，那么所有值都会相等 // 此时区间最小值就是 val node.val = val; node.add = val; }} 接着按照题目要求，实现其他的调用代码即可： 12345678910111213141516171819202122232425262728class RangeModule { final int low = 1; final int high = (int) 1e9; MaxLinkSegmentTree segmentTree; public RangeModule() { segmentTree = new MinLinkSegmentTree(low, high); } public void addRange(int left, int right) { segmentTree.update(left, right - 1, 1); } public boolean queryRange(int left, int right) { int ret = segmentTree.query(left, right - 1); // 区间最小值大于 0 表示被跟踪了 return ret &gt; 0; } public void removeRange(int left, int right) { // 这里更新的值必须使用小于 0 的整数 // 不能用 0，因为懒标志用 0 表示无更新了 // 设成 0 的话会导致线段树不更新数据 // 相当于 0 已经被懒标志占用了，使用 0 会造成冲突 segmentTree.update(left, right - 1, -1); }} 6.4 小结上面列举了几种线段树的几种常见使用场景： 区间和 区间最大值 区间最小值 线段树本质就是区间缓存，所以对于： 多次区间查询 多次区间更新 就比较适用，不过具体用哪种，视情况而定。 总结什么是线段树？ 线段树本质上是一种缓存，它缓存的是区间值 父节点就是子节点的缓存 为什么要用线段树？ 通过缓存，提高多次区间查询和区间修改的性能 重点在于多次，多次，多次！！！ 线段树的实现方式？ 静态线段树：一开始就创建好所有节点和构建树结构 动态线段树：区间访问过程中动态创建节点和初始化 静态线段树： 简单线段树（基于数组） 动态线段树： 动态估点（基于数组） 动态开点（基于指针） 参考 https://leetcode.cn/problems/range-sum-query-mutable/solution/by-lfool-v3x9/ https://leetcode.cn/problems/my-calendar-iii/solution/xian-duan-shu-by-xiaohu9527-rfzj/ https://leetcode.cn/problems/falling-squares/solution/by-ac_oier-zpf0/ https://www.cnblogs.com/chengmf/p/16451615.html","link":"/datastructure/tree/segment_tree/"},{"title":"二分查找","text":"二分查找一、二分查找模板123456789left = low, right = high;while (left &lt;= right) { int mid = left + (right - left) / 2; if (满足条件) { right = mid - 1; } else { left = mid + 1; }} 在二分法中，有几个需要注意的地方： 循环判定条件（while） 二分中值的计算（mid） 区间范围的收缩（left、right） 这几个地方经常出问题，写错了就容易导致结果不对。 二、循环判定条件循环判定条件可以分为 2 种： while (left &lt; right) while (left &lt;= right) 什么时候使用 &lt;？什么时候使用 &lt;= 呢？ 2.1 while (left &lt; right)循环结束时，满足以下情况： 终止条件 left == right 结果范围 [low, high] left 阈值范围 [low, high] right 阈值范围 [low, high] 当 left == right 时就终止循环，也就是说最后的元素是没有进入循环体内的。 所以，要使用这种方式 最后的元素（arr[left/right]）就不能对返回结果造成影响 满足这种要求的情况有2种： 返回元素值：认定最后的元素 arr[left/right] 就是默认的返回结果 返回元素索引：默认返回的就是 left 或 right 这种边界索引 满足其中之一，才能够使用 while (left &lt; right) 这种判定条件。 2.2 while (left &lt;= right)循环结束时，满足以下情况： 终止条件 left &gt; right 结果范围 [low - 1, high + 1] left 阈值范围 [low, high + 1] right 阈值范围 [low - 1, high] 当 left &gt; right 时才终止循环，就意味着所有元素都会进入循环体内。 所以，要使用这种方式： 判断数组所有元素后，才能得到最后的返回结果 满足这种要求的情况有： 返回元素值：查找元素不一定在数组内，即最后的元素 arr[left/right] 不一定是返回结果 返回元素索引：返回可能是数组范围外的索引，比如 low - 1 或 high + 1 满足其中之一，就能使用 while (left &lt;= right) 这种判定条件。 2.3 小结返回是元素值时： while (left &lt; right)：查找元素已经明确在数组内，最后的 arr[left/right] 是默认结果 while (left &lt;= right)：查找元素不一定在数组内，需要遍历所有数组元素 返回是元素索引时： while (left &lt; right)：查找索引明确在 [low, high] 内，最后的 left/right 是默认结果 while (left &lt;= right)：可能是数组范围外的索引，比如 low - 1 或 high + 1 综上所述： 不确定 [low, high] 内有满足条件的结果时，循环条件就加上 = 号 三、二分中值的计算一般来说，二分中值的计算方式有以下几种： mid = (left + right) / 2 mid = left + (right - left) / 2 mid = left + ((right - left) &gt;&gt; 1) 哪种方式比较好呢？推荐第 2 种。 第 1 种存在整数溢出问题，所以用的比较少。 第 3 种其实和第 2 种一样，从理论上说移位 &gt;&gt; 还比除法 / 快。但是由于 &gt;&gt; 操作符的优先级比 + 号低，所以需要加多一层括号。不过括号比较容易遗漏，没有第 2 种方法直观。 上面的计算方式是向下取整，还有一种向上取整的计算方式： mid = right - (right - left) / 2 向上取整和向下取整用法是一样的，只不过是在不同场景下使用。 四、区间范围的收缩二分法实际上就是收缩左右边界，直到找到满足条件的值为止。 不过区间收缩的方式有好几种，包括： left = mid + 1 right = mid - 1 left = mid right = mid 这几种方式可以组合成各种情况，但是用不好的话，就很容易造成死循环。 比如说，使用 left = mid 和 right = mid - 1 组合： 12345678while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] &lt;= x) { left = mid; } else { right = mid - 1; }} 假设此时 left = 0, right = 1, arr = {1, 2}, x = 1，那么代码就会陷入死循环。 死循环的原因就是左右边界没有收缩，导致一直无法达到循环结束条件。 死循环都是出现在 left = mid 和 right = mid 上 因为 left = mid 和 right = mid 在某些情况下可能会出现一直没有收缩区间的情况。 如果非要用 left = mid 或者 right = mid 的话，一定要注意边界收缩的情况，避免死循环。 比如说，寻找第一个等于给定值 x 的位置： 12345678while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] &lt; x) { left = mid + 1; } else { right = mid; }} 注意满足条件和区间收缩一定不能写错，别写成上面的死循环代码。 这种组合方式换成 left = mid + 1 和 right = mid - 1 组合的话，可以写成这样： 12345678910111213while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] == x) { if (mid == 0 || arr[mid - 1] != x) { return mid; } right = mid - 1; } else if (arr[mid] &lt; x) { left = mid + 1; } else { right = mid - 1; }} 使用 left = mid + 1 和 right = mid - 1 组合的话，就不会出现区间没收缩的情况。 从代码简洁性上看，确实是 right = mid 更优雅，但是写起来容易有坑。 推荐全部使用 left = mid + 1 和 right = mid - 1 作为区间收缩的方式，避免死循环 虽然代码没那么简洁，但是至少它问题少、逻辑清晰、容易看懂。 五、适用场景 依赖于顺序表结构和随机访问，基本上都是数组 数据必须是有序的 不适合数据量太小，不如直接遍历来的快 数据量过大也不行，内存空间可能放不下整个数组，不过可以用局部二分查找 六、二分查找案例6.1 第一个等于给定值的位置123456789101112131415161718int findFirstEqual(int[] arr, int x) { int n = arr.length; int left = 0, right = n - 1; while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] == x) { if (mid == 0 || arr[mid - 1] != x) { return mid; } right = mid - 1; } else if (arr[mid] &lt; x) { left = mid + 1; } else { right = mid - 1; } } return -1;} 6.2 最后一个等于给定值的位置123456789101112131415161718int findLastEqual(int[] arr, int x) { int n = arr.length; int left = 0, right = n - 1; while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] == x) { if (mid == n - 1 || arr[mid + 1] != x) { return mid; } left = mid + 1; } else if (arr[mid] &lt; x) { left = mid + 1; } else { right = mid - 1; } } return -1;} 6.3 第一个大于等于给定值的位置12345678910111213141516int findFirstNotLessThan(int[] arr, int x) { int n = arr.length; int left = 0, right = n - 1; while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] &gt;= x) { if (mid == 0 || arr[mid - 1] &lt; x) { return mid; } right = mid - 1; } else { left = mid + 1; } } return -1;} 6.4 最后一个小于等于给定值的位置12345678910111213141516int findLastNotGreatThan(int[] arr, int x) { int n = arr.length; int left = 0, right = n - 1; while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] &lt;= x) { if (mid == n - 1 || arr[mid + 1] &gt; x) { return mid; } left = mid + 1; } else { right = mid - 1; } } return -1;} 总结 循环判定条件，推荐使用 while (left &lt;= right) 中值计算，推荐使用 mid = left + (right - left) / 2 区间收缩方式，推荐全部使用 left = mid + 1 和 right = mid - 1","link":"/algorithm/binary/binary_search/"},{"title":"基数排序","text":"基数排序一、算法描述1.1 核心思想 数据有高低位之分，位之间有递进关系 高位相等的情况下，才去对比低位大小 按照低位到高位的顺序，使用稳定排序算法对每一位排序 1.2 细节解释 数据有高低位之分，比如十进制数字 1232，字符串 dwsc，二进制 1001 等等。 这些类型的数据都有高低位，而且是高位大的数据肯定比高位小的数据大。 比如 123 和 234，123 最高位 1 小于 234 最高位 2，所以 123 &lt; 234。 基数排序就是利用数据的每一位进行排序，最终得到有序序列的 比如说，数组 [12, 3, 154, 78, 9, 245, 35, 92]。 因为数字长度不同，所以首先将所有数字补 0 进行长度对齐： 12345678012003154078009245035092 然后按照从低位到高位进行排序： 12345678910当前数组 取出“个”位 按“个”位排序 012 xx2 012 003 xx3 092 154 xx4 003 078 =&gt; xx8 =&gt; 154 009 xx9 245 245 xx5 035 035 xx5 078 092 xx2 009 12345678910当前数组 取出“十”位 按“十”位排序 012 x1x 003 092 x9x 009 003 x0x 012 154 =&gt; x5x =&gt; 035 245 x4x 245 035 x3x 154 078 x7x 078 009 x0x 092 12345678910当前数组 取出“百”位 按“百”位排序 003 0xx 003 009 0xx 009 012 0xx 012 035 =&gt; 0xx =&gt; 035 245 2xx 078 154 1xx 092 078 0xx 154 092 0xx 245 排完之后，就是最终的排序结果了： 1[3, 9, 12, 35, 78, 92, 154, 245] 基数排序的关键在于从低位往高位排序，这样能保证高位排序是最后的。 二、算法实现2.1 找出数据最大值1234567// 找到最大值int max = Integer.MIN_VALUE;for (int a : arr) { if (a &gt; max) { max = a; }} 2.2 计算数据的基数12345int radix = 0;while(max &gt; 0) { max = max / 10; radix++;} 2.3 从低位到高位排序123456// 从低位到高位对数组进行排序int exp = 1;for (int i = 0; i &lt; radix; i++) { countSort(arr, exp); exp *= 10;} 对每一位进行排序，则使用计数排序（或者其他稳定排序算法也行）。 三、算法分析3.1 时间复杂度 最好时间复杂度：O(n) 最坏时间复杂度：O(n) 平均时间复杂度：O(n) 3.2 空间复杂度 空间复杂度：O(n) 非原地算法 3.3 稳定性 稳定排序算法 四、适用场景 数据可以分割出“位”来比较 数据有高低位之分，位之间有递进关系 每一位的数据范围不能太大，要可以用线性排序算法来排序 附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * 基数排序 * &lt;p&gt; * 时间复杂度：O(n) * &lt;p&gt; * 空间复杂度：O(n) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2022/9/6 */public class RadixSort implements Sort { @Override public void sort(int[] arr) { // 找到数组最大值 int max = Integer.MIN_VALUE; for (int a : arr) { if (a &gt; max) { max = a; } } // 计算基数大小 int radix = 0; while(max &gt; 0) { max = max / 10; radix++; } // 从低位到高位对数组进行排序 int exp = 1; for (int i = 0; i &lt; radix; i++) { countSort(arr, exp); exp *= 10; } } /** * 计数排序 * * @param arr 数组 * @param exp 指数 */ private void countSort(int[] arr, int exp) { // 统计每个数字（0-9）的次数 int[] counts = new int[10]; for (int a : arr) { counts[(a / exp) % 10]++; } // 累计数字的次数和 for (int i = 1; i &lt; counts.length; i++) { counts[i] += counts[i - 1]; } // 更新排序结果到原数组 int[] copy = Arrays.copyOf(arr, arr.length); for (int i = copy.length - 1; i &gt;= 0; i--) { int index = (copy[i] / exp) % 10; counts[index]--; arr[counts[index]] = copy[i]; } }}","link":"/algorithm/sort/radixsort/"},{"title":"桶排序","text":"桶排序一、算法描述1.1 核心思想 把不同范围的数据划分到不同的桶中 桶与桶之间是有序的，桶间无需排序 只需要对桶内的数据排序 1.2 细节解释 比如说，数组 [2, 7, 4, 9, 4, 8, 0, 7, 7, 2, 4, 4, 1, 6]。 数据范围是 [0, 9]，假设桶大小为 3，那么可以划分成 4 个桶。 12345678| | | | | | | || | | | | | | || | | | | | | || | | | | | | || | | | | | | ||___| |___| |___| |___| 0 1 2 3 -- 桶编号[0,2] [3,5] [6,8] [9,11] -- 桶数据范围 然后遍历排序数组，将数据按照范围分发到不同的桶中： 12345678| | | | | | | || | | | | 6 | | || 1 | | 4 | | 7 | | || 2 | | 4 | | 7 | | || 0 | | 4 | | 8 | | ||_2_| |_4_| |_7_| |_9_| 0 1 2 3 -- 桶编号[0,2] [3,5] [6,8] [9,11] -- 桶数据范围 这个时候，桶之间的数据是有序的，所以只需对桶内数据进行排序即可： 12345678| | | | | | | || | | | | 8 | | || 2 | | 4 | | 7 | | || 2 | | 4 | | 7 | | || 1 | | 4 | | 7 | | ||_0_| |_4_| |_6_| |_9_| 0 1 2 3 -- 桶编号[0,2] [3,5] [6,8] [9,11] -- 桶数据范围 桶内排好序之后，按照桶的顺序遍历获取数据即可： 1[0, 1, 2, 2, 4, 4, 4, 4, 6, 7, 7, 7, 8, 9] 桶排序就是利用了桶的有序性，避免了大范围的排序，换成了小范围排序。 二、算法实现2.1 找出数据范围1234567891011// 找出数据的范围（最小最大值）int min = Integer.MAX_VALUE;int max = Integer.MIN_VALUE;for (int num : arr) { if (num &gt; max) { max = num; } if (num &lt; min) { min = num; }} 2.2 根据数据范围划分桶桶大小需要根据实际情况设置，不同类型的数据，桶大小可能不一样。 123456// 根据数据范围平均划分桶int n = (max - min) / width + 1;List&lt;List&lt;Integer&gt;&gt; buckets = new ArrayList&lt;&gt;(n);for (int i = 0; i &lt; n; i++) { buckets.add(new ArrayList&lt;&gt;());} 2.3 将数据分发到不同桶123456// 把不同范围的数据划分到不同的桶里面for (int num : arr) { int index = (num - min) / width; List&lt;Integer&gt; list = buckets.get(index); list.add(num);} 2.4 对桶内数据排序1234// 桶之间已经是有序的了，只需对桶内排序for (List&lt;Integer&gt; bucket : buckets) { Collections.sort(bucket);} 2.5 按顺序收集桶数据1234567// 按桶的顺序遍历所有数据，就是已经排好序的了int k = 0;for (List&lt;Integer&gt; bucket : buckets) { for (Integer num : bucket) { arr[k++] = num; }} 三、算法分析3.1 时间复杂度如果数据都划分到同一个桶内，那么就回退成单数组排序的性能了。 最好时间复杂度：O(n) 最坏时间复杂度：O(nlogn) 平均时间复杂度：O(nlogn) 3.2 空间复杂度 空间复杂度：O(n) 非原地算法 3.3 稳定性 稳定排序算法 四、适用场景 外部排序 数据量比较大 数据容易划分为多个桶 数据分布范围比较均匀 五、限制条件 要求排序数据能很容易的划分成 n 个桶，且桶与桶之间是有序的 分布在各个桶之间的数据是比较均匀的 附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * 桶排序 * &lt;p&gt; * 时间复杂度：O(n) * &lt;p&gt; * 空间复杂度：O(w) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2022/9/5 */public class BucketSort implements Sort { int width; public BucketSort() { this(10); } public BucketSort(int width) { this.width = width; } @Override public void sort(int[] arr) { // 找出数据的范围（最小最大值） int min = Integer.MAX_VALUE; int max = Integer.MIN_VALUE; for (int num : arr) { if (num &gt; max) { max = num; } if (num &lt; min) { min = num; } } // 根据数据范围平均划分桶 int n = (max - min + width) / width; List&lt;List&lt;Integer&gt;&gt; buckets = new ArrayList&lt;&gt;(n); for (int i = 0; i &lt; n; i++) { buckets.add(new ArrayList&lt;&gt;()); } // 把不同范围的数据划分到不同的桶里面 for (int num : arr) { int index = (num - min) / width; List&lt;Integer&gt; list = buckets.get(index); list.add(num); } // 桶之间已经是有序的了，只需对桶内排序 for (List&lt;Integer&gt; bucket : buckets) { Collections.sort(bucket); } // 按桶的顺序遍历所有数据，就是已经排好序的了 int k = 0; for (List&lt;Integer&gt; bucket : buckets) { for (Integer num : bucket) { arr[k++] = num; } } }}","link":"/algorithm/sort/bucketsort/"},{"title":"计数排序","text":"计数排序一、算法描述1.1 核心思想 计数排序是桶排序的桶大小为 1 的一种特殊情况 由于桶大小为 1，所以桶内都是相同的值 桶内都是相同的值，无需桶内排序，只需要记录数据频率 最后排序时，按照数据频率将数据填充回原数组 1.2 细节解释 比如说，数组 [6, 0, 5, 0, 9, 4, 1, 7, 4]。 数据范围是 [0, 9]，所以可以划分为 10 个桶，每个桶大小是 1。 这里的桶直接用数组替代，因为只需要计数就够了，不需要保留原数据。 123 0 1 2 3 4 5 6 7 8 9 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___| | | | | | | | | | | 然后遍历排序数组，将数字频率统计到计数数组中： 123 0 1 2 3 4 5 6 7 8 9 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___| 2 | 1 | 0 | 0 | 2 | 1 | 1 | 1 | 0 | 1 | 桶内的数值表示的是对应数字的频率。 这里可以通过扫描计数数组，填充原数组就能排好序了： 123456int k = 0;for (int i = 0; i &lt; counts.length; i++) { for (int j = 0; j &lt; counts[i].length; j++) { arr[k++] = i; }} 简单点说，计数排序的处理过程就是： 统计所有不同数字的出现频率 按照频率将数字填充到数组 处理过程不复杂，关键就在于利用了数字的天然有序性。 1.3 频率累计和按照数字频率填充数字回原数组时，可以利用频率累计和来实现。 比如上面的计数数组，将其从左至右累计起来，可得到： 123 0 1 2 3 4 5 6 7 8 9 ___ ___ ___ ___ ___ ___ ___ ___ ___ ___| 2 | 3 | 3 | 3 | 5 | 6 | 7 | 8 | 8 | 9 | 累计和 counts[i] 的意思就是，小于等于 i 的值有 counts[i] 个。 利用这个特性，可以将数字 x 直接定位到它最终排序好的位置。 比如 x = 4，counts[4] = 5，说明小于等于 x 的有 5 个。 那么 x 排好序后的位置就是第 5 位，放到数组中就是 arr[4] = x。 123 0 1 2 3 4 5 6 7 8 ___ ___ ___ ___ ___ ___ ___ ___ ___| | | | | x | | | | | 但是如果接着又有一个 y = 7，y 应该放哪里呢？ 难道也放 arr[4] 吗？这会覆盖掉 x 的，不可以放。 实际上，在放入 x 的时候，需要同时修改累计和，将其减一 count[4]--，表示已经有 1 个数字放回去了。 所以当遍历到 y 时，实际上是 counts[4] = 4，所以 y 的位置应该是 arr[3]： 123 0 1 2 3 4 5 6 7 8 ___ ___ ___ ___ ___ ___ ___ ___ ___| | | | y | x | | | | | 通过频率累计和的方式，可以逐个将数据摆到正确的位置。 二、算法实现2.1 找出数据范围1234567891011// 找出数据的范围（最小最大值）int min = Integer.MAX_VALUE;int max = Integer.MIN_VALUE;for (int num : arr) { if (num &gt; max) { max = num; } if (num &lt; min) { min = num; }} 2.2 划分出大小为 1 的桶123// 初始化计数范围int n = max - min + 1;int[] counts = new int[n]; 2.3 将数据映射到桶内通大小是1，都是相同值，不用记录数据，只需要计数就行： 12345// 统计数字的频率for (int num : arr) { int index = num - min; counts[index]++;} 2.4 统计频率累计和1234// 频率累计和for (int i = 1; i &lt; counts.length; i++) { counts[i] += counts[i - 1];} 2.5 倒序摆放数据倒序的作用是为了保证数组数据的稳定性。 如果不需要稳定性，正序遍历也是可以的。 1234567// 倒序遍历获取排序结果int[] copy = Arrays.copyOf(arr, arr.length);for (int i = copy.length - 1; i &gt;= 0; i--) { int index = copy[i] - min; counts[index]--; arr[counts[index]] = copy[i];} 三、算法分析3.1 时间复杂度 最好时间复杂度：O(n) 最坏时间复杂度：O(n) 平均时间复杂度：O(n) 3.2 空间复杂度 空间复杂度：O(n) 非原地算法 3.3 稳定性 稳定排序算法（倒序摆放） 四、适用场景 数据范围（max - min）比较小 数据范围（max - min）比数据量（n）要小得多 附录1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 计数排序 * &lt;p&gt; * 时间复杂度：O(n) * &lt;p&gt; * 空间复杂度：O(n) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2022/9/5 */public class CountSort implements Sort { @Override public void sort(int[] arr) { // 找出数据的范围（最小最大值） int min = Integer.MAX_VALUE; int max = Integer.MIN_VALUE; for (int num : arr) { if (num &gt; max) { max = num; } if (num &lt; min) { min = num; } } // 初始化计数范围 int n = max - min + 1; int[] counts = new int[n]; // 统计数字的数量 for (int num : arr) { int index = num - min; counts[index]++; } // 累计数量和 for (int i = 1; i &lt; counts.length; i++) { counts[i] += counts[i - 1]; } // 倒序遍历获取排序结果 int[] copy = Arrays.copyOf(arr, arr.length); for (int i = copy.length - 1; i &gt;= 0; i--) { int index = copy[i] - min; counts[index]--; arr[counts[index]] = copy[i]; } }}","link":"/algorithm/sort/countsort/"},{"title":"归并排序","text":"归并排序一、算法描述1.1 核心思想 二分，将数据分割成2部分，分别排序，再合并2个排好序的数据 递归，一直分割数据，直到无法分割，才开始递归合并返回 整个二分和合并的过程类似于一棵二叉树，从下往上合并数据，先对子树排序，再合并成根节点 1.2 细节解释 比如说，数组 [5, 7, 2, 4, 3, 6, 1]。 首先将数据不断地分割成 2 部分，直到无法分割为止： 12 ___ ___ ___ ___ ___ ___ ___| 5 | | 7 | | 2 | | 4 | | 3 | | 6 | | 1 | 然后从下往上开始合并排序返回： 1234567891011121314151617181920 ___ ___ ___ ___ ___ ___ ___| 5 | | 7 | | 2 | | 4 | | 3 | | 6 | | 1 | -- 原始数组 | | | | | | | |_______| |_______| |_______| | | | | | V V V V ___ ___ ___ ___ ___ ___ ___ | 5 | 7 | | 2 | 4 | | 3 | 6 | | 1 | -- 第一层合并 | | | | |_______________| |___________| | | V V ___ ___ ___ ___ ___ ___ ___ | 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 第二层合并 | | |_____________________________| | V ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | -- 第三层合并 归并排序采用的是分治思想，由小的有序数据逐渐合并成大的有序数据。 不过也不需要分到元素个数为 1 那么小，可以分到 4 时，就直接采用插入排序可能会更快一些。 归并排序中 2 个有序数组合并成 1 个数组时，一般采用双指针，类似这样： 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | | | | | | | | -- 额外空间 判断双指针指向元素的大小，小的放到额外空间中，然后移动指针： 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | | | | | | | -- 额外空间 通过不断判断和移动双指针，最终可以完成对 2 个有序数组的合并： 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | | | | | | -- 额外空间 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | | | | | -- 额外空间 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | 4 | | | | -- 额外空间 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | 4 | 5 | | | -- 额外空间 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | 4 | 5 | 6 | | -- 额外空间 123456789 lp rp | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 5 | 7 | | 1 | 3 | 6 | -- 当前数组 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | -- 额外空间 利用额外空间合并完成之后，再把排好序的数据回写到原数组即可。 二、算法实现二分排序代码，将数据分割成2部分，分别排序： 1234567891011121314private void sort(int[] arr, int start, int end) { if (start + 1 &gt;= end) { return; } // 计算中点 int mid = start + (end - start) / 2; // 对左边进行排序 sort(arr, start, mid); // 对右边进行排序 sort(arr, mid, end); // 合并左右两边的数据 merge(arr, start, mid, end);} 合并排好序的数据： 1234567891011121314151617181920212223private void merge(int[] arr, int start, int mid, int end) { int n = end - start; int[] tempArr = new int[n]; int i = start, j = mid, k = 0; while (i &lt; mid &amp;&amp; j &lt; end) { // 优先排左边的，保证稳定性 if (arr[i] &lt;= arr[j]) { tempArr[k++] = arr[i++]; } else { tempArr[k++] = arr[j++]; } } // 左边剩余元素 while (i &lt; mid) { tempArr[k++] = arr[i++]; } // 右边剩余元素 while (j &lt; end) { tempArr[k++] = arr[j++]; } // 注意复制到原数组时，起点是 start System.arraycopy(tempArr, 0, arr, start, n);} 三、算法分析3.1 时间复杂度 最好时间复杂度：O(nlogn) 最坏时间复杂度：O(nlogn) 平均时间复杂度：O(nlogn) 3.2 空间复杂度 空间复杂度：O(n) 非原地算法，需要额外空间 3.3 稳定性 稳定排序算法 四、适用场景 空间比较充足 利用空间换时间提升性能 附录1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 归并排序 * &lt;p&gt; * 时间复杂度：O(nlogn) * &lt;p&gt; * 空间复杂度：O(1) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2022/9/1 */public class MergeSort implements Sort { @Override public void sort(int[] arr) { sort(arr, 0, arr.length); } /** * 排序 * * @param arr 数组 * @param start [start, end) * @param end [start, end) */ private void sort(int[] arr, int start, int end) { if (start + 1 &gt;= end) { return; } // 计算中点 int mid = start + (end - start) / 2; // 对左边进行排序 sort(arr, start, mid); // 对右边进行排序 sort(arr, mid, end); // 合并左右两边的数据 merge(arr, start, mid, end); } /** * 合并排序数组 * * @param arr 数组 * @param start [start, end) * @param mid [start, mid) 和 [mid, end) * @param end [start, end) */ private void merge(int[] arr, int start, int mid, int end) { int n = end - start; int[] mergeArr = new int[n]; int i = start, j = mid, k = 0; while (i &lt; mid &amp;&amp; j &lt; end) { // 优先排左边的，保证稳定性 if (arr[i] &lt;= arr[j]) { mergeArr[k++] = arr[i++]; } else { mergeArr[k++] = arr[j++]; } } // 左边剩余元素 while (i &lt; mid) { mergeArr[k++] = arr[i++]; } // 右边剩余元素 while (j &lt; end) { mergeArr[k++] = arr[j++]; } // 注意复制到原数组时，起点是 start System.arraycopy(mergeArr, 0, arr, start, n); }}","link":"/algorithm/sort/mergesort/"},{"title":"冒泡和插入对比","text":"冒泡和插入对比一、比较次数冒泡排序比较： 12345678for (int i = 0; i &lt; n; i++) { for (int j = n - 1; j &gt; i; j--) { // 比较 if (arr[j] &lt; arr[j - 1]) { ... } }} 插入排序比较: 12345678for (int i = 1; i &lt; n; i++) { int x = arr[i]; int j = i; // 比较 for (; j &gt; 0 &amp;&amp; x &lt; arr[j - 1]; j--) { ... }} 从比较次数上说，冒泡和插入的比较次数差不多，都是 O(n) 级别的。 二、交换次数冒泡排序交换： 12345678for (int i = 0; i &lt; n; i++) { for (int j = n - 1; j &gt; i; j--) { ... // 交换 swap(arr, j, j - 1); ... }} 插入排序比较: 12345678for (int i = 1; i &lt; n; i++) { int x = arr[i]; int j = i; for (; j &gt; 0 &amp;&amp; x &lt; arr[j - 1]; j--) { // 交换 arr[j] = arr[j - 1]; }} 从交换次数上来说： 冒泡的交换（赋值）次数是 O(3n)：swap(arr, j, j - 1); 插入的交换（赋值）次数是 O(1n)：arr[j] = arr[j - 1]; 理论上说，冒泡排序的交换次数是插入排序的 3 倍。 三、实验对比使用数据测试冒泡排序和插入排序： 总共 10000 个数组 每个数组包含 [50, 250] 个元素 实验结果如下： 冒泡排序：348.1134 ms 插入排序：66.1865 ms 插入排序的性能是冒泡的好几倍。","link":"/algorithm/sort/bubble_insert_compare/"},{"title":"插入排序","text":"插入排序一、算法描述1.1 核心思想 数据分为已排序区间和未排序区间 插入都是从未排序区间取出元素，插入到已排序区间合适的位置中 插入已排序区间时，同时要保证已排序区间的有序性 1.2 细节解释 比如说，数组 [2, 7, 1, 4, 3, 6, 5]。 首先分成未排序和已排序区间，第 1 个值无需排序，默认属于已排序区间： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 2 | | 7 | 1 | 4 | 3 | 6 | 5 | 此时从未排序区间中取一个值 7，插入到已排序区间： 因为 7 &gt; 2，所以 7 直接插入到 2 后面： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 2 | 7 | | 1 | 4 | 3 | 6 | 5 | 继续从未排序区间取值 1，此时 1 &lt; 7、1 &lt; 2，所以插入到 2 前面： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 7 | | 4 | 3 | 6 | 5 | 以此类推，后面每一步的结果如下： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 4 | 7 | | 3 | 6 | 5 | 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 7 | | 6 | 5 | 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 6 | 7 | | 5 | 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 经过 n 轮插入以后，数组就排好序了。 二、算法实现12345678910111213public void insertSort(int[] arr) { int n = arr.length; for (int i = 1; i &lt; n; i++) { // 未排序区间数据元素 int x = arr[i]; int j = i; // 插入到已排序区间合适的位置 for (; j &gt; 0 &amp;&amp; x &lt; arr[j - 1]; j--) { arr[j] = arr[j - 1]; } arr[j] = x; }} 执行过程如下： 1234567891011121314151617===== 初始数组 =====[0, 3, 1, 6, 2, 5, 4]=====第 1 轮插入=====[0, 1, 3, 6, 2, 5, 4]=====第 2 轮插入=====[0, 1, 3, 6, 2, 5, 4]=====第 3 轮插入=====[0, 1, 2, 3, 6, 5, 4]=====第 4 轮插入=====[0, 1, 2, 3, 5, 6, 4]=====第 5 轮插入=====[0, 1, 2, 3, 4, 5, 6] 三、算法分析3.1 时间复杂度 最好时间复杂度：O(n) 最坏时间复杂度：O(n^2) 平均时间复杂度：O(n^2) 3.2 空间复杂度 空间复杂度：O(1) 原地算法 3.3 稳定性 稳定排序算法 附录123456789101112131415161718192021222324252627282930/** * 插入排序 * &lt;p&gt; * 时间复杂度：最好 O(n) 最差 O(n^2) 平均 O(n^2) * &lt;p&gt; * 空间复杂度：O(1) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2022/7/21 */public class InsertSort implements Sort { @Override public void sort(int[] arr) { int n = arr.length; for (int i = 1; i &lt; n; i++) { // 未排序区间数据元素 int x = arr[i]; int j = i; // 插入到已排序区间合适的位置 for (; j &gt; 0 &amp;&amp; x &lt; arr[j - 1]; j--) { arr[j] = arr[j - 1]; } arr[j] = x; } }}","link":"/algorithm/sort/insertsort/"},{"title":"选择排序","text":"选择排序一、算法描述1.1 核心思想 数据分为已排序区间和未排序区间 从未排序区间中找到最小/最大的元素，交换到未排序区间的头部 交换到未排序区间头部后，将头部划入已排序区间的末尾 1.2 细节解释 比如说，数组 [2, 7, 1, 4, 3, 6, 5]。 首先分成未排序和已排序区间，已排序区间一开始是空的： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___ | 2 | 7 | 1 | 4 | 3 | 6 | 5 | 首先找到未排序区间的最小值，也就是 1，和头部元素交换，并将头部划入已排序区间： 123456已排序 未排序 _______ | | V V ___ ___ ___ ___ ___ ___ ___ | 1 | 7 | 2 | 4 | 3 | 6 | 5 | 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | | 7 | 2 | 4 | 3 | 6 | 5 | 继续从未排序区间找最小值，得到 2，交换到头部，然后将头部 2 划入已排序区间： 123456 已排序 未排序 ___ | | V V ___ ___ ___ ___ ___ ___ ___| 1 | | 2 | 7 | 4 | 3 | 6 | 5 | 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | | 7 | 4 | 3 | 6 | 5 | 以此类推，分别交换得到 3、4、5、6、7 的最终位置： 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | | 4 | 7 | 6 | 5 | 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | | 7 | 6 | 5 | 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 5 | | 6 | 7 | 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 5 | 6 | | 7 | 123 已排序 未排序 ___ ___ ___ ___ ___ ___ ___ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 经过 n 轮交换，数组就排好序了。 二、算法实现1234567891011121314public void selectSort(int[] arr) { int n = arr.length; for (int i = 0; i &lt; n; i++) { // 寻找未排序区间内的最小值 int min = i; for (int j = i + 1; j &lt; n; j++) { if (arr[j] &lt; arr[min]) { min = j; } } // 将最小值插入到已排序区间的末尾 swap(arr, min, i); }} 执行过程如下： 1234567891011121314151617181920212223===== 初始数组 =====[0, 3, 1, 6, 2, 5, 4]=====第 1 轮插入=====[0, 3, 1, 6, 2, 5, 4]=====第 2 轮插入=====[0, 1, 3, 6, 2, 5, 4]=====第 3 轮插入=====[0, 1, 2, 6, 3, 5, 4]=====第 4 轮插入=====[0, 1, 2, 3, 6, 5, 4]=====第 5 轮插入=====[0, 1, 2, 3, 4, 5, 6]=====第 6 轮插入=====[0, 1, 2, 3, 4, 5, 6]=====第 7 轮插入=====[0, 1, 2, 3, 4, 5, 6] 三、算法分析3.1 时间复杂度 最好时间复杂度：O(n^2) 最坏时间复杂度：O(n^2) 平均时间复杂度：O(n^2) 3.2 空间复杂度 空间复杂度：O(1) 原地算法 3.3 稳定性 不稳定排序算法 附录12345678910111213141516171819202122232425262728293031/** * 选择排序 * &lt;p&gt; * 时间复杂度：最好 O(n^2) 最差 O(n^2) 平均 O(n^2) * &lt;p&gt; * 空间复杂度：O(1) * &lt;p&gt; * 稳定性：不稳定 * * @author weijiaduo * @since 2022/7/21 */public class SelectSort implements Sort { @Override public void sort(int[] arr) { int n = arr.length; for (int i = 0; i &lt; n; i++) { // 寻找未排序区间内的最小值 int min = i; for (int j = i + 1; j &lt; n; j++) { if (arr[j] &lt; arr[min]) { min = j; } } // 将最小值插入到已排序区间的末尾 swap(arr, min, i); } }}","link":"/algorithm/sort/selectsort/"},{"title":"冒泡排序","text":"冒泡排序一、算法描述1.1 核心思想 每次冒泡操作只会操作相邻的2个元素 每轮冒泡至少让一个元素移动到它正确的位置 最多经过n轮冒泡后，所有元素都会被移到正确的位置 1.2 细节解释 比如说，数组 [2, 7, 1, 4, 3, 6, 5]。 12 ___ ___ ___ ___ ___ ___ ___| 2 | 7 | 1 | 4 | 3 | 6 | 5 | 从后面往前面冒泡，首先 5，判断 5 和 6，由于 5 &lt; 6 所以 5 要往前冒泡： 12345 ___ | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 7 | 1 | 4 | 3 | 5 | 6 | 继续判断 5，到 3 了，5 &gt; 3，所以 5 不能往前冒泡了，当前对象换成 3： 1234 | V ___ ___ ___ ___ ___ ___ ___| 2 | 7 | 1 | 4 | 3 | 5 | 6 | 接下来是 3 和 4 对比，3 &lt; 4，所以 3 要往前冒泡： 12345 ___ | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 7 | 1 | 3 | 4 | 5 | 6 | 下一轮是 3 和 1，3 &gt; 1，切换当前对象为 1： 1234 | V ___ ___ ___ ___ ___ ___ ___| 2 | 7 | 1 | 3 | 4 | 5 | 6 | 下来是 1 和 7，1 &lt; 7，1 要往前冒泡： 12345 ___ | | V V ___ ___ ___ ___ ___ ___ ___| 2 | 1 | 7 | 3 | 4 | 5 | 6 | 最后是 1 和 2，1 &lt; 2，所以 1 要往前冒泡： 12345 ___ | | V V ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 7 | 3 | 4 | 5 | 6 | 这样一轮冒泡就结束了，此时 1 已经在它应该在的位置了。 每过一轮冒泡，总是能把一个值放到它正确的位置，经过 n 轮后就排好序了。 二、算法实现 总共执行 n 轮冒泡 每轮冒泡，会将剩余未排序元素的最小值放到数组前面 1234567891011121314public void bubbleSort(int[] arr) { int n = arr.length; // 进行 n 轮冒泡 for (int i = 0; i &lt; n; i++) { // 每轮冒泡，都会将一个元素放置到正确的位置 for (int j = n - 1; j &gt; i; j--) { // 每次只会操作相邻的2个元素 if (arr[j] &lt; arr[j - 1]) { // 交换相邻元素 swap(arr, j, j - 1); } } }} 举个例子，原始数据是：[0, 3, 1, 6, 2, 5, 4]，冒泡排序过程如下： 12345678910111213141516171819202122232425262728293031323334=====第 1 轮冒泡=====[0, 3, 1, 6, 2, 4, 5][0, 3, 1, 6, 2, 4, 5][0, 3, 1, 2, 6, 4, 5][0, 3, 1, 2, 6, 4, 5][0, 1, 3, 2, 6, 4, 5][0, 1, 3, 2, 6, 4, 5]=====第 2 轮冒泡=====[0, 1, 3, 2, 6, 4, 5][0, 1, 3, 2, 4, 6, 5][0, 1, 3, 2, 4, 6, 5][0, 1, 2, 3, 4, 6, 5][0, 1, 2, 3, 4, 6, 5]=====第 3 轮冒泡=====[0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6]=====第 4 轮冒泡=====[0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6]=====第 5 轮冒泡=====[0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6]=====第 6 轮冒泡=====[0, 1, 2, 3, 4, 5, 6]=====第 7 轮冒泡===== 三、算法优化当某轮冒泡中，没有执行任何交换时，说明数组已经排序好了，可以直接跳出循环： 1234567891011121314151617181920public void bubbleSort(int[] arr) { int n = arr.length; // 进行 n 轮冒泡 for (int i = 0; i &lt; n; i++) { // 每轮冒泡，都会将一个元素放置到正确的位置 boolean flag = false; for (int j = n - 1; j &gt; i; j--) { // 每次只会操作相邻的2个元素 if (arr[j] &lt; arr[j - 1]) { // 交换相邻元素 swap(arr, j, j - 1); flag = true; } } // 一轮冒泡里没有交换，说明已经排好序了 if (!flag) { break; } }} 上面同样的例子，执行过程如下： 123456789101112131415161718192021222324252627=====第 1 轮冒泡=====[0, 3, 1, 6, 2, 4, 5][0, 3, 1, 6, 2, 4, 5][0, 3, 1, 2, 6, 4, 5][0, 3, 1, 2, 6, 4, 5][0, 1, 3, 2, 6, 4, 5][0, 1, 3, 2, 6, 4, 5]=====第 2 轮冒泡=====[0, 1, 3, 2, 6, 4, 5][0, 1, 3, 2, 4, 6, 5][0, 1, 3, 2, 4, 6, 5][0, 1, 2, 3, 4, 6, 5][0, 1, 2, 3, 4, 6, 5]=====第 3 轮冒泡=====[0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6]=====第 4 轮冒泡=====[0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6][0, 1, 2, 3, 4, 5, 6]=====第 4 轮跳出循环===== 四、算法分析4.1 时间复杂度 最好时间复杂度：O(n) 最坏时间复杂度：O(n^2) 平均时间复杂度：O(n^2) 4.2 空间复杂度 空间复杂度：O(1) 原地算法 4.3 稳定性 稳定排序算法 附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 冒泡排序 * &lt;p&gt; * 时间复杂度：最好 O(n) 最差 O(n^2) 平均 O(n^2) * &lt;p&gt; * 空间复杂度：O(1) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2022/7/21 */public class BubbleSort implements Sort { /** * 排序 * * @param arr 数组 */ @Override public void sort(int[] arr) { // slowSort(arr); fastSort(arr); } /** * 慢一点的冒泡排序 * * @param arr 数组 */ private void slowSort(int[] arr) { int n = arr.length; for (int i = 0; i &lt; n; i++) { for (int j = n - 1; j &gt; i; j--) { if (arr[j] &lt; arr[j - 1]) { swap(arr, j, j - 1); } } } } /** * 快一点的冒泡排序 * * @param arr 数组 */ private void fastSort(int[] arr) { int n = arr.length; for (int i = 0; i &lt; n; i++) { boolean flag = false; for (int j = n - 1; j &gt; i; j--) { if (arr[j] &lt; arr[j - 1]) { swap(arr, j, j - 1); flag = true; } } // 一轮冒泡里没有交换，说明已经排好序了 if (!flag) { break; } } }}","link":"/algorithm/sort/bubblesort/"},{"title":"快速排序","text":"快速排序一、算法描述1.1 核心思想 二分，选取一个值x，将数据分割成2部分，一部分大于x，一部分小于x 递归，不断选点分割数据，直到最后无法分割 整个二分过程类似于一棵二叉树，从上往下排序，先确定根节点位置，再处理子树排序 1.2 细节解释 比如说， 数组 [5, 7, 2, 4, 3, 6, 1]。 首先选取一个值，比如说 5。 以 5 基准，将其他数据分割成 2 部分：一部分小于 5，一部分大于 5。 123 小于5 大于5 ___ ___ ___ ___ ___ ___| 2 | 4 | 3 | 1 | | 7 | 6 | 然后将 5 插入 2 部分的中间： 123 小于5 大于5 ___ ___ ___ ___ ___ ___ ___| 2 | 4 | 3 | 1 | | 5 | | 7 | 6 | 此时 5 就已经排好了。接着继续对左右 2 部分进行递归排序。 (1) 先对左边小于 5 的部分排序 首先选取一个值 2，然后以 2 为基准分割成 2 部分： 123小于2 大于2 ___ ___ ___| 1 | | 4 | 3 | 将 2 插入中间位置： 123小于2 大于2 ___ ___ ___ ___| 1 | | 2 | | 4 | 3 | 此时 2 就排好了。接着不断往下递归，直到无法分割为止。 最后可以得到： 12 ___ ___ ___ ___| 1 | | 2 | | 3 | | 4 | (2) 再对右边大于 5 的部分排序 同理，也是递归分割数据，最后可以得到： 12 ___ ___| 6 | | 7 | (3) 最后完整的序列结果 12 ___ ___ ___ ___ ___ ___ ___| 1 | | 2 | | 3 | | 4 | | 5 | | 6 | | 7 | 二、算法实现2.1 递归二分排序12345678910void partSort(int[] arr, int start, int end) { if (start &lt; end) { // 分区 int m = partition(arr, start, end); // 左边排序 partSort(arr, start, m); // 右边排序 partSort(arr, m + 1, end); }} 2.2 对数据分区1234567891011121314151617int partition(int[] arr, int start, int end) { // 选取分区点 int p = pivot(arr, start, end - 1); // 将分区点放到最前面 swap(arr, start, p); int ref = arr[start]; int lp = start; // 将数据与分区点对比，分成小于和大于2部分 for (int i = lp + 1; i &lt; end; i++) { if (arr[i] &lt;= ref) { swap(arr, ++lp, i); } } // 将分区点放到它最终的位置 swap(arr, start, lp); return lp;} 2.3 分区点的选择123456789// 采用左中右三点取中值的方式int pivot(int[] arr, int i, int j) { int mid = i + (j - i) / 2; if (arr[i] &lt; arr[j]) { return arr[mid] &gt; arr[i] ? mid : j; } else { return arr[mid] &lt; arr[i] ? mid : i; }} 三、算法分析3.1 时间复杂度 最好时间复杂度：O(nlogn) 最坏时间复杂度：O(n^2) 平均时间复杂度：O(nlogn) 3.2 空间复杂度 空间复杂度：O(1) 原地算法 3.3 稳定性 不稳定排序算法 四、适用场景 数据量比较大 数据有序性比较差 附录1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * 快速排序 * &lt;p&gt; * 时间复杂度：最好 O(nlogn) 最差 O(n^2) 平均 O(nlogn) * &lt;p&gt; * 空间复杂度：O(logn) * &lt;p&gt; * 稳定性：不稳定 * * @author weijiaduo * @since 2022/7/16 */public class QuickSort implements Sort { /** * 排序 * * @param arr 数组 */ @Override public void sort(int[] arr) { partSort(arr, 0, arr.length); } /** * 递归排序 * * @param arr 数组 * @param start [start, end) * @param end [start, end) */ private void partSort(int[] arr, int start, int end) { if (start &lt; end) { // 分区 int m = partition(arr, start, end); // 左边排序 partSort(arr, start, m); // 右边排序 partSort(arr, m + 1, end); } } /** * 二分数组 * * @param arr 数组 * @param start [start, end) * @param end [start, end) * @return 分隔点索引 */ private int partition(int[] arr, int start, int end) { // 选取分区点 int p = pivot(arr, start, end - 1); // 将分区点放到最前面 swap(arr, start, p); int ref = arr[start]; int lp = start; // 将数据与分区点对比，分成小于和大于2部分 for (int i = lp + 1; i &lt; end; i++) { if (arr[i] &lt;= ref) { swap(arr, ++lp, i); } } // 将分区点放到它最终的位置 swap(arr, start, lp); return lp; } /** * 选择分区点（选择三个点的中值位置） * * @param arr 数组 * @param i [i, j] * @param j [i, j] * @return 分区点索引 */ private int pivot(int[] arr, int i, int j) { int mid = i + (j - i) / 2; if (arr[i] &lt; arr[j]) { return arr[mid] &gt; arr[i] ? mid : j; } else { return arr[mid] &lt; arr[i] ? mid : i; } }}","link":"/algorithm/sort/quicksort/"},{"title":"16_03_Happen-Before原则的借助","text":"Happen-Before原则的借助Happen-Before 原则可以保证变量的可见性，因此可以通过 “借助” 的方式，来间接地实现对无锁保护变量的安全性保护。 “借助” 技术，一般将程序次序规则和其他某个规则（比如监视器锁规则或者 volatile 变量规则）结合起来实现的。 这种 “借助” 技术，对于代码语句的顺序非常敏感，因此很容易出错，属于一种高级技术。 举个例子来说明一下这个技术。 一、有并发问题的例子123456789101112131415161718class VolatileTest { int x = 0; boolean ready = false; // 线程A，先执行 public void writer() { x = 1; ready = true; } // 线程B，后执行 public void reader() { if (ready == true) { // x的值是什么，0？1？ } }} 线程 B 读到的值可能是什么呢？ (1) 首先，编译出来的指令可能会重排序优化 那么，线程 A 执行的指令代码可能是这样的： 1234public void writer() { ready = true; x = 1;} 也就是说，线程 A 可能先执行 ready = true，然后再执行 x = 1。 (2) 其次，线程 B 对于线程 A 的“影响”存在可见性问题 那么，线程 B 看到的情况可能有几种： 没看到 ready = true（可见性问题） 看到了 ready = true，但是没有看到 x = 1（有序性问题） 看到了 ready = true，也看到了 x = 1 理论上来说，只有第三种情况，才是正确的，但结果未必是这样的。 所以，由于存在有序性问题和可见性问题，线程 B 读到的 x 值是未知的。 二、“借助”技术的可见性保证这里，只对上面例子中的 ready 加了 volatile 修饰。 123456789101112131415161718class VolatileTest { int x = 0; volatile boolean ready = false; // 线程A，先执行 public void writer() { x = 1; ready = true; } // 线程B，后执行 public void reader() { if (ready == true) { // x的值是什么，0？1？ } }} 那么线程 B 看到的值都是什么？ (1) 程序次序规则 首先，volatile 变量具有禁止指令重排序的语义，可以保持有序性。 那么在线程 A 中，操作 x = 1 就只能在操作 ready = true 之前执行。 依据程序顺序规则，操作 x = 1 先于操作 ready = true。 (2) volatile 变量规则 其次，对于 volatile 变量 ready，线程 A 写操作在线程 B 的读操作之前执行 依据 volatile 变量规则，操作 ready = true 也先于操作 ready == true。 (3) 传递性规则 最后，依据传递性规则，操作 x = 1 必然先于操作 ready == true。 所以，线程 B 执行到 ready == true 时，必然可以看到 x = 1。 总结通过间接地利用 Happen-Before 原则，可以实现无锁保护变量的可见性。 不过这种技术，需要很精确地控制操作的执行顺序，一不小心就很容易写错。","link":"/lang/java/core/concurrency/16_03_Happen-Before%E5%8E%9F%E5%88%99%E7%9A%84%E5%80%9F%E5%8A%A9/"},{"title":"16_02_Java内存模型","text":"Java内存模型一、什么是内存模型？缓存一致性问题： 在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory） 当多处理器对同一块主内存区域进行操作时，可能会导致各自的缓存数据不一致，这就是缓存一致性问题 内存模型： 内存模型，是指在特定的操作协议下，对特定的内存或缓存进行读写访问的抽象过程 内存模型，定义了如何以一种安全可靠的方式去读写访问内存或缓存 简答来讲，内存模型规定了什么时候读入数据、什么时候写入数据、读写的顺序的等内存访问的问题 缓存一致性协议: 为了解决缓存一致性问题，内存模型就需要引入一些缓存一致性协议，比如 MSI、MESI、MOSI 等 缓存一致性协议，并不是针对某种内存模型，而是一种通用的缓存同步规范 Java 内存模型，是 JVM 定义的一个内存模型，使用的缓存一致性协议是 MESI 协议 二、为什么要有内存模型？定义 Java 内存模型的目的： 屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果 定义Java内存模型的好处： Java 内存模型统一了底层不同架构平台上内存模型的接口 程序无需关注运行平台的差异，只需要关注 Java 内存模型提供了怎么样的内存保证 程序不用去考虑底层访问的性能问题，由 JVM 负责去优化，JVM 会根据硬件的特性去优化执行速度 比如说，Java 内存模型保证了 volatile 变量的写入是对所有线程可见的。 程序员只需知道 volatile 变量是所有线程可见的即可，至于内存模型底层是怎么实现的，用的时候无需了解。 三、Java 内存模型的设计3.1 内存层次划分内存层次： 主内存（Main Memory）：主内存只有一个，所有变量数据都存储在主内存中 工作内存（Working Memory）：每条线程都有自己的工作内存，使用的变量都是主内存变量的一份拷贝 内存操作： 线程对变量的所有操作（读取、赋值等）都是在自己的工作内存中进行 不同线程之间不能直接访问对方工作内存中的变量 线程之间的变量值共享，只能通过主内存来完成 3.2 内存间的交互操作内存交互问题： 变量如何从主内存拷贝到工作内存？ 变量如何从工作内存同步回主内存？ 原子操作： lock（锁定）：作用于主内存变量，锁定主内存中的变量，防止其他线程访问 read（读取）：作用于主内存变量，读取主内存中的变量 load（加载）：作用于工作内存变量，将 read 拿到的变量，拷贝到工作内存中 use（使用）：作用于工作内存变量，使用工作内存中的变量 assign（赋值）：作用于工作内存变量，对工作内存的变量进行赋值 store（存储）：作用于工作内存变量，将工作内存的变量传送到主内存 write（写入）：作用于主内存变量，将 store 传送出来的变量写入主内存变量 unlock（解锁）：作用于主内存变量，将主内存中变量的锁定状态解除 执行规则： 一个新的变量，只能在主内存中“诞生” 不允许 read 和 load、store 和 write 操作之一单独出现 一个变量在同一时刻只允许一条线程对其进行 lock 操作 对一个变量执行 lock 操作，那将会清空工作内存中此变量的值 对变量执行 unlock 操作前，必须先把此变量同步回主内存中 3.3 内存模型的并发设计针对并发中出现的原子性、可见性、有序性问题，内存模型给了多种并发保证方式，来确保它们的安全性。 3.3.1 内存指令的并发保证(1) 原子性： 由 Java 内存模型直接保证的原子性操作包括 read、load、use、assign、store、write 更大范围的原子性操作，Java 内存模型还提供了 lock 和 unlock 来满足 (2) 可见性： Java 内存模型依赖于主内存作为传递媒介，来实现可见性： 写入变量后，将值同步刷新回主内存，比如通过 unlock 操作实现 读取变量前，从主内存中获取最新值，比如通过 lock 操作实现 一个线程的操作结果对于另一个线程可见，那必然是经过了主内存的传递 (3) 有序性： Java 内存模型是通过按需禁止重排序来避免有序性问题的 通过底层指令集的某些指令来禁止重排序，Java 语言层面可以使用 volatile 关键字 3.3.2 关键字的并发保证Java 语言中的并发关键字包括 synchronized、volatile、final。 (1) synchronized： 可以保证原子性、可见性、有序性 原子性：由“一个变量在同一时刻只允许一条线程对其进行 lock 操作”规则保证 可见性：由“对变量执行 unlock 操作前，必须先把此变量同步回主内存中”规则保证 有序性：由“一个变量在同一时刻只允许一条线程对其进行 lock 操作”规则保证，这条规则决定了持有同一个锁的两个同步块只能串行地进入 (2) volatile： 可以保证可见性和有序性 可见性：volatile 变量保证了新值可以立即同步回主内存中，以及每次使用前立即从主内存中刷新 有序性：volatile 关键字本身设计就包含了禁止指令重排序地语义 (3) final： 可以保证可见性 可见性：被 final 修饰的字段，在构造器中一旦正确安全初始化完成后（安全发布），就保证了它的可见性 并发关键字可以让程序自己选择是否要控制可见性和有序性。 3.3.3 先行发生原则（happens-before）的并发保证Java 内存模型为了保证可见性和有序性，规定了一种先行发生原则（happens-before）。 先行发生原则定义： 想要保证执行操作 B 的线程，能够看到执行操作 A 的结果，A 和 B 必须满足 Happen-Before 原则 如果操作 A 发生于操作 B 之前，那么操作 A 产生的“影响”就能被执行操作 B 的线程所观察到 其中“影响”包括：修改了内存中共享变量的值、发送了消息、调用了方法等 先行发生原则特点： 操作 A 先行发生于操作 B，这里先行是指时间顺序上的先行发生 前一个操作的“影响”对后续操作是可见的。比如修改了内存中共享变量的值 先行发生规则： 程序次序规则（Program Order Rule）：一个线程内，保证程序语义的串行性 管程锁定规则（Monitor Lock Rule）：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作（必须是同一个锁） volatile 变量规则（Volatile Variable Rule）：对一个 volatile 变量，对于它的写操作先行发生于后面对它的读操作 线程启动规则（Thread Start Rule）：Thread 对象的 start() 方法先行发生于此线程的每一个动作 线程终止规则（Thread Termination Rule）：线程中的所有操作，都先行于对于此线程的终止检测 线程中断规则（Thread Interruption Rule）：对线程 interrupt() 方法的调用先行发生于对此线程的中断检测 对象终结规则（Object Termination Rule）：对象的初始化完成（构造函数执行结束）先行发生于它的 finallize() 方法的开始 传递性规则（Transitivity Rule）：如果 A 先行于 B，B 先行于 C，那么 A 先行于 C 举几个例子： (1) 管程锁定规则 管程锁定规则，规定了 unlock 操作先行发生于 lock 操作。 也就是说，上一个 unlock 操作之前产生的“影响”，对于下一个 lock 操作是可见的。 12345678910111213// 线程 Asynchronized (this) { // 此处自动加锁 lock // count 是共享变量 this.count = 1;} // 此处自动解锁 unlock// 线程 B synchronized (this) { // 此处会执行 lock 操作 if (this.count == 1) { // 管程锁定规则可以确保看到 count 变量的值 }} // 此处会执行 unlock 操作 假设线程 A 先拿到锁，对 count 变量进行了修改，得到 count = 1，然后执行 unlock 操作退出加锁区域。 接着线程 B 再执行 lock 操作去获取锁，线程 A 的 unlock 操作先于线程 B 的 lock 操作执行。 依据管程锁定规则，那么线程 B 就能看到线程 A 的修改，也就是线程 B 内可以看到 count = 1。 (2) 线程启动规则 线程启动规则，规定了 Thread 对象的 start() 方法先行发生于此线程的每一个动作。 也就是说，在 Thread 对象的 start() 方法执行前所产生的“影响”，线程内都是可见的。 123456789101112131415161718static int count = 0;Thread B = new Thread(() -&gt; { // 主线程调用B.start()之前 // 所有对共享变量的修改，此处皆可见 if (count == 1) { // 线程启动规则可以保证能进入到这里 }});// 对共享变量var修改count = 1;// count &gt; 0 是为了确保 count = 1 在 B.start(); 之前执行（程序次序规则）if (count &gt; 0) { // 主线程启动子线程 B.start();} 主线程在启动子线程 B 的 start() 方法前的操作，即 count = 1，对于线程 B 内而言，是可见的。 也就是，主线程对 count 的修改，先行于线程 B 的 start() 方法，那么线程 B 内部就可以看到修改的结果。 3.3.4 初始化安全性的并发保证内存模型还提供了一些在对象初始化方面的并发保证： 静态初始化器，可以保证对所有线程具有可见性 对于被正确构造的对象，所有线程都能看到构造函数给 final 域设置的值，包括 final 域引用对象内可达的值 12345678910111213public class SafeStates { private static Object object = new Object(); private final Map&lt;String, String&gt; states; public SafeStates() { states = new HashMap&lt;&gt;(); states.put(&quot;1&quot;, &quot;a&quot;); states.put(&quot;2&quot;, &quot;b&quot;); states.put(&quot;3&quot;, &quot;c&quot;); }} 也就是说，由 SafeStates 创建的对象，它里面的 object 和 states，对于所有线程而言，都是可见的。 而且，states 里面的值 1、2、3 对所有线程也是可见的。 但是，初始化安全性的保证，只保证对象在初始化阶段是安全可见的。 如果后面改变的了对象的值，比如在构造函数外执行 state.put(&quot;4&quot;, &quot;d&quot;)，这个值的可见性就无法保证，必须采用同步。","link":"/lang/java/core/concurrency/16_02_Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"16_01_并发问题来源","text":"并发问题来源一、缓存带来的可见性问题 计算机中可以保存数据的地方有几个：寄存器、缓存、主内存 原始数据都保存在主存上，最初的读取和最终的写入，都是在主存上操作 CPU 与主存之间存在缓存，每个 CPU 都有自己独立的的缓存 操作数据时，首先要将原始数据从主存中读取到 CPU 的缓存中，然后再对缓存的数据进行操作 单 CPU 下，一个线程对缓存的修改，对于另一个线程来说是可见的，因为只有一个缓存 多 CPU 下，线程可能运行在不同 CPU 上，操作的是各自不同的缓存，相互之间是不可见的 比如，主存中一个变量 count = 1； 线程 A 在 CPU1 上运行，读取 count 到缓存 Cache1，然后执行 count++; 线程 B 在 CPU2 上运行，也读取 count 缓存 Cache2，然后执行 count++; 假如 A 和 B 是同时读取的 count，它们拿到后都是 1，接着执行了 count++ 后，结果都变成了 2。 最后线程 A 和线程 B 同步变量到主存后，count 的值最终只会是 2，但是理论上应该是 3 才对。 这都是因为线程 A 和线程 B 各自只在自己的缓存上操作数据，相互不可见，导致没有意识到 count 被改了。 二、任务切换带来的原子性问题 一个线程任务不可能长期占用 CPU，每隔一段时间，就需要切换线程任务 线程任务切换一般采用时间片作为单位，比如 50 毫秒一个时间片 线程在执行1个或多个时间片后，就可能会被切换到其他线程任务 如果后面的线程修改了之前线程的数据，那等下次轮到之前线程执行时，它的状态就可能会和它之前被切换前的状态不一致，继续执行下去就有可能出现并发问题 比如 long 变量是 64 位。 线程 A 刚加载了它的前 32 位数据，就被切换走了，开始执行线程 B。 然后线程 B 把变量值改了，写了新值进去，然后又切换回线程 A 执行。 此时线程 A 去加载后 32 位时，数据已经和之前的不一样了。 最终，旧值的前 32 位 + 新值的后 32 位，这 2 个 32 位拼起来的 64 位就会是一个意料之外的值。 三、指令重排带来的有序性问题 编译器生成的指令顺序，可能会和源代码的顺序不同，因为它会对代码进行优化，以便提高执行效率 处理器可以采用乱序或并行的方式来执行指令，比如指令流水线，所以也不一定是按照编译器生成的指令顺序来执行 缓存变量提交到主内存的次序可能会改变，即缓存中先写的变量，不一定会被先提交到主内存中 比如下面可能会出现重排序的例子： 1234567891011121314151617181920212223242526public class PossibleReordering { static int x = 0, y = 0; static int a = 0, b = 0; public static void main(String[] args) throws InterruptedException { Thread one = new Thread(() -&gt; { a = 1; // 1 x = b; // 2 }); Thread other = new Thread(() -&gt; { b = 1; // 3 y = a; // 4 }); one.start(); other.start(); one.join(); other.join(); System.out.println(&quot;(&quot; + x + &quot;,&quot; + y + &quot;)&quot;); }} 由于每个线程中的各个操作没有数据流依赖性，所以这些操作可以乱序执行。 也就是说，1和2之间没有依赖关系，所以重排序后2可能比1先执行；同理，4也可能比3先执行。 因此，输出的结果就可能有4种： (0, 1) (1, 0) (1, 1) (0, 0) 其中，(0, 0) 就是由于指令重排引起的，重排后的执行顺序可能是这样的： 12345时间线&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;线程A x=b; a=1;线程B b=1; y=a;","link":"/lang/java/core/concurrency/16_01_%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E6%9D%A5%E6%BA%90/"},{"title":"15_02_原子变量","text":"原子变量一、原子变量类原子变量类相当于是一种泛化的 volatile 变量，能够支持原子和有条件的读写操作。 1.1 原子类型 标量类：AtomicInteger、AtomicLong、AtomicBoolean、AtomicReference 数组类：AtomicIntegerArray、AtomicLongArray、AtomicBooleanArray 更新器类：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicBooleanFieldUpdater 复合变量类：AtomicMarkableReference 1.2 性能比较 原子变量比锁的粒度更细、量级更轻 原子变量将发生竞争的范围缩小至单个变量上 原子变量通常会更快，因为它不需要挂起或重新调度线程 在高度竞争的情况下，锁的性能会比原子变量更好，原因是锁会挂起线程，避免了很多线程上下文切换 在中低竞争的情况下，原子变量能提供更高的可伸缩性 二、非阻塞算法 非阻塞的计数器：单状态 非阻塞的数字区域：单不可变对象，包含多状态 非阻塞的栈：单状态 非阻塞的队列：多状态 2.1 非阻塞的计数器12345678910111213141516171819202122/** * 《并发编程实战》-第15章 * 基于 CAS 实现的非阻塞计数器 * @since 2022/4/27 */public class CasCounter { private SimulatedCAS value; public int getValue() { return value.get(); } public int increment() { int v; do { v = value.get(); } while (v != value.compareAndSwap(v, v + 1)); return v + 1; }} 2.2 非阻塞的数字区域12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 《并发编程实战》-第15章 * 原子变量 + 不可变对象实现多状态更新 * @since 2022/4/27 */public class CasNumberRange { private static class IntPair { // 不变性条件：lower &lt;= upper final int lower; final int upper; public IntPair(int lower, int upper) { this.lower = lower; this.upper = upper; } } private final AtomicReference&lt;IntPair&gt; values = new AtomicReference&lt;&gt;(new IntPair(0, 0)); public int getLower() { return values.get().lower; } public int getUpper() { return values.get().upper; } public void setLower(int i) { while (true) { IntPair oldValue = values.get(); if (i &gt; oldValue.upper) { throw new IllegalArgumentException(&quot;Can't set lower to &quot; + i + &quot; &gt; upper&quot;); } IntPair newValue = new IntPair(i, oldValue.upper); if (values.compareAndSet(oldValue,newValue)) { break; } } } public void setUpper(int i) { while (true) { IntPair oldValue = values.get(); if (i &lt; oldValue.lower) { throw new IllegalArgumentException(&quot;Can't set upper to &quot; + i + &quot; &lt; lower&quot;); } IntPair newValue = new IntPair(oldValue.lower, i); if (values.compareAndSet(oldValue,newValue)) { break; } } }} 2.2 非阻塞的栈12345678910111213141516171819202122232425262728293031323334353637383940/** *《并发编程实战》-第15章 * 非阻塞栈 * @since 2022/4/27 */public class ConcurrentStack&lt;E&gt; { private AtomicReference&lt;Node&lt;E&gt;&gt; top = new AtomicReference&lt;&gt;(); public void push(E item) { Node&lt;E&gt; newTop = new Node&lt;&gt;(item); Node&lt;E&gt; oldTop; do { oldTop = top.get(); newTop.next = oldTop; } while (!top.compareAndSet(oldTop, newTop)); } public E pop() { Node&lt;E&gt; oldTop; do { oldTop = top.get(); if (oldTop == null) { return null; } } while (!top.compareAndSet(oldTop, oldTop.next)); oldTop.next = null; return oldTop.item; } private static class Node&lt;E&gt; { public final E item; public Node&lt;E&gt; next; public Node(E item) { this.item = item; } }} 2.3 非阻塞的队列1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** *《并发编程实战》-第15章 * 非阻塞链表 * @since 2022/4/30 */public class LinkQueue&lt;E&gt; { private final Node&lt;E&gt; dummy = new Node&lt;&gt;(null, null); private final AtomicReference&lt;Node&lt;E&gt;&gt; head = new AtomicReference&lt;&gt;(dummy); private final AtomicReference&lt;Node&lt;E&gt;&gt; tail = new AtomicReference&lt;&gt;(dummy); /** * 推入队列尾部 * 分 2 步 CAS： * 1. 设置 tail.next 为 newNode * 2. 设置 tail 为 tail.next */ public boolean put(E item) { Node&lt;E&gt; newNode = new Node&lt;&gt;(item, null); while (true) { Node&lt;E&gt; curTail = tail.get(); Node&lt;E&gt; next = curTail.next.get(); if (curTail != tail.get()) { continue; } if (next != null) { // 中间态，可能成功或失败 // 2. 设置 tail 为 tail.next tail.compareAndSet(curTail, next); } else { // 1. 设置 tail.next 为新增加的 item if (curTail.next.compareAndSet(null, newNode)) { // 中间态，可能成功或失败 // 2. 设置 tail 为 tail.next tail.compareAndSet(curTail, newNode); return true; } } } } /** * 返回队列头部 */ public E pop() { while (true) { // head 是一个哨兵节点，下一个节点才是数据 Node&lt;E&gt; curHead = head.get(); Node&lt;E&gt; firstNode = curHead.next.get(); if (firstNode == null) { return null; } Node&lt;E&gt; secondNode = firstNode.next.get(); if (curHead.next.compareAndSet(firstNode, secondNode)) { firstNode.next.set(null); return firstNode.item; } } } private static class Node&lt;E&gt; { final E item; final AtomicReference&lt;Node&lt;E&gt;&gt; next; public Node(E item, Node&lt;E&gt; next) { this.item = item; this.next = new AtomicReference&lt;&gt;(next); } }}","link":"/lang/java/core/concurrency/15_02_%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F%E5%92%8C%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5/"},{"title":"15_01_CAS操作","text":"CAS 操作一、锁的劣势 采用独占的方式访问锁的守护变量 获取锁，存在挂起和恢复线程的问题，这些操作都比较耗时 等待锁时，线程不能做其他的事情 容易出现活跃性故障，比如死锁、活锁等 锁竞争激烈时，线程调度开销会非常大 二、CAS 操作2.1 基本原理基本原理： CAS 包含3个操作数：内存原值 V，期望旧值 A，写入新值 B 当且仅当 V == A 时，才能将 V 更新为 B 简单地说，就是当 V == A 时，CAS 就认为没有其他线程修改过内存值 V，可以直接写入新值。 当多线程竞争同一个 CAS 时，只有其中一个线程可以成功，其他线程均失败 用代码模拟 CAS 操作大概如下： 123456789101112131415161718192021public class SimulatedCAS { private int value; public synchronized int get() { return value; } public synchronized int compareAndSwap(int expectValue, int newValue) { int oldValue = value; if (oldValue == expectValue) { value = newValue; } return oldValue; } public synchronized boolean compareAndSet(int expectValue, int newValue) { return (expectValue == compareAndSwap(expectValue, newValue)); } } 实际上 CAS 操作会由底层的 JVM 或操作系统实现，是一种原子操作。 CAS 的使用模式通常是这样的： 首先从内存 V 中读取到值 A，此时 V == A 然后根据 A 计算得到新值 B 接着通过 CAS 以原子方式将 V 的值更新为 B 如果 CAS 成功，则返回；否则一般都需要重新执行 CAS 伪代码如下： 1234567while(true) { A = V; B = A + 1; if (CAS(V, A, B)) { return; }} 使用 CAS 时，一般都是循环执行代码，直到 CAS 成功为止。 2.2 硬件支持在多处理器架构中，一般都提供有一些特殊指令，用于管理对共享数据的并发访问： Test-and-Set（测试并设置） Fetch-and-Increment（获取并递增） Compare-and-Swap（比较并交换） Load-Linked（加载链接） Store-Conditional（存储条件） 这些特殊指令，提供了某种形式的“原子“读写操作，可以安全地访问共享数据。 2.3 JVM 支持硬件指令虽然提供了 CAS 的实现，但是在 Java 代码中是不能直接使用硬件指令的。 所以 JVM 会将 CAS 代码编译成底层硬件提供的最有效方法： 在支持 CAS 的平台上，JVM 会将 CAS 代码编译为相应的（多条）机器指令 在不支持 CAS 的平台上，JVM 将会使用自旋锁来代替 CAS 操作 JVM 为 Java 代码执行 CAS 操作提供了底层的支持。 2.4 锁和 CAS 的区别 独占锁是一项悲观技术；而 CAS 是一项乐观的技术 获取锁失败时，线程会阻塞挂起；而竞争 CAS 失败时，线程不会阻塞，而是直接返回 锁的获取可能导致操作系统级别的锁定、线程挂起以及上下文切换等；而 CAS 操作不会 锁可以自动处理竞争问题（JVM 实现）；而 CAS 需要由调用者处理竞争问题（循环 CAS 直到成功） 锁定时，至少需要一次 CAS，所以锁的开销基本都会比 CAS 大 竞争激烈时，锁的性能会更好；而竞争不激烈时，CAS 的性能会更好 竞争激烈时，CAS 会导致很多线程空自旋等待，浪费 CPU 资源","link":"/lang/java/core/concurrency/15_01_CAS%E6%93%8D%E4%BD%9C/"},{"title":"14_条件队列","text":"条件队列一、状态依赖性管理1.1、前提条件类中一般有很多依赖于状态的方法，只有满足某些条件时才能正常执行。 比如说，在有界队列中的方法： put 方法调用前，必须满足 !isFull() 条件 take 方法调用前，必须满足 !isEmpty() 条件 像 !isFull()、!isEmpty() 这种被操作依赖的状态条件，称为前提条件。 前提条件中可能包含一个或多个状态变量： 123public boolean isEmpty() { return size == 0;} 前提条件 isEmpty() 这里就包含了一个状态变量：size。 1.2 前提条件的处理对于单线程程序而言，当前提条件不满足时，都是直接从该方法返回； 但是对于并发程序而言，前提条件不满足的情况下，可以有其他选择方案： 前提条件失败，可以直接返回 前提条件失败，可以一直等待条件变为真 并发程序中，前提条件可以等待的要求就是：线程之间共享状态变量。 线程在等待前提条件变为真，而变为真的情况只能是被其他线程修改了状态变量 因此，对于前提条件的要求如下： 前提条件中涉及的状态变量，必须由对象的锁来保护，否则会有线程安全性问题 等待前提条件变为真的线程，必须释放对象的锁，否则其他线程无法修改状态变量 前提条件的等待实现，有2种方式： 非阻塞的轮询 阻塞的等待 二、非阻塞的轮询2.1 将前提条件的失败传递给调用者前提条件失败，最简单的处理方式就是：直接返回失败。 123456public synchronized void put(V item) { if (isFull()) { throw new IllegalStateException(&quot;Queue full&quot;); } doPut(item);} 当前提条件失败后，调用者将收到异常。 但是，如果调用者想要一直等待到前提条件变为真，就必须自己处理异常和重试： 12345678while (true) { try { put(item); break; } catch (IllegalStateException e) { // 等待前提条件变为真 }} 这种方式称为忙等待或者自旋等待，会消耗大量的 CPU 时间。 不过，这种方式还可以使用休眠来进行优化： 123456789while (true) { try { put(item); break; } catch (IllegalStateException e) { // 休眠一会，避免消耗大量的 CPU 时间 Thread.sleep(SLEEP_TIME); }} 但存在一个问题，休眠可能会导致系统的响应性变差。 因为在休眠期间，前提条件可能变为真了，但是线程还处于休眠状态，无法执行。 2.2 通过轮询与休眠来实现简单的阻塞由调用者来负责处理异常和重试，调用的代码会变得非常复杂。 为了减低调用者的代码重复率和复杂度，可以将重试移入方法中： 123456789101112public void put(V item) throws InterruptedException { while (true) { synchronized (this) { if (!isFull()) { doPut(item); return; } } // 休眠一会，避免消耗大量的 CPU 时间 Thread.sleep(SLEEP_TIME); }} 将代码迁入方法内后，调用者那边就变简单了，只需要调用接口即可。 不过这种方式依旧存在响应性问题。 2.3 非阻塞方式的弊端非阻塞方式实现的前提条件等待弊端有： 自旋等待会消耗大量的 CPU 时间 定时休眠会导致系统的响应性变差 每次失败都会休眠一段时间，如果休眠期间前提条件变为真了，但还是要等休眠结束后，才会继续执行。 三、阻塞的条件队列3.1 条件队列条件队列是通过一种等待-通知的方式，用来解决非阻塞方式的弊端。 当前提条件失败时，线程进入阻塞等待状态 当前提条件满足后（其他线程修改状态后），通知唤醒等待线程 通过等待-通知的方式，避免了自旋等待和定时休眠的问题。 实际上，等待-通知方式的原理就是： 阻塞等待时，将当前线程放入锁对象的一个队列中 通知唤醒时，从锁对象队列中取出一个或多个线程，让它们继续执行 在等待-通知过程中用到的队列，就称为条件队列。 3.2 条件谓词（前提条件）条件谓词，就是指的被某个操作依赖的前提条件，它是由类中各个状态变量构成的表达式。 比如条件谓词（前提条件） isEmpty()： 123public boolean isEmpty() { return size == 0;} 用到的状态变量就是 size。 在设计一个依赖于状态的类时，必须找出类中的条件谓词和依赖于条件谓词的操作。 比如之前提到的： 依赖操作：put()、take() 条件谓词：isEmpty()、isFull() 状态变量：size 统计完后，这些操作中涉及到的条件谓词、变量代码都需要加锁处理。 3.3 内置条件队列在 Java 中，每个对象都内置有一个条件队列。 操作内置条件队列，需要执行特定的方法。比如说： 123456789public void put(V item) throws InterruptedException { synchronized (this) { while (isFull()) { wait(); // 进入内置条件队列阻塞等待 } doPut(item); notifyAll(); // 通知唤醒内置条件队列中的线程 }} 当执行 wait() 方法之后，实际上就会进入 this 对象的内置条件队列。 而执行 notifyAll() 方法之后，就会唤醒所有在内置条件队列中的线程。 内置条件队列，底层是由 JVM 来实现和维护的，所以无需写 Java 代码去管理。 3.4 显式条件队列除了内置锁，Java 中还提供了显式锁 Lock，它的作用和内置锁是一样的。 显式锁也有自己的条件队列： 1234567891011121314final Lock lock = new ReentrantLock();public void put(V item) throws InterruptedException { lock.lock(); try { while (isFull()) { lock.await(); // 进入显式条件队列阻塞等待 } doPut(item); lock.signalAll(); // 通知唤醒显式条件队列中的线程 } finally { lock.unlock(); }} 显式条件队列和内置条件队列的区别是： 内置条件队列，是由 JVM 来实现和维护的；而显式锁的条件队列是由锁类自己实现的 内置条件队列，只能有一个；而显式锁的条件队列可以有多个 内置锁的条件等待是不可中断的；而显示锁的条件等待是可以中断的 内置的条件队列是非公平的；而显式的条件队列提供了公平和非公平两种方式 比如说，显示锁支持多个条件队列： 12345678910111213141516final Lock lock = new ReentrantLock();final Condition notFull = lock.newCondition();final Condition notEmpty = lock.newCondition();public void put(V item) throws InterruptedException { lock.lock(); try { while (isFull()) { notFull.await(); // notFull 条件队列 } doPut(item); notEmpty.signalAll(); // notEmpty 条件队列 } finally { lock.unlock(); }} 这里就用了 2 个显式条件队列，分别是 notFull 和 notEmpty。 3.5 条件队列和轮询阻塞的条件队列和非阻塞的轮询，在本质上还是一样的： 条件队列并没有改变轮询的语义 条件队列只是对轮询进行了优化：CPU 效率、上下文切换开销和响应性 条件队列只是使得前提条件的等待方式变得更高效了。 四、条件队列的使用4.1 加锁后操作条件队列，是绑定在等待对象上的，所以对条件队列的操作，都必须先拿到对象的锁。 1234567891011public void put(V item) throws InterruptedException { // 先拿到对象的锁 synchronized (lock) { while (isFull()) { // 在锁对象的条件队列上阻塞等待 lock.wait(); } doPut(item); lock.notifyAll(); }} 操作条件队列，不管是出队还是入队，都需要先获取对象的锁。 对于内置条件队列而言，wait()、notifyAll() 方法就是入队和出队的操作。 所以 wait() 方法和 notifyAll() 方法必须在获取对象锁之后才能执行。 4.2 循环等待条件线程被唤醒后，必须重新校验条件谓词，避免是伪唤醒： 条件队列可以被多个条件谓词使用，比如 isEmpty() 和 isFull() 可以共用同一个条件队列 线程从开始唤醒到真正执行这段时间内，条件谓词有可能从真变为了假 基于各种情况，线程唤醒后，应该再重新验证一下条件谓词，否则可能会出现线程安全问题。 不要使用这种非循环等待的方式： 123456789public void put(V item) { synchronized (this) { if (isFull()) { // 应该用 while 循环 wait(); } doPut(item); notifyAll(); }} 因为你永远不知道，为什么线程会被唤醒，比如这种无条件唤醒： 1234567// 假设此时阻塞了queue.put(item);// 没有条件，直接唤醒所有线程synchronized (queue) { queue.notifyAll();} 线程完全不知道，是在什么情况下被唤醒的，它只知道被唤醒了而已。 如果唤醒后直接执行后续代码，有可能条件是不满足的，所以应该采用循环等待的方式。 4.3 锁对象必须是同一个不同的对象，拥有各自不同的条件队列。 前提条件用到的锁对象，必须和条件队列绑定的锁对象是同一个。 比如说： 123456789public void put(V item) { synchronized (lock1) { if (isFull()) { lock2.wait(); } doPut(item); lock3.notifyAll(); }} 假如执行了 lock2.wait() 方法，那么线程就会被阻塞，并进入 lock2 的条件队列中。 线程进入了阻塞，而此时线程还拿着 lock1 的锁没有释放，因为线程阻塞后释放的是 lock2 的锁。 这就导致，其他线程完全没有办法执行 put() 方法了。 除此以外，状态变量不是由同一个锁保护，还可能出现死锁、并发安全等问题。 4.4 避免信号丢失信号丢失，是指线程在等待一个已经发生过的信号。 唤醒可以分为 2 种方式： notify：随机唤醒条件队列中的一个线程 notifyAll：唤醒条件队列中的所有线程 其中，使用 notify 唤醒1个线程时，有可能导致信号丢失。 一个条件队列可以绑定多个条件谓词 唤醒随机时，就不知道是唤醒的是哪个条件谓词相关的线程 可能通知信号被其他条件谓词的线程劫持了，从而导致真正需要的线程无法唤醒 举个栗子： 线程 A 在等待条件 PA；线程 B 在等待条件 PB 此时条件 PA 满足了，然后调用 notify() 方法唤醒，结果唤醒的是线程 B 线程 B 一看，自己的 PB 条件还未满足，又阻塞去了 结果导致线程 A 没有收到唤醒信号 所以，如果想使用 notify() 方法，必须满足以下条件： 条件队列关联的条件谓词是一样的 所有等待线程的类型都相同 单进单出，每次只有1个线程来执行 建议，优先使用 notifyAll() 方法，除非使用 notifyAll() 方法出现了性能问题。 notifyAll() 方法会唤醒所有等待线程，因此会带来一些性能问题： 可能会出现大量的上下文切换 可能会出现大量的锁竞争 比如说，n 个等待线程，使用 notifyAll() 可能会导致 O(n^2) 次唤醒操作，但实际只需要 n 次而已。 不过，可以使用条件通知来稍微优化一下 notifyAll()： 123456789101112public void put(V item) { synchronized (this) { if (isFull()) { wait(); } boolean wasEmpty = isEmpty(); doPut(item); if (wasEmpty) { notifyAll(); } }} 实际上，单次通知 notify() 和条件通知，都是对 notifyAll() 的优化。 但是这 2 种优化在使用时很容易写错，所以应该考虑清楚后再使用。 4.5 子类继承当父类使用单次通知或条件通知时，子类可能会变得比较复杂。 子类可能会违背单次通知和条件通知的原则 也就是说，单次通知和条件通知都是限制了特定情况下触发的，如果子类变更了这类需求，就有可能导致信号丢失等问题。 子类如果破坏了单次通知和条件通知，那么子类需要自己增加合适的通知机制，比如使用 notifyAll 对于状态依赖且使用条件队列的类，其设计原则应该满足： 要么等待-通知等协议完全向子类公开，协议需写入正式文档 要么完全阻止子类参与等待-通知等过程 因为等待-通知机制是很容易出错的，所以设计时需谨慎。 公开给子类实现：将父类的协议规定写入文档，让子类按文档要求实现 禁止子类参与等待-通知过程：将条件队列、锁、状态变量等隐藏起来，使得子类看不见 实际上就是，要么完全由子类自己实现等待-通知，要么完全由父类实现等待-通知。 4.6 入口协议和出口协议对于依赖状态或影响状态的操作，都应该定义好入口协议和出口协议： 入口协议：即该操作的条件谓词（前提条件） 出口协议：即该操作修改的状态所影响到的条件谓词 比如说，操作 put 的出入口协议： 入口协议：isEmpty()出口协议：isFull() 在实际使用时，应该这样： 入口协议不满足时，进入条件队列等待阻塞 出口协议满足时，通知条件队列唤醒线程 用代码来表示，大概就是这样： 12345678910111213141516public void put(V item) { lock.lock(); try { // 入口协议，不满足时进入条件队列等待 while (isFull()) { notFull.await(); } doPut(item); // 出口协议，满足后通知条件队列唤醒线程 notEmpty.signalAll(); } finally { lock.unlock(); }} 另外，应该将入口协议和出口协议写入正式文档。 总结前提条件： 前提条件：被操作方法依赖的状态条件，可能包含一个或多个状态变量 对于并发程序而言，在前提条件不满足的情况下，可以有不同的处理方案 前提条件失败，可以直接返回 前提条件失败，可以一直等待条件变为真 线程在等待前提条件变为真，而变为真的情况只能是被其他线程修改了状态变量 前提条件中涉及的状态变量，必须由对象的锁来保护，否则会有线程安全性问题 等待前提条件变为真的线程，必须释放对象的锁，否则其他线程无法修改状态变量 前提条件的等待实现，有2种方式： 非阻塞的轮询 阻塞的等待 轮询等待（忙等待、自旋等待）： 轮询等待直到前提条件变为真，就必须自己处理异常和重试 轮询等待的弊端： 自旋等待会消耗大量的 CPU 时间 定时休眠会导致系统的响应性变差 条件队列： 条件队列是通过一种等待-通知的方式，用来解决非阻塞方式的弊端 当前提条件失败时，线程进入阻塞等待状态 当前提条件满足后（其他线程修改状态后），通知唤醒等待线程 条件队列：在等待-通知过程中用到的队列 条件谓词：就是指的被某个操作依赖的前提条件 内置条件队列： 在 Java 中，每个对象都内置有一个条件队列 执行 wait()、notify()、notifyAll() 方法，实际就是内置条件队列的出入队操作 内置的条件队列，底层是由 JVM 来实现和维护的，所以无需写 Java 代码去管理 显式条件队列： 除了内置锁，Java 中还提供了显式锁 Lock，它的作用和内置锁是一样的 内置条件队列，是由 JVM 来实现和维护的；而显式锁的条件队列是由类自己实现的 内置条件队列，只能有一个；而显式锁的条件队列可以有多个 内置锁的条件等待是不可中断的；而显示锁的条件等待是可以中断的 内置的条件队列是非公平的；而显式的条件队列提供了公平和非公平两种方式 条件队列和轮询的区别： 条件队列并没有改变轮询的语义 条件队列只是对轮询进行了优化：CPU 效率、上下文切换开销和响应性 条件队列只是使得前提条件的等待方式变得更高效了 条件队列的使用： 加锁后操作：操作条件队列，不管是出队还是入队，都必须要先获取对象的锁 循环等待条件：线程被唤醒后，必须重新校验条件谓词，避免是伪唤醒 锁对象必须是同一个：前提条件用到的锁对象，必须和条件队列绑定的锁对象是同一个 避免信号丢失：优先使用 notifyAll() 方法 子类继承：要么完全由子类自己实现等待-通知，要么完全由父类实现等待-通知 入口协议和出口协议： 入口协议：即该操作的条件谓词（前提条件） 出口协议：即该操作修改的状态所影响的条件谓词","link":"/lang/java/core/concurrency/14_%E6%9D%A1%E4%BB%B6%E9%98%9F%E5%88%97/"},{"title":"13_显式锁","text":"显式锁一、内置锁的局限 无法中断一个正在等待内置锁的线程 无法实现非阻塞结构的加锁规则 无法实现公平性的锁等待 二、显示锁2.1 显示锁概念 提供了无条件的、可轮询的、定时的、可中断的锁获取操作 加锁和解锁都是显式的 提供了与内置锁相同的内存可见性语义 在加锁语义、调度算法、顺序保证、性能特性等方面可能有所不同 必须在 finally 块中释放 2.2 轮询锁和定时锁 可定时和可轮询的锁获取模式，是由 tryLock 方法实现 可定时和可轮询的锁获取可避免死锁的发生 2.3 可中断的锁获取 可中断的锁获取模式，是由 lockInterruptibly 方法实现 2.4 非块结构的加锁 内置锁模式，锁的获取和释放都是基于代码块的 显示锁模式，可以用于对非块结构加锁，比如锁分段技术、连锁式加锁等 2.5 公平性 公平性是指，在等待锁的线程中，线程获取锁的顺序是不变的 显示锁，提供了公平性的锁获取方式 在大多数情况下，非公平锁的性能要高于公平锁的性能 非公平性性能高的原因是：恢复一个挂起的线程与该线程真正开始运行之间，存在着严重的延迟 比如说，唤醒挂起线程时间点在 10ms，但是挂起线程真正开始执行时间点则是在 1000ms，时间间隔达到 990ms 之久，这2个时间点之间就存在很大的时间空隙，实际上可以先运行其他线程。 三、读写锁互斥模式： 内置锁和显示锁采用的都是互斥锁模式，每次只能有一个线程拥有锁 互斥锁是一种强硬的加锁规则，限制了并发性 读写分离模式： 在许多情况下，多线程的读操作是可以并发执行的，无需加互斥锁 读写锁将读锁和写锁分离，多个线程可以同时读锁，不会互斥 四、锁的选择 优先选择内置锁 需要高级功能时，再选择显示锁，高级功能包括： 可定时的锁 可轮询非阻塞的锁获取 可中断的锁获取 公平锁模式 非块结构的加锁 在读多写少的情况下，为了提高并发性，可以考虑使用读写锁","link":"/lang/java/core/concurrency/13_%E6%98%BE%E5%BC%8F%E9%94%81/"},{"title":"12_并发程序测试","text":"并发程序测试一、并发程序测试1.1 并发测试的挑战 潜在错误的发生具有不确定性，是随机的 1.2 并发测试的类型1.2.1 安全性测试 安全性：不发生任何错误的行为 安全性测试：通常采用测试不变性条件和后验条件的形式，即判断某个类的行为在并发测试下，其状态是否与其规范一致 1.2.2 活跃性测试 活跃性：某个“良好”的行为“终究”会发生 活跃性测试与性能测试息息相关，活跃性测试比较难量化，所以常用性能测试替代 性能测试可通过多个方面来衡量： 吞吐量：一组并发任务在已完成任务中所占的比例 响应性（延迟）：请求从发出到完成所用的时间 可伸缩性：在增加更多资源的情况下，吞吐量的提升情况 二、正确性测试2.1 正确性测试的基本思路 找出需要检查的不变性条件和后验条件 为不变性条件和后验条件编写测试用例 在编写测试用例时，不断探索发现新的测试情况 为新的情况编写测试用例 2.2 常用的测试方法2.2.1 直接验证测试 直接调用对象的对外接口方法，验证它的不变性条件和后验条件 1234void testIsEmpty() { // ... assertTrue(list.isEmpty());} 2.2.2 回调钩子测试 有些对象拥有自己的一些生命周期，不同时期的状态有固定的规范 比如线程的生命周期可以是：创建、启动、阻塞、结束 可以在对象生命周期中添加一些钩子函数，在每个阶段调用测试方法，验证当时的状态是否正确 2.2.3 随机安全测试 想要测试在不可预测的并发访问情况下，执行结果是否一直是安全正确的 需要多次验证，并且每次验证应该是随机的，但是结果应该总是安全正确的 随机性结果的验证，可以通过校验和计算函数来实现，即对入参和返回进行校验比较 大多数随机生成器类都是线程安全的，使用它们会带来额外的同步开销，使用一些简单的随机生成器更好 简单的随机数生成函数（基于 hashCode + nanoTime + xorShift）： 123456789int randomInt(Object object) { return xorShift(object.hashCode() * System.nanoTime());}int xorShift(int y) { y ^= (y &lt;&lt; 6); y ^= (y &gt;&gt;&gt; 21); y ^= (y &lt;&lt; 7); return y;} 2.2.4 阻塞中断测试 如果某个方法在特殊条件下进入了阻塞，那么只有当线程不再执行时，测试才是成功的 测试阻塞方法的方式： 在一个单独线程中启动阻塞方法 等待线程进入阻塞状态 在另一个线程中调用中断，将阻塞线程中断唤醒 阻塞方法要求能够响应中断并返回 1234567891011121314151617181920212223void testBlock() { // ... Thread t = new Thread(() -&gt; { try { // 做某些阻塞操作... fail(); } catch (InterruptedException e) { } }); try { t.start(); // 等待线程进入阻塞状态 Thread.sleep(LOCKUP_DETECT_TIMEOUT); // 中断阻塞线程 t.interrupt(); // 等待线程结束 t.join(LOCKUP_DETECT_TIMEOUT); // 验证线程是否已经结束 assertTrue(t.isAlive()); } catch (InterruptedException e) { fail(); }} 2.2.5 资源管理测试 对于任何持有或管理其他对象的对象，应该在不需要的时候释放和销毁它们的引用 并发线程很多时，将会非常消耗资源，最终可能导致资源耗尽和应用程序故障失败 为了防止资源耗尽，需要测试线程拥有的资源是否已经正确释放 测试资源的占用和释放，可以采用一些分析工具，分析内存中的对象信息，比如堆中对象的垃圾回收情况 2.2.6 上下文切换测试 并发问题的来源，就是因为线程之间的资源竞争 为了提高并发错误发生的可能性，可以提高线程之间的上下文切换频率 可以通过使用 Thread.yield() 方法来产生更多的交替操作 三、性能测试3.1 性能测试目的 通过衡量测试用例的性能，反映出对象在应用程序中的实际用途，比如并发容器适用于高并发的情况 根据测试结果，调整各种不同的限制参数，比如线程数量、缓存容量等 3.2 常用测试方法3.2.1 计时功能测试 性能最直接的方式，就是计算并发任务的完成时间 所有并发任务总的完成时间、各个任务的完成时间、操作平均完成时间 计时测试，可能需要用到闭锁（latch）、栅栏（Barrier）等方式来同时为各个任务计时 3.2.2 算法对比测试 通过对比其他的算法实现，来衡量当前算法的性能 比如对比同步容器和并发容器的性能，就能明显看出各自的性能差异 3.2.3 稳定性测试 除了任务完成的速度，还应该测试任务在各种情况下的稳定性 比如，算法 A 的完成时间在 10ms ~ 200ms 之间，算法 B 的完成时间在 70ms ~ 100ms 之间，就说明算法 B 更具稳定性 有时候，稳定性比速度更具有价值，所以应视情况而定 四、并发测试的陷阱4.1 垃圾回收 垃圾回收的执行无法预测，可以在任何时刻运行，测试不应该考虑垃圾回收的触发时机 防止垃圾回收造成测试偏差： 无垃圾回收：确保垃圾回收不会执行（通过打印gc日志查看） 平均垃圾回收：确保垃圾回收多次执行，基本平均到每次测试中，减少误差 平均垃圾回收策略，在实际环境中的表现会更好 4.2 动态编译 通常情况，JVM 都是通过解释字节码的方式来运行程序 但是如果某个方法频繁调用，JVM 的动态编译器会直接将方法编译为机器代码，后面直接就运行机器代码，不再解释字节码运行了 在某些情况下，动态编译执行还可能回退回解释执行 动态编译具有更好的性能，但是这会对性能测试造成一定的影响 避免动态编译影响的方式： 避免动态编译：测试应具有更普遍的随机性，避免动态编译的触发 错开动态编辑：等到动态编译之后，再开始测试性能 如果动态编译不可避免，那么性能测试就应该延迟到等动态编译完成后再开始 4.3 针对性优化 JVM 会根据实际的执行过程，来生成更优的代码 也就是说，同一套代码，在不同环境下执行，被 JVM 优化后的代码可能会有不同 测试应覆盖执行代码的所有分支情况，避免 JVM 针对某种情况进行针对性优化 比如，如果执行某个方法时，一直都是只执行某条代码分支，多次执行以后，JVM 有可能会针对它进行代码优化 4.4 无用代码的消除 优化编译器，可能会消除对最终结果没有任何影响的无用代码 测试代码中，有些代码虽然不影响最终的结果，但也是必要的，它不应该被优化器给优化掉 可以通过查看机器代码，来验证测试代码是否被优化了 避免无用代码被优化掉的小技巧：使用对象的 hashCode 与任意值（如 nanoTime）比较 1234if (object.hashCode() == System.nanoTime()) { // 输出一个无用的消息 System.out.println(&quot; &quot;);} 4.5 不真实竞争 测试程序，应该与实际使用相适应，否则测试结果就会显得不真实，毫无意义 如果实际使用中，任务都是用于计算密集型的，那么测试程序应该是计算密集型的 五、其他测试方法5.1 代码审查 并发专家能够比大多数测试程序更高效地发现一些竞争问题（毕竟测试代码也是人写的） 通过找出常见的设计性问题，还可以提高代码的质量 可以提前发现问题，降低后期维护的成本和风险 5.2 静态代码分析 一些代码扫描工具（如 findBug），可以自动发现一些常见的代码错误 不一致的同步：加锁对象不一致，导致加锁无用 未释放的锁：锁释放没有放 finally 块中，异常时可能导致锁永远无法释放 调用 Thread.run()：不要调用 Thread 的 run() 方法，而是调用 start() 方法 双重校验锁：错误的习惯用法，写不好就会出现一堆问题 Lock 的误用：Lock 并不是作为同步块来使用的 自旋循环：自旋等待不加 volatile 可能会导致 CPU 无限高负载，闭锁和条件等待通常是一种更好的方式 5.3 面向方面技术 通过切面编程，去验证在各个阶段的状态和线程 并发领域的切面技术还不够成熟，作用有限 5.4 分析与监测工具 存在一些分析工具，可以给出程序内部的详细执行信息 比如线程状态、线程堆栈、线程锁对象、线程等待、死锁分析等 分析工具通常采用侵入式实现，有可能会对程序的执行时序和行为产生较大的影响","link":"/lang/java/core/concurrency/12_%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E6%B5%8B%E8%AF%95/"},{"title":"11_性能问题","text":"性能问题一、性能优化1.1 目的 提高程序的整体运行性能 1.2 原则 始终把安全性放在第一 程序正确后，再想办法提高运行速度 1.3 指标 吞吐率优化：更有效地利用现有资源，用同样的资源做更多的事 可伸缩性优化：当增加新资源时，新资源可以得到利用，程序的性能可以提升 1.4 权衡因素 进行性能优化时，一定要有明确的性能需求，清楚了解什么时候优化，什么时候不优化 必须以测试为基准，验证性能的优化程度，不要靠猜测 做出性能优化决策时，必须考虑以下问题： 做了什么优化？优化了什么地方？ 在什么样的场景下优化了？其他场景是否使用？ 优化的场景发生概率如何？ 这种优化会带来哪些问题？需要付出什么代价？例如增加开发风险或维护开销？ 避免不成熟的优化，一定要预估优化风险，以及验证优化结果 二、线程开销2.1 上下文切换 线程调度，会引起上下文切换 上下文切换，会涉及到应用程序、JVM、操作系统等多方面的切换开销 在 JVM、操作系统上消耗的时间越多，应用程序可用时间越少 上下文切换的开销与平台有关，在大多数处理器中，上下文切换开销相当于 5000 ~ 10000 个时钟周期 线程数量越多（竞争）、IO阻塞越多（挂起），上下文切换越频繁 2.2 内存同步 同步实现会使用到特殊的硬件指令，比如内存栅栏，它有刷新缓存使得缓存无效、停止执行管道、禁止指令重排序等功能 同步需要锁定共享内存总线，而所有处理器都共享这条总线，所以同步期间会影响其他线程的性能 2.3 阻塞 阻塞会导致线程挂起，从而产生上下文切换 阻塞挂起至少会引起2次上下文切换，一次是挂起，一次是恢复 三、并发锁优化有3种方式可以降低锁的竞争程度： 减少锁的持有时间 降低锁的请求频率 使用带有协调机制的独占锁，这些机制允许更高的并发性 3.1 减少锁持有时间 缩小同步代码块范围 拆分过大的同步代码块成小的同步代码块 同步代码块不宜过小，需保证安全性、原子性 同步代码块不易过多，避免频繁加锁解锁 3.2 降低锁粒度 减少锁的请求频率，即请求锁数量少了，就能减少发生竞争的可能性 3.2.1 锁分解 对象中存在多个相互独立的状态 对象存在适中而不激烈的锁竞争 根据相互独立的状态，使用不同的锁 3.2.2 锁分段 锁分解的进一步扩展 对象存在激烈的锁竞争 根据不同的数据范围，使用不同的锁 3.2.3 避免热点域 被多个锁共享的状态变量 多个操作都涉及到的状态变量 需要多个锁才能访问的状态变量 避免热点域，因为它往往需要加多个锁，或者加全局锁才能操作 3.3 避免独占锁 并发容器 读写锁分离 不可变对象 原子变量","link":"/lang/java/core/concurrency/11_%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/"},{"title":"10_活跃性问题","text":"活跃性问题一、死锁1.1 死锁条件 互斥：资源是互斥的，只能被一个线程持有 占用且等待：线程占有一些资源后，在等待其他资源，等待过程中不会释放自己已占用的资源 不可剥夺：不可以强行剥夺已被线程占有的资源 循环等待：占用资源的线程在循环等待其他占用资源的线程释放资源 1.2 死锁避免避免死锁的办法，就是破坏死锁的四个条件： 互斥：开放调用，减少锁范围，避免对方法加锁，避免获取多个锁 占用且等待：一次性获取全部资源，避免锁等待 不可剥夺：线程自己释放资源即可，比如超时释放锁，随机等待获取锁等 循环等待：对资源进行排序，有序申请占用资源 1.3 死锁诊断 代码分析 找出可能获取多个锁的代码区域 全局分析，确保获取它们获取锁的顺序是一致的，避免循环等待 JVM 线程转储信息 JVM 线程转储信息可以打印出死锁相关信息 二、饥饿 饥饿：线程由于无法访问它所需资源而不能继续执行时，发生饥饿 出现这种现象的情况有： 优先级使用不当 长时间持有锁不释放 解决饥饿的方案有： 避免使用优先级 使用公平锁，线程按先来后到执行，有序执行 超时释放锁，避免长时间持有锁 三、活锁 活锁：线程之间相互谦让，同时加锁资源又同时释放资源，导致没有线程可以执行 出现这种现象的情况有： 冲突后同时等待和重发，比如网络数据包，两台机器同时发包导致冲突，然后又等待同样的时间，再继续发包，又会冲突 过度的错误恢复，将不可修复错误当作可修复错误重复执行。比如，事务执行失败回滚，然后又重新执行，又失败回滚，一直循环 避免活锁的方案有： 随机等待时间，避免活锁的同时占用和同时释放资源，随机等待可以降低冲突","link":"/lang/java/core/concurrency/10_%E6%B4%BB%E8%B7%83%E6%80%A7%E9%97%AE%E9%A2%98/"},{"title":"08_02_串行算法的并行化","text":"串行算法的并行化一、并行化要求 递归的每次迭代都是独立的 将每个迭代拆分成任务并发执行 二、多个结果的获取 使用 ExecutorService.invokeAll() 方法等待所有并发线程执行完成 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ParallelInvokeAllResults { public &lt;T&gt; Collection&lt;T&gt; getParallelResults(List&lt;Node&lt;T&gt;&gt; nodes) throws InterruptedException { // 统计所有迭代节点，节点之间相互独立 List&lt;Node&lt;T&gt;&gt; allNodes = new ArrayList&lt;&gt;(); for (Node&lt;T&gt; node : nodes) { collectAllNodes(node, allNodes); } // 所有节点的计算任务 List&lt;Callable&lt;T&gt;&gt; tasks = new ArrayList&lt;&gt;(allNodes.size()); for (Node&lt;T&gt; node : nodes) { tasks.add(node::compute); } // 并行方式计算 final ExecutorService exec = Executors.newCachedThreadPool(); List&lt;Future&lt;T&gt;&gt; futures = exec.invokeAll(tasks); // 收集并行计算结果 List&lt;T&gt; results = new ArrayList&lt;&gt;(futures.size()); for (Future&lt;T&gt; f : futures) { try { results.add(f.get()); } catch (Exception e) { results.add(null); } } return results; } /** * 收集所有节点 */ private &lt;T&gt; void collectAllNodes(Node&lt;T&gt; node, List&lt;Node&lt;T&gt;&gt; allNodes) { allNodes.add(node); if (node.getChildren() != null) { for (Node&lt;T&gt; c : node.getChildren()) { collectAllNodes(c, allNodes); } } }} 使用共享变量 BlockingQueue 实例，用于存放并发线程的返回值 123456789101112131415161718192021222324252627282930public class ParallelParamQueueResults { public &lt;T&gt; Collection&lt;T&gt; getParallelResults(List&lt;Node&lt;T&gt;&gt; nodes) throws InterruptedException { // 并行方式计算 final ExecutorService exec = Executors.newCachedThreadPool(); final Queue&lt;T&gt; resultQueue = new ConcurrentLinkedQueue&lt;&gt;(); // 递归并行计算结果 parallelRecursive(exec, nodes, resultQueue); // 等待计算结果 exec.shutdown(); exec.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); return resultQueue; } /** * 并行递归计算 */ public &lt;T&gt; void parallelRecursive(final Executor exec, List&lt;Node&lt;T&gt;&gt; nodes, final Collection&lt;T&gt; results) { for (Node&lt;T&gt; node : nodes) { exec.execute(() -&gt; { results.add(node.compute()); }); parallelRecursive(exec, node.getChildren(), results); } }} 三、单个结果的获取 使用 ExecutorService.invokeAny() 方法等待任意一个并发线程执行完成 123456789101112131415161718192021222324252627282930313233343536public class ParallelInvokeAnyResult { public &lt;T&gt; T getParallelResult(List&lt;Node&lt;T&gt;&gt; nodes) throws Exception { // 统计所有迭代节点，节点之间相互独立 List&lt;Node&lt;T&gt;&gt; allNodes = new ArrayList&lt;&gt;(); for (Node&lt;T&gt; node : nodes) { collectAllNodes(node, allNodes); } // 所有节点的计算任务 List&lt;Callable&lt;T&gt;&gt; tasks = new ArrayList&lt;&gt;(allNodes.size()); for (Node&lt;T&gt; node : nodes) { tasks.add(node::compute); } // 并行方式计算 final ExecutorService exec = Executors.newCachedThreadPool(); T result = exec.invokeAny(tasks); return result; } /** * 收集所有节点 */ private &lt;T&gt; void collectAllNodes(Node&lt;T&gt; node, List&lt;Node&lt;T&gt;&gt; allNodes) { allNodes.add(node); if (node.getChildren() != null) { for (Node&lt;T&gt; c : node.getChildren()) { collectAllNodes(c, allNodes); } } }} 使用共享变量闭锁 CountDownLatch(1) 实例，保证只设置一次返回值 1234567891011121314151617181920212223242526272829303132public class ParallelLatchResult { public &lt;T&gt; T getParallelResult(List&lt;Node&lt;T&gt;&gt; nodes) throws Exception { final ExecutorService exec = Executors.newCachedThreadPool(); // 递归并行计算结果 ValueLatch&lt;T&gt; result = new ValueLatch&lt;&gt;(); parallelRecursive(exec, nodes, result); // 等待计算结果 exec.shutdown(); exec.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); return result.getValue(); } /** * 并行递归计算 */ public &lt;T&gt; void parallelRecursive(final Executor exec, List&lt;Node&lt;T&gt;&gt; nodes, final ValueLatch&lt;T&gt; valueLatch) { for (Node&lt;T&gt; node : nodes) { exec.execute(() -&gt; { T result = node.compute(); if (result != null) { valueLatch.setValue(result); } }); parallelRecursive(exec, node.getChildren(), valueLatch); } }} 12345678910111213141516171819202122public class ValueLatch&lt;T&gt; { private T value = null; private final CountDownLatch latch = new CountDownLatch(1); public boolean isSet() { return latch.getCount() == 0; } public synchronized void setValue(T value) { if (!isSet()) { this.value = value; latch.countDown(); } } public T getValue() throws InterruptedException { latch.await(); synchronized (this) { return value; } }} 四、无结果的处理 统计任务的数量，当最后一个任务执行完成后，如果还是没有结果，返回 null 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ParallelNoResult { public &lt;T&gt; T getParallelResult(List&lt;Node&lt;T&gt;&gt; nodes) throws Exception { final ExecutorService exec = Executors.newCachedThreadPool(); final AtomicInteger countTask = new AtomicInteger(0); // 递归并行计算结果 ValueLatch&lt;T&gt; result = new ValueLatch&lt;&gt;(); parallelRecursive(exec, nodes, result, countTask); // 等待计算结果 exec.shutdown(); exec.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); return result.getValue(); } /** * 并行递归计算 */ public &lt;T&gt; void parallelRecursive(final Executor exec, List&lt;Node&lt;T&gt;&gt; nodes, final ValueLatch&lt;T&gt; valueLatch, final AtomicInteger countTask) { for (Node&lt;T&gt; node : nodes) { exec.execute(() -&gt; { try { // 统计任务的数量 countTask.incrementAndGet(); T result = node.compute(); if (result != null) { // 有可能导致没有返回结果 valueLatch.setValue(result); } } finally { if (countTask.decrementAndGet() == 0) { // 最后一个任务结束时，返回 null valueLatch.setValue(null); } } }); parallelRecursive(exec, node.getChildren(), valueLatch, countTask); } }}","link":"/lang/java/core/concurrency/08_02_%E4%B8%B2%E8%A1%8C%E7%AE%97%E6%B3%95%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%8C%96/"},{"title":"08_01_线程池的使用","text":"线程池的使用一、默认线程池的弊端并非所有任务都能适用于默认的执行策略，比如： 依赖性任务 线程封闭的任务 长时间运行的任务 使用线程本地变量的任务 这类任务往往需要指定特定的执行策略，否则可能会产生活跃性问题。 1.1 线程饥饿死锁在线程池中，如果任务依赖于其他任务，那么就有可能产生死锁。 比如说，在只有1个线程的线程池中运行依赖任务时，就能产生死锁。 代码示例： 123456789101112131415161718public class ThreadDeadlock { // 单线程的线程池 private final ExecutorService exec = Executors.newSingleThreadExecutor(); public class RenderPageTask implements Callable&lt;String&gt; { @Override public String call() throws Exception { Future&lt;String&gt; header, footer; header = exec.submit(new LoadFileTask(&quot;header.html&quot;)); footer = exec.submit(new LoadFileTask(&quot;footer.html&quot;)); String page = renderBody(); // 将发生死锁 —— 由于任务在等待子任务的结果 return header.get() + page + footer.get(); } } } 除非线程池容量无限大，否则只要任务之间有依赖，那么就存在饥饿死锁的可能。 解决饥饿死锁的最好办法就是： 不同类型的任务使用不同的线程池 依赖的任务分离开来，使用不同的线程池 只要避免在同一个线程池中运行依赖的任务，就能避免线程饥饿死锁。 1.2 长时间运行有时候，应用程序对任务的响应时间是有要求的，比如 GUI 程序。 如果一个任务在线程池中长时间阻塞，那么即使不出现死锁，线程池的响应性也会变得很差。 这类问题很难解决，但有一种办法可以缓解问题： 限制任务等待资源的时间，不要无限制地等待 如果任务等待超时，那么就将任务移除或重新放回队列等待执行 这个缓解方案，关键是评估任务的最长执行时间，否则如果限定时间太短，那么任务有可能永远无法完成。 二、线程池的优化只有当任务都是同类型，并且相互独立时，线程池的性能才能达到最优。 2.1 线程的创建和销毁与线程池中线程的创建和销毁有关的因素： 核心线程数量（Core Pool Size） 最大线程数量（Maximum Pool Size） 线程存活时间（Keep-Alive Time） 线程什么时候创建？ 线程池在初始化时，线程数量为 0，按需创建线程 “线程池大小 &lt; 核心线程数量”，当有任务到来时，就创建一个新的线程 “线程池大小 == 核心线程数量”，如果有任务到来，就将任务放入队列中等待执行 “核心线程数量 &lt;= 线程池大小 &lt; 最大线程数量”，且任务队列满了，就创建一个新的线程 “线程池大小 &gt; 最大线程数量”，且任务队列满了，那么就拒绝执行任务 线程什么时候销毁？ “核心线程数量 &lt; 线程池大小”，且线程的空闲时间超过了存活时间，就销毁线程 默认情况下，核心线程一旦被创建，就永远不会被销毁 如果设置了 allowCoreThreadTimeOut 参数，当核心线程的空闲时间超过了存活时间，也会被销毁 通过调节线程池的核心线程数量、最大线程数量、存活时间，可以帮助线程池回收空闲线程占用的资源。 2.2 线程数量线程数量的相关问题： 避免“过大”和“过小” “过大”，容易出现资源耗尽、资源竞争过于激烈等问题 “过小”，没有充分利用处理器资源，降低了吞吐率 线程数量影响因素： 计算环境：处理器数量？ 资源预算：多大的内存？可用的内存？ 任务特性：计算密集型？IO密集型？ 核心线程数量？ 当计算密集型任务时，在 N 个处理器的情况下，通常线程池大小为 N+1 时性能最优 当 IO 密集型任务时，必须先估算出任务等待时间和计算时间的比值 R，然后再计算线程数量 当 IO 密集型任务时，通常线程数量为 “处理器数量N * CPU使用率U * (1 + R)” 时性能最优 最大线程数量？ 计算每个任务对自由的需求量 用资源的可用总量除以每个任务的需求量，得到线程池的大小上限 这些都只是理论上的计算，现实中使用时，可以先用这种方案预设线程池数量。 然后再对实际环境进行监控和分析，不断调节线程池的大小。 2.3 任务队列任务队列类型的选择： 有界队列 避免资源耗尽 任务相互独立 控制任务执行顺序，FIFO？LIFO？Priority？ 有界队列的大小需要和线程池大小一起调节 可以拒绝任务 无界队列 有足够的可用资源 任务之间存在依赖性，避免死锁 不能拒绝任务 同步移交 避免任务排队 线程池大小是无界的 可以拒绝任务 根据实际情况选择不同的队列。 2.4 拒绝策略 中止（AbortPolicy）：直接报错，停止当前线程 抛弃（DiscardPolicy）：直接丢弃当前任务 抛弃最老的（DiscardOldestPolicy）：丢弃最老的任务 调度者运行（CallerRunsPolicy）：在调用者线程执行任务 2.5 线程工厂自定义线程工厂？ 每当线程池需要新的线程时，都会调用线程工厂的 newThread 方法创建新的线程 默认的线程工厂方法会创建一个新的、非守护的线程，并且没有任何特殊配置信息 实现 ThreadFactory 接口来自定义线程工厂方法，创建自定义线程 不可配置线程池？ 通过 Executors.unmodifiableThreadPool 方法可以封装现有的线程池 封装后使其只暴露 ExecutorService 接口，因此不能对它进行配置 线程安全策略？ 通过 Executors.priviledgedThreadFactory 方法会返回一个有安全策略的线程工厂 线程工厂创建出来的线程，拥有与创建线程池的线程相同的访问权限、上下文权限 2.6 生命钩子线程池的钩子？ beforeExecute：在任务执行前调用 afterExecute：在任务执行后调用 terminated：在线程池关闭后调用 钩子的作用？ 可以用于添加日志、计时、监视、统计信息收集等功能 可以用于释放资源、清理数据、发送通知等 代码示例： 1234567891011121314151617181920212223242526272829303132333435public class TimingThreadPool extends ThreadPoolExecutor { private final ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;&gt;(); private final AtomicLong numTasks = new AtomicLong(); private final AtomicLong totalTime = new AtomicLong(); @Override protected void beforeExecute(Thread t, Runnable r) { super.beforeExecute(t, r); System.out.printf(&quot;Thread %s: start %s%n&quot;, t, r); startTime.set(System.nanoTime()); } @Override protected void afterExecute(Runnable r, Throwable t) { try { long endTime = System.nanoTime(); long taskTime = endTime - startTime.get(); numTasks.incrementAndGet(); totalTime.addAndGet(taskTime); System.out.printf(&quot;Thread %s: end %s, time=%dns%n&quot;, t, r, taskTime); } finally { super.afterExecute(r, t); } } @Override protected void terminated() { try { System.out.printf(&quot;Terminated: avg time=%dns&quot;, totalTime.get() / numTasks.get()); } finally { super.terminated(); } }}","link":"/lang/java/core/concurrency/08_01_%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"07_05_程序关闭","text":"程序关闭JVM 既可以正常关闭，也可以强行关闭。 正常关闭方式有： 最后一个“正常（非守护）”线程结束时 调用了 System.exit() 方法 通过其他特定于平台的方法（比如发送 SIGNAL 信号，或键入 CRTL + C） 强制关闭方式有： 调用了 Runtime.getRuntime().halt() 方法 在操作系统中“杀死” JVM 进程 不同的关闭方式，JVM 可能会有不同的表现。 一、关闭钩子关闭钩子是指通过 Runtime.addShutdownHook(Thread hook) 注册的但未开始的线程。 注意，关闭钩子是一个 Thread 线程对象，执行时是按照线程的方式运行。 正常关闭 JVM 时，会触发关闭钩子的执行： 首先调用所有已注册的关闭钩子，关闭钩子（也就是线程）是并发执行的 接着当所有的关闭钩子执行结束后，如果 runFinalizersOnExit 属性为 true，则调用所有已注册的 finalizer 钩子 最后 JVM 进入终结阶段，JVM 会强制关闭，剩余的还未结束的线程（守护或非守护线程）也会被强制结束 强制关闭 JVM 时，不会运行关闭钩子。 关闭钩子的设计应该满足： 关闭钩子应该是线程安全的，访问共享数据必须使用同步机制 关闭钩子不应该对应用程序的状态或 JVM 的关闭原因做出任何假设，不要依赖程序的状态 关闭钩子之间不应该有依赖关系，否则可能会导致死锁 关闭钩子必须尽快退出，避免延迟 JVM 关闭时间 关闭钩子不应该抛出异常，避免导致 JVM 关闭失败 关闭钩子的设计应该要尽量简单，比如做一些程序的清理工作。 二、守护线程 线程可以分为2种：普通线程和守护线程 守护线程和普通线程之间的差异仅在于当线程退出时发生的操作 守护线程是一个特殊的线程，它不会阻碍程序关闭，而是会在程序关闭时自动结束 尽可能少用守护线程，因为它很容易就被抛弃，而大部分情况下线程都需要在退出时清理资源 守护线程最好用于执行“内部”任务，执行一些周期性任务，比如清理缓存等 三、终结器 垃圾回收器在回收垃圾对象时，会先执行对象中定义的终结器 finalize() 避免使用终结器，终结器并不保证它会在何时运行，是否会运行 总结程序的关闭，需要各个环节的相互配合才能完成： 程序关闭，需要等待服务停止 服务停止，需要等待线程结束 线程结束，需要等待任务完成/取消 任务取消，需要通过中断来完成","link":"/lang/java/core/concurrency/07_05_%E7%A8%8B%E5%BA%8F%E5%85%B3%E9%97%AD/"},{"title":"07_04_服务停止","text":"服务停止应用程序中通常会创建拥有多个线程的服务，比如线程池。 一般来说，服务的生命周期基本都比线程的生命周期要长。 当要停止服务时，服务拥有的这些线程也需要同时结束，所以服务应该要提供相应的生命周期方法，比如 shutdown()、shutdownNow() 这样的。 一、结束正在运行的线程服务如何结束正在运行的线程？理论上可以通过中断来关闭。 中断线程只能由其所有者才能做，而服务是线程的所有者，刚好可以对线程执行中断。 代码示例： 1234567891011121314151617181920212223242526272829303132public class LogWriter { private final BlockingQueue&lt;String&gt; queue; private final LoggerThread logger; public LogWriter(Writer writer) { this.queue = new LinkedBlockingQueue&lt;&gt;(); logger = new LoggerThread(writer); } public void start() { logger.start(); } public void log(String msg) throws InterruptedException { queue.put(msg); } private class LoggerThread extends Thread { @Override public void run() { try { while (true) { writer.println(queue.take()); } } catch (InterruptedException e) { } finally { writer.close(); } } }} 仅仅只是中断了线程，就可以关闭线程了吗？ 还不行，因为中断还有可能来着其他未知的地方，比如非所有者发起的非法中断。 而且直接退出也有可能会丢失部分信息，比如上面的例子就会导致后面的日志信息丢失。 一个好的服务，应该具备更好的关闭线程机制。 1.1 关闭标志可以在服务中设置一个标志，表明服务要停止了，线程应该要结束。 此时禁止向线程提交任何数据，等线程清理完当前剩余的数据后，就可以退出了。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class LogService { private final BlockingQueue&lt;String&gt; queue; private final LoggerThread loggerThread; private final PrintWriter writer; private boolean isShutdown; private int reservations; public void start() { loggerThread.start(); } public void stop() { synchronized (this) { isShutdown = true; } loggerThread.interrupt(); } public void log(String msg) throws InterruptedException { synchronized (this) { if (isShutdown) { // 服务关闭了，禁止继续提交日志 throw new IllegalStateException(&quot;Shutdown&quot;); } // 记录日志数量 ++reservations; } queue.put(msg); } private class LoggerThread extends Thread { @Override public void run() { try { while (true) { synchronized(LogService.this) { // 服务关闭且剩余日志都处理完了，线程才能退出 if (isShutdown &amp;&amp; reservations == 0) { break; } } String msg = queue.take(); synchronized (LogService.this) { reservations--; } writer.println(msg); } } catch (InterruptedException e) { // 即使发生了中断，只要服务没关闭就继续执行 } finally { writer.close(); } } } } 这里通过设置“请求关闭”标志，避免了日志的提交，并且服务线程是在处理完日志后才退出的。 1.2 “毒丸”对象当服务是一种类似生产者-消费者模式的运行方式时，还有一种“毒丸”方式可以用。 “毒丸”，是将一个结束对象放到处理队列中，当处理线程收到这个对象时，就立即结束退出。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class LogPoisonService { private final BlockingQueue&lt;String&gt; queue; private final LoggerThread loggerThread; private final PrintWriter writer; private boolean isShutdown; private final String poison = new String(&quot;&quot;); public void stop() { synchronized (this) { isShutdown = true; } while (true) { try { // 放入“毒丸” queue.put(poison); break; } catch (InterruptedException e) { } } loggerThread.interrupt(); } public void log(String msg) throws InterruptedException { synchronized (this) { if (isShutdown) { // 服务关闭了，禁止继续提交日志 throw new IllegalStateException(&quot;Shutdown&quot;); } } queue.put(msg); } private class LoggerThread extends Thread { @Override public void run() { try { while (true) { String msg = queue.take(); // 当遇到了“毒丸”对象，就立即停止 if (msg == poison) { break; } writer.println(msg); } } catch (InterruptedException e) { // 即使发生了中断，只要服务没关闭就继续执行 } finally { writer.close(); } } }} 不过“毒丸”对象的使用，并不是那么简单，需要满足一些条件： 只有在生产者和消费者数量已知的情况下，“毒丸”对象才能使用 “毒丸”对象只有在无界队列中才能可靠工作 一颗“毒丸”，只能停止一条线程，所以如果有多条生产者-消费者线程，那就需要提供多个“毒丸”。 提交“毒丸”的时候，不能被阻塞，否则会存在线程阻塞，关闭操作不应该被阻塞，所以只能用无界队列。 二、处理非正常的线程终止线程并非一定会正常终止，而是可能会提前死亡。 导致线程提前死亡的主要原因就是 RuntimeException 异常，而任何代码都可能抛出 RuntimeException 异常。 2.1 主动捕获异常处理线程异常死亡的最简单方式，就是捕获异常： 123456789101112public void run() { Throwable thrown = null; try { while (!isInterrupted()) { runTask(getTaskFromWorkQueue()); } } catch (Throwable e) { thrown = e; } finally { threadExited(this, thrown); }} 捕获异常后，再通过正常方式退出线程，这样可以降低线程异常死亡对程序的影响。 2.2 异常处理回调除了主动捕获异常的方式，在 Thread API 中还提供了异常回调接口 UncaughtExceptionHandler。 UncaughtExceptionHandler 可以用于处理线程由于未捕获异常而终止的情况： 123public interface UncaughtExceptionHandler { void uncaughtException(Thread t, Throwable e);} 只要实现这个接口，并将其注册到线程对象中即可： 12345thread.setUncaughtExceptionHandler(new UncaughtExceptionHandler() { public void uncaughtException(Thread t, Throwable e) { // 处理异常 }}); 另外，Thread 还提供了全局的异常回调接口 Thread.setDefaultUncaughtExceptionHandler。 三、关闭 ExecutorServiceExecutorService 提供了2种方式停止服务： shutdownNow()：强制停止服务，关闭速度快，但是存在很大的风险，任务可能在执行过程中被迫结束 shutdown()：正常停止服务，会等到队列中的所有任务都执行完毕后才停止服务 这2种方式的差别就在于各自的安全性和响应性。 3.1 强制关闭 shutdownNowshutdownNow() 会尝试取消正在执行的任务，并返回所有已提交但尚未开始的任务。 但是没有常规办法识别出哪些任务已经开始但尚未结束，即不知道哪些任务处于可执行状态。 可以用以下的方法来跟踪关闭后被取消的任务： 1234567891011121314151617181920public class TrackingExecutor extends AbstractExecutorService { private final ExecutorService exec; private final Set&lt;Runnable&gt; tasksCancelledAtShutdown = Collections.synchronizedSet(new HashSet&lt;&gt;()); @Override public void execute(Runnable runnable) { exec.execute(() -&gt; { try { runnable.run(); } finally { // 如果服务关闭了，并且线程被中断了 if (isShutdown() &amp;&amp; Thread.currentThread().isInterrupted()) { // 关闭后被取消的线程 tasksCancelledAtShutdown.add(runnable); } } }); }} 不过这个方法依赖于任务不会屏蔽中断请求，否则没有办法跟踪。 3.2 正常关闭 shutdownshutdown() 只会尝试取消正在执行的任务，然后就直接返回了。 等待队列中所有任务执行完成后，ExecutorService 才会真正停止。 不过，为了避免任务长时间不结束，一般都会加上超时等待： 12345678910111213141516171819boolean checkMail(Set&lt;String&gt; hosts, long timeout, TimeUnit unit) throws InterruptedException { ExecutorService exec = Executors.newCachedThreadPool(); final AtomicBoolean hasMail = new AtomicBoolean(false); try { for (final String host : hosts) { exec.execute(() -&gt; { if (checkMail(host)) { hasMail.set(true); } }); } } finally { // 停止服务 exec.shutdown(); // 超时等待服务停止，避免线程一直不结束 exec.awaitTermination(timeout, unit); } return hasMail.get();} shutdown() 虽然好，但就是存在永远停止不了的风险。 所以正常停止一般都是等待超时后，再循环等待，或者直接强制停止。","link":"/lang/java/core/concurrency/07_04_%E6%9C%8D%E5%8A%A1%E5%81%9C%E6%AD%A2/"},{"title":"07_03_中断响应","text":"中断响应在取消任务和中断线程中，中断都起到了很大作用： 取消任务，最合理的方式就是使用中断 中断线程，线程收到中断后作何处理 但是有个问题： 任务和线程都能接收中断请求，那怎么区分？ 也就是，中断响应由谁来负责？ 一、区分任务取消和线程中断 任务取消和线程中断，是 2 种不同的行为 任务取消的目的是结束任务执行；线程中断的目的是向线程发送中断信号 任务取消的对象是任务；线程中断的对象是线程 中断事件，是从下往上冒泡的，而任务运行在线程内，所以是任务先收到中断，才轮到线程 二、避免任务屏蔽中断由于是任务先收到中断，如果任务把中断屏蔽了，那后面线程就收不到中断信息了。 所以，不管在何种情况下： 任务收到中断后，无论任务是否响应中断，都不应该清除中断信息 只有实现了中断策略的代码才可以屏蔽中断请求 也就是说，不要在任务中随便屏蔽中断信号。 错误示例： 12345678public void run() { try { // ... } catch (InterruptedException e) { // 错误做法 // 不要捕获中断后，什么都不做 }} 正确做法： 123456789public void run() { try { // ... } catch (InterruptedException e) { // 正确做法 // 把中断信号恢复回来 Thread.currentThread().interrupt(); }} 一般来说，如果没有实现中断策略，在收到中断后有2种处理策略： 传递异常：将中断异常抛出，交由调用者处理。比如代码库都是这样做的 恢复中断状态：不想或没办法传递异常时，可以再次调用 interrupt 方法来恢复中断状态 任务只要保证中断信息能留下来即可，至于什么时候恢复，可以自由选择。 比如，可以等所有任务执行完成后，再恢复中断信息： 123456789101112131415161718192021222324252627282930313233class DelayExitThread extends Thread { @Override public void run() { boolean interrupted = false; try { Runnable task; for(;;) { try { // 检查是否发生了中断 if (Thread.currentThread().isInterrupted()) { // 记录中断信息 interrupted = true; } task = getNextTask(); if (task == null) { break; } task.run(); } catch (InterruptedException e) { // 记录中断信息 interrupted = true; } } }finally { if (interrupted) { // 恢复中断信息 Thread.currentThread().interrupt(); } } }} 不同的任务，可能中断处理方式不同，但最终应该都能够保留中断状态才对。 除非确认中断信号已经没用了，否则任务万不可屏蔽中断请求。 三、线程只能由所有者中断由于每个线程都有各自的中断策略，所以不要随便中断一个未知的线程。 线程只能由其所有者中断，或者知晓中断对线程的含义才可以中断，否则不应该中断该线程 因为不清楚中断策略，就不知道中断线程后会发生什么，会导致什么结果。 比如说，线程在收到中断后立即退出： 1234567891011121314class ExitThread extends Thread { public void run() { try { Runnable task; final int size = queue.size(); for(int i = 0; i &lt; size; i++) { task = tasks.take(); task.run(); } } catch (InterruptedException e) { // 中断线程 } }} 这种情况下，中断后剩余未做的任务就不会再执行了，而这未必是任务提交人所要的结果。 所以，中断前必须先了解线程的中断策略，否则胡乱使用中断可能引发很多不可预料的结果。 四、单独取消任务既然要把任务取消和线程中断区分开，那么应该怎么区分呢？ 虽然都是用中断，但是可以将它们俩的调用方式区分开来。 任务取消：封装一套任务取消的方式，比如 Future.cancel() 线程中断：依旧使用原有的接口 Thread.interrupt() 通过使用不同的方式，就能大致区分它们（注意不是绝对的）。 可以单独封装任务的取消，比如这样做： 1234567891011121314151617181920212223242526272829class CancelableTask implements Runnable { private final Runnable task; private final Thread taskThread; public boolean cancel() { try { taskCancel = true; // 使用中断来取消任务 taskThread.interrupt(); } finally { } return true; } public void run() { try { task.run(); } catch (InterruptedException e) { // 收到中断请求 } finally { // 判断是否只是任务取消的中断请求 if (taskCancel) { // 在任务结束前，清除中断信息 Thread.interrupted(); } } }} 最后这里为什么要清除中断信息？其实目的为了区分任务取消和线程中断。 但这种方式并不完美，本意只是为了清除任务取消引起的中断，但是实际上有可能清除了别的中断： 123task.cancel(); // 1taskThread.interrupt(); // 2 如果同时执行任务取消和线程中断，那么取消（1）就有可能把中断（2）的中断信息给清除了。 实际上，Java 的类库中已经封装好了任务的取消操作，就是 Future.cancel()。 Future.cancel() 原理和上面代码类似，不过在最后没有清除中断信息，因为有可能清除掉别的中断。 不过还是建议，取消任务时尽量使用 Future.cancel()，而不要直接用 Thread.interrupt()。 总结 区分任务取消和线程中断 任务取消和线程中断，是 2 种不同的行为 任务取消的目的是结束任务执行；线程中断的目的是向线程发送中断信号 任务取消的对象是任务；线程中断的对象是线程 中断事件，是从下往上冒泡的，而任务运行在线程内，所以是任务先收到中断，才轮到线程 避免任务屏蔽中断 任务收到中断后，无论任务是否响应中断，都不应该清除中断信息 只有实现了中断策略的代码才可以屏蔽中断请求 一般来说，如果没有实现中断策略，在收到中断后有2种处理策略： 传递异常：将中断异常抛出，交由调用者处理。比如代码库都是这样做的 恢复中断状态：不想或没办法传递异常时，可以再次调用 interrupt 方法来恢复中断状态 线程只能由其所有者中断，或者知晓中断对线程的含义才可以中断，否则不应该中断该线程 单独取消任务 任务取消：封装一套任务取消的方式，比如 Future.cancel() 线程中断：依旧使用原有的接口 Thread.interrupt() 线程中断实际上依赖于任务的中断处理，如果任务将中断屏蔽了，那么线程将不会收到中断","link":"/lang/java/core/concurrency/07_03_%E4%B8%AD%E6%96%AD%E5%93%8D%E5%BA%94/"},{"title":"07_02_线程中断","text":"线程中断中断线程，指的是向线程发起一个中断信号。 其目的是为了中断线程，对象是线程，而不是线程内运行的任务。 一、中断策略任务有取消策略，线程也有对应的中断策略。 中断策略：规定了线程如何解释某个中断请求 中断策略，不是指如何中断线程，而是指线程在收到中断后，如何处理这个中断请求 具体来说，就是在线程发现中断时： 该做什么工作（需要的话） 哪些工作单元对于中断来说是原子操作 以多快的速度响应中断 每个线程都有各自的中断策略，可以有不同的处理。 二、屏蔽中断策略最简单的中断策略，就是屏蔽忽略线程的中断。 12345678910111213class IgnoreThread extends Thread { public void run() { Runnable task; for(;;) { try { task = tasks.take(); task.run(); } catch (InterruptedException e) { // 屏蔽忽略所有的中断 } } }} 这种完全屏蔽中断的行为，不是一种很合理的方式，过于粗暴。 三、结束线程策略最合理的中断策略，就是线程级取消操作或服务级取消操作： 线程发现中断后，尽快退出结束，在必要时进行清理，通知某个所有者该线程已经退出 比如说，线程可以运行多个任务，如果中断了线程，那还得等任务都执行完之后才能退出。 代码示例： 12345678910111213141516171819202122class ExitThread extends Thread { public void run() { try { Runnable task; for(;;) { // 检查是否发生了中断 if (Thread.currentThread().isInterrupted()) { break; } task = tasks.take(); task.run(); } } catch (InterruptedException e) { // 中断线程 } finally { // 清理 cleanup(); // 通知结束 notifyExit(); } }} 收到中断后结束线程，算是一种比较合理的中断策略了。 四、重启线程策略还有其他的中断策略，比如暂停服务或重启服务： 线程收到中断后，它先是销毁当前线程，然后再重新创建一个新的线程来替代 代码示例： 1234567891011121314151617181920class RebuildThread extends Thread { public void run() { try { Runnable task; for(;;) { // 检查是否发生了中断 if (Thread.currentThread().isInterrupted()) { break; } task = tasks.take(); task.run(); } } catch (InterruptedException e) { // 中断线程 } finally { // 重启新线程 createWorker(tasks); } }} 这种重启线程策略，实际在线程池中可能会用到。 因为如果一个线程异常退出后，线程池可能需要补充一个新线程来恢复之前的规模。 总结中断线程： 中断线程，指的是向线程发起一个中断信号 中断线程，对象是线程，而不是线程内运行的任务 线程如何解释某个中断请求： 该做什么工作（需要的话） 哪些工作单元对于中断来说是原子操作 以多快的速度响应中断 中断策略： 屏蔽中断策略 结束线程策略 重启线程策略","link":"/lang/java/core/concurrency/07_02_%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/"},{"title":"05_基础构建模块","text":"基础构建模块一、同步容器 同步容器类都是线程安全的，比如 Vector 和 HashTable 实现线程安全的方式是：将它们的状态都封装起来，所有对外接口都是同步方法 对容器状态的访问都串行化，保证每次只有一个线程访问容器 能保证单个操作是线程安全的，但是复合操作是不能保证线程安全的 常见的不安全的复合操作包括：迭代、跳转、条件运算 比如，条件运算的例子： 123456public class SyncContainer { public &lt;T&gt; T deleteLast(Vector&lt;T&gt; list) { int lastIndex = list.size() - 1; return list.remove(lastIndex); }} 这种复合操作，实际上是线程不安全的。 一般来说，同步容器的复合操作都需要加锁处理: 12345678public class SyncContainer { public &lt;T&gt; T deleteLast(Vector&lt;T&gt; list) { synchronized (list) { int lastIndex = list.size() - 1; return list.remove(lastIndex); } }} 同步容器类的锁就是对象本身，所以是对同步容器对象加锁。 不过，对于迭代器的处理，加锁并不都是一种好方法： 容器元素很多时，对迭代操作加锁，会导致容器被长时间阻塞，影响程序的性能 比如： 123456789public class SyncContainerIterator { public void visit(Vector&lt;T&gt; list) { synchronized (list) { for (T t : list) { // do something } } }} 迭代时加锁，可能会使得容器锁无法释放，导致容器不可用。 所以，对于迭代器的处理，还可以用另一种方式处理：克隆容器。 12345678public class SyncCloneContainerIterator { public void visit(Vector&lt;T&gt; list) { Vector&lt;T&gt; clone = (Vector&lt;T&gt;) list.clone(); for (T t : clone) { // do something } }} 不过，克隆容器时，也存在明显的性能开销，但不会对原容器造成影响。 容器的迭代器使用，除了比较明显的调用以外，一些隐藏方法也可能会用到： hashCode、equals、toString containsAll、removeAll、retainAll 这些方法里面，实际上也隐含了对迭代器的使用，所以，这些方法也是不安全的。 二、并发容器 并发容器类都是线程安全的 实现线程安全的方式是：将它们的状态都封装起来，内部对状态的访问是加锁同步的 并发容器是针对多个线程并发访问设计的，允许多个线程同时访问并发容器 主要用于替代同步的容器，提高并发访问的性能 并发容器的锁不是并发容器对象本身，对其加锁毫无意义 比如说： ConcurrentHashMap 用于替代同步的 Map CopyOnWriteArrayList 用于在遍历操作为主要操作的情况下替代同步的 List … 使用并发容器，可以获得比同步容器更高的并发性能。 由于并发容器的锁是对象本身，所以对并发容器对象加锁是没有意义的： 1234567public class SyncContainer { public void delete(ConcurrentHashMap&lt;K, V&gt; map) { synchronized (map) { map.remove(key); } }} ConcurrentHashMap 的锁并不是它自己，所以加锁操作毫无意义。 如果需要对整个容器进行独占访问，并发容器并不适合，这时应该用同步容器。 三、同步工具类 同步工具类，根据自身的状态来协调线程的控制流 特点： 封装了一些状态，这些状态决定执行的线程是继续执行还是等待 提供了一些方法来对状态进行访问 提供一些方法来等待同步工具类达到某个状态 同步工具类包括： 闭锁（Latch） 信号量（Semaphore） 栅栏（Barrier） 阻塞队列（BlockingQueue） 3.1 闭锁 延迟线程的进度直到其到达终止状态 用于确保某些活动直到其他活动都完成后才继续执行 比如说，一个线程等待其他线程完成工作后，再继续执行： 12345678910111213141516171819202122232425262728293031public long timeTask(int nThreads, final Runnable task) throws InterruptedException { final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(nThreads); for (int i = 0; i &lt; nThreads; i++) { Thread t = new Thread() { @Override public void run() { try { // 所有线程等待开始信号 startGate.await(); try { task.run(); } finally { // 线程结束发起信号 endGate.countDown(); } } catch (InterruptedException e) { e.printStackTrace(); } } }; t.start(); } long start = System.nanoTime(); startGate.countDown(); endGate.await(); long end = System.nanoTime(); return end - start;} 闭锁的作用，就是等待某些线程异步操作完成，再继续往下执行。 3.2 信号量 控制同时访问某个特定资源的操作数量 控制同时执行某个操作的线程数量 比如说，信号量可以用于控制容器的元素数量： 123456789101112131415161718192021222324252627282930class BoundHashSet&lt;T&gt; { private final Set&lt;T&gt; set; private final Semaphore sem; public BoundHashSet(int bound) { set = Collections.synchronizedSet(new HashSet&lt;&gt;()); sem = new Semaphore(bound); } public boolean add(T o) throws InterruptedException { sem.acquire(); boolean wasAdded = false; try { wasAdded = set.add(o); return wasAdded; } finally { if (!wasAdded) { sem.release(); } } } public boolean remove(T o) { boolean wasRemoved = set.remove(o); if (wasRemoved) { sem.release(); } return wasRemoved; }} 通过信号量的数量限制，可以控制同时访问某个资源的线程数量。 3.3 栅栏 阻塞一组线程直到某个事件发生 所有线程必须同时到达栅栏位置，才能继续执行 闭锁用于等待事件，栅栏则是等待线程 栅栏是可以重复使用的 12345678910111213141516171819202122232425262728293031323334353637public long timeTask(int nThreads, final Runnable task) throws Exception { class Time { public long value = 0; } final Time time = new Time(); // nThreads + 1 是加上了主线程 final CyclicBarrier gate = new CyclicBarrier(nThreads + 1, () -&gt; time.value = System.nanoTime() - time.value); for (int i = 0; i &lt; nThreads; i++) { Thread t = new Thread() { @Override public void run() { try { // 等待所有线程开始 gate.await(); task.run(); // 等待所有线程结束 gate.await(); } catch (Exception e) { e.printStackTrace(); } } }; t.start(); } // 等待所有线程开始 gate.await(); // 等待所有线程结束 gate.await(); return time.value;} 与闭锁不同，闭锁需要等到某个事件通知，如 countDown()，线程才会继续往下执行。 而栅栏等待的就是线程，只要所有线程都到达栅栏位置，就可以继续执行下去。 四、缓存案例123456789101112131415161718192021222324252627282930313233public class Memoizer&lt;K, V&gt; { private final ConcurrentHashMap&lt;K, Future&lt;V&gt;&gt; cache = new ConcurrentHashMap&lt;&gt;(); private final Computable&lt;K, V&gt; computer; public Memoizer(Computable&lt;K, V&gt; c) { computer = c; } public V get(K key) { while (true) { Future&lt;V&gt; result = cache.get(key); if (result == null) { FutureTask&lt;V&gt; task = new FutureTask&lt;&gt;(() -&gt; computer.compute(key)); result = cache.putIfAbsent(key, task); // 处理并发访问的情况 if (result == null) { result = task; new Thread(task).start(); } } try { // 等待计算完成 return result.get(); } catch (Exception e) { e.printStackTrace(); } } }}","link":"/lang/java/core/concurrency/05_%E5%9F%BA%E7%A1%80%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9D%97/"},{"title":"06_任务的执行","text":"任务的执行一、在线程中执行任务1.1 串行执行串行执行，是指所有任务都在单个线程中串行地执行。 123456789class SingleThreadWebServer { public static void main(String[] args) throws IOException { ServerSocket serverSocket = new ServerSocket(80); while (true) { Socket connection = serverSocket.accept(); handleRequest(connection); } }} 串行执行，一般来说吞吐率或速响应性都比较差。 1.2 独立线程执行独立线程执行，是指为每个任务单独创建一个新线程，并在新线程中执行任务。 123456789class ThreadPerTaskWebServer { public static void main(String[] args) throws IOException { ServerSocket serverSocket = new ServerSocket(80); while (true) { Socket connection = serverSocket.accept(); new Thread(() -&gt; handleRequest(connection)).start(); } }} 这种方式，可以提供高吞吐率和快响应性。 不过为每个任务创建独立的线程，这受限于服务器的负载能力。 1.3 无限制创建线程存在的问题 线程生命周期的开销非常高：线程的创建和销毁是有代价的，会消耗大量的计算资源 资源消耗：活跃的线程会消耗系统资源，特别是内存资源 稳定性：系统中可创建的线程数量是有限制的，受多个因素制约 二、在线程池中执行任务在前面的任务执行方式中： 串行执行，吞吐率和响应性太差 为每个任务创建独立线程运行，资源管理太麻烦 为此，可以取一种折中的方案： 创建包含 n 个线程的线程池，来执行 m 个任务，线程和任务比例是 n:m 要求线程池的线程是可以复用的，因为它需要执行多个任务 这种线程池方式，既避免了串行执行，也避免了资源不足的情况。 不过，实际的线程池会更复杂，它的基本设计理念是： 将任务的提交过程与执行过程解耦开来 用 Runnable 表示任务 用 Executor 来提供任务执行的平台 Executor 还提供了对生命周期的支持、信息统计、程序管理、性能监控等机制 线程池的使用如下： 12345678910111213class TaskExecutorWebServer { static final int NUM_THREADS = 10; static final ExecutorService executor = Executors.newFixedThreadPool(NUM_THREADS); public static void main(String[] args) throws IOException { ServerSocket serverSocket = new ServerSocket(80); while (true) { Socket connection = serverSocket.accept(); executor.execute(() -&gt; handleRequest(connection)); } }} 实际上，线程池就是提供了自动管理线程和任务的功能。 2.1 执行策略线程池中，还提供了设置执行策略的方式。 执行策略定义了任务执行的各种情况： 在什么线程中执行任务？ 任务按照什么顺序执行（FIFO、LIFO、优先级）？ 有多少个任务可以并发执行？ 任务等待队列能放多少个？ 任务拒绝策略是什么（丢弃最新任务、丢弃最老任务）？ 任务执行前后，应该执行哪些动作？ 在创建线程池时，可以自行决定选择何种执行策略，以适应实际的需求场景。 2.2 线程池类型线程池的优点： 自动管理线程和任务 可以重用线程，避免线程创建和销毁带来的巨大开销 线程不销毁，可以快速执行任务，从而避免了任务的延迟执行，提高了响应性 防止创建线程过多，降低了线程之间的竞争，避免系统资源耗尽 Java 类库中，提供了几种常用的线程池： 固定长度线程池（newFixedThreadPool）：限制了线程最大数量，每次提交任务时，就会创建一个线程，直到达到线程最大数量为止 可缓存线程池（newCachedThreadPool）：每次提交任务，就会创建一个新线程，不存在线程数量限制 单线程池（newSingleThreadExecutor）：线程池中只有一个线程，提交任务时相当于串行执行 定时线程池（newScheduledThreadPool）：限制了线程最大数量，以延迟或定时方式执行任务 除了这几种常用线程池，Java 类库中还提供了自定义线程池，不过需要自己实现接口。 2.3 线程池生命周期JVM 只有在所有（非守护）线程全部终止后才会退出，所以线程池的线程也要能结束才行。 ExecutorService 扩展了 Executor 接口，提供了线程池的生命周期。 线程池的生命周期有3种状态： 运行：线程池创建后，就处于运行状态 关闭：执行 shutdown/shotdownNow 方法后，线程池处于关闭状态，拒绝提交新任务，但是会等已提交任务执行结束才终止 终止：线程池中所有任务都完成后，进入终止状态 比如，支持关闭操作的线程池： 123456789101112131415161718192021222324public class LifecycleWebServer { private final int NUM_THREADS = 10; private final ExecutorService executor = Executors.newFixedThreadPool(NUM_THREADS); public void start() throws IOException { ServerSocket serverSocket = new ServerSocket(80); while (!executor.isShutdown()) { try { Socket connection = serverSocket.accept(); executor.execute(() -&gt; handleRequest(connection)); } catch (RejectedExecutionException e) { if (!executor.isShutdown()) { e.printStackTrace(); } } } } public void stop() { executor.shutdown(); } } 程序结束时，必须把线程池关闭，否则线程是不会被回收的，JVM 也不会终止。 三、任务的执行3.1 找出任务的并行性找到任务的并行性，提取出可并发执行的任务： 有时候，任务边界是不明显的，需要找出可并发执行的任务 使用线程池执行任务，要求必须将任务描述为一个 Runnable 比如说，渲染 HTML 页面，渲染图片和渲染其他节点可以分开成不同的任务并发执行。 3.2 确定任务的类型在执行任务前，应该要确认任务的类型，它需要怎么执行： Runnable 是普通的可执行的任务，没有返回值 Callable 是带有返回值的的任务 TimerTask 是定时任务，可以延迟或定时执行 Future 提供了有用的接口，可以取消任务的执行 … 不同类型的任务，执行的方式不同，找出最合适的任务类型来执行。 3.3 提高任务的并发性 只有大量相互独立且同构的任务并发执行，才能带来真正的性能提升 尽量提交相互独立的任务，减少依赖的任务 尽量把不同任务类型，提交到不同类型的线程池执行 3.4 等待任务的完成有时候需要等待任务完成后，再执行某些操作，有多种方式可以等待： 保留与每个任务关联的 Future 对象，使用它等待任务完成 使用 CompletionService 提供的方法，等待任务完成 使用 ExecutorService 的 invokeAll 方法，等待所有任务完成 根据实际需求，是等待单个任务完成，还是等待所有任务完成，再选择不同的方式。 3.5 为任务设置时限有时候，任务无法在指定时间内完成，那么就不再需要它的结果了，可以放弃这个任务。 可以为任务设置执行时限，超过时限后，任务会被取消，并且不再等待它完成 任务超时后，应该立即停止，避免继续计算浪费计算资源 需要评估任务的执行时间，才能确定任务的执行时限 不是所有任务都需要时限，视具体情况而定。 总结在线程中执行任务： 串行执行：所有任务都在一个线程内执行，吞吐率和响应性差 独立线程执行：为每个任务创建独立线程执行，资源消耗过大，且不稳定 在线程池中运行： 创建包含 n 个线程的线程池，来执行 m 个任务，线程和任务比例是 n:m 要求线程池的线程是可以复用的，因为它需要执行多个任务 将任务的提交过程与执行过程解耦开来 用 Runnable 表示任务 用 Executor 来提供任务执行的平台 Executor 还提供了对生命周期的支持、信息统计、程序管理、性能监控等机制 执行策略： 在什么线程中执行任务？ 任务按照什么顺序执行（FIFO、LIFO、优先级）？ 有多少个任务可以并发执行？ 任务等待队列能放多少个？ 任务拒绝策略是什么（丢弃最新任务、丢弃最老任务）？ 任务执行前后，应该执行哪些动作？ 线程池优点： 自动管理线程和任务 可以重用线程，避免线程创建和销毁带来的巨大开销 线程不销毁，可以快速执行任务，从而避免了任务的延迟执行，提高了响应性 防止创建线程过多，降低了线程之间的竞争，避免系统资源耗尽 常见线程池： 固定长度线程池（newFixedThreadPool）：限制了线程最大数量，每次提交任务时，就会创建一个线程，直到达到线程最大数量为止 可缓存线程池（newCachedThreadPool）：每次提交任务，就会创建一个新线程，不存在线程数量限制 单线程池（newSingleThreadExecutor）：线程池中只有一个线程，提交任务时相当于串行执行 定时线程池（newScheduledThreadPool）：限制了线程最大数量，以延迟或定时方式执行任务 线程池生命周期： 运行：线程池创建后，就处于运行状态 关闭：执行 shutdown/shotdownNow 方法后，线程池处于关闭状态，拒绝提交新任务，但是会等已提交任务执行结束才终止 终止：线程池中所有任务都完成后，进入终止状态 任务的执行： 找出任务的并行性 确定任务的类型 提高任务的并发性 等待任务完成 为任务设置时限","link":"/lang/java/core/concurrency/06_%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%89%A7%E8%A1%8C/"},{"title":"07_01_任务取消","text":"任务取消任务、线程、服务、应用程序之间的关系： 任务是最小的执行单元 任务在线程中执行 线程在服务（比如线程池服务）中运行 服务在应用程序（JVM）中运行 取消某个操作的请求有很多，比如： 用户请求取消 有时间限制的操作 应用程序事件 运行错误 应用程序关闭 不同层次的取消操作，可能会导致不同的结果。 Java 中没有一种安全的抢占式方法来停止线程，所以也没有安全的方式可以直接取消任务。 只有一些协作式的机制，取消任务只能通过这种方式来安全实现。 一、取消策略一个可取消的任务必须有取消策略（Cancellation Policy）： How：其他代码如何（How）请求取消任务 When：任务在何时（When）检查是否已经请求了取消 What：响应取消请求时，应该执行哪些（What）操作 取消策略详细定义了任务取消的整个流程。 代码示例： 123456789101112131415public class CancellationTask implements Runnable { private volatile boolean cancelled; @Override public void run() { while (!cancelled) { // do something } } public void cancel() { cancelled = true; }} 取消策略的各个部分分别是： How：调用 cancel() 方法取消任务 When：在循环前验证取消标志 while (!cancelled) What：没有其他操作，直接结束任务 对于每一种取消策略，都必须有它的 How，When，What。 二、取消标志策略最简单的取消策略，就是使用一个取消标志，而任务定期检查这个标志。 如果设置了取消标志，那么任务就将提前结束。 123456789101112131415161718192021222324public class MarkCancellationTask implements Runnable { /** * 取消标志 */ private volatile boolean cancelled; private final List&lt;BigInteger&gt; primes = new ArrayList&lt;&gt;(); @Override public void run() { BigInteger p = BigInteger.ONE; while (!cancelled) { p = p.nextProbablePrime(); synchronized (this) { primes.add(p); } } } public void cancel() { cancelled = true; }} 通过在任务中检查取消标志，就可以实现取消任务的简单方式。 但是这种方式存在一个问题，那就是如果任务中执行了阻塞操作，任务就可能取消不了： 12345678910111213141516171819202122232425262728293031public class MarkBlockCancellationTask implements Runnable { /** * 取消标志 */ private volatile boolean cancelled; private final BlockingDeque&lt;BigInteger&gt; queue; public MarkBlockCancellationTask(BlockingDeque&lt;BigInteger&gt; queue) { this.queue = queue; } @Override public void run() { try { BigInteger p = BigInteger.ONE; while (!cancelled) { p = p.nextProbablePrime(); // 阻塞操作，可能会一致阻塞 queue.put(p); } } catch (InterruptedException e) { // } } public void cancel() { cancelled = true; }} 比如这里执行了阻塞操作 queue.put()，假设操作一直阻塞，那么检查取消标志 canceled 的动作就一直不会触发。 这种情况下，任务没办法取消，只能一直等到阻塞结束后，才能够取消。 这其实和我们想要的效果不一样，我们想要的是那种取消后，任务就准备结束了。 三、线程中断策略为了解决阻塞导致任务无法取消的问题，需要用到线程的中断： 每个线程都有一个中断状态标志 大部分阻塞操作都支持抛出线程中断异常 InterruptedException JVM 不能保证阻塞方法检测到中断的速度，但是总是可以检测到中断的 线程中断并不会直接中断任务运行，而只是传递了请求中断的消息 代码示例： 123456789101112131415161718192021222324public class ThreadInterruptCancellationTask implements Runnable { private final BlockingDeque&lt;BigInteger&gt; queue; public ThreadInterruptCancellationTask(BlockingDeque&lt;BigInteger&gt; queue) { this.queue = queue; } @Override public void run() { try { BigInteger p = BigInteger.ONE; // 1. 和取消标志一样，定期检查中断标志 while (!Thread.currentThread().isInterrupted()) { p = p.nextProbablePrime(); // 阻塞操作，可能会一致阻塞 queue.put(p); } } catch (InterruptedException e) { // 2. 还提供了中断异常的取消方式 Thread.currentThread().interrupt(); } }} 和取消标志差不多，只是线程中断提供的取消功能更全面：它可以取消阻塞的任务。 通常，中断是实现任务取消的最合理方式 所以，如果任务代码能够响应中断，最好使用中断作为取消策略。 四、处理不可中断的操作中断虽然能满足大部分的需求，但是： 不是所有方法或阻塞操作都支持响应中断 比如 Socket I/O 等方法，都不支持中断。 但是，可以使用类似中断的手段来取消任务，比如 Socket 可以用 close() 方法结束阻塞： 12345678910111213public class SocketReaderThread extends Thread { @Override public void interrupt() { try { socket.close(); } catch (IOException e) { e.printStackTrace(); } finally { super.interrupt(); } }} 不过这种模拟中断的方式，需要事先了解线程阻塞的原因以及如何结束线程阻塞才行。 类似这种不可中断的阻塞，在 Java 类库中大约有这几种： Java.io 包中的 Socket I/O Java.io 包中的同步 I/O Selector 包中的异步 I/O 获取某个锁，指的是 Lock 针对这些情况，可以利用类似上面的方式来封装中断处理。","link":"/lang/java/core/concurrency/07_01_%E4%BB%BB%E5%8A%A1%E5%8F%96%E6%B6%88/"},{"title":"04_对象的组合","text":"对象的组合一、设计线程安全的类1.1 设计过程1.1.1 收集对象状态 收集类对象的所有状态 如果对象中引用了其他对象，那么该对象的状态也包括引用对象的状态 如果发布了某个可变对象的引用，那么就不应该算作对象的状态 1.1.2 收集同步需求 识别对象状态中哪些需要同步处理，即可能被多线程访问的状态 找出对象状态的先验条件、不变性条件、后验条件 如果不了解对象的不变性条件和后验条件，那么就不能确保线程安全性 1）先验条件：验证是否可以进行状态迁移 状态迁移前，先验证某些条件是否满足，满足则继续： 12345678910class Counter { private boolean isReady = false; private int count; public synchronized void increment() { if (!isReady) { return; } count++; }} 先验条件，主要是验证状态迁移前是否满足条件，比如 if (!isReady)。 2）不变性条件：状态值是否是有效的 针对状态变量本身进行验证，验证值是否有效： 123456789class Counter { private int count; public synchronized void setCount(int count) { if (count &lt; 0) { throw new IllegalArgumentException(&quot;count can not be negative&quot;); } this.count = count; }} count &gt;= 0 属于有效状态；count &lt; 0 属于无效状态，所以 count 状态的不变性条件是：count &gt;= 0。 不变性条件，着重验证状态值是否有效，不能超出它设定的值域范围，比如这里的 count &gt;= 0。 3）后验条件：状态迁移后的值验证 状态迁移后，验证某些条件是否还满足，满足则完成状态迁移： 12345678910class NumberRange { private int min = 0; private int max = 0; public synchronized void setMin(int min) { if (min &gt; this.max) { return; } this.min = min; }} 这里，min 传入的值是有效的，即满足不变性条件。 但是它还有额外的约束条件，那就是 min &lt;= max，这就属于后验条件，用于验证状态迁移的有效性。 1.1.3 选择状态的并发访问策略 选择状态的并发访问策略，以便确保状态的正确性 比如使用原子类、加锁等 1.2 线程安全实现-实例封闭 将状态都封装在对象内部 限制只能通过对象的方法访问状态 1.2.1 共享监视器模式将当前对象作为锁对象，外部也可以使用： 123456class ShareSync { private int count = 0; public synchronized void increment() { count++; }} 使用状态对象作为锁，那么在类外面也可以使用这个锁： 1234567class Client { public void doSomething(ShareSync sync) { synchronized (sync) { // do something } }} 这种方式会将锁暴露给外面，是一种共享的监视器模式。 不过，外部代码如果错误地获取锁对象，有可能会产生活跃性问题。 1.2.2 私有监视器模式对象内部使用私有的监视器，外部不能访问： 12345678910class PrivateSync { private final Object lock = new Object(); private int count = 0; public void increment() { synchronized (lock) { count++; } }} 由于加锁对象是私有的，在类外面也不能使用这个锁，是一种私有的监视器模式。 1.2.3 重入锁模式除了使用监视器，还可以使用重入锁： 12345678910111213class ReentrantSync { private final ReentrantLock lock = new ReentrantLock(); private int count = 0; public void increment() { lock.lock(); try { count++; } finally { lock.unlock(); } }} 重入锁模式，除了写法有些不同，功能上和监视器模式差不多。 和监视器模式一样，重入锁模式也可以分为共享模式和私有模式。 二、线程安全类的组合当从头构建一个类，或者将多个非线程安全的类组合在一起时，同步策略是相当有用的。 但是如果类中的各个状态都是线程安全的，那这个时候是否还需要同步策略？ 2.1 单状态组合 单状态是普通类型，需要同步策略，由组合提供同步 单状态是线程安全类，可以由自身保证线程安全性，无需额外同步策略 普通状态： 123456class SingleState { private int count = 0; public synchronized void increment() { count++; }} 线程安全状态： 123456class SingleSafeState { private AtomicInteger count = new AtomicInteger(0); public void increment() { count.getAndIncrement(); }} 2.2 多独立状态组合 相互独立的多个普通状态，需要同步策略，由组合提供同步 相互独立的多个线程安全状态，无需额外的同步策略，由状态自身保证线程安全性 普通独立状态： 12345678910class MultiState { private int count = 0; private boolean ready = false; public synchronized void increment() { count++; } public synchronized void setReady() { ready = true; }} 线程安全独立状态： 12345678910class MultiSafeState { private AtomicInteger count = new AtomicInteger(0); private AtomicBoolean ready = new AtomicBoolean(false); public void increment() { count.getAndIncrement(); } public void setReady() { ready.getAndSet(true); }} 2.3 多关联状态组合 有关联/依赖关系的多个状态，必须要同步策略，由组合提供同步 关联关系：先验条件、不定性条件、后验条件 12345678910111213141516class MultiRelationState { private int min = 0; private int max = 0; public synchronized void setMin(int min) { if (min &gt; this.max) { return; } this.min = min; } public synchronized void setMax(int max) { if (max &lt; this.min) { return; } this.max = max; }} 2.4 公开状态组合 组合在一起的状态，以公开的方式发布给外部，实现状态共享 组合不需要再提供同步策略，因为已经不算在自己的管辖范围内了 由外部代码自行对发布的共享状态添加同步策略 对外发布共享状态： 1234class MultiPublicState { public volatile int count = 0; public AtomicBoolean ready = new AtomicBoolean(false);} 外部自己控制同步策略： 1234567891011class Client { private MultiPublicState state; public void increment() { synchronized (state) { state.count++; } } public void setReady() { state.ready.getAndSet(true); }} 三、线程安全类的扩展 如何给线程安全类添加新的方法？ 保证原子性、保证线程安全性？ 3.1 客户端加锁机制客户端代码自己控制同步策略，实现所需功能： 12345678910class Client { private Vector&lt;Integer&gt; list; public void putIfAbstent(int value) { synchronized (list) { if (!list.contains(value)) { list.add(value); } } }} 优点：不需要修改原始类的代码。 缺点：所有用到这个方法的地方，都要重复写一份同样的代码，容易出错。 3.2 修改原始类源码在有源码修改权的情况下，直接在原始类上添加线程安全方法： 1234567class Vector&lt;E&gt; { public synchronized void putIfAbstent(E value) { if (!contains(value)) { add(value); } }} 优点：实现简单，封装性好，是最安全的。 缺点：第三方的代码基本上没办法修改。 3.3 扩展原始类在原始类支持继承扩展的情况下，直接继承添加新方法： 1234567class ChildVector&lt;E&gt; extends Vector&lt;E&gt; { public synchronized void putIfAbstent(E value) { if (!contains(value)) { add(value); } }} 优点：实现简单，可维护性好。 缺点：继承依赖于原始类对象，一旦原始类发生变更，继承类也需要同时更新；不是所有类都支持继承；继承还会增加类结构的复杂度。 3.4 代理原始类对象使用组合代理原始对象，包装一层： 12345678910111213class VectorProxy&lt;E&gt; { private Vector&lt;E&gt; vector; public VectorProxy(Vector&lt;E&gt; vector) { this.vector = vector; } public void putIfAbstent(E value) { synchronized (vector) { if (!vector.contains(value)) { vector.add(value); } } }} 优点：实现简单，封装性好，可维护性好。 缺点：对象类型发生变化，所有用到原始类的地方都需要修改。多加了一层，可能有轻微的性能损失。 总结设计线程安全的类： 收集对象状态 收集同步需求 选择状态的并发访问策略 实例封闭： 共享监视器模式 私有监视器模式 重入锁模式 线程安全类的组合： 单状态组合 多独立状态组合 多关联状态组合 公开状态组合 线程安全类的扩展： 客户端加锁机制 修改原始类源码 扩展原始类 代理原始类对象","link":"/lang/java/core/concurrency/04_%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BB%84%E5%90%88/"},{"title":"03_对象的共享","text":"对象的共享一、共享对象可能存在的问题？ 多个线程同时访问或修改共享对象时，可能会出现冲突，即原子性问题 一个线程修改对象状态后，其他线程未必能够看到发生的变化，即内存可见性 二、共享对象的可见性2.1 可见性问题有哪些？内存可见性可能带来的问题： 无法确保一个线程在修改状态时，其他线程能够适时看到状态变化 比如，多核运CPU、多级缓存、重排序等，都可能会影响线程对对象状态的读取 举个栗子： 12345678910111213141516public class Novisibility { private static boolean ready; private static int number; public static void main(String[] args) { new Thread(() -&gt; { while (!ready) { Thread.yield(); } System.out.println(number); }).start(); number = 42; ready = true; }} 理论上说，等到 ready 为 true 后，子线程就会打印出 number 的值 42。 但是由于内存可见性，可能会出现几种情况： 主线程在修改 ready 为 true 后，可能子线程看到的 ready 仍然是 false，结果就是程序一直循环等待下去； 还有一种可能，就是子线程会打印出 0，而不是 42。因为存在重排序的问题，代码 ready = true; 有可能会在 number = 42; 之前执行，导致数据与预期不符。 内存可见性，会带来一些数据读写的有效性问题，比如失效数据、错误数据等。 2.1.1 失效数据 一个线程修改了对象状态，其他线程可能获取到状态的最新值，也可能获取到旧的失效值 失效数据可能会导致意料之外的异常、数据结构被破坏、不精确的计算等等问题 2.1.2 错误的64位值 Java内存模型要求，变量的读取和写入都是原子操作 但是对于非 volatile 类型的 long 和 double 等 64 位的变量，JVM 是允许将 64 位的读写操作分成两个 32 位的读写操作的，这样就可能会出现错误的 64 位值 比如，先读取了变量的前 32 位数据，结果这个时候被别的线程修改了变量值，然后读取后 32 位数据，但是此时可能读到的是修改后的值的后 32 位数据，这时就会出现一个异常的不存在的 64 位值 2.2 如何解决可见性问题 为了确保多线程之间的读写操作可见性，必须使用同步机制 2.2.1 内置锁（监视器） 内置锁（监视器）是一种同步机制，它可以保证多个线程之间的读写操作可见性 为了保证所有线程都能够看到共享变量的最新值，所有读写线程都必须在同一个锁上同步 2.2. volatile 变量 volatile 变量提供了一种稍弱的同步机制，也可以保证线程之间的可见性 读取 volatile 变量时，总是会返回最新写入的值 写入 volatile 变量时，总是会立即写入新值，但是不会等待其他线程的写入，即不会阻塞其他线程的写操作 volatile 是一种比内置锁更轻量级的同步机制，因为它不会阻塞其他线程 三、什么是线程封闭（避免共享）？ 解决内存可见性问题的最简单方法，就是不共享变量，那样就不会出现内存可见性问题 如果不共享数据，仅在单线程中访问数据，就不需要同步，这种技术称为线程封闭 3.1 Ad-hoc 线程封闭 线程封闭实现，由程序自己实现和维护 比如使用 volatile 变量，可以看到其他线程修改的最新值，但是不能避免线程安全性 这种由程序自己维护的线程封闭实现，代价比较大，而且比较脆弱 3.2 栈封闭 只使用局部变量去访问对象，称为栈封闭 每个线程都有自己的栈，局部变量都在栈上，所以局部变量是只属于当前线程的 Java语言确保基本类型的局部变量始终是封闭在线程内的 对于引用类型的基本变量，只有局部生成的对象才是线程封闭的 这种方式，只能确保在栈中的局部对象是安全的，如果局部变量引用的是全局对象，全局对象还是会存在线程安全问题 3.3 线程本地变量 ThreadLocal ThreadLocal 可以确保每个线程都拥有属于自己的变量副本 ThreadLocal 变量的修改，只对当前线程生效，不会影响其他线程 这种方式可以确保对象是安全的，但是不应该滥用，毕竟 ThreadLocal 变量保存的对象虽然是安全的，但是它自己本身却相当于是一种全局变量，那就会存在线程安全问题 四、如何安全共享？想要在多个线程之间共享对象，必须确保安全地进行共享。 否则，可能会出现各种并发问题，比如线程之间的可见性问题。 1234567891011121314151617public class Share { public static Share instance; public int number; public Share(int number) { this.number = number; } public void init() { if (instance == null) { instance = new Share(11) } }} 类似这种方式共享的对象，是非常不安全的，很容易就出现线程安全问题。比如： instance 共享对象可能被多个线程创建多次，最终只保留了最后的一个对象 其他线程可能看不到最新的 instance 共享对象，看到的可能是 null，也可能是某个实例 其他线程看到的共享对象 instance 的状态 number 可能是失效的，即 number 不是 11，而可能是 0 反正如果不进行安全发布，共享对象就可能存在各种并发问题。 4.1 什么是发布和逸出？发布（Publish）：使得对象能够在当前作用域之外的代码使用。 比如： 将对象引用保存到其他代码可以访问的地方，比如保存到静态变量上 从方法调用中返回对象引用，使得其他地方可以使用 将对象引用作为参数传递给其他方法 简单来说，就是将一个局部生成的对象暴露给外面，使得外面的代码可以使用它，这就是发布，实际就是共享对象。 逸出（Escape）：某个不应该发布的对象被发布出去了。 比如： 123456789public class Escape { private String[] numbers = new String[] { &quot;1&quot;, &quot;2&quot; }; public String[] getNumbers() { return numbers; }} 发布地数组 numbers 实际上已经属于逸出了，因为它的原始引用被发布到了外部，调用者就可以直接修改数组的数据。 实际上，应该复制一份数组，再进行发布，避免直接修改原数组，从而避免逸出。 虽然调用者不一定会对逸出数据进行操作，但是误用该引用的风险始终是存在的。 4.2 什么是安全地构造对象？安全地构造对象是指： 不要发布一个尚未构造完成的对象 不要在构造过程中使 this 引用逸出 常见的不安全构造对象方式有： 在构造函数中启动一个线程，对象未构造完成之前，线程就可以看见 this 引用 在构造函数中调用可重写的方法，就有可能在子类中被逸出 举个例子： 123456789101112public class UnsafePublish { private int number; public UnsafePublish(int n) { new Thread(() -&gt; { System.out.println(number); }).start(); this.number = n; }} 因为在对象还未构造完成之前，线程有可能就执行了，而此时对象的状态 number 可能是不对的。 4.3 共享对象类型有哪些？4.3.1 不可变对象不可变对象（Immutable Object）：对象在其被创建之后就不能被修改。 需满足以下条件： 对象创建后其状态就不能修改 对象的所有域都是 final 类型（技术上不一定，只要保障不被修改即可） 对象是正确安全构造好的（没有 this 逸出等） 不可变对象的特性： 不可变对象一定是线程安全的 因为线程的不安全性就是来源于状态的变化，不可变对象的状态无法改变，就不存在线程安全问题。 4.3.2 事实不可变对象事实不可变对象（Effectively Immutable Object）：技术上对象是可变的，但是在程序中发布后就不会再改变。 需满足条件： 对象一旦创建完成后，就不会再有人去修改它，即使它是可以修改的 事实不可变对象的特性： 安全发布的事实不可变对象是线程安全的 注意，事实不可变对象需要“安全发布”，才可以保证线程安全。 4.3.3 可变对象可变对象：就是普通的发布对象，可以被任意线程修改。 4.4 如何安全发布？4.4.1 安全发布的要求 要安全地发布对象，必须保证对象的引用和对象的状态是同时对其他线程可见的 4.4.2 安全发布的常用模式 在静态初始化函数中初始化一个对象引用 将对象的引用保存到 volatile 类型的域或者原子类 AtomicReference 中 将对象的引用保存到某个正确构造对象的 final 类型域中 将对象的引用保存到一个由锁保护的域中 简单举例（实际不一定是这样用的）: 12345678910111213141516171819202122public class Share { // 由锁保护的域 private static Map&lt;String, Share&gt; instances = new ConcurrentMap&lt;&gt;(); static { instances.put(&quot;share&quot;, new Share(0)) } // 静态初始化函数 private static Share instance1 = new Share(1); // volatile 类型 private static volatile Share instance2; // final 域 private final Share instance3; private int number; public Share(int number) { this.number = number; } public Share(Share share) { this.instance3 = share; }} 4.4.3 安全共享对象 不可变对象，可以通过任意机制发布 事实不可变对象，必须通过安全方式发布 可变对象，必须通过安全方式发布，并且使用时必须是线程安全的（如由原子类或者某个锁保护起来） 总结共享对象问题： 多个线程同时访问或修改共享对象时，可能会出现冲突，即读写冲突 一个线程修改对象状态后，其他线程未必能够看到发生的变化，即内存可见性 可见性问题： 无法确保一个线程在修改状态时，其他线程能够适时看到状态变化 失效数据：一个线程修改了对象状态，其他线程可能获取到状态的最新值，也可能获取到旧的失效值 错误数据：对于非 volatile 类型的 long 和 double 等 64 位的变量，JVM 是允许将 64 位的读写操作分成两个 32 位的读写操作的，这样就可能会出现错误的 64 位值 可见性解决方案： 为了确保多线程之间的读写操作可见性，必须使用同步机制 内置锁（监视器） 内置锁（监视器）是一种同步机制，它可以保证多个线程之间的读写操作可见性 为了保证所有线程都能够看到共享变量的最新值，所有读写线程都必须在同一个锁上同步 volatile 变量 volatile 变量提供了一种稍弱的同步机制，也可以保证线程之间的可见性 读取 volatile 变量时，总是会返回最新写入的值 写入 volatile 变量时，总是会立即写入新值，但是不会等待其他线程的写入，即不会阻塞其他线程的写操作 volatile 是一种比内置锁更轻量级的同步机制，因为它不会阻塞其他线程 线程封闭（不共享）： Ad-hoc 线程封闭 线程封闭实现，由程序自己实现和维护 这种由程序自己维护的线程封闭实现，代价比较大，而且比较脆弱 栈封闭 每个线程都有自己的栈，局部变量都在栈上，所以局部变量是只属于当前线程的 Java语言确保基本类型的局部变量始终是封闭在线程内的 对于引用类型的基本变量，只有局部生成的对象才是线程封闭的 线程本地变量 ThreadLocal ThreadLocal 可以确保每个线程都拥有属于自己的变量副本 ThreadLocal 变量的修改，只对当前线程生效，不会影响其他线程 发布和逸出： 发布（Publish）：使得对象能够在当前作用域之外的代码使用 逸出（Escape）：某个不应该发布的对象被发布出去了 安全构造对象： 不要发布一个尚未构造完成的对象 不要在构造过程中使 this 引用逸出 共享对象类型： 不可变对象（Immutable Object）：对象在其被创建之后就不能被修改 事实不可变对象（Effectively Immutable Object）：技术上对象是可变的，但是在程序中发布后就不会再改变 可变对象：就是普通的发布对象，可以被任意线程修改 安全发布模式： 在静态初始化函数中初始化一个对象引用 将对象的引用保存到 volatile 类型的域或者原子类 AtomicReference 中 将对象的引用保存到某个正确构造对象的 final 类型域中 将对象的引用保存到一个由锁保护的域中 安全共享对象： 不可变对象，可以通过任意机制发布 事实不可变对象，必须通过安全方式发布 可变对象，必须通过安全方式发布，并且必须是线程安全的或者由某个锁保护起来的","link":"/lang/java/core/concurrency/03_%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%85%B1%E4%BA%AB/"},{"title":"02_线程安全性","text":"线程安全性一、什么是线程安全？ 当多个线程访问某个类时，这个类始终能表现出正确的行为，就称这个类是线程安全的 线程安全类，一般都封装了必要的同步机制，使用时无需额外进行同步 二、线程安全隐患从何而来？ 线程安全性，来自多个线程同时访问共享和可变的状态 共享，意味着可以被多个线程访问 可变，意味着状态的值在其生命周期内可以发生变化 一个对象是否是线程安全的，取决于它是否被多个线程访问 三、如何实现线程安全？1、无状态对象，一定是线程安全的 线程安全性，就是因为存在共享和可变的状态。 如果一个对象没有任何状态（没有任何共享和可变的状态），就不存在线程安全问题。 2、单一状态，可以使用原子类来维护，从而避免线程安全问题 原子操作，是指对于访问同一个状态的所有操作而言，是一些列不可分割的操作。 比如，“读取-修改-写入”（例如递增运算），为了保证线程安全，要求这些操作是原子的。 使用原子类来维护状态的对象，一定是线程安全的。 3、状态的复合操作，需要加锁同步机制来保证线程安全 原子类本身是线程安全的，但是多个原子操作组合在一起，就未必是线程安全的。 使用加锁同步机制，可以保证访问共享状态的复合操作是线程安全的。 使用加锁同步机制，必须保证同一个状态从始至终都只由同一个锁来保护。 同步锁是可重入的，即在同一个线程中，可以多次获取同一个锁，但是最后也要保证释放这么多次锁。 同步锁是互斥的，最多只有一个线程持有这个锁。","link":"/lang/java/core/concurrency/02_%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7/"},{"title":"管程","text":"管程一、是什么？管程，是由一组数据以及定义在这组数据上的操作组成的模块或软件包。 管程的组成： 局部于管程内部的数据说明，对外而言是共享数据 对该数据结构进行操作的一组数据 对局部于管程的共享数据设置初始值的语句 管程的特性： 局部于管程的数据只能被管程内的过程访问 一个进程只有通过管程内的过程才能访问共享数据 每次仅允许一个进程在管程内执行某个过程 简单来说： 管程就是封装了临界区和互斥操作的实现，保证只有一个进程可以访问临界区 管程是一个编程语言成分，它不是由程序员来保证互斥访问，而是由编译器来实现 管程和信号量的区别是啥？ 管程实际上是在信号量的基础上，再封装了一层，保证同步以及互斥 管程是一种高级同步原语，信号量则是一种低级同步原语 二、为什么？引入管程的目的有： 为了解决临界区分散所带来的管理和控制问题 使用信号量控制临界区，每次都需要在临界区内写 P、V 操作，很容易就写错了 管程相当于把 P、V 操作移到了管程内部来统一实现，有效地避免了分散和难管理的问题 比如说，采用信号量访问临界区时： 123456789101112131415P(S)count++;V(S);...P(S)count--;V(S)...P(S)count = 1;V(S) 每次访问共享变量，就必须采用 P、V 操作，这样临界区就很分散（比如这里就分了3个临界区）。 如果在某个临界区，忘记写 P 或 V 操作了，必然会导致某种问题，比如并发不安全，永远阻塞等。 为了避免这种分散，不好管理，就出现了管程： 12345678910111213141516monitor counter { int count; void increment() { count++; } void decrement() { count--; } void set(int c) { count = c; }}counter.increment();counter.decrement();counter.set(1); 注意，管程保证了同一时刻内只会有一个进程，所以没有并发问题。 管程，就是提供了很方便的接口给我们使用，并且还帮我们实现了同步和互斥。 三、怎么用？管程是一种编程语言成分，也就是说，使用管程，必须是语言自身支持才行。 管程的互斥实现，是编译器负责的。 就比如说，java 中的 synchronized 关键字，实际上底层就利用了管程： 123synchronized increment (lock) { count++;} synchronized 关键字保护的临界区，可以保证只有1个线程能访问，底层实际上由管程对象来实现的。 访问 synchronized 的临界区时，必须先获取 lock 锁对象对应的管程对象。","link":"/operating_system/basic/monitors/"},{"title":"信号量","text":"信号量一、是什么？信号量本质上是一个计数器，用于控制多进程/线程对共享资源的访问。 在进入一个关键代码段之前，必须先获取一个信号量 一旦该关键代码段完成了，必须释放之前获取的信号量 信号量即可以用于同步（如生产者-消费者），也可以用于互斥（二元信号量）。 二、为什么？ 信号量的主要目的是为了在保护共享资源的情况下，对进程/线程进行同步协调。 在并发环境下，需要对共享资源进行保护时，可以考虑用信号量。 三、怎么用？信号量本身是表示可用资源数量，所以它的取值是一个非负整数。 信号量，除了它的初始化以外，只有2种操作可用： P(S)：如果S的值大于零，就给它减1；如果它的值为零，就挂起该进程 V(S)：如果有其他进程因等待S而被挂起，就让它恢复运行；否则就给它加1 并且，需满足以下条件： P(S) 和 V(S) 必须都是不可分割的原子操作 它的功能定义就类似这样： 123456P (S) { while (S &lt;= 0) { // process block wait } S--;} 1234567V (S) { if (S has wait process) { signal wait process } else { S++; }} 注：P(S) 和 V(S) 都是原子操作，这里的定义只用于表示它们里面做了什么事。 有了信号量，就能够控制对共享资源的访问了，举个简单的例子： 123456789101112131415semaphore S = 1;void producer() { int item; item = produce_item(); inert_item(item); V(S); /* 通知消费者，已放入数据 */}void consumer() { P(S); /* 消费者必须在此等待生产者放入数据 */ int item; item = remove_item(); consume_item(item);} P(S) 用于等待信号量的可用资源，没有可用资源时，进程将陷入沉睡。 V(S) 用于唤醒在信号量 S 上等待的进程。 另外，P(S) 和 V(S)，也可以用 wait(S) 和 signal(S) 来表示。 四、数据结构？一般来说，信号量的结构定义可以是这样： 1234typedef struct { int value; struct process *wait_list;} semaphore; 其中，value 表示信号量可用资源数量，wait_list 表示在此信号量上等待的进程列表。 对应的 P(S) 和 V(S) 操作定义如下： 1234567wait(semaphore *S) { S-&gt;value--; if (S-&gt;value &lt; 0) { add this process to S-&gt;wait_list; block(); }} 1234567signal(semaphore *S) { S-&gt;value++; if (S-&gt;value &lt;= 0) { remove a process P from S-&gt;wait_list; wakeup(P); }} 其中 操作 block() 挂起调用它的进程，操作 wakeup(P) 重新启动阻塞进程 P 的执行。 在这种实现中，信号量的值可以是负数，这和经典的信号量定义是不一样的： 大于0时，表示可用资源数量 等于0时，表示无可用资源，并且没有进程在等待 小于0时，表示无可用资源，但是有进程在等待，其绝对值表示等待的进程数量 这种实现方式在实际的操作系统中比较常见。 五、如何保证原子性？信号量的操作必须是原子的，否则还是会出现并发问题。 信号量，本身也是一个临界资源，所以可以采用临界区互斥的方式实现原子性 临界区互斥的实现方式有： 单处理器中，采用暂时屏蔽中断的方式，等操作完信号量后再打开 多处理器中，采用硬件指令（TestAndSet 或 Swap）来给信号量加互斥锁访问 比如说，在 linux 系统中，信号量定义是这样的： 12345struct semaphore { raw_spinlock_t lock; /* 自旋锁 */ unsigned int count; /* 信号量值 */ struct list_head wait_list; /* 进程等待链表 */}; 在信号量结构中，会带有一个锁变量 lock。 每当对信号量操作时，都需要先对这个 lock 进行互斥加锁，然后才能操作。 比如，P(S) 的实现（在 linux 中是 down()）如下： 12345678910void down(struct semaphore *sem){ unsigned long flags; raw_spin_lock_irqsave(&amp;sem-&gt;lock, flags); /* 自旋等待信号量的锁变量 */ if (likely(sem-&gt;count &gt; 0)) sem-&gt;count--; else __down(sem); /* 如果信号量小于等于0，进入等待队列 */ raw_spin_unlock_irqrestore(&amp;sem-&gt;lock, flags); /* 释放信号量的锁 */} 这实现代码写得很清晰了： 操作前，首先获取信号量的锁变量，这里是用的自旋锁获取 加锁成功后，再判断信号量的可用资源数 如果可用资源数大于0，则直接减一；否则进入信号量的等待队列 操作完成后，释放信号量的锁 至于 raw_spin_lock_irqsave 自旋锁是如何实现的，实际上就是由更底层的硬件指令来完成的。 比如 TestAndSet 或 Swap 等指令，TestAndSet 指令就类似于这样： 12345/* 进入临界区 */void enter_region(int *lock){ while (TestAndSet(lock)); /* 自旋加互斥锁 */} 另外，还有一个问题，进入等待队列时都做了啥？具体看一下源码： 12345678910111213141516171819202122232425262728293031323334353637383940static inline int __sched __down_common(struct semaphore *sem, long state, long timeout){ /* 为当前进程创建waiter对象 */ struct task_struct *task = current; struct semaphore_waiter waiter; /* 添加到信号量的等待队列 */ list_add_tail(&amp;waiter.list, &amp;sem-&gt;wait_list); waiter.task = task; waiter.up = false; for (;;) { if (signal_pending_state(state, task)) goto interrupted; if (unlikely(timeout &lt;= 0)) goto timed_out; __set_task_state(task, state); /* 在切换到其他进程前，释放信号量的锁 */ raw_spin_unlock_irq(&amp;sem-&gt;lock); /* 调度切换进程 */ timeout = schedule_timeout(timeout); /* 重新获取信号量的锁 */ raw_spin_lock_irq(&amp;sem-&gt;lock); /* 被V(S)操作唤醒了 */ if (waiter.up) return 0; } timed_out: list_del(&amp;waiter.list); return -ETIME; interrupted: list_del(&amp;waiter.list); return -EINTR;} 从这里可以看到，进程如果在调用 P(S) 时拿不到资源，就会做几件事： 把当前进程添加到信号量的等待队列 释放信号量的锁，因为当前进程要睡眠了，如果不释放，别的进程就拿不到了 调度切换到其他进程，实际上并没有真正睡眠，而是等待了一段时间 过一段时间后，等待进程再次调度执行时，又会做几件事： 重新获取信号量的锁，不管对信号量做什么，即使只是验证它的值，也要先获取锁 检查自己是不是被别人用 V(S) 唤醒了 如果没有被唤醒，则进入下一轮等待 就这样，一直重复等待，直到拿到信号量的可用资源为止。 总结信号量是什么？ 信号量本质上是一个计数器，用于控制多进程/线程对共享资源的访问 在进入一个关键代码段之前，必须先获取一个信号量 一旦该关键代码段完成了，必须释放之前获取的信号量 信号量即可以用于同步（如生产者-消费者），也可以用于互斥（二元信号量） 为什么要用信号量？ 信号量的主要目的是为了在保护共享资源的情况下，对进程/线程进行同步协调 在并发环境下，需要对共享资源进行保护时，可以考虑用信号量 信号量怎么用？ 信号量本身是表示可用资源数量，所以它的取值是一个非负整数 信号量，除了它的初始化以外，只有2种操作可用： P(S)：如果S的值大于零，就给它减1；如果它的值为零，就挂起该进程 V(S)：如果有其他进程因等待S而被挂起，就让它恢复运行；否则就给它加1 P(S) 和 V(S) 必须都是不可分割的原子操作 P(S) 和 V(S) 操作，也可以用 wait(S) 和 signal(S) 来表示 信号量的数据结构？ 在这种实现中，信号量的值可以是负数，这和经典的信号量定义是不一样的： 大于0时，表示可用资源数量 等于0时，表示无可用资源，并且没有进程在等待 小于0时，表示无可用资源，但是有进程在等待，其绝对值表示等待的进程数量 信号量实现比较灵活，但是正数始终表示可用资源数 信号量的原子性保证？ 信号量，本身也是一个临界资源，所以可以采用临界区互斥的方式实现原子性 单处理器中，采用暂时屏蔽中断的方式，等操作完信号量后再打开 多处理器中，采用硬件指令（TestAndSet 或 Swap）来给信号量加互斥锁访问 在 linux 系统中，信号量采用的是锁变量法来互斥访问信号量 信号量结构中自带有一个锁变量 使用自旋锁来给锁变量加锁 自旋锁底层实际上是用的硬件指令实现 进入等待队列时都做了什么？以 linux 系统为例： 把当前进程添加到信号量的等待队列 释放信号量的锁，因为当前进程要睡眠了，如果不释放，别的进程就拿不到了 调度切换到其他进程，实际上并没有真正睡眠，而是等待了一段时间 一段时间后，进程再次被调度执行时： 重新获取信号量的锁，不管对信号量做什么，即使只是验证它的值，也要先获取锁 检查自己是不是被别人用 V(S) 唤醒了 如果没有被唤醒，则进入下一轮等待","link":"/operating_system/basic/semaphore/"},{"title":"临界区互斥","text":"临界区互斥一、基本概念1.1 临界概念定义： 临界资源：一次仅允许1个进程/线程使用的资源。比如，进程间的共享内存 临界区：对临界资源进行访问的代码片段。比如，进程中对共享内存进行访问的程序片段 1.2 同步 同步是一种进程/线程之间的合作关系 为完成某种任务而建立的多个进程或者线程之间的协调调用，次序等待，传递消息告知资源占用情况 同步是一种协调关系，为的是有序地运行 1.3 互斥 互斥是一种进程/线程之间的制约关系 当一个进程/线程进入临界区时，其他进程/线程必须等待 互斥具有唯一性和排它性，为的是避免访问冲突 二、实现临界区互斥的基本方法为禁止2个进程/线程同时进入临界区，需满足以下条件： 空闲等待：临界区空闲时，允许进程/线程进入临界区 忙则等待：2个进程/线程不允许同时处于临界区，后来的进程/线程必须等待 有限等待：不能让进程/线程无限期地等待进入临界区 让权等待：当进程/线程不能进入临界区时，应立即释放处理器，防止忙等待 2.1 软件方法2.1.1 锁变量法直接用1个全局锁变量，其初始值为0，来记录当前进入临界区的进程： 1234567891011121314int turn;/* 进入临界区 */void enter_region(int process) /* 当前进程号 */{ while (turn != 0); /* 其他进程正在访问临界区 */ turn = process; /* 设置临界区访问标志 */}/* 离开临界区 */void leave_region(int porcess) /* 当前进程号 */{ turn = 0; /* 设置临界区访问标志 */} 这种方法有可能导致2个进程同时进入临界区。 因为 while(turn != 0) 这一处代码有可能被2个进程同时执行，然后验证都能通过。 2.1.2 双标志法2个线程时，给每个进程1个标志，用于表示当前线程正处于临界区内： 12345678910111213141516int interested[2]/* 进入临界区 */void enter_region(int process) /* 当前进程号，进程号是0或1 */{ int other; other = 1 - process; /* 另一方进程号 */ while (interested[other] == 1); /* 另一方进程正在访问临界区 */ interested[process] = 1; /* 设置当前进程状态 */}/* 离开临界区 */void leave_region(int porcess) /* 当前进程号，进程号是0或1 */{ interested[process] = 0; /* 设置当前进程状态 */} 和锁变量法一样，同样存在2个进程同时进入临界区的情况。 while (interested[other] == 1); 可能会并发同时执行，2个进程验证都能通过。 2.13 Peterson 算法当2个进程同时要访问临界区时，结合锁变量 + 双标志法，后进入的线程需等待前一个线程执行完成： 123456789101112131415161718int turn;int interested[2]/* 进入临界区 */void enter_region(int process) /* 当前进程号，进程号是0或1 */{ int other; other = 1 - process; /* 另一方进程号 */ interested[process] = 1; /* 设置当前进程状态 */ turn = process; /* 设置临界区访问标志 */ while (turn == process &amp;&amp; interested[other] == 1); /* 另一方进程正在访问临界区 */}/* 离开临界区 */void leave_region(int porcess) /* 当前进程号，进程号是0或1 */{ interested[process] = 0; /* 设置当前进程状态 */} 在2个进程的情况下，可以保证在同一时间段内，只有1个进程能够访问临界区。 后来的进程会在 while (turn == process &amp;&amp; interested[other] == 1); 这里等待前一个进程退出临界区为止。 2.2 硬件方法2.2.1 中断屏蔽法进程切换，只会在 CPU 发生中断的情况下，所以只要禁止一切中断，就能避免进程切换。 它的基本模式如下： 1234567891011/* 进入临界区 */void enter_region(int process){ 关闭中断}/* 离开临界区 */void leave_region(int porcess){ 打开中断} 屏蔽中断，实际上只会对单处理器生效。 比如说，在处理器1上屏蔽中断，是不会影响到处理器2的中断的，处理器2依旧能正常处理中断信号。 所以，屏蔽中断法，只能对单处理器生效，对于多处理器还是有问题的。 2.2.2 硬件指令法计算机中有一些特殊的硬件指令，允许对一个内存字的内容进行检测和修改，并且保证读和写是不可分割的。即在该指令结束前，其他处理器均不允许访问该内存字。 这种硬件的原子指令，基本都是通过锁住内存总线，以达到禁止其他 CPU 访问内存字的目的。 屏蔽中断和锁住总线的区别： 屏蔽中断：只会对当前 CPU 生效，不影响其他 CPU 的中断处理 锁住总线：对所有 CPU 生效，因为 CPU 读写内存字，必须要经过内存总线 通过锁住总线的方式，可以避免多个 CPU 同时访问相同的内存字。 硬件指令法，实际上就是硬件版的锁变量法： 首先为每个临界区都设置一个共享变量 lock 然后利用硬件的原子指令设置 lock 的值 设置成功的进程，就拿到了临界区的访问权 设置不成功的进程，就进行自旋等待 具体看一下有哪些原子指令可以实现互斥。 (1) TestAndSet 指令 TestAndSet 指令的作用就是测试并设置内存字的值。 这类指令有 TSL 指令，它会将一个内存字读到寄存器，并在该内存地址上设值一个非零值。 伪代码类似这样（实际由硬件实现，是不可分割的原子操作）： 123456int TestAndSet (int *lock) { int old; old = *lock; *lock = 1; return old;} 利用这个指令实现的临界区互斥方法： 1234567891011/* 进入临界区 */void enter_region(int *lock){ while (TestAndSet(lock)); /* 自旋加互斥锁 */}/* 离开临界区 */void leave_region(int *lock){ *lock = 0; /* 释放互斥锁 */} 硬件原子指令保证 TestAndSet(&amp;lock) 是不可分割的，所以不存在2个进程都验证通过的情况。 (2) Swap 指令 Swap 指令的作用就是交换2个位置的内存，而且是原子不可分割的。 这类指令有 XCHG 指令，它可以交换2个位置的内存。 伪代码类似这样（实际由硬件实现，是不可分割的原子操作）： 123456void Swap (int *a, int *b) { int t; t = *a; *a = *b; *b = t;} 利用这个指令实现的临界区互斥方法： 1234567891011/* 进入临界区 */void enter_region(int *lock){ while (Swap(&amp;lock, 1)); /* 自旋加互斥锁 */}/* 离开临界区 */void leave_region(int *lock){ *lock = 0; /* 释放互斥锁 */} 硬件原子指令保证 Swap(&amp;lock, 1) 是不可分割的，所以也不存在2个进程都验证通过的情况。 总结临界概念： 临界资源：一次仅允许1个进程/线程使用的资源。比如，进程间的共享内存 临界区：对临界资源进行访问的代码片段。比如，进程中对共享内存进行访问的程序片段 同步： 同步是一种进程/线程之间的合作关系 为完成某种任务而建立的多个进程或者线程之间的协调调用，次序等待，传递消息告知资源占用情况 同步是一种协调关系，为的是有序地运行 互斥： 互斥是一种进程/线程之间的制约关系 当一个进程/线程进入临界区时，其他进程/线程必须等待 互斥具有唯一性和排它性，为的是避免访问冲突 临界区互斥实现： 软件互斥： 锁变量法和双标志法，都不是完美的临界区互斥实现 Peterson 算法，可以正确互斥，保证2个进程互斥访问临界区 只支持2个进程的互斥，自旋等待可能非常占用 CPU 资源 硬件互斥： 中断屏蔽法，只对单处理器保证互斥访问临界区，多处理器无效 硬件指令法，可以保证对多处理器下互斥访问临界区 支持任意进程数量的互斥，支持进程有多个临界区（设多个临界区锁变量即可） 软硬件互斥实现，都有忙等待的缺点","link":"/operating_system/basic/critical_section/"},{"title":"SSH","text":"SSHSSH是一种网络协议，用于计算机之间的加密登录。 SSH只是一种协议，存在多种实现，既有商业实现，也有开源实现。 一、基本用法 SSH主要用于远程登录。 假定要以用户名user登录远程主机8.8.8.8： 1$ ssh user@8.8.8.8 当本地用户名与远程用户名一致，登录时可以省略用户名： 1$ ssh 8.8.8.8 SSH的默认端口是22，可以使用参数p进行调整，比如使用8888端口： 1$ ssh -p 8888 user@8.8.8.8 二、请求流程SSH 的登录流程如下： 远程主机收到用户的登录请求，把自己的公钥发给用户 用户使用这个公钥，将登录密码加密后，发送回来 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录 三、口令登录如果是第一次登录远程主机，系统会出现下面的提示： 1234567$ ssh user@hostThe authenticity of host 'host (8.8.8.8)' can't be established.RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.Are you sure you want to continue connecting (yes/no)? 这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？ 所谓”公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。 很自然的一个问题就是，用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。 假定经过风险衡量以后，用户决定接受这个远程主机的公钥： 1Are you sure you want to continue connecting (yes/no)? yes 系统会出现一句提示，表示host主机已经得到认可： 1Warning: Permanently added 'host,8.8.8.8' (RSA) to the list of known hosts. 然后，会要求输入密码： 1Password: (enter password) 如果密码正确，就可以登录了。 当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。 每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 四、公钥登录使用密码登录，每次都必须输入密码，非常麻烦。好在SSH还提供了公钥登录，可以省去输入密码的步骤。 所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。 4.1 用户端设置这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个： 1$ ssh-keygen 运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。 运行结束以后，在$HOME/.ssh/目录下，会新生成两个文件：id_rsa.pub和id_rsa。前者是你的公钥，后者是你的私钥。 这时再输入下面的命令，将公钥传送到远程主机host上面： 1$ ssh-copy-id user@8.8.8.8 好了，用户端的设置就完成了。 4.2 远程端设置打开远程主机的/etc/ssh/sshd_config这个文件，检查下面几行前面”#”注释是否取掉： 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 然后，重启远程主机的ssh服务。 远程主机将用户的公钥，保存在登录后的用户主目录的$HOME/.ssh/authorized_keys文件中。公钥就是一段字符串，只要把它追加在authorized_keys文件的末尾就行了。 这里不使用上面的ssh-copy-id命令，改用下面的命令，解释公钥的保存过程： 1$ ssh user@host 'mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub 写入authorized_keys文件后，公钥登录的设置就完成了。","link":"/operating_system/basic/SSH/"},{"title":"内核版本","text":"内核版本主要是Linux内核版本的说明。 一、内核版本号格式Linux内核版本号的格式可以分为3个阶段： 早期版本，在1.0以前 过渡版本，在1.0 ~ 2.6之间 最新版本，在2.6.0以后 1.1 早期版本 用于在1.0以前，版本号格式是 x.xx，例如 0.01、0.02、···、1.0 等。 1.2 过渡版本用于1.0 ~ 2.6之间，版本号格式是 A.B.C，例如 2.0.28、2.4.18、···、2.6.0 等。 123A : 表示大幅度转变的内核，只有当发生重大变化的代码和内核发生才会发生，在历史上曾改变两次的内核：1994年的1.0及1996年的2.0B : 是指一些重大修改的内核，奇数表示开发版本，偶数表示稳定版本C : 是内核修订版本号，是指轻微修订的内核。当有安全补丁、bug修复、新的功能或驱动程序时，便会有变化 1.3 最新版本用于2.6.0以后，版本号格式是 major.minor.patch-build.desc，例如 2.6.32-642.15.1.el6.x86_64、4.4.131-1.el7.elrepo.x86_64 等。 1234567891011major : 主版本号，有结构变化才变更 minor : 次版本号，新增功能时才发生变化，一般技术表示测试版，偶数表示生产版 patch : 补丁包数或次版本的修改次数 build : 编译（或构建）的次数，每次编译可能对少量程序做优化或修改，但一般没有大的（可控的）功能变化。desc : 当前版本的特殊信息，其信息由编译时指定，具有较大的随意性，有如下的标识是常用的： rc（或r），表示发行候选版本（release candidate），rc后的数字表示该正式版本的第几个候选版本，多数情况下，各候选版本之间数字越大越接近正式版。 smp，表示对称多处理器（Symmetric MultiProcessing）。 pp，在Red Hat Linux中常用来表示测试版本（pre-patch）。 EL，在Red Hat Linux中用来表示企业版Linux（Enterprise Linux）。 mm，表示专门用来测试新的技术或新功能的版本。 fc，在Red Hat Linux中表示Fedora Core。 例如 2.6.32-642.15.1.el6.x86_64，它的说明如下： 123456第一个组数字：2, 主版本号第二个组数字：6, 次版本号，当前为稳定版本第三个组数字：32, 修订版本号第四个组数字：642.15.1，表示发型版本的补丁版本el6：则表示我正在使用的内核是 RedHat / CentOS 系列发行版专用内核x86_64：采用的是64位的CPU 二、内核版本分类2.1 mainline主线版本。 2.2 stable稳定版，由mainline在时机成熟时发布，稳定版也会在相应版本号的主线上提供bug修复和安全补丁，但内核社区人力有限，因此较老版本会停止维护，而标记为EOL(End of Life)的版本表示不再支持的版本。 2.3 longterm(Long Term Support)长期支持版，长期支持版的内核不再支持时会标记EOL。 2.4 linux-next，snapshot代码提交周期结束之前生成的快照，用于给Linux代码贡献者们做测试。 三、查看内核版本3.1 cat /proc/version12[root@home]# cat /proc/versionLinux version 4.4.131-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC) ) #1 SMP Wed May 2 13:09:02 EDT 2018 3.2 uname -a12[root@home]# uname -aLinux bogon 4.4.131-1.el7.elrepo.x86_64 #1 SMP Wed May 2 13:09:02 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux 四、查看系统版本4.1 lsb_release -alsb_release -a 适用于所有的Linux发行版本。 LSB是Linux Standard Base的缩写，lsb_release命令用来显示LSB和特定版本的相关信息。如果使用该命令时不带参数，则默认加上-v参数。 说明： 12345678-v 显示版本信息。-i 显示发行版的id。-d 显示该发行版的描述信息。-r 显示当前系统是发行版的具体版本号。-c 发行版代号。-a 显示上面的所有信息。-h 显示帮助信息。-s 输出简短的描述信息(仅限于redhat和fedora系统) 。 3.2 cat /etc/issuecat /etc/issue 适用于所有的Linux发行版本。 12[root@home]# cat /etc/issueUbuntu 14.04.5 LTS \\n \\l 3.2 cat /etc/redhat-releasecat /etc/redhat-release 适用于Redhat系的Linux。 12[root@home]# cat /etc/redhat-releaseCentOS Linux release 7.5.1804 (Core) 参考 https://jasonhzy.github.io/2019/02/05/linux-kernel-version/","link":"/operating_system/linux/kernel_version/"},{"title":"系统启动流程","text":"系统启动流程操作系统是存储在磁盘中的，那计算机是如何启动操作系统，并执行它的代码呢？ 为了了解操作系统的启动流程，首先介绍一些基本的概念。 一、基本概念1.1 BIOS 在计算机主板上，有一个称为基本输入输出系统（Basic Input Output System，BIOS）的固件（即写入到硬件的软件程序）。 BIOS 是计算机系统在启动过程中主动执行的第一个程序。 1.2 扇区磁盘上可以分为扇区（Sector）和磁道（Track）2种单位，其中扇区的物理大小设计有2种，分别是512字节和4K字节。 早期磁盘的第一个扇区（旧磁盘扇区都是512字节）里面含有重要的信息，它里面包括了2个信息： 主引导记录（Master Boot Record，MBR）：可以安装启动引导程序的地方，有446字节； 分区表（partition table）：用于记录整块磁盘的分区情况，有64字节。 1.3 MBR主引导记录（Master Boot Record，MBR）是安装启动引导程序的地方，可以用于加载操作系统核心文件，从而启动操作系统。 例如，在电脑安装双系统以后，启动计算机时，经常可以看到系统选择菜单，询问我们选择启动哪个系统，这个选择程序就是启动引导程序。 1.4 分区表分区表主要用于记录磁盘分区的状态，它仅有64字节，因此最多仅能记录4组记录，每组记录区记录了该区段的起始与结束的柱面号码。 分区只是针对那64个字节的分区表进行设置 分区表仅能写入4组分区信息 分区的最小单位是柱面（Cylinder） 分区类型只有2种：主要（Primary）分区和扩展（Extended）分区 主要分区和扩展分区最多只能4个 扩展分区最多只能有1个（操作系统限制） 主要分区不能再继续分区 扩展分区可以进一步分为更细的分区，这些分区称为逻辑分区（logical partition） 例如： 64字节分区表 分区 柱面 P1 1 ~ 100（Primary） P2 101 ~ 200（Primary） P3 201 ~ 300（Primary） P4 301 ~ 400（Extended） 扩展分区记录 分区 柱面 L1 301 ~ 330 L2 331 ~ 360 L3 361 ~ 400 1.5 DBR实际上启动引导程序除了可以安装在MBR以外，还可以安装在每个分区的启动扇区（boot sector）中，这个扇区称为分区引导扇区（DOS Boot Record，DBR）。 DBR和MBR是比较类似的，MBR是整个磁盘的第一个扇区，而DBR则是分区的第一个扇区，它们都可以安装启动引导程序。 就比如说，整个磁盘分成了4个分区，分区情况如下： 分区 柱面 P1 1 ~ 100（Primary） P2 101 ~ 200（Primary） P3 201 ~ 300（Primary） P4 301 ~ 400（Primary） 那么，对于整个磁盘来说，MBR就位于0号扇区上，每个分区的DBR则分别位于1号、101号、201号和301号扇区上。 二、启动流程计算机的启动流程大致是这样的： BIOS：检查设备情况，并决定第一个可启动的设备 MBR：识别可启动设备的第一个扇区内的主引导记录，执行启动引导程序 启动引导程序：读取内核文件，或者执行下一个启动引导程序 内核文件：启动操作系统 2.1 BIOS在计算机启动时，首个执行的程序就是 BIOS，它的主要作用包括： 检查所安装的RAM数量 检测键盘、鼠标和其他基本设备是否已安装并正常响应 扫描总线并找出连在上面的所有设备 读取存储在CMOS存储器中的设备清单，并决定启动设备 读入启动设备的第一个扇区，识别主引导记录和分区表，并执行其中包含的启动引导程序 2.2 MBR在BIOS执行的最后，会读取启动设备的主引导记录MBR，并开始执行其中的启动引导程序，此时BIOS就完成了它的任务，接下来就交给启动引导程序了。 启动引导程序的作用主要包括： 加载内核文件 转交给其他启动引导程序 1）加载内核文件 实际上就是加载操作系统文件，加载完成之后，就可以直接启动操作系统了，同时启动引导程序的任务也就完成了。 2）转交给其他启动引导程序 由于启动引导程序不仅可以安装在MBR上，还可以安装在DBR上。因此在某些情况下，MBR的启动引导程序可以将执行权转交给DBR中的启动引导程序。 就比如说，磁盘分为4个分区： 分区 柱面 P1 1 ~ 100（Primary） P2 101 ~ 200（Primary） P3 201 ~ 300（Primary） P4 301 ~ 400（Primary） 假如P1和P2分区分别安装了Windows和Linux。那么启动过程中首先会执行MBR的启动引导程序，如果此时MBR启动引导程序提供了2个选项： 选项一 直接加载P1分区的Windows内核文件 选项二 转交给P2分区的DBR的启动引导程序 当选择了选项二，那么MBR启动引导程序就会加载P2分区的DBR，并执行DBR的启动引导程序，然后剩下的事就交给DBR的启动引导程序了。 这其实就是多重引导的工作原理，首先执行的肯定是MBR的启动引导程序，然后通过切换到DBR的启动引导程序，来实现多个操作系统的切换。 2.3 启动引导程序启动引导程序的目的在于加载内核文件，它会识别磁盘内的文件系统格式，从而读取内核文件，启动操作系统。","link":"/operating_system/basic/startup/"},{"title":"中介者模式","text":"中介者模式一、什么是中介者模式？中介者模式（Mediator Design Pattern）：定义一个单独的（中介）对象，来封装一系列对象的交互。将这组对象之间的交互都委派给中介对象，来避免对象之间的直接交互。 英文原文： Mediator pattern defines a separate (mediator) object that encapsulates the interaction between a set of objects and the objects delegate their interaction to a mediator object instead of interacting with each other directly. 它有几个特点： 一组对象之间存在相互交流的情况，也就是一种网状关系 定义一个上帝（中介）对象，负责中转对象之间的交互，来避免对象之间的直接联系 相当于加了个中间层转换，把网状关系变成了星型关系 中介者模式，也称为调停模式，负责多个对象之间的互相沟通。 二、为什么要用中介者模式？中介者模式的应用场景比较少，一般用在下面的场景中： 多个对象之间存在复杂的网状关系，难以扩展和维护时 通过使用中介者模式，可以避免复杂的网状关系，降低对象之间的耦合度。 原来1个对象需要和n个对象交互，使用中介者模式后，1个对象只需要和中介者打交道就可以了。 三、怎么用中介者模式？中介者模式中的角色： 中介者（Mediator）：定义决策的接口 具体中介者（Concrete Mediator）：实现了中介者接口的具体角色 同事（Colleague）：定义了与中介者交互的接口 具体同事（Concrete Colleague）：实现了同事接口的具体角色 中介者模式结构： 示例程序结构： 中介者（Mediator）： 1234public interface Mediator { void createColleagues(); void colleagueChanged();} 同事（Colleague）： 1234public interface Colleague { void setMediator(Mediator mediator); void setColleagueEnabled(boolean enabled);} 具体同事（Concrete Colleague）： 1234567891011121314151617181920212223public class ColleagueCheckbox extends Checkbox implements ItemListener, Colleague { private Mediator mediator; public ColleagueCheckbox(String caption, CheckboxGroup group, boolean state) { super(caption, group, state); } @Override public void setMediator(Mediator mediator) { this.mediator = mediator; } @Override public void setColleagueEnabled(boolean enabled) { setEnabled(enabled); } @Override public void itemStateChanged(ItemEvent e) { mediator.colleagueChanged(); }} 123456789101112131415161718public class ColleagueButton extends Button implements Colleague { private Mediator mediator; public ColleagueButton(String caption) { super(caption); } @Override public void setMediator(Mediator mediator) { this.mediator = mediator; } @Override public void setColleagueEnabled(boolean enabled) { setEnabled(enabled); }} 123456789101112131415161718192021222324public class ColleagueTextField extends TextField implements TextListener, Colleague { private Mediator mediator; public ColleagueTextField(String text, int columns) { super(text, columns); } @Override public void setMediator(Mediator mediator) { this.mediator = mediator; } @Override public void setColleagueEnabled(boolean enabled) { setEnabled(enabled); setBackground(enabled ? Color.WHITE : Color.lightGray); } @Override public void textValueChanged(TextEvent e) { mediator.colleagueChanged(); }} 具体中介者（Concrete Mediator） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class LoginFrame extends Frame implements ActionListener, Mediator { private ColleagueCheckbox checkGuest; private ColleagueCheckbox checkLogin; private ColleagueTextField textUser; private ColleagueTextField textPass; private ColleagueButton buttonOk; private ColleagueButton buttonCancel; public LoginFrame(String title) { super(title); setBackground(Color.lightGray); setLayout(new GridLayout(4, 2)); createColleagues(); add(checkGuest); add(checkLogin); add(new Label(&quot;Username&quot;)); add(textUser); add(new Label(&quot;Password&quot;)); add(textPass); add(buttonOk); add(buttonCancel); colleagueChanged(); pack(); show(); } @Override public void createColleagues() { // 初始化组件 CheckboxGroup g = new CheckboxGroup(); checkGuest = new ColleagueCheckbox(&quot;Guest&quot;, g, true); checkLogin = new ColleagueCheckbox(&quot;Login&quot;, g, true); textUser = new ColleagueTextField(&quot;&quot;, 10); textPass = new ColleagueTextField(&quot;&quot;, 10); textPass.setEchoChar('*'); buttonOk = new ColleagueButton(&quot;OK&quot;); buttonCancel = new ColleagueButton(&quot;Cancel&quot;); // 绑定中介者 checkGuest.setMediator(this); checkLogin.setMediator(this); textUser.setMediator(this); textPass.setMediator(this); buttonOk.setMediator(this); buttonCancel.setMediator(this); // 绑定事件处理 checkGuest.addItemListener(checkGuest); checkLogin.addItemListener(checkLogin); textUser.addTextListener(textUser); textPass.addTextListener(textPass); buttonOk.addActionListener(this); buttonCancel.addActionListener(this); } @Override public void colleagueChanged() { if (checkGuest.getState()) { // 访客模式 textUser.setColleagueEnabled(false); textPass.setColleagueEnabled(false); buttonOk.setColleagueEnabled(true); } else { // 登录模式 textUser.setColleagueEnabled(true); userPassChanged(); } } private void userPassChanged() { if (textUser.getText().length() &gt; 0) { textPass.setColleagueEnabled(true); buttonOk.setColleagueEnabled(textPass.getText().length() &gt; 0); } else { textPass.setColleagueEnabled(false); buttonOk.setColleagueEnabled(false); } } @Override public void actionPerformed(ActionEvent e) { System.out.println(e.toString()); System.exit(0); }} 四、中介者模式有什么优缺点？优点： 从网状关系，变成了星型关系，复杂度变低了 对象之间的交互变简单了，更容易扩展和维护 缺点： 中介者对象容易变得臃肿，难以维护","link":"/design_pattern/mediator/"},{"title":"备忘录模式","text":"备忘录模式一、什么是备忘录模式？备忘录模式（Memento Desidn Pattern）：在不违背封装性原则的前提下，捕获一个对象的内部状态，并在对象之外保存，以便之后恢复对象为先前的状态。 它的几个特点是： 要求不要违背封装性原则 保存的是对象的内部状态，意味着对象外部不应该对保存的数据进行操作，而是假设不知道它的数据结构 保存的数据，相当于快照，可以用于撤销恢复 备忘录模式，也称为快照模式。 二、为什么要用备忘录模式？备忘录模式，使用的场景比较有限，主要就是用在防丢失、撤销、恢复上。 比如说， 编辑软件一般都会提供撤回操作 Ctrl + Z，回退到修改之前的状态 数据库也提供了回滚操作，可以回滚到之前的状态 玩游戏时，游戏也可以存档，失败后可以从存档状态重新开始 很多地方都可以用备忘录模式，但是场景大部分都是快照、撤销、恢复等。 三、怎么用备忘录模式？备忘录模式中的角色： 生成者（Originator）：生成和恢复快照的角色 快照（Memento）：生成者生成的内部状态快照数据 负责人（Caretaker）：负责通知生成者进行快照的生成和恢复，快照也是在此管理 备忘录模型结构： 示例程序结构： 生成者（Originator）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class Gamer { private static String[] fruitsName = { &quot;苹果&quot;, &quot;葡萄&quot;, &quot;香蕉&quot;, &quot;橘子&quot; }; private int money; private List&lt;String&gt; fruits = new ArrayList&lt;&gt;(); private Random random = new Random(); public Gamer(int money) { this.money = money; } public int getMoney() { return money; } public String getFruit() { String prefix = &quot;&quot;; if (random.nextBoolean()) { prefix = &quot;好吃的&quot;; } return prefix + fruitsName[random.nextInt(fruitsName.length)]; } public void bet() { int dice = random.nextInt(6) + 1; if (dice == 1) { money += 100; System.out.println(&quot;所持金钱增加了。&quot;); } else if (dice == 2) { money /= 2; System.out.println(&quot;所持金钱减半了。&quot;); } else if (dice == 6) { String f = getFruit(); System.out.println(&quot;获得了水果（&quot; + f + &quot;）。&quot;); fruits.add(f); } else { System.out.println(&quot;什么都没有发生。&quot;); } } public Memento createMemento() { Memento memento = new Memento(money); for (String f : fruits) { if (f.startsWith(&quot;好吃的&quot;)) { memento.addFruit(f); } } return memento; } public void restoreMemento(Memento memento) { this.money = memento.getMoney(); this.fruits = memento.getFruits(); } @Override public String toString() { return &quot;Gamer{&quot; + &quot;money=&quot; + money + &quot;, fruits=&quot; + fruits + '}'; }} 快照（Memento）： 123456789101112131415161718192021222324public class Memento { private int money; private ArrayList&lt;String&gt; fruits; Memento(int money) { this.money = money; this.fruits = new ArrayList&lt;&gt;(); } public int getMoney() { return money; } void addFruit(String fruit) { fruits.add(fruit); } @SuppressWarnings(&quot;unchecked&quot;) ArrayList&lt;String&gt; getFruits() { return (ArrayList&lt;String&gt;) fruits.clone(); }} 负责人（Caretaker）： 1234567891011121314151617181920public static void main(String[] args) { Gamer gamer = new Gamer(100); Memento memento = gamer.createMemento(); for (int i = 0; i &lt; 100; i++) { System.out.println(&quot;===== &quot; + i + &quot; =====&quot;); System.out.println(&quot;当前状态：&quot; + gamer); gamer.bet(); System.out.println(&quot;所持金钱为 &quot; + gamer.getMoney() + &quot; 元。&quot;); // 保存状态 if (gamer.getMoney() &gt; memento.getMoney()) { System.out.println(&quot;所持金钱增加了，保存当前状态。&quot;); memento = gamer.createMemento(); } else if (gamer.getMoney() &lt; memento.getMoney() / 2) { System.out.println(&quot;所持金钱减半了，保存当前状态。&quot;); gamer.restoreMemento(memento); } }} 四、备忘录模式有什么优缺点？优点： 实现了内部状态的封装，避免被外部破坏 提供了快速备份、撤销、恢复的操作 将快照单独管理，避免生成者报错过多数据，符合单一职责 缺点： 快照会占用较多内存资源 五、备忘录模式的优化？ 全量备份和增量备份相结合，低频全量备份，高频增量备份，两者结合来做恢复 比如，每天进行一次全量备份，没小时进行一次增量备份 恢复备份时，可以用前一天的全量备份 + 当天的增量备份","link":"/design_pattern/memento/"},{"title":"迭代器模式","text":"迭代器模式一、什么是迭代器模式？迭代器模式（Iterator Design Pattern）：提供一种方式来访问聚合里面的所有元素，而不暴露聚合对象的内部数据结构。 迭代器模式，也称为游标模式，主要用于遍历数据集合。 迭代器模式的几个特点： 目的是为了遍历集合数据 特点是可以避免集合的内部数据结构暴露，增加集合内部实现的灵活性 迭代器是为了遍历集合数据，所以一个完整的迭代器，肯定是包括集合和迭代器2部分。 迭代器模式，关注重点在于遍历数据，而不是按照什么顺序遍历。 比如说，集合里是按照字母顺序保存的，但使用迭代器遍历时，遍历顺序并不一定是按字母排序。 所以，迭代器并不一定按照结构遍历，而是主要为了遍历数据。 二、为什么要用迭代器模式？2.1 想要遍历集合的所有数据迭代器的目的就是为了遍历数据，所以是为了遍历集合，可使用迭代模式。 2.2 不想暴露集合内部数据结构有些时候，会出现 不想被人知道集合内部的数据结构 或者可能会修改内部数据结构实现 的情况，这时就需要隐藏内部的数据结构实现。 但是又需要遍历数据，这个时候就可以提供一个迭代器接口给外面调用。 2.3 想要统一集合的遍历结构假如有很多种集合类型，比如 List、Set、Map、Tree、Graph 等。 每种数据结构是不同的，在实际遍历时需要写的代码也不一样。 比如，遍历树的方式就有前序遍历、中序遍历、后序遍历等，代码都不同。 想要按照统一的方式遍历这些集合，就可以用迭代器来实现。 2.4 想要特殊的遍历方式有时候，想要按照某种顺序去遍历集合中的数据，可以自定义迭代器是完成。 比如按照字母顺序遍历，按照添加顺序遍历，按照添加顺序逆序遍历等等。 这个时候，可以为不同的遍历方式提供不同的迭代器实现。 三、怎么用迭代器模式？迭代器模式中的角色包括： 迭代器（Iterator）：定义了遍历集合数据的接口 具体迭代器（ConcreteIterator）：实现了迭代器接口的具体迭代器，和具体的集合数据结构绑定 集合（Aggregate）：集合接口，定了了创建迭代器的接口 具体集合（ConcreteAggregate）：实现了集合接口的具体集合，提供属于自己的迭代器实现 迭代器模型结构： 示例程序结构： 迭代器（Iterator）： 1234public interface Iterator&lt;T&gt; { boolean hasNext(); T next();} 集合（Aggregate）： 123public interface Aggregate&lt;T&gt; { Iterator&lt;T&gt; iterator();} 具体集合（ConcreteAggregate）： 12345678910111213141516171819202122232425262728293031323334353637383940public class BookShelf implements Aggregate&lt;Book&gt; { private Book[] books; private int last = 0; public BookShelf(int maxSize) { this.books = new Book[maxSize]; } public Book getBookAt(int index) { return books[index]; } public void appendBook(Book book) { sortInsert(book); } public int getLength() { return last; } private void sortInsert(Book book) { int index = last; for (; index &gt; 0; index--) { Book b = books[index - 1]; if (book.getName().compareTo(b.getName()) &lt;= 0) { break; } books[index] = b; } books[index] = book; last++; } @Override public Iterator&lt;Book&gt; iterator() { return new BookShelfIterator(this); }} 具体迭代器（ConcreteIterator）： 1234567891011121314151617181920public class BookShelfIterator implements Iterator&lt;Book&gt; { private BookShelf bookShelf; private int index; public BookShelfIterator(BookShelf bookShelf) { this.bookShelf = bookShelf; index = 0; } @Override public boolean hasNext() { return index &lt; bookShelf.getLength(); } @Override public Book next() { return bookShelf.getBookAt(index++); }} 四、迭代器模式有什么优缺点？优点： 统一集合的遍历方式，特别是对于复杂结构来说更友好 集合与迭代分离，耦合性低，很方便扩展迭代器 隐藏集合的数据结构，提高集合内部实现的灵活性 缺点： 客户端只能调用已有的迭代器，集合实现者需提供足够的迭代器实现 迭代器增加了类的数量，在一定程度上增加了程序的复杂性 五、实际场景 JDK 中的集合类，基本都实现了 Iterator 迭代器 ArrayList 中提供了正序和逆序2种迭代器 LinkedHashMap 提供了按照添加顺序遍历的迭代器接口","link":"/design_pattern/iterator/"},{"title":"职责链模式","text":"职责链模式一、职责链模式是什么？职责链模式（Chain of Responsibility Design Pattern）：将请求的发送和接收解耦，让多个接收者都有机会处理这个请求。将接收者串联起来，并沿着接收者链传递请求，直到某个接收者能够处理它为止。 英语原文： Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request. Chain the receiving objects and pass the request along the chain until an object handles it. 职责链的几个特点： 存在多个接收者可以处理请求 请求只需被某个接收者处理即可 请求也可以被多个接收者处理 职责链的目的在于，找到一个可以处理请求的接收者就好了。 二、为什么要用职责链模式？2.1 想要运行时确定请求接收者如果谁负责处理某个请求是不确定的，而是想要在运行时确定，可以尝试用职责链。 2.2 想要动态增删处理者想要在运行时动态添加和删除，或者自定义接收处理，可以用职责链模式。 2.3 想要按优先级处理请求如果想要根据请求类型，按照某种优先级处理，可以使用职责链模式。 可以按优先级处理，是职责链一个重要的特性。 三、职责链模式怎么用？职责链模式可以分为2种情况： 只要有一个接收者处理请求，职责链就停止了 所有接收者都可以处理请求，直到职责链结束 具体使用哪种形式，看实际的需求。 职责链模式中出现的角色： 处理者（Handler）：定义职责链中处理器的接口 具体处理者（ConcreteHandler）：实现了处理者接口的具体实现，是实际处理请求的接收者 请求者（Client）：发送请求的角色 职责链结构： 示例程序结构： 处理者接口（Handler）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class Support { private String name; private Support next; public Support(String name) { this.name = name; } public Support setNext(Support next) { this.next = next; return next; } /** * 解决问题的步骤 */ public final void support(Trouble trouble) { if (resolve(trouble)) { done(trouble); } else if (next != null) { next.support(trouble); } else { fail(trouble); } } /** * 解决问题的方法 */ protected abstract boolean resolve(Trouble trouble); protected void done(Trouble trouble) { System.out.println(trouble + &quot; is resolved by &quot; + this + &quot;.&quot;); } protected void fail(Trouble trouble) { System.out.println(trouble + &quot; can not be resolved.&quot;); } public String toString() { return &quot;[&quot; + name + &quot;]&quot;; }} 具体处理者（ConcreteHandler）： 123456789101112public class NoSupport extends Support { public NoSupport(String name) { super(name); } @Override protected boolean resolve(Trouble trouble) { return false; }} 1234567891011121314public class OddSupport extends Support { public OddSupport(String name) { super(name); } @Override protected boolean resolve(Trouble trouble) { if (trouble.getNumber() % 2 == 1) { return true; } return false; }} 1234567891011121314151617public class LimitSupport extends Support { private int limit; public LimitSupport(String name, int limit) { super(name); this.limit = limit; } @Override protected boolean resolve(Trouble trouble) { if (trouble.getNumber() &lt; limit) { return true; } return false; }} 123456789101112131415161718public class SpecialSupport extends Support { private int number; public SpecialSupport(String name, int number) { super(name); this.number = number; } @Override protected boolean resolve(Trouble trouble) { if (trouble.getNumber() == number) { return true; } return false; }} 四、职责链模式有什么优缺点？优点： 请求和接收解耦，可扩展性好 接收者可以动态调整，灵活性好 每个接收者的职责唯一，符合单一职责原则 缺点： 职责链可能存在有序性，接收者不能随意调整，否则容易出问题 职责链需要注意循环链接的问题 职责链可能比较长，影响效率","link":"/design_pattern/chain/"},{"title":"策略模式","text":"策略模式一、什么是策略模式？策略模式（Strategy Design Pattern）：定义一系列算法，并将算法封装起来，使得它们可以相互替换。策略模式可以使得算法独立于客户端（即使用算法的地方）。 英语原文: Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it. 策略模式有几个特点： 存在多种算法 算法之间可以相互替换，说明它们返回结果的影响是一样的，只是算法内部实现不同 策略独立于客户端，单独实现 比如说，排序功能，排序的结果可能都是一样的，但是可以使用不同的算法，如选择排序、冒泡排序、快速排序等。 二、为什么要用策略模式？2.1 好处在于：策略与客户端解耦策略独立封装，在客户端那边是感知不到细节的，很方便扩展新的实现。 2.2 典型应用场景：在运行时动态选择策略比如说，程序中设置一个类型变量，指定某种策略，然后在运行时改变类型值，就能动态改变策略。 例如，排序策略，数据很少时，直接用冒泡排序，数据很多时，可以用归并排序。 2.3 利用策略模式来移除if-else语句策略独立封装后，就可以采用查表法去获取指定的策略，无需使用if-else语句。 1Strategy strategy = StrategyFactory.get(strategyType); 当然，实际上if-else语句并没有移除，只是从客户端转移到了策略获取的地方。 但是这样做就减少了客户端的工作量，避免了很多出错的情况。 三、怎么用策略模式？使用策略模式，重点在于策略之间的可替换性。 策略模式中的角色包括： 策略（Strategy）：定义了策略所必须的接口。 具体策略（ConcreteStrategy）：实现了策略接口的具体策略（战略、方法和算法） 上下文（Context）：使用策略的地方，即调用Strategy接口的地方 策略模式的结构： 示例程序结构： 策略（Strategy）： 1234public interface Strategy { Hand nextHand(); void study(boolean win);} 具体策略（ConcreteStrategy）： 1234567891011121314151617181920212223public class WinningStrategy implements Strategy { private Random random; private boolean won = false; private Hand preHand; public WinningStrategy(int seed) { random = new Random(seed); } @Override public Hand nextHand() { if (!won) { preHand = Hand.getHand(random.nextInt(3)); } return preHand; } @Override public void study(boolean win) { won = win; }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ProbStrategy implements Strategy { private Random random; private int preHandValue = 0; private int currentHandValue = 0; private int[][] history = { {1, 1, 1}, {1, 1, 1}, {1, 1, 1} }; public ProbStrategy(int seed) { random = new Random(seed); } @Override public Hand nextHand() { int bet = random.nextInt(getSum(currentHandValue)); int handValue = 0; if (bet &lt; history[currentHandValue][0]) { handValue = 0; } else if (bet &lt; history[currentHandValue][0] + history[currentHandValue][1]) { handValue = 1; } else { handValue = 2; } preHandValue = currentHandValue; currentHandValue = handValue; return Hand.getHand(handValue); } @Override public void study(boolean win) { if (win) { history[preHandValue][currentHandValue]++; } else { history[preHandValue][(currentHandValue + 1) % 3]++; history[preHandValue][(currentHandValue + 2) % 3]++; } } private int getSum(int hv) { int sum = 0; for (int i = 0; i &lt; 3; i++) { sum += history[hv][i]; } return sum; }} 上下文（Context）： 12345678910111213141516171819202122232425262728293031323334public class Player { private String name; private Strategy strategy; private int winCount; private int loseCount; private int gameCount; public Player(String name, Strategy strategy) { this.name = name; this.strategy = strategy; } public Hand nextHand() { return strategy.nextHand(); } public void win() { strategy.study(true); winCount++; gameCount++; } public void lose() { strategy.study(false); loseCount++; gameCount++; } public void even() { gameCount++; }} 四、策略模式有什么优缺点？优点： 策略与客户端解耦，可扩展性好 策略独立扩展，符合单一职责原则 策略之间可相互替代，符合里斯替换原则 在一定程度上，策略模式可以减少客户端的if-else语句，避免代码错误 缺点： 策略类可能会很多，后期会比较难维护 客户端需要了解各种策略的区别（但不需要了解实现细节），才能选择合适的策略","link":"/design_pattern/strategy/"},{"title":"桥接模式","text":"桥接模式一、什么是桥接模式？桥接模式（Bridge Design Pattern）:将抽象与实现解耦，让他们能够独立变化。 或者，桥接模式就是将类的功能层次结构和类的实现层次结构分离开来，降低它们的耦合度。 抽象，即类的功能层次结构，采用的是继承的方式。 实现，即类的实现层次结构，采用的是组合的方式。 1.1 多用组合少用继承桥接模式，还有通俗一些的解释：一个类存在多个独立变化的维度时，可以通过组合方式让这些维度独立扩展。 比如说，汽车 Car 是一种抽象类型。 它的品牌类型，可以是奔驰、宝马、奥迪等； 而每辆车，它可能有好几个挡位，比如自动档、手动挡、手自一体等。 假设有m种品牌，n种挡位，那么它既可以形成成 m * n 种组合。 如果只采用继承来实现这些组合的话，那就需要有 m * n 个类，如果还有其他维度，那么组合数量会更多。 但是通过桥接模式，将品牌和挡位分离，采用组合的方式的话，就只需要 m + n 个类，大大减少了类的数量。 桥接模式，实际上就是利用组合来避免继承爆炸。 1.2 基于接口编程如果从结构上来说的话，继承就相当于是一棵树，组合就相当于在树与树之间的连接，它们构成了森林。 每棵树，都是一个维度，都有自己的抽象功能层次结构； 而每个维度之间，又存在着联系，这种联系就是一种实现层次。 树与树之间的联系，一般都是通过顶层的接口抽象来关联的，互相之间是基于接口连接。 桥接模式，实际上是通过接口来进行交互。 二、为什么要用桥接模式？桥接模式的主要作用有几个： 将类的功能层次和实现层次分离，降低耦合度 使用组合替代继承，避免组合爆炸的问题 把各个维度独立出来，方便进行扩展 使用桥接模式，最主要的就是避免类继承层次过深，而采用组合的方式来避免这种情况。 比如说，有m个维度，每个维度有n种变化，每种变化又包含k种情况，采用继承来做，就需要 m * n * k 个类。 如果将各个维度独立开来，采用组合的方式，就只需要 m + n + k 个类。 而且各个维度可以单独变化扩展，可维护性也会增强。 桥接模式适用于类层次和类关联比较复杂的情况，如果类层次结构很简单，使用桥接模式反而过于复杂。 三、怎么用桥接模式？桥接模式中的几个角色： 抽象化（Abstraction）：类功能层次的抽象类，里面包含了一个实现者的引用 扩展后的抽象化（Refined Abstraction）：在抽象化的基础上扩展了新功能 实现者（Implementor）：类实现层次的抽象类，被抽象化角色包含在内 具体实现者（ConcreteImplememtor）：是实现者的具体实现 桥接模式结构： 示例程序结构： 抽象化（Abstraction）： 123456789101112131415161718192021222324252627public class Display { private DisplayImpl impl; public Display(DisplayImpl impl) { this.impl = impl; } public void open() { impl.rawOpen(); } public void print() { impl.rawPrint(); } public void close() { impl.rawClose(); } public final void display() { open(); print(); close(); }} 扩展后的抽象化（Refined Abstraction）： 1234567891011121314public class CountDisplay extends Display { public CountDisplay(DisplayImpl impl) { super(impl); } public void multiDisplay(int times) { open(); for (int i = 0; i &lt; times; i++) { print(); } close(); }} 实现者（Implementor）： 1234567public abstract class DisplayImpl { public abstract void rawOpen(); public abstract void rawPrint(); public abstract void rawClose();} 具体实现者（ConcreteImplememtor）： 123456789101112131415161718192021222324252627282930313233public class StringDisplayImpl extends DisplayImpl { private String string; private int width; public StringDisplayImpl(String string) { this.string = string; this.width = string.getBytes().length; } @Override public void rawOpen() { printLine(); } @Override public void rawPrint() { System.out.println(&quot;|&quot; + string + &quot;|&quot;); } @Override public void rawClose() { printLine(); } private void printLine() { System.out.print(&quot;+&quot;); for (int i = 0; i &lt; width; i++) { System.out.print(&quot;-&quot;); } System.out.println(&quot;+&quot;); }} 四、桥接模式有什么优缺点？优点： 将类的功能层次和实现层次分离，降低耦合度 使用组合替代继承，避免组合爆炸的问题 把各个维度独立出来，方便进行扩展 缺点： 结构变得复杂了，可读性变差了","link":"/design_pattern/bridge/"},{"title":"代理模式","text":"代理模式一、什么代理模式？代理模式（Proxy Design Pattern）：在不改变原始类（被代理类）的情况下，对它进行功能的增强。 代理模式有几个特点： 不会改变原始类（被代理类） 核心功能还是由原始类（被代理类）实现 代理类只负责增强的那部分功能 代理，就是帮别人做事情，核心工作还是由被代理人做，但是其他琐碎的事则可以交给代理人。 比如租房时，我们可以找中介帮忙找房子、等一系列事，减少自己的工作量。 这里的中介就是一个代理，我们自己就是被代理人。 二、为什么要用代理模式？使用代理模式主要有几个目的： 保护目标对象 增强目标对象 隔离功能 保护对象，就是利用代理对象，隔离原始对象的数据，以达到保护对象的目的。 比如说，通过代理类去验证权限，有权限时才可以访问原始对象的数据。 增强对象，就是原始对象功能比较简单，可以通过代理类为其增加额外功能。 比如说，通过代理类去增加缓存，来提高接口的访问速度。 隔离功能，比如隔离业务功能和非业务功能，把非业务功能的代码放在代理类实现。 比如，接口监控、统计、鉴权、限流、事务、幂等、日志等。 三、代理模式怎么用？3.1 静态代理静态代理，就是每个被代理对象，都需要编写一个代理类。 这就是说，编写原始类时，必须同时编写一个代理类，否则就没有办法实现代理模式了。 比如说，有100个原始类：Base1、Base2 …… Base100。 那么，静态代理实现，就需要同时编写 100 个代理类：Proxy1、Proxy2 …… Proxy100。 （真要这么写，手都得废了~~~~~） 3.2 动态代理动态代理，就是解决静态代理的问题，改成由程序动态生成代理类，无需自己编写代理类。 比如说，静态代理需要编写100个代理类：Proxy1、Proxy2 …… Proxy100。 如果是动态代理，只需1个代理生成类即可：ProxyCreator，用来生成不同的代理类。 动态代理，实际就是搞了一个工厂类，专门用于生成代理类，减少手动编写的工作量。 动态代理，虽然不需要自己写代理类，但是一般都需要编写生成动态代理类的代码。 不过像生成动态代理类这种代码，实际上有很多框架都实现了，比如Spring、CgLib等，直接用即可。 3.3 模型结构代理模型中的角色包括： 抽象主题（SUbject）：被代理的目标类接口，或者抽象类 真实主题（RealSubject）：被代理目标的实现类 代理角色：代理的实现类，实现了抽象主题接口，内部蕴含真实主题的引用 模型结构： 示例程序结构： 抽象主题（Subject）： 1234567891011121314151617181920public interface Printable { /** * 设置名称 * @param name 名称 */ void setPrinterName(String name); /** * 获取名称 */ String getPrinterName(); /** * 打印输出 * @param string 输出字符串 */ void print(String string);} 真实主题（RealSubject）： 1234567891011121314151617181920212223242526272829303132333435363738394041public class Printer implements Printable { private String name; public Printer() { heavyJob(&quot;Printer 的实例生成中&quot;); } public Printer(String name) { this.name = name; heavyJob(&quot;Printer 的实例生成中（&quot; + name + &quot;）&quot;); } @Override public void setPrinterName(String name) { this.name = name; } @Override public String getPrinterName() { return name; } @Override public void print(String string) { } private void heavyJob(String msg) { System.out.println(msg); for (int i = 0; i &lt; 5; i++) { try { Thread.sleep(1000); } catch (Exception e) { e.printStackTrace(); } System.out.print('.'); } System.out.println(&quot;结束。&quot;); }} 代理角色（Proxy）： 123456789101112131415161718192021222324252627282930313233343536public class ProxyPrinter implements Printable { private String name; private Printer real; public ProxyPrinter() {} public ProxyPrinter(String name) { this.name = name; } @Override public void setPrinterName(String name) { if (real != null) { real.setPrinterName(name); } this.name = name; } @Override public String getPrinterName() { return name; } @Override public synchronized void print(String string) { realize(); real.print(string); } private synchronized void realize() { if (real == null) { real = new Printer(name); } }} 四、代理模式有什么优缺点？优点： 代理对象对原始对象起到了保护作用 代理对象可以对原始对象进行扩展 缺点： 每个原始对象都需要有自己的代理类 代理类相当于多了一层中介，而且还增加了功能，接口的访问速度变慢了 系统的复杂度增加了，代码调试变得更麻烦 五、代理模式的形式 远程代理：隐藏目标对象存在于不同地址空间的事实，方便客户端访问。例如，JAVA 中的 RMI（RemoteMethodInvocation：远程方法调用），调用远程方法接口，就像是在本地调用一样。 虚拟代理：当创建的目标对象开销很大时，只有当真正需要实例时，才会生成和初始化实例。例如，下载一幅很大的图像需要很长时间，因某种计算比较复杂而短时间无法完成，这时可以先用小比例的虚拟代理替换真实的对象，消除用户对服务器慢的感觉。 安全代理：控制不同种类客户对真实对象的访问权限，比如不同客户允许调用的接口不一样。 智能指引：附加一些额外的处理功能。例如，计算接口的访问次数，可以在代理类中处理。 延迟加载：指为了提高系统的性能，延迟对目标的加载。例如，Hibernate 中就存在属性的延迟加载和关联表的延时加载。 六、和其他模式的对比6.1 代理 vs. 装饰器装饰器模式和代理模式的模式结构上很类似，但是它们的使用目的不同： 装饰器模式：偏向于给原始对象增加新的业务功能 代理模式：偏向于给原始对象减轻负担，或者说增加非业务功能","link":"/design_pattern/proxy/"},{"title":"访问者模式","text":"访问者模式一、什么是访问者模式？访问者模式（Visitor Design Patten）：将作用于数据结构中的操作分离出来，形成单独的操作类，这样就可以在不改变数据结构的情况下，扩展出新的操作。 它将数据结构与数据处理分离开来，保持数据结构不变，而允许扩展新的处理。 二、访问者模式的应用场景是什么？ 被处理的数据结构相对稳定 被处理的数据结构要求保持不变，尽量避免数据处理影响到数据结构 数据处理类型比较多，相对复杂，并且数据处理数量是可变化的，可扩展的 就比如说文件，文件类型虽然多，但是常用的也就那几种文件，如PPT、Word、Pdf等。 总的来说，文件数据类型相对来说比较稳定，不容易变动。 但是对文件的操作就比较频繁了，比如对文件内容搜索、分页、调整样式等，有各种各样的操作，是变化的。 这种情况下，使用访问者模式将文件和操作分离，很容易就能添加新的操作行为。 三、访问者模式的结构是怎么样的？访问者模式中的登场角色： 访问者（Visitor）：负责对数据结构中的每个具体元素（ConcreteElement）声明访问接口，表示访问该元素 具体的访问者（ConcreteVisitor）：负责实现Visitor接口 元素（Element）：表示被Visitor访问的对象，声明了接受Visitor访问的接口 具体元素（ConcreteElement）：负责实现Element接口 对象结构（ObjectStructure）：负责处理Element角色的集合 示例程序结构： Viitor 和 Element： 1234public interface Visitor { void visit(File file); void visit(Directory directory);} 123public interface Element { void accept(Visitor visitor);} Entry： 123456789101112131415161718public abstract class Entry implements Element { public abstract String getName(); public abstract int getSize(); public Entry addEntry(Entry entry) { throw new FileTreatmentException(); } public Iterator iterator() { throw new FileTreatmentException(); } @Override public String toString() { return getName() + &quot; (&quot; + getSize() + &quot;)&quot;; }} 12345678910111213141516171819202122232425public class File extends Entry { private String name; private int size; public File(String name, int size) { this.name = name; this.size = size; } @Override public void accept(Visitor visitor) { visitor.visit(this); } @Override public String getName() { return name; } @Override public int getSize() { return size; }} 1234567891011121314151617181920212223242526272829303132333435363738394041public class Directory extends Entry { private String name; private ArrayList&lt;Entry&gt; dir = new ArrayList&lt;&gt;(); public Directory(String name) { this.name = name; } @Override public void accept(Visitor visitor) { visitor.visit(this); } @Override public Entry addEntry(Entry entry) { dir.add(entry); return this; } @Override public Iterator iterator() { return dir.iterator(); } @Override public String getName() { return name; } @Override public int getSize() { int size = 0; Iterator&lt;Entry&gt; it = dir.iterator(); while (it.hasNext()) { Entry entry = it.next(); size += entry.getSize(); } return size; }} ListVisitor： 1234567891011121314151617181920212223public class ListVisitor implements Visitor { private String currentDir = &quot;&quot;; @Override public void visit(File file) { System.out.println(currentDir + &quot;/&quot; + file); } @Override public void visit(Directory directory) { System.out.println(currentDir + &quot;/&quot; + directory); String saveDir = currentDir; currentDir = currentDir + &quot;/&quot; + directory.getName(); Iterator it = directory.iterator(); while (it.hasNext()) { Entry entry = (Entry) it.next(); entry.accept(this); } currentDir = saveDir; }} 四、访问者模式有什么优缺点？优点 可扩展性好。将数据与处理分离，方便增加新的处理 符合单一职责原则。每种操作都被封装成同一类的访问者，功能都比较单一 缺点： 可读性略差：访问者模式的代码结构是略微有点绕的，可读性和可理解性有点差 破坏依赖倒置原则。访问者依赖了具体的数据结构类型，而不是抽象数据结构 增加新的数据结构类麻烦。访问者是依赖了具体的数据结构的，增加一种新的数据结构，需要在访问者种增加新的处理接口 五、关于访问者的一些问题5.1 访问者模式将数据与操作分离，是否违背面向对象设计原则？ 从表面上看，分离数据和操作，是违背了面向对象设计原则的 从另一角度看，操作也可以认为是对象，访问者模式只是将数据对象和操作对象组合起来了 访问者结构中，数据是属于变化比较少的，而操作则是属于变化比较多的 访问者模式，将不变部分（数据）和可变部分（操作）分离，使用组合方式关联，是符合面向对象设计的 5.2 访问者模式的替代方案？ 可使用工厂方法模式替代 每种操作类型，对应一个操作工厂类，为不同的数据类型生成不同的操作对象 比如文件Word、Pdf，抽取操作对应一个工厂ExtractFactory，为不同数据类型提供不同的实现WordExtractor、PdfExtractor 新增压缩操作Comoress，定义一个工厂CompressFactory，提供不同的操作实现WordCompressor、PdfCompressor 5.3 什么时候用访问者模式？什么时候用工厂方法模式？具体的使用场景参考： 垂直扩展较多，即数据类型可变时，使用工厂模式比较合适 水平扩展较多，即操作类型可变时，使用访问者模式比较合适 垂直、水平扩展都比较多，即数据和操作都可变时，可使用模板模式 + 工厂模式/访问者模式 (1) 操作变化少，而数据类型经常变动，如添加新文件类型Txt、Excel等 使用访问者模式，就需要修改已有的每种操作类型，不符合开闭原则 使用工厂模式，只需要增加新的工厂类和操作类，无需修改原来的代码，符合开闭原则 (2) 数据类型基本不变，但是操作变化多，如为文件添加搜索、过滤、样式等操作 使用工厂模式，就需要为每种操作都添加工厂类和操作实现类，虽然符合开闭原则，但是类结构变得很复杂了，类数量也增多了 使用访问者模式，只需要添加新的操作类即可，符合开闭原则，而且可以避免增加很多类 (3) 数据类型和操作类型都可变，如文件可扩展Txt、Excel，操作也可扩展搜索、过滤等 在数据类型垂直扩展上，可以使用模板模式抽取公共的代码到父类中，避免重复代码 在操作类型水平扩展上，如果操作数量不多，类数量不多，可使用工厂模式实现 在操作类型水平扩展上，如果操作数量很多，可使用访问者模式实现，避免类数量过多","link":"/design_pattern/visitor/"},{"title":"状态模式","text":"状态模式一、什么是状态模式？状态模式（State Design Pattern）：对有状态的对象，把复杂的“判断逻辑”提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。 通常情况下，状态只作为数据，而不是对象，它只在对象之间进行流转，是对象之间数据交流的一种方式。 状态模式，则是将状态也当成是一个对象，赋予它数据和行为动作，它的数据就是状态，行为动作就是状态转换。 二、为什么要用状态模式？ 对象存在多种状态，在不同状态下，对象会做出不同的行为 对象的状态，会被外部的事件影响，从而导致对象的状态发生变化 应对这种情况，一般有几种方法解决。 2.1 分支逻辑法 传统的解决方案是：对不同的状态、事件、动作都考虑到，使用 if-else 加以判断，处理不同的情况 if-else 这种方式，代码逻辑复杂，判断条件臃肿，可读性差，可扩展性差，容易遗漏情况 2.2 查表法 对分支逻辑法的一种优化是，把 if-else 的判断逻辑迁移到一张表中，比如二维表 通过 key-value 的形式，将状态转换和状态动作都映射成一张二维表，根据状态和事件能直接查到下一步的转换和动作 这种方式，比起 if-else 要优雅一些，代码结构清晰，可读性和可扩展性较好 2.3 状态模式 分支逻辑和查表，都是一种正向的逻辑判断，即所有的状态转换和动作执行，都是由外部事件触发和外部处理的 状态模式，则是一种反向思维，事件触发依旧是外部的，但是改成了由状态自己本身进行状态转换和动作执行 状态模式，就是把之前由上下文处理的状态转换和动作，都迁移到了状态对象里面，隔离了不同状态的代码逻辑 优点是，符合“单一职责”，代码可读性好，结构清晰，可读性和可维护性好 缺点是，会引入较多的状态类，代码可维护性变差了一些 三、怎么实现状态模式？状态模式包括以下几个角色： 上下文环境（Context）：用于内部维护一个当前状态，并负责具体状态的切换 抽象状态（State）：定义的状态接口，用以抽象对象的状态行为 具体状态（ConcreteState）：抽象状态的实现类，主要实现是状态的行为以及转换 状态模式结构： 示例代码结构： 状态和上下文接口： 12345678public interface State { void doClock(Context context, int hour); void doUse(Context context); void doAlarm(Context context); void doPhone(Context context);} 12345678public interface Context { void setClock(int hour); void changeState(State state); void callSecurityCenter(String msg); void recordLog(String msg);} 不同状态类： 123456789101112131415161718192021222324252627282930313233343536public class DayState implements State { private static DayState singleton = new DayState(); private DayState() {} public static DayState getInstance() { return singleton; } @Override public void doClock(Context context, int hour) { if (hour &lt; 9 || 17 &lt;= hour) { context.changeState(NightState.getInstance()); } } @Override public void doUse(Context context) { context.recordLog(&quot;使用金库（白天）&quot;); } @Override public void doAlarm(Context context) { context.callSecurityCenter(&quot;按下警铃（白天）&quot;); } @Override public void doPhone(Context context) { context.callSecurityCenter(&quot;正常通话（白天）&quot;); } @Override public String toString() { return &quot;白天&quot;; }} 123456789101112131415161718192021222324252627282930313233343536public class NightState implements State { private static NightState singleton = new NightState(); private NightState() {} public static NightState getInstance() { return singleton; } @Override public void doClock(Context context, int hour) { if (9 &lt;= hour &amp;&amp; hour &lt; 17) { context.changeState(DayState.getInstance()); } } @Override public void doUse(Context context) { context.callSecurityCenter(&quot;紧急，晚上使用金库！&quot;); } @Override public void doAlarm(Context context) { context.callSecurityCenter(&quot;按下警铃（晚上）&quot;); } @Override public void doPhone(Context context) { context.callSecurityCenter(&quot;晚上的通话记录&quot;); } @Override public String toString() { return &quot;晚上&quot;; }} 上下文实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class SafeFrame extends Frame implements ActionListener, Context { private TextField textClock = new TextField(60); private TextArea textScreen = new TextArea(10, 60); private Button buttonUse = new Button(&quot;使用金库&quot;); private Button buttonAlarm = new Button(&quot;按下警铃&quot;); private Button buttonPhone = new Button(&quot;正常通话&quot;); private Button buttonExit = new Button(&quot;结束&quot;); private State state = DayState.getInstance(); private ActionEvent e; public SafeFrame(String title) { super(title); setBackground(Color.lightGray); setLayout(new BorderLayout()); add(textClock, BorderLayout.NORTH); textClock.setEditable(false); add(textScreen, BorderLayout.CENTER); textScreen.setEditable(false); Panel panel = new Panel(); panel.add(buttonUse); panel.add(buttonAlarm); panel.add(buttonPhone); panel.add(buttonExit); add(panel, BorderLayout.SOUTH); pack(); show(); buttonUse.addActionListener(this); buttonAlarm.addActionListener(this); buttonPhone.addActionListener(this); buttonExit.addActionListener(this); } public void actionPerformed(ActionEvent e) { this.e = e; System.out.println(e.toString()); if (e.getSource() == buttonUse) { state.doUse(this); } else if(e.getSource() == buttonAlarm) { state.doAlarm(this); } else if (e.getSource() == buttonPhone) { state.doPhone(this); } else if (e.getSource() == buttonExit) { System.exit(0); } else { System.out.println(&quot;?&quot;); } } @Override public void setClock(int hour) { String clockString = &quot;现在时间是 &quot;; if (hour &lt; 10) { clockString += &quot;0&quot; + hour + &quot;:00&quot;; } else { clockString += hour + &quot;:00&quot;; } System.out.println(clockString); textClock.setText(clockString); state.doClock(this, hour); } @Override public void changeState(State state) { System.out.println(&quot;从 &quot; + this.state + &quot; 状态变为了 &quot; + state + &quot; 状态。&quot;); this.state = state; } @Override public void callSecurityCenter(String msg) { textScreen.append(&quot;呼叫： &quot; + msg + &quot;\\n&quot;); } @Override public void recordLog(String msg) { textScreen.append(&quot;记录 ... &quot; + msg + &quot;\\n&quot;); }} 四、状态模式有什么优缺点？优点： 结构清晰。将状态相关的转换和动作都局部化分割到状态对象中，符合“单一职责”原则 可扩展性强。很容易就能扩展一种新状态，不过可能要修改其他状态类的转换代码 缺点： 类数据增多。每个状态都是一个类，必然会导致状态类增多 状态转换结构不清晰。状态转换写在每个单独的状态类里面，而没有一个完整的转换图，在代码可读性上不是那么好 五、与其他模式的对比5.1 职责链模式 职责链模式和状态模式，都能处理过多 if-else 的问题 职责链模式，强调的是对象间状态的转移，不同对象之间并不知道对方的存在，只是由外部按照职责链顺序执行 状态模式，更强调的是对象内状态的转换，对象之间互相知道对方的存在，便于进行状态转换 5.2 策略模式 策略模式，对象之间是以一种可互相替换的方式存在 状态模式，对象是以不同状态的形式存在，是一种互相转换的关系，但不是可替换的","link":"/design_pattern/state/"},{"title":"观察者模式","text":"观察者模式一、什么是观察者模式？观察者模式（Observer Design Pattern）：多个对象之间存在一对多的关系，当一个对象的状态发生改变时，所有其他依赖的对象都会收到通知。 观察者模式也被称为发布-订阅模式。 负责通知其他依赖对象称为被观察者，被通知的对象称为观察者。 在现实中，对象之间总是存在依赖关系的，一个对象的状态改变，往往会影响到其他的依赖对象。 观察者模式主要用于一对多的关系的情况，当某个对象状态发生改变时，需要通知其他所有的依赖对象。 比如说公众号订阅、天气预报通知等，都属于观察者模式。 二、为什么要用观察者模式？为什么要用观察者模式？ 假如不用观察者模式，那按照正常的逻辑，一对多的影响关系应该如何做呢？ 没办法，只能把所有依赖对象都放在状态对象里面，当状态改变后，逐个调用依赖对象的接口去通知变更。 状态对象必须知道各个依赖对象的存在以及它们的类型，才能准确地调用它们的接口 一旦要新增依赖对象，只能去修改状态对象的代码 没办法很好做到动态添加和删除依赖对象，灵活性不够 状态对象和依赖对象都放在一起，代码耦合性高，而且扩展性很差 观察者模式，目的就是为了将依赖对象解耦，并且实现动态添加和删除依赖对象。 三、观察者模式怎么用？观察者模式中的几个角色： 抽象被观察者（Subject）：表示被观察的对象，定义了注册、删除、通知观察者的方法。 具体被观察者（ConcreteSubject）：具体被观察对象的实现，主要是状态变化后，通知所有观察者的实现 抽象观察者（Observer）：抽象观察者，定义了被通知的接口回调方法 具体观察者（ConcreteObserver）：实现了抽象观察者的通知方法，执行具体的行为 观察者模式结构： 示例程序结构： 示例程序代码： 观察者： 1234public interface Observer { /** 观察者被通知的回调接口 */ void update(NumberGenerator generator);} 12345678910111213public class DigitObserver implements Observer { @Override public void update(NumberGenerator generator) { System.out.println(&quot;DigitObserver: &quot; + generator.getNumber()); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } }} 123456789101112131415161718public class GraphObserver implements Observer { @Override public void update(NumberGenerator generator) { System.out.println(&quot;GraphObserver: &quot;); int count = generator.getNumber(); for (int i = 0; i &lt; count; i++) { System.out.print(&quot;*&quot;); } System.out.println(); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } }} 被观察者： 123456789101112131415161718192021222324252627public abstract class NumberGenerator { /** 观察者集合 */ private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); /** 添加观察者 */ public void addObserver(Observer observer) { observers.add(observer); } /** 移除观察者 */ public void removeObserver(Observer observer) { observers.remove(observer); } /** 通知所有观察者 */ public void notifyObservers() { for (Observer observer : observers) { observer.update(this); } } /* 被观察者状态改变的接口方法 */ public abstract int getNumber(); public abstract void execute();} 123456789101112131415161718public class RandomNumberGenerator extends NumberGenerator { private Random random = new Random(); private int number; @Override public int getNumber() { return number; } @Override public void execute() { for (int i = 0; i &lt; 20; i++) { number = random.nextInt(50); notifyObservers(); } }} 四、观察者模式有什么优缺点？优点： 降低了被观察者与观察者的耦合度 提高了灵活性，方便新增和删除观察者对象 缺点： 在多对多的情况下，观察者之间可能会比较混乱，容易出现循环","link":"/design_pattern/observer/"},{"title":"解释器模式","text":"解释器模式一、什么是解释器模式？解释器模式（Interpreter Design Pattern）：对具有某种语法规则的语言表示，定义一个解释器来处理这个语法 Interpreter pattern is used to defines a grammatical representation for a language and provides an interpreter to deal with this grammar. 解释器模式的一些特点： 存在某种语法规则，比如算术运算表达式，中英文翻译等 语法规则可能会出现循环、递归 解释器模式就是根据语法规则去解读“句子” 二、为什么要用解释器模式？场景： 一些重复出现的问题可以用一种简单的语言来表达 当有一个语言中的句子可以表示为一个抽象语法树时 原理： 简单的语法规则，可以不用解释器模式，防止过度设计 复杂的语法规则解析，逻辑复杂，代码量多 复杂语法解析代码都写在一个类中，代码的耦合度会很高，并且不易维护和扩展 将语法规则拆分成多条细则，拆分到各个小类中，避免解析类过于膨胀 每条细则，都是单独的单元，只负责对这部分语法规则进行解析 三、解释器的结构是怎么样的？解释器中包含的角色有： 抽象表达式（AbstrctExpression）：定义了语法树节点的共同接口 终结符表达式（TerminalExpression）：负责语法树中的叶子节点 非终结符表达式（NoterminalExpression）：负责语法树中的非叶子节点 上下文环境（Context）：提供必要信息或者公共的方法 示例程序结构： 抽象表达式（AbstrctExpression）: 123public abstract class Node { public abstract void parse(Context context) throws ParseException;} 终结符表达式（TerminalExpression）: 12345678910111213141516171819public class PrimitiveCommandNode extends Node { private String name; @Override public void parse(Context context) throws ParseException { // &lt;primitive command&gt; ::= go | right | left name = context.currentToken(); context.skipToken(name); if (!&quot;go&quot;.equals(name) &amp;&amp; !&quot;right&quot;.equals(name) &amp;&amp; !&quot;left&quot;.equals(name)) { throw new ParseException(name + &quot; is undefined&quot;); } } @Override public String toString() { return name; }} 非终结符表达式（NoterminalExpression）: 12345678910111213141516public class ProgramNode extends Node { private Node commandListNode; @Override public void parse(Context context) throws ParseException { // &lt;program&gt; ::= program &lt;command list&gt; context.skipToken(&quot;program&quot;); commandListNode = new CommandListNode(); commandListNode.parse(context); } @Override public String toString() { return &quot;[&quot; + &quot;program=&quot; + commandListNode + &quot;]&quot;; }} 1234567891011121314151617181920212223242526public class CommandListNode extends Node { private List&lt;Node&gt; commandNodes = new ArrayList&lt;&gt;(); @Override public void parse(Context context) throws ParseException { // &lt;command list&gt; ::= &lt;command&gt;* end while (true) { if (context.currentToken() == null) { throw new ParseException(&quot;Missing end&quot;); } if (&quot;end&quot;.equals(context.currentToken())) { context.skipToken(&quot;end&quot;); break; } Node commandNode = new CommandNode(); commandNode.parse(context); commandNodes.add(commandNode); } } @Override public String toString() { return commandNodes.toString(); }} 1234567891011121314151617181920public class CommandNode extends Node { private Node node; @Override public void parse(Context context) throws ParseException { // &lt;command&gt; ::= &lt;repeat command&gt; | &lt;primitive command&gt; if (&quot;repeat&quot;.equals(context.currentToken())) { node = new RepeatCommandNode(); } else { node = new PrimitiveCommandNode(); } node.parse(context); } @Override public String toString() { return node.toString(); }} 1234567891011121314151617181920public class RepeatCommandNode extends Node { private int number; private Node commandListNode; @Override public void parse(Context context) throws ParseException { // &lt;repeat command&gt; ::= repeat &lt;number&gt; &lt;command list&gt; context.skipToken(&quot;repeat&quot;); number = context.currentNumber(); context.nextToken(); commandListNode = new CommandListNode(); commandListNode.parse(context); } @Override public String toString() { return &quot;[repeat &quot; + number + &quot; &quot; + commandListNode + &quot;]&quot;; }} 上下文环境（Context） 1234567891011121314151617181920212223242526272829303132333435363738394041public class Context { private StringTokenizer tokenizer; private String currentToken; public Context(String text) { tokenizer = new StringTokenizer(text); nextToken(); } public String nextToken() { if (tokenizer.hasMoreTokens()) { currentToken = tokenizer.nextToken(); } else { currentToken = null; } return currentToken; } public String currentToken() { return currentToken; } public void skipToken(String token) throws ParseException { if (!token.equals(currentToken)) { throw new ParseException(&quot;Warning: &quot; + token + &quot; is expected, but &quot; + currentToken + &quot; is found&quot;); } nextToken(); } public int currentNumber() throws ParseException { int number = 0; try { number = Integer.parseInt(currentToken); } catch (Exception e) { throw new ParseException(&quot;Warning: &quot; + e); } return number; } } 四、解释器模式有什么优缺点？优点： 符合“单一职责”原则，每个语法细则都是一个类，只负责自己那部分的解析 可扩展性好，扩展新的语法规则简单，只需要新增类或者继承已有类即可 缺点： 引起类膨胀，每条规则都定义一个类，如果规则很多，就会出现大量的类 执行效率低，使用了大量的循环和递归，同时调试也很麻烦 应用场景少，简单的规则一般用不上解释器模式，复杂规则的场景比较少，一般用在语言解析比较多 五、应用场景 正则表达式 算术运算表达式","link":"/design_pattern/interpreter/"},{"title":"命令模式","text":"命令模式一、什么是命令模式？命令模式（Command Design Pattern）：将请求封装为一个对象，使得发出请求的责任和执行请求的责任分割开。 命令有时也可以称为事件，比如点击鼠标、按下键盘等事件，通常会将它们封装成一个事件对象，然后按顺序放入队列中，再逐个去处理它们。 二、为什么要用命令模式？ 大部分编程语言是无法将函数作为参数传递给其他函数的 利用命令模式，可以把函数封装成命令对象，模拟函数作为参数 命令模式，主要用来控制命令的执行，比如异步、延迟、排队等，同时还支持撤销、重做、存储、统计命令等 三、命令模式的结构是怎么样的？命令模式包含以下几个角色： 抽象命令：负责定义命令接口 具体的命令：负责实现命令接口 命令接收者：执行命令时的目标对象 命令发动者：发动执行命令的角色，或者说持有命令，并开始执行命令的地方 示例程序结构： 抽象命令接口（Command）: 123public interface Command { void execute();} 具体的命令（ConcreteCommand）： 123456789101112131415public class DrawCommand implements Command { protected Drawable drawable; private Point position; public DrawCommand(Drawable drawable, Point position) { this.drawable = drawable; this.position = position; } @Override public void execute() { drawable.draw(position.x, position.y); }} 12345678910111213141516171819202122232425262728public class MacroCommand implements Command { private Stack commands = new Stack(); @Override public void execute() { Iterator it = commands.iterator(); while (it.hasNext()) { ((Command)it.next()).execute(); } } public void append(Command cmd) { if (cmd != this) { commands.push(cmd); } } public void undo() { if (!commands.isEmpty()) { commands.pop(); } } public void clear() { commands.clear(); }} 命令接收者（Receiver）： 123public interface Drawable { void draw(int x, int y);} 命令发动者（Invoker）： 123456789101112131415161718192021222324252627public class DrawCanvas extends Canvas implements Drawable { /* 颜色 */ private Color color = Color.red; /* 绘制的原点半径 */ private int radius = 6; /* 历史记录 */ private MacroCommand history; public DrawCanvas(int width, int height, MacroCommand history) { setSize(width, height); setBackground(Color.white); this.history = history; } public void paint(Graphics g) { System.out.println(&quot;paint&quot;); history.execute(); } @Override public void draw(int x, int y) { Graphics g = getGraphics(); g.setColor(color); g.fillOval(x - radius, y - radius, radius * 2, radius * 2); }} 四、命令模式有什么优缺点？优点： 结构清晰，请求与接收解耦，命令之间相互隔离 扩展性好，很方便就能扩展新的命令 缺点： 容易产生大量的命令类，增加系统复杂度 请求和接收是分离的，可读性变差了，增加了代码理解上的难度","link":"/design_pattern/command/"},{"title":"享元模式","text":"享元模式一、享元模式是什么？享元设计模式（FlyWeight Design Pattern）：通过共享已有实例，来避免创建新的实例，减少空间消耗，提高资源利用率 享元，意思就是共享的对象、单元、元素等。 主要特点： 相同实例对象只保留一份，即享元对象 需要某个实例时，尽量共用享元对象 享元对象可以减少对象的数量 享元模式的本质就是缓存对象，减少资源消耗。 二、为什么要用享元模式？享元模式，目的就是为了共享对象、减少资源的消耗。 使用享元模式，为的就是减少资源消耗、降低内存，提高资源利用率。 三、该如何用享元模式？使用享元模式，需要注意几点： 享元对象应该是不可变的，即没有setter方法 享元对象会对所有地方都有影响 享元对象中不应该存在可变的信息，即有可能发生变化的内容 享元对象不应该被垃圾回收 享元对象的内部状态是不可变的，外部转台是可变的 比如，数据库连接池，用户名、密码、url这些属于享元对象的内部状态，不可变； 连接可用标记等属性，属于外部状态，是可变的，比如回收连接后，可用标记会设为true。 享元模式的几个角色包括： 抽象享元角色（FlyWeight）：表示享元类的接口 具体享元角色（ConcreteFlyWeight）：表示被共享的享元实例对象 非享元角色（Unsharable Flyweight）：表示外部状态，区别于享元对象的内部状态，以参数形式注入享元对象 享元工厂（FlyWeightFactory）：负责生成和管理享元对象的工厂 享元模式结构： 示例程序结构： 享元类： 123456789101112131415161718192021222324252627public class BigChar { /* 字符名称 */ private char charName; /* 字体字符串 */ private String fontData; public BigChar(char charName) { this.charName = charName; loadCharData(); } private void loadCharData() { String fileDir = &quot;src/com/pattern/flyweight/numbers/&quot;; String fileName = fileDir + &quot;big&quot; + charName + &quot;.txt&quot;; try (BufferedReader reader = new BufferedReader(new FileReader(fileName))) { String line; StringBuffer buf = new StringBuffer(); while ((line = reader.readLine()) != null) { buf.append(line).append(&quot;\\n&quot;); } fontData = buf.toString(); } catch (IOException e) { e.printStackTrace(); } }} 享元工厂： 1234567891011121314151617181920212223242526public class BigCharFactory { private static BigCharFactory instance = new BigCharFactory(); /* 享元对象池 */ private Map&lt;String, BigChar&gt; pool = new HashMap&lt;&gt;(); private BigCharFactory(){} public static BigCharFactory getInstance() { return instance; } /** * 获取享元对象接口 */ public BigChar getChar(char charName) { BigChar bigChar = pool.get(&quot;&quot; + charName); if (bigChar == null) { bigChar = new BigChar(charName); pool.put(&quot;&quot; + charName, bigChar); } return bigChar; }} 享元使用： 123456789101112131415161718public class BigString { private BigChar[] chars; public BigString(String string) { loadString(string); } private void loadString(String string) { chars = new BigChar[string.length()]; BigCharFactory factory = BigCharFactory.getInstance(); for (int i = 0; i &lt; string.length(); i++) { char charName = string.charAt(i); chars[i] = factory.getChar(charName); } }} 四、享元模式有什么优缺点？优点： 共享相同对象，资源消耗低、利用率高 对象数量少，方便管理享元对象 缺点： 需要将共享对象分离出来，可能会使得程序变得复杂 五、享元和单例、缓存、对象池的区别5.1 享元 vs. 单例 单例本质是为了控制实例的数量，重点在于数量。 享元关注的点是实例共享，重点在于共享，数量不是主要矛盾。 5.2 享元 vs. 缓存 缓存的作用是为了提高查询速度，目的在于提高效率。 享元的目标是为了降低资源消耗，主要关注点是资源的利用率。 5.3 享元 vs. 对象池 对象池主要用于管理对象，重点在于对一批对象进行管理分配回收。 享元主要还是为了对象的复用，在管理方面不是特别关注。 六、享元模式的实际应用Integer： Java 中 Integer 默认缓存 -128 ~ 127 之间的数字对象 Integer 的缓存对象是一开始就创建好的 String： Java 中 String 对象会缓存到字符串常量池中，其他地方可以直接引用 String 的常量池对象是动态创建的","link":"/design_pattern/flyweight/"},{"title":"门面模式","text":"门面模式一、什么门面模式？门面模式（Facade Design Pattern）：为子系统提供一组统一的接口，定义一组高层接口让系统更加易用。 二、接口设计存在什么问题？ 接口粒度过小时，接口的易用性就会变低，需要调用多个接口才能完成一件事 接口粒度过大时，可复用性就会变低，需要针对不同业务需求实现不同的接口，导致接口无限膨胀 当一个系统的功能越来越强，子系统会越来越多，对子系统的访问也变得越来越复杂 二、门面模式有什么用处？2.1 设计原理 把粒度小的接口封装统一的门面接口，提高接口的易用性 可以针对不同的业务需求，组装复用接口，形成不同的门面接口 通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问 对外有统一的接口，外部程序无需知道内部子系统的实现，提高了易用性和可维护性 2.2 实际应用场景 在日常编码工作中，我们都在有意无意的大量使用外观模式。比如，高层模块要调度多个模块的类（2个以上的类对象），我们就会创建一个新的类封装它们，并提供精简的接口给高层模块用 各种第三方SDK、开源类库，很大概率都会使用外观模式 移动端通过门面模式可以把很多个请求合并成一个，减少发送的请求数量，提高移动端的加载速度 三、门面模式怎么用？门面模式不是增加功能接口，实际上只是通过对已有接口进行组合封装，形成一个对外的统一接口。 由门面接口把原始接口组装起来，控制接口的调用顺序，这样外部调用时就不需要自己去实现流程控制了。 3.1 模式结构 3.2 示例程序 子系统1（Database）： 123456789101112131415161718public class Database { private Database() { } public static Properties getProperties(String dbname) { String filename = &quot;src/com/pattern/facade/&quot; + dbname + &quot;.txt&quot;; Properties prop = new Properties(); try { prop.load(new FileInputStream(filename)); } catch (IOException e) { System.out.println(&quot;Warning: &quot; + filename + &quot; is not found&quot;); e.printStackTrace(); } return prop; }} 子系统2（HtmlWriter）： 123456789101112131415161718192021222324252627282930313233343536public class HtmlWriter { private Writer writer; public HtmlWriter(Writer writer) { this.writer = writer; } public void title(String title) throws IOException { writer.write(&quot;&lt;html&gt;&quot;); writer.write(&quot;&lt;head&gt;&quot;); writer.write(&quot;&lt;title&quot; + title + &quot;&lt;/title&gt;&quot;); writer.write(&quot;&lt;/head&gt;&quot;); writer.write(&quot;&lt;body&gt;\\n&quot;); writer.write(&quot;&lt;h1&gt;&quot; + title + &quot;&lt;/h1&gt;\\n&quot;); } public void paragraph(String msg) throws IOException { writer.write(&quot;&lt;p&gt;&quot; + msg + &quot;&lt;/p&gt;\\n&quot;); } public void link(String href, String caption) throws IOException { paragraph(&quot;&lt;a href=\\&quot;&quot; + href + &quot;\\&quot;&gt;&quot; + caption + &quot;&lt;/a&gt;&quot;); } public void mailto(String mailAddr, String username) throws IOException { link(&quot;mailto: &quot; + mailAddr, username); } public void close() throws IOException { writer.write(&quot;&lt;/body&gt;&quot;); writer.write(&quot;&lt;/html&gt;\\n&quot;); writer.close(); }} 门面接口（PageMaker）： 123456789101112131415161718192021public class PageMaker { private PageMaker(){} public static void makeWelcomePage(String mailAddr, String filename) { try { Properties mailProp = Database.getProperties(&quot;maildata&quot;); String username = mailProp.getProperty(mailAddr); HtmlWriter writer = new HtmlWriter(new FileWriter(filename)); writer.title(&quot;Welcome to &quot; + username + &quot;'s page!&quot;); writer.paragraph(username + &quot; 欢迎来到 &quot; + username + &quot; 的主页。&quot;); writer.paragraph(&quot;等待你的邮件哦！&quot;); writer.mailto(mailAddr, username); writer.close(); System.out.println(filename + &quot; is created for &quot; + mailAddr + &quot; (&quot; + username + &quot;)&quot;); } catch (IOException e) { e.printStackTrace(); } }} 四、门面模式的优缺点是什么？优点： 把粒度小的接口封装统一的门面接口，提高接口的易用性 可以针对不同的业务需求，组装复用接口，形成不同的门面接口 缺点： 违反“开闭原则”，增加新的子系统，可能需要修改门面类的代码 代码的冗余，门面模式实际只是对接口进行组装，并不包含业务功能代码 不可复用性，门面接口一般是针对特定的业务需求组合封装而成，所以复用性不好","link":"/design_pattern/facade/"},{"title":"装饰器模式","text":"装饰器模式一、什么是装饰器模式？装饰器（Decorator）模式：指在不改变现有对象结构的情况下，动态地给该对象增加一些职责（即增加其额外功能）的模式。 在现实生活中，常常需要对现有产品增加新的功能或美化其外观，如房子装修、相片加相框等，都是装饰器模式。 二、为什么要用装饰器模式？2.1 装饰和代理装饰器模式和代理模式，都可以用于增强原始类现有功能，但它们的使用还是有一点区别的： 代理模式中，增加的功能是与原始类核心功能无关的 装饰器模式中，增加的功能是与原始类核心功能相关的 装饰器模式中，装饰器和原始类都是继承于同一个父类，因而可以实现嵌套装饰 2.2 装饰和继承继承也可以实现功能增强，装饰和继承的区别在于： 继承可能会导致类组合爆炸，类结构异常复杂，代码不易维护和扩展 装饰器模式使用组合替代继承，而且继承于同一父类，代码易于扩展 三、怎么用装饰器模式？3.1 模式的结构是怎么样的？装饰器模式的主要角色包括： 抽象构件角色（Component）：定义的抽象接口，用于规范被附加功能的对象 具体构件角色（ConcreteComponet）：实现抽象构件，实现它自己的核心功能 抽象装饰角色（Decorator）：定义的抽象装饰接口，继承于抽象构件，并包含具体构件的实例 具体装饰角色（ConcreteDecorator）：实现抽象装饰接口，为具体构件对象添加额外的功能 3.2 装饰器模式示例示例程序的类结构图： 抽象构件： 123456789101112131415public abstract class Display { public abstract int getColumns(); public abstract int getRows(); public abstract String getRowText(int row); public final void show() { for (int i = 0; i &lt; getRows(); i++) { System.out.println(getRowText(i)); } }} 具体构件： 123456789101112131415161718192021222324252627public class StringDisplay extends Display { private String string; public StringDisplay(String string) { this.string = string; } @Override public int getColumns() { return string.getBytes().length; } @Override public int getRows() { return 1; } @Override public String getRowText(int row) { if (row == 0) { return string; } else { return null; } }} 抽象装饰： 1234567891011121314151617181920212223public abstract class Border extends Display { protected Display display; protected Border(Display display) { this.display = display; } @Override public int getColumns() { return display.getColumns(); } @Override public int getRows() { return display.getRows(); } @Override public String getRowText(int row) { return display.getRowText(row); }} 具体装饰： 123456789101112131415161718192021public class SideBorder extends Border { private char borderChar; protected SideBorder(Display display, char ch) { super(display); this.borderChar = ch; } @Override public int getColumns() { // 左右两边加上装饰符后，长度需要加2 return 1 + display.getColumns() + 1; } @Override public String getRowText(int row) { // 给左右两边加上装饰符 return borderChar + display.getRowText(row) + borderChar; }} 12345678910111213141516171819202122232425262728293031323334353637public class FullBorder extends Border { protected FullBorder(Display display) { super(display); } @Override public int getColumns() { return 1 + display.getColumns() + 1; } @Override public int getRows() { return 1 + display.getRows() + 1; } @Override public String getRowText(int row) { if (row == 0) { // 上边框 return &quot;+&quot; + makeLine('-', display.getColumns()) + &quot;+&quot;; } else if (row == display.getRows() + 1) { // 下边框 return &quot;+&quot; + makeLine('-', display.getColumns()) + &quot;+&quot;; } else { return &quot;|&quot; + display.getRowText(row - 1) + &quot;|&quot;; } } private String makeLine(char ch, int count) { StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; count; i++) { sb.append(ch); } return sb.toString(); }} 四、装饰器模式有什么优缺点？优点： 使用组合代替继承，可以灵活地扩展功能，即插即用 不同装饰者的组合，可以实现不同的功能效果 缺点： 使用装饰器模式会增加很多子类，使用起来可能会比较麻烦 如果过度使用装饰器，可能会导致类嵌套过深，增加了程序的复杂性","link":"/design_pattern/decorator/"},{"title":"组合模式","text":"组合模式一、组合模式是什么？Compose objects into tree structure to represent part-whole hierarchies.Composite lets client treat individual objects and compositions of objects uniformly. 组合模式（Composite Design Pattern）：将一组对象组织成树形结构，以表示一种“部分 - 整体”的层次结构。 也可以这么说，组合模式就是把容器与内容看成同一种对象，并将它们组合成树状结构，创造一种递归的形式。 比如文件和目录，虽然直观上是不同的对象，但是如果使用组合模式来实现它们的话，可以将文件和目录都看成是继承于同一种条目类，因此算是属于同一类对象。 其次，目录中又可以继续放文件和目录，形成了递归，最终是一种树状的层次结构。 二、为什么要用组合模式？组合模式使用的场景有限，对数据格式比较严格： 数据必须是一种树形结构，类似文件和目录 尽管场景少，但是数据满足递归结构时，组合模式还是能发挥比较大的作用的： 组合模式可以让客户端以统一的方式访问数据节点，因为它们是同一种对象 三、组合模式的结构是怎么样的？组合模式包含的角色有以下几个： 抽象组件（Component）：为树叶组件和复合组件提供一致性的抽象接口，并实现它们的默认行为 树叶组件（Leaf）：表示内容，不能再放其他抽象组件对象，在结构中属于最小对象 复合组件（Composite）：表示容器，可以放入其他抽象组件对象，包括树叶组件和复合组件 示例程序结构： 抽象组件： 12345678910111213141516171819202122public abstract class Entry { public abstract String getName(); public abstract int getSize(); public Entry add(Entry entry) throws FileTreatmentException { throw new FileTreatmentException(); } public void printList() { printList(&quot;&quot;); } protected abstract void printList(String prefix); @Override public String toString() { return getName() + &quot; (&quot; + getSize() + &quot;)&quot;; }} 树叶组件： 12345678910111213141516171819202122232425public class File extends Entry { private String name; private int size; public File(String name, int size) { this.name = name; this.size = size; } @Override public String getName() { return name; } @Override public int getSize() { return size; } @Override protected void printList(String prefix) { System.out.println(prefix + &quot;/&quot; + this); }} 复合组件： 12345678910111213141516171819202122232425262728293031323334353637public class Directory extends Entry { private String name; private List&lt;Entry&gt; directory = new ArrayList&lt;&gt;(); public Directory(String name) { this.name = name; } @Override public String getName() { return name; } @Override public int getSize() { int size = 0; for (Entry entry : directory) { size += entry.getSize(); } return size; } @Override public Entry add(Entry entry) throws FileTreatmentException { directory.add(entry); return this; } @Override protected void printList(String prefix) { System.out.println(prefix + &quot;/&quot; + this); for (Entry entry : directory) { entry.printList(prefix + &quot;/&quot; + name); } }} 客户端调用： 123456789101112131415161718192021222324252627282930313233public class MainTest { public static void main(String[] args) { System.out.println(&quot;Making root entries...&quot;); Directory rootDir = new Directory(&quot;root&quot;); Directory binDir = new Directory(&quot;bin&quot;); Directory tmpDir = new Directory(&quot;tmp&quot;); Directory usrDir = new Directory(&quot;usr&quot;); rootDir.add(binDir); rootDir.add(tmpDir); rootDir.add(usrDir); binDir.add(new File(&quot;vi&quot;, 10000)); binDir.add(new File(&quot;latex&quot;, 20000)); rootDir.printList(); System.out.println(&quot;&quot;); System.out.println(&quot;Making user entries...&quot;); Directory yuki = new Directory(&quot;yuki&quot;); Directory hanako = new Directory(&quot;hanako&quot;); Directory tomura = new Directory(&quot;tomura&quot;); usrDir.add(yuki); usrDir.add(hanako); usrDir.add(tomura); yuki.add(new File(&quot;diary.html&quot;, 100)); yuki.add(new File(&quot;Composite.java&quot;, 300)); hanako.add(new File(&quot;memo.text&quot;, 400)); tomura.add(new File(&quot;game.doc&quot;, 500)); tomura.add(new File(&quot;junk.maik&quot;, 600)); rootDir.printList(); } } 四、组合模式有什么优缺点？优点： 可以统一地对待内容组件和复合组件，使用简单 添加新的组件，不会影响客户端调用，满足“开闭原则” 缺点： 不容易识别组件对象的类型","link":"/design_pattern/composite/"},{"title":"适配器模式","text":"适配器模式一、什么是适配器模式？适配器模式（Adapter Design Pattern）：将一个类的接口转换成希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 适配者模式的几个特点： 已存在旧接口实现 希望使用新接口，但是又不想重新实现，想要复用已有的旧接口实现类 适配器模式，就是将旧接口实现适配为新接口。 二、适配器模式用来做什么？2.1 模式原理 将现有的业务功能旧接口重新封装，改用新接口调用 统一多个实现类的接口设计，为外部提供统一的接口调用 替换外部依赖的接口，改成自己系统的接口 本质上，就是在不改变旧接口实现的情况下，将旧接口转为为新接口 比如说，系统一开始没有设计接口规范，先实现的业务功能，后来才想起要定接口规范，但同时希望能够保留原有的实现代码 2.2 实际场景Java 中有很多日志框架，在项目开发中，我们常常用它们来打印日志信息。 其中，比较常用的有 log4j、logback，以及 JDK 提供的 JUL(java.util.logging) 和 Apache 的 JCL(Jakarta Commons Logging) 等。 大部分日志框架都提供了相似的功能，比如按照不同级别（debug、info、warn、erro……）打印日志等，但它们却并没有实现统一的接口。 这时候，Slf4j 就出现了，提供了统一的接口定义，但它是在 JUL、JCL、log4j 等日志框架出现后才设计的。 然而，日志框架也不可能牺牲掉版本兼容性，将原本的接口改造成符合 Slf4j 接口规范。 所以 Slf4j 不仅仅提供了统一的接口定义，还提供了针对不同日志框架的适配器。 最后，在开发时，统一使用 Slf4j 提供的接口来打印日志，具体使用哪种日志框架实现（log4j、logback……），可以动态地指定。 三、适配器模式的结构是怎么样的？适配器模式可以分为2种： 类适配器：适配以类继承的形式实现 对象适配器：适配以类组合的形式实现 这2种实现方式的区别： 类适配器采用继承来实现，同时拥有旧接口和新接口的功能 对象适配器采用组合实现，只实现了新接口 类适配器的代码耦合度较高 12345678910111213141516// 新接口public interface ITarget {}// 旧接口实现类public class Adaptee {}// 类适配器: 基于继承public class Adapter extends Adaptee implements ITarget {}// 对象适配器：基于组合public class Adapter implements ITarget { private Adaptee adaptee;} 四、怎么实现一个适配器？4.1 类适配器 可采用多重继承方式实现 C++ 可定义一个适配器类，来同时继承当前系统的业务接口和现有组件库中已经存在的组件接口 Java 不支持多继承，但可以定义一个适配器类来实现当前系统的业务接口，同时又继承现有组件库中已经存在的组件 123// 类适配器: 基于继承public class Adapter extends Adaptee implements ITarget {} 4.2 对象适配器 采用组合的方式 适配类实现新接口，同时将旧接口实现类注入适配类中 1234// 对象适配器：基于组合public class Adapter implements ITarget { private Adaptee adaptee;} 五、适配器有什么优缺点？优点： 复用了现有的类，不需要修改原有代码 通过适配类来解耦，新接口和原有接口耦合性较低 缺点： 类结构变得复杂 代码可读性降低 六、模式扩展适配器模式，可扩展为双向适配器模式。 既可以把适配者（Adaptee）转换为新接口（Target），也可以把新接口（Target）转换为适配者接口（Adaptee）。","link":"/design_pattern/adapter/"},{"title":"原型模式","text":"原型模式一、什么是原型模式？原型设计模式（Prototype Design Pattern），是指根据实例原型、实例模型来生成新的实例对象。 也就是用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。 重点在于新实例对象，不是创建出来的，而是基于已有的原型对象复制的。 二、为什么要用原型模式？ 对象之间相同或相似，即只是个别的几个属性不同的时候 有些对象的创建过程较为复杂，而且有时候需要频繁创建，创建新对象还不如复制已有对象来得快 对象中的数据需要经过复杂的计算才能得到（比如排序、计算哈希值） 对象中的数据需要从 RPC、网络、数据库、文件系统等非常慢速的 IO 中读取 想要复制当前的对象，但是对象内部的数据异常复杂，通过构造函数创建难以实现 比如一个图形，之前做了很多处理，比一开始创建的时候变动了很多，此时想要复制它，通过构造函数新建是难以实现的 想要让生成的实例的框架不依赖于具体的类 框架中不能指定类名来生成实例，所以会先“注册”一个“原型实例”，然后通过复制该“原型”来生成新实例 三、模型的结构是怎么样的？原型模式主要包含以下几种角色： 抽象原型类(Prototype)：负责定义用于复制现有实例来生成新实例的方法 具体原型类(ConcretePrototype)：负责实现复制现有实例并生成新实例的方法 访问类(Client)：负责使用复制实例的方法生成新的实例 四、怎么实现原型模式？原型模式有两种实现方法：深拷贝和浅拷贝。 浅拷贝只会复制对象中基本数据类型数据和引用对象的内存地址，不会递归地复制引用对象，以及引用对象的引用对象…… 深拷贝得到的是一份完完全全独立的对象。所以，深拷贝比起浅拷贝来说，更加耗时，更加耗内存空间 深拷贝和浅拷贝的一些注意事项： 如果要拷贝的对象是不可变对象，浅拷贝共享不可变对象是没问题的 但对于可变对象来说，浅拷贝得到的对象和原始对象会共享部分数据，就有可能出现数据被修改的风险，也就变得复杂多了 没有充分的理由，不要为了一点点的性能提升而使用浅拷贝 示例程序的类结构图： 其中 Product 代表的是原型结构中的 Propotype，UnderlinePen 和 MessageBox 代表的是原型结构中的 ConcretePrototype，而 ProductManager 代表的是原型结构中的 Client。 4.1 Product 接口1234567891011121314public interface Product extends Cloneable { /** * 产品使用的方法 * @param s */ void use(String s); /** * 产品克隆的方法 * @return 克隆出来的新对象 */ Product createClone();} 4.2 UnderlinePen 和 MessageBox 具现类UnderlinePen 是为输出字符串在左右两端添加双引号，并在下边添加下划符号。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 为输出字符串添加下划线，例如： * * &quot;Strong message product&quot; * ~~~~~~~~~~~~~~~~~~~~~~~~ * */public class UnderlinePen implements Product { // 下划符号 private char ch; public UnderlinePen(char ch) { this.ch = ch; } /** * 输出字符串左右添加双引号，下边添加下划符号 * @param s 输出字符串 */ @Override public void use(String s) { int len = s.getBytes().length; System.out.println(&quot;\\&quot;&quot; + s + &quot;\\&quot;&quot;); for (int i = 0; i &lt; len + 2; i++) { System.out.print(ch); } System.out.println(); } @Override public Product createClone() { Product p = null; try { p = (Product) clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return p; }} MessageBox 是为输出字符串添加一个输出框。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*** * 为输出字符串添加输出框，例如： * * *********************** * * Warning box product * * *********************** * */public class MessageBox implements Product { // 输出框符号 private char ch; public MessageBox(char ch) { this.ch = ch; } /** * 为输出字符串添加一个输出框 * @param s 输出字符串 */ @Override public void use(String s) { int len = s.getBytes().length; for (int i = 0; i &lt; len + 4; i++) { System.out.print(ch); } System.out.println(); System.out.println(ch + &quot; &quot; + s + &quot; &quot; + ch); for (int i = 0; i &lt; len + 4; i++) { System.out.print(ch); } System.out.println(); } @Override public Product createClone() { Product p = null; try { p = (Product) clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return p; }} 4.3 ProductManager 访问类12345678910111213141516171819202122232425public class ProductManager { // 保存产品原型实例 private HashMap&lt;String, Product&gt; products = new HashMap&lt;&gt;(); /** * 注册产品原型实例 * @param name 原型名称 * @param product 原型实例 */ public synchronized void register(String name, Product product) { products.put(name, product); } /** * 通过原型名称获取产品新实例对象 * @param name 产品原型名称 * @return 产品新实例对象 */ public Product getProduct(String name) { Product product = products.get(name); return product.createClone(); }} 五、原型模式有什么优缺点？原型模式的优点： 当创建新的对象实例较为复杂时，使用原型模式可以简化对象的创建过程，通过一个已有实例可以提高新实例的创建效率 原型模式提供了简化的创建结构，可以使用深克隆方式保存对象的状态，以便在需要的时候使用（例如恢复到历史某一状态） 原型模式的缺点： 需要为每一个类配备一个克隆方法，这对全新的类来说不是很难，但对已有的类进行改造时，必须修改其源代码，违背了“开闭原则” 当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦 深克隆、浅克隆需要运用得当 扩展 Java 中提供了用于复制实例的方法 clone() clone() 方法定义在 java.lang.Object 中，也就是说，所有 Java 类都有 clone() 方法 clone() 方法内部所执行的是基于内存二进制流的复制，复制了一份和原型对象一样的内存数据 clone() 方法复制的只是对象的内存数据，所以 clone() 方法是浅复制 clone() 方法只会进行复制，不会调用实例的构造函数 重写 clone() 方法时，记得调用父类的 super.clone() 方法 类使用 clone() 方法，这个类必须实现 java.lang.Clonable 接口（自己实现或者父类实现都行） Clonable 是一个标记接口，用于标记该类可以执行 clone() 方法，自身没有声明任何方法","link":"/design_pattern/prototype/"},{"title":"建造者模式","text":"建造者模式一、什么是建造者模式？建造者设计模式（Builder Design Pattern），是指将一个复杂对象的构造与它的表示分离，使同样的构建过程可以创建不同的表示。 使用建造者模式的目的，就是为了解决复杂对象的构建 它将一个复杂的对象分解为多个简单的对象，然后一步一步构建起来。 二、为什么要用建造者模式？ 初始化对象时，过程比较复杂，参数很多，而且还需要校验参数的有效性 初始化对象时，参数之间有一定的依赖关系或约束条件，必须对参数的关系进行校验 创建不可变对象，就不能用构造函数 + set 方法来对属性设值 为了保证对象初始化赋值过程中的有效性 三、模型的结构是怎么样的？建造者模型的主要角色如下： 抽象建造者（Builder）：负责定义用于生成实例的接口 具体建造者（Concrete Builder）：负责实现 Builder 角色的实现类 指挥者（Director）：负责使用 Builder 角色的接口来生成实例 四、如何实现建造者模式？示例程序的类结构图： 其中 TextBuilder 和 HtmlBuilder 代表的是建造者结构中的 ConcreteBuilder。 建造者： 1234567891011121314151617181920212223public interface Builder { /** * 编写标题 * @param title 标题 */ void makeTitle(String title); /** * 编写字符串 * @param string 字符串 */ void makeString(String string); /** * 编写条目 * @param items 条目 */ void makeItems(String[] items); void close();} 指挥者： 12345678910111213141516171819public class Director { private Builder builder; public Director(Builder builder) { this.builder = builder; } public void construct() { builder.makeTitle(&quot;Greeting&quot;); builder.makeString(&quot;从早上至下午&quot;); builder.makeItems(new String[] { &quot;早上好&quot;, &quot;下午好&quot; }); builder.close(); }} 文本建造者： 12345678910111213141516171819202122232425262728293031323334public class TextBuilder implements Builder { private StringBuffer buffer = new StringBuffer(); @Override public void makeTitle(String title) { buffer.append(&quot;=====================================\\n&quot;); buffer.append(&quot;[&quot; + title + &quot;]\\n&quot;); buffer.append(&quot;\\n&quot;); } @Override public void makeString(String string) { buffer.append(&quot;#&quot; + string); buffer.append(&quot;\\n&quot;); } @Override public void makeItems(String[] items) { for (int i = 0; i &lt; items.length; i++) { buffer.append(&quot; .&quot; + items[i] + &quot;\\n&quot;); } buffer.append(&quot;\\n&quot;); } @Override public void close() { buffer.append(&quot;=====================================\\n&quot;); } public String getResult() { return buffer.toString(); }} HTML建造者： 1234567891011121314151617181920212223242526272829303132333435363738394041public class HtmlBuilder implements Builder { private String filename; private PrintWriter writer; @Override public void makeTitle(String title) { filename = title + &quot;.html&quot;; try { writer = new PrintWriter(new FileWriter(filename)); } catch (IOException e) { e.printStackTrace(); } writer.println(&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;&quot; + title + &quot;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&quot;); writer.println(&quot;&lt;h1&gt;&quot; + title + &quot;&lt;/h1&gt;&quot;); } @Override public void makeString(String string) { writer.println(&quot;&lt;p&gt;&quot; + string + &quot;&lt;/p&gt;&quot;); } @Override public void makeItems(String[] items) { writer.println(&quot;&lt;ul&gt;&quot;); for (int i = 0; i &lt; items.length; i++) { writer.println(&quot;&lt;li&gt;&quot; + items[i] + &quot;&lt;/li&gt;&quot;); } writer.println(&quot;&lt;/ul&gt;&quot;); } @Override public void close() { writer.println(&quot;&lt;/body&gt;&lt;/html&gt;&quot;); writer.close(); } public String getResult() { return filename; }} 五、建造者模式有什么优缺点？优点： 封装性好，构建与表示分离，构建由建造者完成 扩展性好，各个具体的建造者相互独立，有利于系统解耦 建造者可对内部的构建过程进行细化，而不影响外部模块 缺点： 建造者必须和被构建目标相同，限制了使用范围，只能用于指定的类型 建造者必须和被构建目标保持一致，目标发生变更时，需要同时修改建造者","link":"/design_pattern/builder/"},{"title":"抽象工厂模式","text":"抽象工厂模式一、什么是抽象工厂模式抽象工厂（AbstractFactory）是一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。 抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产“一个等级”的产品，而抽象工厂模式可生产“多个等级”的产品。 二、为什么要用抽象工厂模式？使用抽象工厂模式一般要满足以下条件： 系统中有多个产品族，每个具体工厂创建同一族但属于不同等级结构的产品 系统一次只可能消费其中某一族产品，即同族的产品一起使用 三、抽象工厂结构是怎么样的？3.1 产品等级结构和产品族（1）产品等级结构 即产品的继承结构。 如一个抽象类是电视机，其子类有海尔电视机、海信电视机、TCL电视机，则抽象电视机与具体品牌的电视机之间构成了一个产品等级结构，抽象电视机是父类，而具体品牌的电视机是其子类。 （2）产品族 在抽象工厂模式中，产品族是指由同一个工厂生产的，位于不同产品等级结构中的一组产品。 比如海尔电器工厂生产的海尔电视机、海尔电冰箱，海尔电视机位于电视机产品等级结构中，海尔电冰箱位于电冰箱产品等级结构中，海尔电视机、海尔电冰箱构成了一个产品族。 3.2 模型结构抽象工厂方法模式的主要角色如下： 抽象工厂（AbstractFactory）：提供了创建产品的接口，它包含多个创建产品的方法，可以创建多个不同等级的产品。 具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。 示例程序的类结构图： 其中 AbstractCompany，AbstractMobilePhone 是抽象工厂方法模式中的 Product，HuaweiComputer, HuaweiMobilePhone, XiaomiComputer, XiaomiMobilePhone 是抽象工厂方法模式中的 ConcreteProduct，AbsractCompany 是抽象工厂方法模式中的 AbstractFactoryHuaweiCompany 和 XiaomiCompany 是抽象工厂方法模式中的 ConcreteFactory。 3.1 AbsractCompany 抽象工厂类1234567891011121314151617public abstract class AbstractCompany { /** * 生产电脑产品 * * @return 电脑产品 */ public abstract AbstractComputer createComputer(); /** * 生产手机产品 * * @return 手机产品 */ public abstract AbstractMobilePhone createMobilePhone();} 3.2 HuaweiCompany 和 XiaomiCompany 具体工厂类12345678910111213141516171819202122232425public class HuaweiCompany extends AbstractCompany { @Override public HuaweiComputer createComputer() { return new HuaweiComputer(); } @Override public HuaweiMobilePhone createMobilePhone() { return new HuaweiMobilePhone(); }}public class XiaomiCompany extends AbstractCompany { @Override public XiaomiComputer createComputer() { return new XiaomiComputer(); } @Override public XiaomiMobilePhone createMobilePhone() { return new XiaomiMobilePhone(); }} 3.3 AbstractCompany 和 AbstractMobilePhone 抽象产品类123456789101112131415161718192021222324252627282930313233public abstract class AbstractComputer { /** * 价格 */ protected Double price; public Double getPrice() { return price; } public void setPrice(Double price) { this.price = price; }}public class AbstractMobilePhone { /** * 价格 */ protected Double price; public Double getPrice() { return price; } public void setPrice(Double price) { this.price = price; }} 3.4 具体产品类1234567891011public class HuaweiComputer extends AbstractComputer {}public class XiaomiComputer extends AbstractComputer {}public class HuaweiMobilePhone extends AbstractMobilePhone {}public class XiaomiMobilePhone extends AbstractMobilePhone {} 四、抽象工厂模式有什么优缺点？抽象工厂模式的优点： 可以在类的内部对产品族中相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理 当增加一个新的产品族时不需要修改原代码，满足开闭原则 抽象工厂模式的缺点： 当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改","link":"/design_pattern/abstract_factory/"},{"title":"工厂方法模式","text":"工厂方法模式一、什么是工厂方法模式？又称工厂模式、多态工厂模式和虚拟构造器模式，通过定义工厂父类负责定义创建对象的公共接口，而子类则负责生成具体的对象。 即将类的实例化（具体产品的创建）延迟到工厂类的子类（具体工厂）中完成，由子类来决定应该实例化（创建）哪一个类。 被创建的对象称为“产品”，把创建产品的对象称为“工厂”。 二、为什么要用工厂方法模式？工厂方法模式通常用于以下场景： 对于某个产品，调用者清楚地知道应该使用哪个具体工厂服务，实例化该具体工厂，生产出具体的产品 只是需要一种产品，而不想知道也不需要知道究竟是哪个工厂为生产的，即最终选用哪个具体工厂的决定权在生产者一方，它们根据当前系统的情况来实例化一个具体的工厂返回给使用者，而这个决策过程这对于使用者来说是透明的 三、工厂方法结构是怎么样的？工厂方法模式的主要角色如下： 抽象工厂（AbstractFactory）：提供了创建产品的接口，通过它访问具体工厂的工厂方法来创建产品。 具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。 示例程序的类结构图： 其中 Shape 是工厂方法模式中的 Product，Circle 和 Square 是工厂方法模式中的 ConcreteProduct，ShapeFactory 是工厂方法模式中的 Factory，CircleFactory 和 SquareFactory 是工厂方法模式中的 ConcreteFactory。 3.1 Shape 抽象产品类123456public abstract class Shape { public abstract void draw();} 3.2 Circle 和 Square 具体产品类1234567891011121314151617181920class Circle extends Shape { public Circle(){} @Override public void draw() { System.out.println(&quot;Draw a circle shape!&quot;); }}class Square extends Shape { public Square(){} @Override public void draw() { System.out.println(&quot;Draw a square shape!&quot;); }} 3.3 ShapeFactory 抽象工厂方法接口123456789public interface ShapeFactory { /** * 产品工厂方法 * @return 产品 */ Shape createShape();} 3.4 CirCleFactory 和 SquareFactory 具体产品工厂类12345678910111213141516class CircleFactory implements ShapeFactory { @Override public Circle createShape() { return new Circle(); }}class SquareFactory implements ShapeFactory { @Override public Square createShape() { return new Square(); }} 四、工厂方法模式有什么优缺点？工厂方法模式的优点： 只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程 在系统增加新的产品时只需要添加具体产品类和对应的具体工厂类，无须对原工厂进行任何修改，满足开闭原则 工厂方法的缺点： 每增加一个产品就要增加一个具体产品类和一个对应的具体工厂类，这增加了系统的复杂度","link":"/design_pattern/factory_method/"},{"title":"单例模式","text":"单例模式一、什么是单例模式？单例设计模式（Singleton Design Pattern）：指一个类只有一个实例，且该类能自行创建这个实例的一种模式。 这个类就是一个单例类，这种设计模式就叫作单例设计模式，简称单例模式。 单例模式有 3 个特点： 单例类只有一个实例对象 该单例对象必须由单例类自行创建 单例类对外提供一个访问该单例的全局访问点 二、为什么要使用单例？从业务概念上，有些数据在系统中只应该保存一份，就比较适合设计为单例类。 表示全局唯一类，比如系统配置类 处理资源访问冲突，比如打印日志类 三、如何实现一个单例？单例需要考虑以下几点： 单例的构造函数必须是 private 访问权限的，避免外部创建对象 考虑线程并发创建单例对象的情况，多线程同时创建单例对象时，是否能够保证只有一个单例生成 考虑是否要延迟加载的情况，比如单例对象是否要等到第一次获取的时候才生成，还是一开始就存在 考虑获取单例对象的性能问题，比如对方法加锁会导致性能变差 单例创建的几种方式： 3.1 饿汉式 在类加载期间，就已经把单例对象初始化好了 不存在线程安全问题 缺点是不支持延迟加载，没有用到该单例就已经初始化好对象了 1234567891011121314151617181920/** * 饿汉单例模式 */public class HungrySingleton { // 类加载的时候初始化，因此不需要同步 private static final HungrySingleton instance = new HungrySingleton(); // 避免在外部被实例化 private HungrySingleton(){} /** * 直接获取单例 * @return 单例对象 */ public static HungrySingleton getInstace() { return instance; }} 3.2 懒汉式 用到时才初始化单例对象 获取单例对象的方法加有锁 synchronized，获取单例时需要加锁、解锁，性能低并且并发度也低 优点是支持延迟加载 12345678910111213141516171819202122232425/** * 懒汉单例模式 */public class LazySingleton { // 保证在所有线程中保持同步 private static volatile LazySingleton instance = null; // 避免在外部被实例化 private LazySingleton(){} /** * 同步获取单例 * @return */ public static synchronized LazySingleton getInstance() { // 需要在判断之前同步 if (instance == null) { instance = new LazySingleton(); } return instance; }} 3.3 双重检测 用到时才初始化单例对象 加锁 synchronized 创建单例，同时单例对象还需要加上关键字 volatile，避免指令重排和同步内存对象 优点是支持延迟加载，除了第一次需要加锁以外，其他情况下都不需要加锁，所以性能也比价高，并发度也高 缺点是，volatile 修饰的变量是到主存读取数据，不走缓存，这个稍微消耗点性能 1234567891011121314151617181920212223242526272829/** * 双重校验锁单例模式 */public class DoubleCheckLockSingleton { // 保证在所有线程中保持同步 private static volatile DoubleCheckLockSingleton instance = null; // 避免在外部被实例化 private DoubleCheckLockSingleton(){} /** * 检查两次，一次不加锁，一次加锁 * @return 单例对象 */ public static DoubleCheckLockSingleton getInstance(){ // 第一次检查，不加锁 if (instance == null) { synchronized (DoubleCheckLockSingleton.class) { // 第二次检查，加锁 if (instance == null) { instance = new DoubleCheckLockSingleton(); } } } return instance; }} 3.4 静态内部类 用到时才加载单例对象 是在静态内部类加载时初始化好单例对象的 不存在线程安全问题 优点是支持延迟加载，不需要加锁，性能高，并发度高。总体上比双重检测上要好 1234567891011121314151617181920212223242526/** * 静态内部类单例模式 */public class StaticInnerSingleton { // 避免在外部被实例化 private StaticInnerSingleton(){} /** * 类级的内部类，也就是静态的成员式内部类， * 该内部类的实例与外部类的实例没有绑定关系， * 而且只有被调用到才会装载，从而实现了延迟加载 */ private static class SingletonHolder { private static StaticInnerSingleton instance = new StaticInnerSingleton(); } /** * 直接获取单例 * @return 单例对象 */ public static StaticInnerSingleton getInstance() { return SingletonHolder.instance; }} 3.5 枚举类 类加载时就初始化好单例了 不支持延迟加载 优点是创建单例对象简单，只需定义枚举对象即可 123456/** * 枚举模式单例 */public enum EnumSingleton { INSTANCE;} 四、单例存在哪些问题？4.1 单例对 OOP 特性的支持不友好 单例对于抽象、继承、多态这几个特性的支持不太好 单例对象的使用，是直接调用的，没有用依赖注入、基于接口调用的形式，因此在抽象方面支持的不是很好 单例类，一般也不会继承，所以继承和多态，基本上是用不到的 4.2 单例会隐藏类之间的依赖关系 一般通过构造函数、参数传递等方式声明的类之间的依赖关系，就能明确知道类的依赖关系 单例的调用，不是通过依赖注入、参数传递来调用的 单例对象一般都是在代码中直接调用，想要知道类的依赖关系，还需要看代码实现，不够明显 4.3 单例对代码的扩展性不友好 单例类，只有一个单例对象，一般也不会继承 单例类，想要添加功能，只能修改单例类的代码，对于可扩展性来说不太友好 4.4 单例对代码的可测试性不友好 单例类这种硬编码式的使用方式（在代码里直接调用），无法实现 mock 替换，可测试性不强 单例对象相当于一个全局对象，在单元测试时，还需要注意各个测试用例之间有没有影响到单例对象的数据，必须测试时受到影响。 4.5 单例不支持有参数的构造函数 单例一般是无参的 想要支持参数，就需要考虑每次传不同参数，以及参数什么时候传进去等情况，比较麻烦 最好的办法是，单例初始化时，自己去读取配置文件来初始化，无需外部传参 五、单例有何替代解决方案？ 使用静态方法，缺点是静态方法不够灵活，也不支持延迟加载 可能要从根上，寻找其他方式来实现全局唯一类了。比如，通过工厂模式、IOC 容器（比如 Spring IOC 容器）来保证，由程序员自己来保证（自己在编写代码的时候自己保证不要创建两个类对象） 如果单例类并没有后续扩展的需求，并且不依赖外部系统，那设计成单例类就没有太大问题","link":"/design_pattern/singleton/"},{"title":"HashMap","text":"HashMap一、定义123public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable {} 二、实现2.1 数据结构HashMap 的底层数据存储结构是“数组 + 链表 + 红黑树”，红黑树结构是 JDK8 之后进行的优化。 1transient Node&lt;K,V&gt;[] table; 123456789101112131415161718192021static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + &quot;=&quot; + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); }} 它的实际结构大概是这样子的： 123456789 0 1 2 3 4 5 6 7 ____ ____ ____ ____ ____ ____ ____ ____| | | 42 | | | 21 | 14 | 15 | / \\ | | 26 58 22 7 / \\ / \\ | 10 34 50 66 6 / \\ 2 18 整个数组长度为8，而2那里放的就是红黑树，6、7那边则放的是链表。 实际上HashMap的数组长度这么短时，是不会有红黑树的，这里只是做个例子展示。 2.2 集合操作1）查找元素 HashMap底层就是“数组 + 链表 + 红黑树”，所以查找也不是很麻烦，只要遍历数组的每一个链表或树就可以。 1234567891011121314151617181920212223242526272829public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;}final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 找到指定hash对应的数组位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 判断第一个节点是否是查找的元素，是则直接返回 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { // 如果第一个节点不是，就遍历后面的元素查找 if (first instanceof TreeNode) // 如果是红黑树结构，按照树的查找来找 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 如果是链表，就逐个遍历查找 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;} 查找的话，可以分为几步： 计算hash对应到table的位置first = table[(n - 1) &amp; hash]，如果first不为null，则进行下一步； 如果first就是所要寻找的元素，那么就直接返回； 如果first是一个树节点（TreeNode），那么就按照树的查找来找目标元素； 如果first是普通节点，就按照链表的顺序，从头到尾寻找目标元素。 理论上来说，只要知道了数据的结构，遍历寻找还是比较简单的。 2）删除元素 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; // 1. 查找删除节点和它的父节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { // 表头或树根节点，即放在数组中的节点 node = p; } else if ((e = p.next) != null) { if (p instanceof TreeNode) { // 红黑树结构 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); } else { // 链表结构 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } // 2. 找到指定节点的话就删除 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) { // 红黑树结构 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); } else if (node == p) { // 链表表头，即放在数组中的节点 tab[index] = node.next; } else { // 链表中的非表头节点 p.next = node.next; } ++modCount; --size; afterNodeRemoval(node); return node; } } return null;} 删除的处理逻辑也不复杂，就是源码写的花里胡哨： 先找到要删除的节点，以及它的父节点，查找过程和上面的类似； 如果是红黑树结构，就按照树结构来删除； 如果是链表结构，直接按照链表结构删除节点，即父节点指向孙子节点。 3）添加元素 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) { // 1. 数组还未初始化，新建数组 n = (tab = resize()).length; } if ((p = tab[i = (n - 1) &amp; hash]) == null) { // 2. hash对应的数组位置还未初始化，直接插入新节点 tab[i] = newNode(hash, key, value, null); } else { // 3. hash对应的数组位置已经初始化，即已存在链表或红黑树 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { // 3.1 表头或树根节点，即放在数组中的节点（用于性能优化） e = p; } else if (p instanceof TreeNode) { // 3.2 红黑树结构 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); } else { // 3.3 链表结构 for (int binCount = 0; ; ++binCount) { // 插入节点不存在，找到链表尾部插入新节点 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) { // 如果达到阈值，需要把链表转化成红黑树 treeifyBin(tab, hash); } break; } // 插入节点已存在，则不插入新节点，而是更新值就行 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 如果插入节点已存在，就更新值，而不是插入新节点 if (e != null) { V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) { // 超过阈值，扩容 resize(); } afterNodeInsertion(evict); return null;} 添加的话，可以分为几步： table未初始化时，先初始化table hash所在的table位置未初始化。计算hash对应到table的位置p = table[(n - 1) &amp; hash]，如果p为null，则直接插入新节点到数组上 添加节点已存在时。如果p在table中已存在，不会新建节点，而是直接更新值 添加节点不存在时，分2种情况： 插入结构是红黑树，如果p是一个树节点（TreeNode），也就是红黑树结构，那么就按照树结构来添加节点 插入结构是链表，如果p是普通节点，也就是链表结构，把新节点添加到链表末尾。另外如果此时超过了阈值，链表会转化为红黑树 需要说明的一点就是，如果添加的元素在HashMap中已存在，那么就会更新对应节点的值，而不是插入新节点。 总的来说，集合的几个操作并不算复杂，复杂的是这些操作引起的扩容问题以及同hash值节点的数据结构变更（链表变树，树变链表）。 2.3 扩容机制1）初始容量 HashMap的初始容量是指数组的长度，它要求数组的长度始终是“2的倍数”，和ArrayDueue的要求一样。 所以当传入的参数不符合要求时，就会对它进行修正： 123456789static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 也就是说，如果传入的初始化容量不是“2的倍数”，会自动被修正为“2的倍数”。 比如，new HashMap(3)实际上底层的数组长度的初始长度会是 4，new HashMap(14)实际上底层的数组长度的初始长度会是 16。 至于为什么要取“2的倍数”，应该和ArrayDueue的一样，其实就是计算从hash值映射到数组时可以更高效： 计算机对于2倍数计算是很快的，直接通过移位操作（n &lt;&lt; 1）就可以实现； 计算hash对应的数组位置时，一般需要取模，但如果容量是2的倍数，那么取模就可以用掩码（table[i = (n - 1) &amp; hash])）来实现，会更高效一些。 2）负载因子 对于扩容，有一个问题，就是什么时候才需要重新调整数组容量？ 因为理论上来说，“数组 + 链表 + 红黑树”是可以放置无数个节点的，是不是一直都不需要调整呢？ 实际上不是，一旦数据多了起来，不论是链表，还是红黑树，它的节点都会变得越来越多，查找也会越来越慢，这个时候就需要减短它的节点数量，来提高性能。 在 HashMap 中，使用了负载因子来表示需要数组扩容的时机： 1final float loadFactor; 为了了解负载因子的作用，先解释一下负载的意义。举个例子说明，比如当前结构如下： 1234567 0 1 2 3 4 5 6 7 ____ ____ ____ ____ ____ ____ ____ ____| 0 | 1 | 42 | 11 | | 21 | 14 | 15 | | | 22 7 | 6 此时的元素数量是 10，数组长度是 8，那么实际负载就是 10 / 8 = 1.25。 负载因子在一定意义上，代表了当前数据结构的饱满程度 假设HashMap的负载因子是0.75，那么对于上面的例子而已，它的负载值 1.25 &gt; 0.75，实际上早就已经需要扩容了。 也就是说，在设定好指定的负载因子后，如果不断添加元素，实际负载也会不断增大，直到大于负载因子时，就需要进行扩容。 另外，HashMap为了减少负载的计算，一般都用阈值threshold来提前计算好会超过负载因子的最大元素数量。 1threshold = table.length * loadFactor; 当元素的数量size &gt; threshold时，就是实际负载超过负载因子的时候，这个时候就要进行扩容。 1234if (size &gt; threshold) { // 超过阈值，扩容 resize();} 实际上，阈值threshold并不是一个必要的变量，只是为了提高性能，减少负载的计算（除法计算），而添加的。 3）扩容容量 HashMap 为了保持“2的倍数”容量，每次扩容都是之前的2倍。也就是 “新容量 = 旧容量 * 2”。 直接看一下扩容代码： 123456789101112131415161718192021222324252627282930313233343536373839final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { // 数组不是第一次初始化时，对旧容量进行扩容 // 如果旧容量已经是最大容量了，就不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 正常情况下，新容量 = 旧容量 * 2 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; } else if (oldThr &gt; 0) { // 数组第一次初始化时，如果初始化容量大于0，就用初始化容量，它也是2的倍数 newCap = oldThr; } else { // 数组第一次初始化时，如果初始化容量为0，就用默认的初始化容量DEFAULT_INITIAL_CAPACITY newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 略掉后面的代码，在后面的4）中贴有} 扩容容量的计算还算简单，主要可以分为几步： 如果不是第一次初始化数组，就对旧容量进行扩容，在没有达到最大容量的情况下，新容量 = 旧容量 * 2 如果是第一次初始化数组，并且初始化容量大于0，那么就用初始化容量作为新容量 如果是第一次初始化数组，并且初始化容量为0，那么就用默认初始化容量作为新容量 当然，代码中间还加上了一些溢出边界的判断，但是总体逻辑差不多就是这样。 4）数据迁移 扩容数组之后，还需要把旧数组的数据迁移到新数组中。先看它的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final Node&lt;K,V&gt;[] resize() { // 略掉前面的代码，在前面的3）中贴有 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) { // 只有一个节点的时候 newTab[e.hash &amp; (newCap - 1)] = e; } else if (e instanceof TreeNode) { // 红黑树结构 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); } else { // 链表结构 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 把旧的链表拆分成2条新链表，同时保留旧链表的顺序 do { next = e.next; if ((e.hash &amp; oldCap) == 0) { // 分配到低位链表 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { // 分配到高位链表 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } 迁移过程可以分为几个步骤： 遍历旧数组的所有元素，重新计算里面每个元素在新数组中的位置，并把它移动到新数组中 因为是扩容了2倍，所以在旧数组中同位置的元素，映射到新数组上面时，会映射到2个位置 如果是红黑树结构，映射到新数组时，也会被拆分成2部分 如果是链表结构，映射到新数组时，也会被拆分成2条链表 举个例子说明一下，假设旧的数据结构如下： 1234567 0 1 2 3 4 5 6 7 ____ ____ ____ ____ ____ ____ ____ ____ | | 9 | | 11 | | 21 | 14 | 15 | | | | 1 22 7 | 6 当前的数组大小是 8，那么按照前面的规则，扩容后的新数组长度应该是 16，重新分配后的结构如下： 12345678910111213141516 0 1 2 3 4 5 6 7 ____ ____ ____ ____ ____ ____ ____ ____ | | 9 | | 11 | | 21 | 14 | 15 | | | | 1 22 7 | 6 | v 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____ ____| | 1 | | | | 21 | 22 | 7 | | 9 | | 11 | | | 14 | 15 | | 6 其实重新hash的计算也很简单，因为是2倍扩容，实际上重新分配时，一部分节点还是在原来的位置，而另一部分会被分出去。 12345if ((e.hash &amp; oldCap) == 0) { // 原来的索引位置 i} else { // 扩容后的索引位置 i + oldCap.length} 另外，HashMap 重新分配后的链表顺序还是和之前一样的。 这一点 HashMap 和 HashTable 不一样，HashTable 扩容后链表结构会反过来。 这是链表的重分配，实际上红黑树的重分配也是一样的，只不过调整树结构稍微麻烦一些，毕竟是有顺序的红黑树。 2.4 树转化除了加上“红黑树”结构以外，HashMap 和 HashTable 的结构都差不多，一般情况下都是“数组 + 链表”。 而 HashMap 为了提高效率，增加了“红黑树”的功能，当然也给代码加了很多复杂操作~~ 什么时候需要红黑树呢？这里先说明一下相关的几个属性： 1234567891011121314/** * 转化树的数组长度阈值 */static final int MIN_TREEIFY_CAPACITY = 64;/** * 链表转树的阈值 */static final int TREEIFY_THRESHOLD = 8;/** * 树转链表的阈值 */static final int UNTREEIFY_THRESHOLD = 6; 这里有3个变量和链表与树转化有关。 其中 MIN_TREEIFY_CAPACITY 和 TREEIFY_THRESHOLD 是链表转红黑树用到的，UNTREEIFY_THRESHOLD 是红黑树转回链表时用到的。 2.4.1 链表转到红黑树HashMap 不是随便就把链表转到红黑树的，而是需要满足某些条件： 数组长度达到阈值 MIN_TREEIFY_CAPACITY，即64 链表长度达到阈值 TREEIFY_THRESHOLD，即8 注意，要同时满足这2个条件，才会将链表转成红黑树。 MIN_TREEIFY_CAPACITY 是转化树需要的数组长度阈值，这是用来干嘛的？ 其实就是当 table 数组太小时，HashMap 宁愿进行扩容，也不愿意把链表转成树。 这个可能是考虑到性能问题，数组比较小时，维护红黑树反而比扩容的性能低。 下面是链表转成红黑树的逻辑判断： 1234567891011121314151617181920212223242526272829// 这个部分的源码上面添加元素写有备注了，就不重复写了final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // 忽略部分代码 if ((p = tab[i = (n - 1) &amp; hash]) == null) { // 忽略部分代码 } else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) { // 忽略部分代码 } else if (p instanceof TreeNode) { // 忽略部分代码 } else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) { // 如果达到阈值，需要把链表转化成红黑树 treeifyBin(tab, hash); } break; } // 忽略部分代码 } } // 忽略部分代码 } // 忽略部分代码} 12345678910111213141516171819202122232425final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; // 如果table很小时，先直接扩容table，而不要把链表转成树 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { TreeNode&lt;K,V&gt; hd = null, tl = null; // 先把链表节点转成树节点，但此时还是链表结构，只是节点类型变了 do { TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); // 这里才真正把链表转成红黑树 if ((tab[index] = hd) != null) hd.treeify(tab); }} 就比如说，当前数组长度是 16，然后其中某个位置的链表很长了，需要转成红黑树。 但此时数组长度还比较小 16 &lt; 64，所以它就不转化成红黑树了，而是直接把数组扩容为 32，然后把长链表拆分，并重新分配到不同位置。 2.4.2 红黑树转回链表当红黑树的节点数量变少了，把它转成链表来维护，反而性能会更好。不过，这个转换回来也要满足某些条件才行： 删除节点后，如果此时红黑树节点数量已经很少了，红黑树将会转回链表 进行扩容时，此时红黑树会拆分成2棵子树，如果拆分后的2棵子树的节点数量低于某个阈值，即 UNTREEIFY_THRESHOLD，红黑树将会转会链表 注意，满足其中1个条件，就会将红黑树转成链表。 首先是“红黑树的节点数量很少”的情况。 这种情况只会出现在删除节点的时候，具体看代码： 123456789101112final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) { // 忽略部分代码 // 移除节点... // 当红黑树的节点数量很少时，将会转回链表 if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) { tab[index] = first.untreeify(map); // too small return; } // 忽略后面很多代码...} 节点数量很少，究竟多少算少呢？按照代码的判断，它有几种情况： 红黑树节点完全没有了 红黑树右子树没有了 红黑树左子树没有了 红黑树的左子树的左子树没有了 这几种情况下，就认定为红黑树的节点数量很少了。 这是为什么？红黑树本质上是一棵平衡树，如果某棵子树没了，另一边的子树肯定没几个节点，那就意味着整棵树就没几个节点了（至于更深层的原因，可以去深入了解红黑树的结构）。 其次是“进行扩容时，如果红黑树节点数量低于 UNTREEIFY_THRESHOLD”。 这种情况只会出现在增加节点导致扩容的时候： 12345678910111213141516171819202122232425final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) { // 忽略部分代码 // 重新分配节点，分成2部分... if (loHead != null) { if (lc &lt;= UNTREEIFY_THRESHOLD) // 如果红黑树的节点数量低于UNTREEIFY_THRESHOLD，就会将其转回链表 tab[index] = loHead.untreeify(map); else { tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); } } if (hiHead != null) { if (hc &lt;= UNTREEIFY_THRESHOLD) // 如果红黑树的节点数量低于UNTREEIFY_THRESHOLD，就会将其转回链表 tab[index + bit] = hiHead.untreeify(map); else { tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); } }} 可以看到，扩容后，会将之前的节点拆分成2部分，如果某部分的节点数量不大于阈值 UNTREEIFY_THRESHOLD，就会将红黑树转回链表。 2.4.3 测试代码针对链表红黑树相互转换的几种情况，写个测试代码来测试一下。 测试的情况分为3种： 添加节点时，链表转红黑树 删除节点时，红黑树节点很少，转回链表 扩容时，红黑树节点少于阈值，转回链表 测试思路是这样的： 明确链表转红黑树时，table 必须要达到阈值 MIN_TREEIFY_CAPACITY，即64。所以一开始就设定容量为64，这样是为了避免中间出现扩容的情况，一旦出现扩容情况就复杂了。 为了测试链表和红黑树的转换时机，需要一直在同一个位置进行增删数据，同时打印 HashMap 的结构。 第3种情况是必须要扩容的，所以为了在同一个位置添加可以快速扩容，把负载因子改小了。但是这个负载因子也不是随便写的，因为必须要使得扩容后红黑树的节点数量不大于阈值 UNTREEIFY_THRESHOLD，即6。同时为了看到红黑树转回链表和不转回链表的情况，最好就是一个大于6，一个小于6，所以这里取的是13，重新分配后刚好满足这样要求（7和6），然后这个负载因子就是根据 13/64 --&gt; 0.2 来算的。 因为 HashMap 的很多属性外部都访问不到，比如 table 成员，然后测试时又需要用到，所以这里通过反射拿到它里面的 table 属性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class PrintHashMap extends HashMap&lt;Integer, Integer&gt; { public PrintHashMap(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor); } @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(&quot;{map size: &quot;).append(size()); Object[] table = getTable(); if (table == null) { return sb.toString(); } sb.append(&quot;, table size: &quot;).append(table.length); if (table.length == 0) { return sb.toString(); } sb.append(&quot;, nodes: {&quot;); boolean hasNotNullNode = false; for (int i = 0; i &lt; table.length; i++) { Object node = table[i]; if (node == null) { continue; } if (hasNotNullNode) { sb.append(&quot;, &quot;); } hasNotNullNode = true; sb.append(i).append(&quot;: &quot;).append(getNodeTypeStr(node)); } sb.append(&quot;}&quot;); sb.append(&quot;}&quot;); return sb.toString(); } private Object[] getTable() { try { Field tableField = HashMap.class.getDeclaredField(&quot;table&quot;); tableField.setAccessible(true); return (Object[]) tableField.get(this); } catch (Exception e) { e.printStackTrace(); } return null; } private String getNodeTypeStr(Object node) { StringBuilder sb = new StringBuilder(); String nodeType = node.getClass().getName(); sb.append(&quot;{type: &quot;).append(nodeType).append(&quot;, value: &quot;).append(node).append(&quot;}&quot;); return sb.toString(); }} 然后下面是具体的测试代码： 123456789101112131415161718192021222324252627282930313233343536public static void main(String[] args) { int index = 1; int size = 64; System.out.println(&quot;测试添加节点时，链表转红黑树&quot;); PrintHashMap map = new PrintHashMap(size, 1); testPut(map, size, index, 10); System.out.println(&quot;测试删除节点时，红黑树节点很少，转回链表&quot;); testRemove(map, size, index, 10); System.out.println(&quot;测试扩容时，红黑树节点少于阈值，转回链表&quot;); map = new PrintHashMap(size, 0.20f); testPut(map, size, index, 13);}private static void testPut(PrintHashMap map, int size, int index, int n) { for (int i = 0; i &lt; n; i++) { map.put(index, index); System.out.println(i + &quot; -&gt; put &quot; + index); System.out.println(map); index += size; } System.out.println();}private static void testRemove(PrintHashMap map, int size, int index, int n) { index = index + n * size; for (int i = 0; i &lt; n; i++) { index -= size; map.remove(index); System.out.println(i + &quot; -&gt; remove &quot; + index); System.out.println(map); } System.out.println();} 最后输出结果是这样的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071测试添加节点时，链表转红黑树0 -&gt; put 1{map size: 1, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}1 -&gt; put 65{map size: 2, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}2 -&gt; put 129{map size: 3, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}3 -&gt; put 193{map size: 4, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}4 -&gt; put 257{map size: 5, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}5 -&gt; put 321{map size: 6, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}6 -&gt; put 385{map size: 7, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}7 -&gt; put 449{map size: 8, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}8 -&gt; put 513{map size: 9, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}9 -&gt; put 577{map size: 10, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}测试删除节点时，红黑树节点很少，转回链表0 -&gt; remove 577{map size: 9, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}1 -&gt; remove 513{map size: 8, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}2 -&gt; remove 449{map size: 7, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}3 -&gt; remove 385{map size: 6, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}4 -&gt; remove 321{map size: 5, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}5 -&gt; remove 257{map size: 4, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 65=65}}}6 -&gt; remove 193{map size: 3, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 65=65}}}7 -&gt; remove 129{map size: 2, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 65=65}}}8 -&gt; remove 65{map size: 1, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}9 -&gt; remove 1{map size: 0, table size: 64, nodes: {}}测试扩容时，红黑树节点少于阈值，转回链表0 -&gt; put 1{map size: 1, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}1 -&gt; put 65{map size: 2, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}2 -&gt; put 129{map size: 3, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}3 -&gt; put 193{map size: 4, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}4 -&gt; put 257{map size: 5, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}5 -&gt; put 321{map size: 6, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}6 -&gt; put 385{map size: 7, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}7 -&gt; put 449{map size: 8, table size: 64, nodes: {1: {type: java.util.HashMap$Node, value: 1=1}}}8 -&gt; put 513{map size: 9, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}9 -&gt; put 577{map size: 10, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}10 -&gt; put 641{map size: 11, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}11 -&gt; put 705{map size: 12, table size: 64, nodes: {1: {type: java.util.HashMap$TreeNode, value: 193=193}}}12 -&gt; put 769{map size: 13, table size: 128, nodes: {1: {type: java.util.HashMap$TreeNode, value: 129=129}, 65: {type: java.util.HashMap$Node, value: 193=193}}} 测试结果基本和上面的源码分析一致： 增加节点，直到节点数量大于阈值 TREEIFY_THRESHOLD 时，即8时，链表就会转成红黑树。 删除节点，直到节点数量很少时，这里是3，红黑树就会转回链表。 扩容时，重新分配得节点数量不大于阈值 UNTREEIFY_THRESHOLD 时，即6时，红黑树就会转回链表。 从这里可以看出了，实际上添加第9个元素时，即节点数量 &gt; 8 时，链表才会转为红黑树。 小结链表转到红黑树需要满足的条件： 添加节点后，数组长度达到阈值 MIN_TREEIFY_CAPACITY，即64 添加节点后，链表长度达到阈值 TREEIFY_THRESHOLD，即8 注意，要同时满足这2个条件，才会将链表转成红黑树 红黑树转回链表需要满足的条件： 删除节点后，红黑树节点数量很少时，红黑树就会转回链表 扩容时，重新分配得节点数量不大于阈值 UNTREEIFY_THRESHOLD 时，即6时 注意，满足其中1个条件，就会将红黑树转回链表 总结数据结构 数据结构是“数组 + 链表 + 红黑树” 扩容机制 负载因子负责控制扩容的时机 当满足“大小 &gt; 容量 * 负载因子”时，才触发扩容 每次扩容是2倍，这是为了维持hash的快速定位 扩容时的重新分配位置，倒序插入 树转化机制 链表转到红黑树 添加节点后，数组长度达到阈值 MIN_TREEIFY_CAPACITY，即64 添加节点后，链表长度达到阈值 TREEIFY_THRESHOLD，即8，但是实际上是下一次再添加时才会转为红黑树，即长度为9时 注意，要同时满足这2个条件，才会将链表转成红黑树 红黑树转回链表 删除节点后，红黑树节点数量很少时，红黑树就会转回链表 红黑树节点完全没有了 红黑树右子树没有了 红黑树左子树没有了 红黑树的左子树的左子树没有了 扩容后，重新分配得节点数量不大于阈值 UNTREEIFY_THRESHOLD 时，即6时 注意，满足其中1个条件，就会将红黑树转回链表","link":"/lang/java/source/jdk8/collection/HashMap/"},{"title":"关键字native","text":"native1. 含义在 JDK 源代码中，有一些方法是被关键字 native 修饰的，就比如 Object 类： 123// java.lang.Objectpublic native int hashCode(); 那 native 的作用是什么呢？ native 修饰的方法表示这个方法是原生函数，其具体实现由非 Java 语言实现，比如 C 语言，其代码定义不在 Java 类中，而是在外部文件中（一般是动态链接库 .dll 文件）。 native 修饰的方法称为本地方法，当在 Java 代码中调用该方法时，JVM 会到外部定义中寻找它的实现代码 在 Java 平台中，与本地代码进行互操作的 API，称为 Java Native Interface (Java 本地接口)。 2. native 方法实现2.1 方法声明要实现 native 方法，首先要声明一个 native 方法。 比如下面的这个类 HelloNative，它声明了一个本地方法 sayHello: 1234567package com.demo;public class HelloNative { // 外部定义方法 public native void sayHello();} 运行时，JVM 会寻找本地方法 sayHello 的外部定义实现（一般是 C/C++ 实现），如果 JVM 没有找到并加载进去，执行 sayHello 方法时就会出现和以下类似的错误信息： 123456789101112package com;import com.demo.HelloNative;public class Main { public static void main(String[] args) { HelloNative helloNative = new HelloNative(); helloNative.sayHello(); } } 错误信息日志： 123Exception in thread &quot;main&quot; java.lang.UnsatisfiedLinkError: com.demo.HelloNative.sayHello()V at com.demo.HelloNative.sayHello(Native Method) at com.Main.main(Main.java:9) 在这里，sayHello 方法并没有外部实现，找不到肯定会报错。 可以自己手写一个外部实现代码，并让 JVM 加载它，然后就可以正常调用 sayHello 了。 2.2 外部定义实现Java 对于 JNI 接口方法定义格式有一定的要求，所以不是随便写就行的。 按照一般的 C/C++ 的文件格式可能无法正常加载到 JVM 中 JDK 中提供了一个 javah 命令，可以用来生成符合 JNI 样式的标头文件 在类 HelloNative 所在包的“根目录”执行以下命令： 12# 生成 JNI 标头文件javah -d com/demo com.demo.HelloNative 这样会在源文件 HelloNative.java 所在目录生成 JNI 标头文件 com_demo_HelloNative.h。 javah 命令默认生成的标头文件名是“包名\\_类名” 生成的 com_demo_HelloNative.h 头文件的内容如下： 12345678910111213141516171819202122/* DO NOT EDIT THIS FILE - it is machine generated */#include &lt;jni.h&gt;/* Header for class com_demo_HelloNative */#ifndef _Included_com_demo_HelloNative#define _Included_com_demo_HelloNative#ifdef __cplusplusextern &quot;C&quot; {#endif/* * Class: com_demo_HelloNative * Method: sayHello * Signature: ()V */JNIEXPORT void JNICALL Java_com_demo_HelloNative_sayHello (JNIEnv *, jobject);#ifdef __cplusplus}#endif#endif 从头文件可以看到，javah 命令生成的标头文件是使用 C 语言声明定义的（extern &quot;C&quot;）： JNI 接口方法名称是“Java\\_包名\\_类名\\_方法名”，该方法和 Java 中的 native 方法是一一对应的 有了头文件的接口方法声明，就可以开始实现具体的代码了。 创建一个文件 com_demo_HelloNative.c，并引入上面生成的头文件 com_demo_HelloNative.h： 1234567#include &quot;com_demo_HelloNative.h&quot;#include &lt;stdio.h&gt; JNIEXPORT void JNICALL Java_com_demo_HelloNative_sayHello(JNIEnv *env, jobject object){ printf(&quot;Hello，world!&quot;);} 实现 native 方法后，还不能直接在 Java 中用，接下来还需要： 将头文件（.h）和实现文件（.c）结合生成动态链接库文件（DLL），然后才能在 Java中使用 不同编译软件的生成命令可能不太一样，比如利用 MinGW GCC 的命令生成： 123# -m64 是指编译成64位的库# 需要注意给路径添加双引号，因为路径上有可能存在空格gcc -m64 -Wl,--add-stdcall-alias -I &quot;%JAVA_HOME%\\include&quot; -I &quot;%JAVA_HOME%\\include\\win32&quot; -shared -o HelloNative.dll .\\com_demo_HelloNative.c 参数 -I 是用于指定头文件（.h，例如 jni.h）的寻找路径。 编译完成后，就可以生成一个实现了 sayHello 接口的 HelloNative.dll 动态链接库文件了。 2.3 加载外部定义生成 dll 后，还要把它加载到 JVM 中后才能使用，所以需要 JVM 能找到 dll 文件： dll 文件需要放到 JVM 能够找到的位置，它才能被正确加载 JVM 默认的加载路径是程序当前目录，或者 System.getProperty(&quot;java.library.path&quot;) 所以只要把 dll 文件放到这些路径中的其中一个，JVM 就能够正常加载到 dll 文件。 加载好 dll 文件后，就可以调用 native 方法了： 12345678910111213141516171819package com;import com.demo.HelloNative;public class Main { static { // &quot;HelloNative&quot; 是 dll 文件名称 // 默认查找路径是程序当前目录 // 或者 System.getProperty(&quot;java.library.path&quot;) System.loadLibrary(&quot;HelloNative&quot;); } public static void main(String[] args) { HelloNative helloNative = new HelloNative(); helloNative.sayHello(); }} 程序的运行结果： 1Hello，world! 3. 流程图12345678910graph LR源文件(.java源文件) --&gt; javacjavac --&gt; 类文件(.class类文件)类文件(.class类文件) --&gt; JVMJVM -- 加载 --&gt; 共享库源文件(.java源文件) -. native方法 .-&gt; javahjavah --&gt; 头文件(.h头文件)头文件(.h头文件) --&gt; 编译链接实现文件(.c文件) --&gt; 编译链接编译链接 --&gt; 共享库 4. 总结 native 方法不是由 java 语言实现的，而是由 C/C++ 语言实现的 native 的外部定义实现一般是编译成 dll 文件后，再被 JVM 加载 native 方法的主要作用是为了跨平台、速度快、隐藏敏感代码 native 方法可以提供 java 访问操作系统底层的需求","link":"/lang/java/other/native/"},{"title":"快速排序的一些总结","text":"前言：最近又写到了有关快速排序的代码，结果半天写不对。从代码的整体上来说，代码结构是没问题的，就是在边界问题上出现了错误，经过一番思考以及查询资料，终于完美解决了，因此特地小记一下。 一. 简介快速排序算法，它的基本原理是： 通过一趟排序将数据分割成两部分 一份数据小，一份数据大 然后再对这两部分数据分别进行快速排序 以此达到数据的排序，其基本逻辑代码如下： 1234567public void quickSort(int[] a, int left, int right) { if (left &lt; right) { int mid = partSort(a, left, right); quickSort(a, left, mid - 1); quickSort(a, mid + 1, right); }} 二. 排序原理快速排序最关键的部分就是如何将大小两部分数据分离，也就是上述代码中的 partSort 的实现。 下面我用一个例子来介绍一下 partSort 的基本原理，假设要对数组进行从小到大的排序： (1) 首先给定需要排序的数组： (2) 选定一个基准值，这里暂时使用最左端的值（也就是5）： (3) 接着利用两个指针分别从数组左端和右端去遍历数据 从左端出发的指针找到比基准值大（&gt; 5）的值时则停止，从右端出发的指针找到比基准值小（&lt; 5）的值时则停止： 此时两个指针都停在了对应的值的位置，左指针指向7，右指针指向1： (4) 然后将这两个位置的数据进行交换： (5) 交换完成之后再执行第3步，直到两个指针相遇（也就是指向同一个位置）时结束交换： (6) 最后一步就是将指针相遇点的值与基准点的值进行交换： 至此，按照基准值为标准，partSort 已经将大小两部分数据分离，完成了快速排序的一次排序过程。 而基准值（就是5）也放在了最终排序结果中它应该放置的地方。 也就是说，快速排序的每一轮 partSort 排序结果，都会将基准值放在它最终排序序列的正确位置。 三. 基准点以及指针移动顺序前面已经简单介绍了排序的过程，其中有几个比较关键的地方： 基准值的选取 基准点 指针的先后移动顺序 基准值的选取 其实基准值的选取没什么好说的，一般都是取最左端或者最右端的值。 当然了，如果有时候对排序要求比较高的话，还可以随机取值或者三元取值（最左端，中点，最右端）等各种取值方法。 基准点 什么是基准点，也就是在进行 partSort 排序前，一般都会将基准值放在数组的最左端或者最右端，这两个位置就是基准点。 指针的先后移动顺序 因为排序时需要两个指针分别在两端往中间移动，移动顺序指的就是谁先移动，谁后移动。 很明显，基准值只会影响排序的速度，而不会影响最终的排序结果，因此此处不讨论。 那基准点和指针先后顺序是否会影响排序的正确性呢？ 下面我就用例子验证一下这个问题。 根据基准点和指针先后顺序，可以分为四种情况： 基准点左端，指针移动先右后左 基准点左端，指针移动先左后右 基准点左端，指针移动先右后左 基准点右端，指针移动先左后右 在验证这几种情况之前，先给出需要排序的数组，假设要将数组按从小到大排序，并选取5为基准值： 3.1 例子演示(1) 基准点左端，指针移动先右后左 那么按照之前 partSort 的排序，最终两指针相遇的位置如下： 最后交换基准值与指针相遇点的值： 好的，这里得到的结果没问题，后续执行也没有问题，这里就不贴图了。 (2) 基准点左端，指针移动先左后右 那么按照之前 partSort 的排序，最终两指针相遇的位置如下： 最后交换基准值和相遇点的值（注意，这里两指针相遇的位置变化了，之前是3，现在是6）： 到这里就已经可以知道结果了，排序已经出错了。 再对另外两种情况（基准点在最右端时）进行分析的时候，也会发现： 也是有一种情况结果正确，另一种情况却会失败。 测试是一样的，这里我就不再贴图分析了，下面我们来分析一下为什么会出现这种问题。 3.2 分析总结要分析出现问题的原因，首先必须要明确以下2点： 基准值在经过一轮排序之后，它所在的位置必定是它在最终排序序列的正确位置； 与基准值交换的值（也就是指针相遇的值）必须属于基准点所在的这一边。 根据这两条规则，可以知道情况2中出现问题的原因正是指针相遇的位置不正确（也就是指针相遇的值不属于基准点所在这一边），导致与基准值交换之后出现排序错误。 那怎么保证最后指针能指向正确的位置呢？下面先给出结论： 基准点在最左端时，指针移动先右后左； 基准点在最右端时，指针移动先左后右。 下面举例论证。 假设要对一个数组进行从小到大的排序，并且选取基准点为最左端。 那如何保证指针相遇值和基准值是属于同一侧，也就是都属于左端呢？ (1) 如果是先移动右指针，再移动左指针 先右移，那肯定会是右指针先停止移动，左指针再停止移动。 那么左右指针相遇时指向的值必然是满足右指针停止条件的值，而满足右指针停止的值必然不大于基准值。 也就是说，此时相遇值是属于左端的，可以和基准值交换。 (2) 如果是先移动左指针，再移动右指针 先右移，那肯定会是左指针先停止移动，右指针再停止移动。 那么左右指针相遇时指向的值必然是满足左指针停止条件的值，而满足左指针停止的值必然大于基准值。 也就是说，此时相遇值是属于右端的，是错误的位置。 同理，当基准点在右端时，先移动左指针，再移动右指针，也能够保证排序的正确性。 因此，只要记住一点，**让基准点对面的的指针先走**，这样就能够得到正确的排序结果。 四. 基准值的问题这里讨论的基准值的问题指的是，当排序左右指针移动过程中，如果遇到与基准值相等的值，此时是应该跳过还是停止？ 为了分析这个问题，首先给出一份 “partSort” 的代码： 123456789101112131415161718192021222324252627282930313233343536373839/** * 从小到大（一般方法） */public static int partSortLeft(int[] a, int left, int right){ if (a == null || left &gt; right) { return -1; } // 左端基准值 int x = a[left]; int lp = left, rp = right; while (lp &lt; rp) { // 先右遍历取小值 while (lp &lt; rp &amp;&amp; a[rp] &gt;= x) { rp--; } // 再左遍历取大值 while (lp &lt; rp &amp;&amp; a[lp] &lt;= x) { lp++; } if (lp &lt; rp) { a[lp] = a[lp] ^ a[rp]; a[rp] = a[lp] ^ a[rp]; a[lp] = a[lp] ^ a[rp]; } } // 交换基准值 if (left &lt; lp) { a[lp] = a[lp] ^ a[left]; a[left] = a[lp] ^ a[left]; a[lp] = a[lp] ^ a[left]; } return lp;} 可以看到，上述代码是按从小到大排序，最左端为基准点，指针是先右后左。根据上面的讨论结果，这样的排序是没有问题的。 但是现在要讨论的不是这个，在上面的代码中，有两条关键语句： 123456789// 先右遍历取小值while (lp &lt; rp &amp;&amp; a[rp] &gt;= x) { rp--;}// 再左遍历取大值while (lp &lt; rp &amp;&amp; a[lp] &lt;= x) { lp++;} 对于 a[rp] &gt;= x 和 a[lp] &lt;= x 这两个地方，其中的 “&gt;=” 和 “&lt;=” 能不能换成其他的符号呢？例如换成 “&gt;” 和 “&lt;”？ 一样地，根据不同的大小符号，可以分为四种情况： a[rp] &gt; x，a[lp] &lt; x a[rp] &gt;= x，a[lp] &lt; x/img/assets a[rp] &gt;= x，a[lp] &lt;= x a[rp] &gt; x，a[lp] &lt;= x 下面用例子来对这几种情况进行说明。 4.1 例子演示下面分别对这几种情况进行分析，代码依旧参考前面给出的代码。 (1) a[rp] &gt; x，a[lp] &lt; x 假如给出一个数组数据如下： 如果按照这个条件执行代码，这里的左右两个指针根本不会发生移动，导致排序陷入死循环，最终得不到排序结果。 (2) a[rp] &gt;= x，a[lp] &lt; x 假如给出一个数组数据如下，并且左右指针已经完成一轮移动了，它们此时的位置如下： 接下来就是交换两个指针指向的值，交换后： 由于排序还没完成，紧接着进行下一轮移动，先移动右指针： 到这里，问题已经出来了，基准值的位置丢失了!!!。 也就是说，后面不管怎么样，最终都无法确定基准值的位置了（也就是所在的数组索引）。 前面说过，**partSort 方法最终需要返回基准值的最终位置**，然后才能正确地分成一大一小的两部分进行递归排序。 但是此时却把基准值的位置给弄丢了，那最后也就无法拿到正确的分割点，排序肯定失败。 至于后面的两种情况，此处我就不分析了，这两种情况是可以得到正确结果的，至于怎么得到，大家可以试一试。 4.2 分析总结根据上面讨论中出现的情况，需要注意两点： 不能陷入死循环 不能丢失基准值的位置 为了避免这两种情况，必须在代码中实现以下两点： 有一边必须携带 “=”，才能够防止死循环； 带 “=” 这一边，必须属于基准点这一边的指针（因为该指针是从基准点出发，不能让它把基准点交换出去）。 为了减少麻烦和不必要的错误，以及保证分离的大小两部分数据的平衡性，最简单的方法就是两边都带 “=”。 五. 总结总的来说，写快速排序时，需要注意一下几点： 基准点在最左端时，指针移动先右后左； 基准点在最右端时，指针移动先左后右； 遇到等于基准值的位置，直接跳过（两边都带 “=”）。 总之一句话，基准点对面的指针先移动，移动时都带 “=”。 问题排除暂无 参考 http://www.cnblogs.com/ahalei/p/3568434.htmlhttps://blog.csdn.net/lemon_tree12138/article/details/50622744","link":"/algorithm/sort/quicksort-keys/"},{"title":"二分插入排序","text":"二分插入排序一、算法描述1.1 核心思想 数据分为已排序区间和未排序区间 从未排序区间取出元素，通过二分法找到合适的位置，插入到已排序区间中 插入已排序区间时，同时要保证已排序区间的有序性 总体上和插入排序差不多，只是在插入的时候，使用二分查找来找到合适的插入位置。 1.2 细节解释比如说，数组 [2, 7, 1, 4, 3, 6, 5]。 首先分成未排序和已排序区间，第 1 个值无需排序，默认属于已排序区间： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 2 | | 7 | 1 | 4 | 3 | 6 | 5 | 此时从未排序区间中取一个值 7，插入到已排序区间： 通过二分法定位到 7 应该在的位置 [1]，所以 7 直接插入 [1] 的位置： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 2 | 7 | | 1 | 4 | 3 | 6 | 5 | 继续从未排序区间取值 1，二分法定位到 [0]，所以 1 直接插入 [0] 的位置： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 7 | | 4 | 3 | 6 | 5 | 以此类推，后面每一步的结果如下： 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 4 | 7 | | 3 | 6 | 5 | 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 7 | | 6 | 5 | 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 6 | 7 | | 5 | 123已排序 未排序 ___ ___ ___ ___ ___ ___ ___| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 经过 n 轮插入以后，数组就排好序了。 二、算法实现二分插入排序算法的伪代码如下： 12345678910111213insertSort(int[] arr) { for (i = 1; i &lt; n; i++) { // 未排序区间数据元素 x = arr[i]; // 二分查找合适的插入位置 loc = firstGreat(arr, 0, i - 1, x); // 插入到已排序区间合适的位置 for (j = i; j &gt; loc; j--) { arr[j] = arr[j - 1]; } arr[loc] = x; }} 执行过程如下： 1234567891011121314151617===== 初始数组 =====[0, 3, 1, 6, 2, 5, 4]=====第 1 轮插入=====[0, 1, 3, 6, 2, 5, 4]=====第 2 轮插入=====[0, 1, 3, 6, 2, 5, 4]=====第 3 轮插入=====[0, 1, 2, 3, 6, 5, 4]=====第 4 轮插入=====[0, 1, 2, 3, 5, 6, 4]=====第 5 轮插入=====[0, 1, 2, 3, 4, 5, 6] 三、算法分析3.1 时间复杂度 最好时间复杂度：O(nlogn) 最坏时间复杂度：O(n^2) 平均时间复杂度：O(n^2) 从复杂度上看，二分插入排序比插入排序的复杂度还要高，但在实际中，还是二分插入排序性能更好。 因为二分插入排序相比于插入排序，只是提升了比较速度，即比较次数从 n^2 -&gt; nlogn。 然而二分插入排序的交换次数没有改变，所以总体复杂度和插入排序是一样的。 但实际排序中，比较次数的影响会更大，所以二分插入排序的性能会显得更好。 3.2 空间复杂度 空间复杂度：O(1) 原地算法 3.3 稳定性 稳定排序算法 附录12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 二分插入排序 * &lt;p&gt; * 时间复杂度：最好 O(nlogn) 最差 O(n^2) 平均 O(n^2) * &lt;p&gt; * 空间复杂度：O(1) * &lt;p&gt; * 稳定性：稳定 * * @author weijiaduo * @since 2023/9/28 */public class BinaryInsertSort implements Sort { @Override public void sort(int[] arr) { int n = arr.length; for (int i = 1; i &lt; n; i++) { int x = arr[i]; // 二分查找合适的插入位置 int loc = firstGreat(arr, 0, i - 1, x); // 插入到已排序区间合适的位置 for (int j = i; j &gt; loc; j--) { arr[j] = arr[j - 1]; } arr[loc] = x; } } /** * 寻找第一个大于指定值的位置 * * @param arr 数组 * @param lo 起始位置 [lo, hi] * @param hi 结束位置 [lo, hi] * @param val 指定值 * @return 符合条件的索引 */ private int firstGreat(int[] arr, int lo, int hi, int val) { int left = lo, right = hi; while (left &lt;= right) { int mid = left + (right - left) / 2; if (arr[mid] &gt; val) { if (mid == 0 || arr[mid] &lt;= val) { return mid; } right = mid - 1; } else { left = mid + 1; } } return left; }}","link":"/algorithm/sort/binaryinsertsort/"},{"title":"INDEX.LIST","text":"INDEX.LIST一、INDEX.LIST 是什么？jar 包里面声明的索引列表，描述了 jar 包下所有的资源文件的路径，包含了应用程序及其扩展程序中的包的位置信息。 其作用就类似一个索引目录，目的是为了快速定位，类加载器会使用它来提高类的加载速度。 二、为什么要用 INDEX.LIST？明确一点，应用程序在没加载某个类前，是不知道这个类是在哪个 jar 包里面的。 这个时候，想要找到这个类，应用程序就必须遍历所有的 jar 包，然后在每个 jar 包里面去查找这个类。 如果 jar 包是在网络中，那么这个过程是非常耗时和浪费带宽的。 为了优化类的搜索过程，jar 包规范中就提出了一个 JarIndex 索引机制 JarIndex 机制会收集应用程序中定义的所有 JAR 文件的内容，并将这些信息存储到第一个 JAR 文件中的索引文件中 这个索引文件就是 INDEX.LIST。 比如说，INDEX.LIST 文件示例如下： 1234567891011JarIndex-Version: 1.0 JarIndex_Main.jar sp JarIndex_test.jar Sample SampleDir/JarIndex_test1.jar org org/apache org/apache/xerces org/apache/xerces/framework org/apache/xerces/framework/xml4j 这个索引文件内容的含义就是： 这个jar包索引了其他3个jar文件，分别是：JarIndex_Main.jar、 JarIndex_test.jar、SampleDir/JarIndex_test1.jar JarIndex_Main.jar 中包含了 sp 这个包 JarIndex_test.jar 中包含了 Sample 这个包 SampleDir/JarIndex_test1.jar 中包含了 org、org/apache、org/apache/xerces 这些包 也就意味着，如果应用程序要加载 org.apache.xerces.framework.xml4j.XML4JConfiguration 这个类时，可以优先去 SampleDir/JarIndex_test1.jar 这个 jar 包里面查找。 如果在 SampleDir/JarIndex_test1.jar 里面就找到了类，那就不需要去遍历所有的 jar 包搜索了。 通过这种索引机制，可以减少遍历所有的 jar 包的情况，提高类的加载速度。 三、索引 jar 包的层级结构在 jar 包中，如果有一个名为 META-INF/INDEX.LIST 的文件，那么这个 jar 包就是一个索引 jar 包。 这个索引 jar 包中的 INDEX.LIST 文件就是索引文件，它的内容就是上面的示例内容。 如果一个 jar 包是索引 jar 包，那么它就会包含其他的 jar 包，这些 jar 包就是它的扩展 jar 包。 扩展 jar 包的内容就是索引 jar 包中 INDEX.LIST 文件中的内容。 比如说，JarIndex_Main.jar 就是一个索引 jar 包，它的扩展 jar 包就是 JarIndex_test.jar 和 SampleDir/JarIndex_test1.jar。 这样就形成了一个索引 jar 包的层级结构。 四、如何创建 INDEX.LIST 索引使用下述命令为 JarIndex_Main.jar、JarIndex_test.jar 和 JarIndex_test1.jar 创建一个索引文件 1jar -i JarIndex_Main.jar JarIndex_test.jar SampleDir/JarIndex_test1.jar 这样就会在 JarIndex_Main.jar 中创建一个名为 META-INF/INDEX.LIST 的索引文件。 参考 https://www.cnblogs.com/anuoruibo/p/2432160.html","link":"/lang/java/other/INDEX.LIST/"},{"title":"jar 命令","text":"jar 命令一、jar命令语法123456789101112131415161718用法: jar {ctxui}[vfmn0PMe] [jar-file] [manifest-file] [entry-point] [-C dir] files ...选项: -c 创建新档案 -t 列出档案目录 -x 从档案中提取指定的 (或所有) 文件 -u 更新现有档案 -v 在标准输出中生成详细输出 -f 指定档案文件名 -m 包含指定清单文件中的清单信息 -n 创建新档案后执行 Pack200 规范化 -e 为捆绑到可执行 jar 文件的独立应用程序指定应用程序入口点 -0 仅存储; 不使用任何 ZIP 压缩 -P 保留文件名中的前导 '/' (绝对路径) 和 &quot;..&quot; (父目录) 组件 -M 不创建条目的清单文件 -i 为指定的 jar 文件生成索引信息 -C 更改为指定的目录并包含其中的文件(可以理解为首先cd到指定目录)如果任何文件为目录, 则对其进行递归处理。清单文件名, 档案文件名和入口点名称的指定顺序与 'm', 'f' 和 'e' 标记的指定顺序相同。 二、替换文件1、命令 jar -tvf 列出自己需要替换文件的路径 例如（profile） 1jar -tvf xxxx.war | grep profile 2、解压需要替换文件的路径 (WEB-INF/classes/profile 代表上一行命令找到的路径) 1jar -xvf xxx.war WEB-INF/classes/profile 3、替换文件 1cp /xxx/profile WEB-INF/classes/ 4、还原 war 包(相当于把刚才解压的目录，在打包回去) 1jar -uvf xxx.war WEB-INF/classes/profile 三、删除文件1、新建一个临时目录 tmp，复制 jar 包到里面 12345mkdir tmpcp xxx.jar tmp/cd tmp 2、在 tmp 解压 jar 包： 1jar -xvf xxx.jar 3、删除指定的文件 1rm -rf com.test.OldClass.class 4、删除 jar 包 把之前复制到目录这里的 jar 包删除，避免等会打包时把它打进去： 1rm -rf xxx.jar 5、重新压缩 jar 包 删除文件结束后，就可以重新压缩 jar 包了： 1jar -cvf new.jar ./ new.jar 是新 jar 包名称，./ 是指定压缩的路径，这里是当前目录。 6、替换新 jar 包 最后，把新 jar 替换掉旧的 jar 包，并删除临时目录： 12345cd ..mv tmp/new.jar xxx.jarrm -rf tmp 这就完成了删除 jar 内文件的操作。","link":"/lang/java/other/jar_cmd/"},{"title":"String.replaceAll()","text":"String.replaceAll()String.replaceAll() 方法的定义和实现是这样的： 123public String replaceAll(String regex, String replacement) { return Pattern.compile(regex).matcher(this).replaceAll(replacement);} 第1个参数是正则表达式，第2个参数则是替换的字符串。 但并不是那么简单，实际上存在着坑点，方法注释里面说到： 123Note that backslashes ({@code \\}) and dollar signs ({@code $}) in thereplacement string may cause the results to be different than if it werebeing treated as a literal replacement string; 简单点说，就是第2个参数 replacement 中，如果包含斜杠 \\ 或者 $，那么它就不仅仅是一个普通的替换字符串。 一、特殊字符 $$ 在参数 replacement 中是特殊字符，可用于表示第1个正则参数匹配的子串。 比如说，$0 表示匹配的第一个子串： 12String s = &quot;abc&quot;; // abcs = s.replaceAll(&quot;b&quot;, &quot;, $0, &quot;); // a, b, c 第2个参数中的 $0 实际就是正则匹配子串 b。 所以，$ 在参数 replacement 中算是比较特殊的存在。 二、转义字符 \\那如果确实是要替换字符 $，怎么办？ 那就是用转义字符 \\，把 $ 换成 \\$，$ 就会被认为是普通字符了。 比如这样： 12String s = &quot;abc&quot;; // abcs = s.replaceAll(&quot;b&quot;, &quot;, \\\\$, &quot;); // a, $, c 因此，参数 replacement 里面的斜杠 \\ 也是特殊字符，是专门用于转义的。 所以，\\ 出现在参数 replacement 时也需要注意转义的情况。 比如说，想要把 a,b,c 里面的 , 替换成 \\，下面这种写法是不行的： 12String s = &quot;a,b,c&quot;; // a,b,cs = s.replaceAll(&quot;,&quot;, &quot;\\\\&quot;); // character to be escaped is missing 直接报错了，这是为什么？ 首先，在 java 字符串表达式中，表示一个 \\ 字符，本身就需要转义，写成 \\\\ 其次，replacement 这个参数自己也需要转义，所以还要给 \\\\ 再转义，写成 \\\\\\\\ 才行 所以，下面这种写法才是正常的： 12String s = &quot;a,b,c&quot;; // a,b,cs = s.replaceAll(&quot;,&quot;, &quot;\\\\\\\\&quot;); // a\\b\\c 总的来说，String.replaceAll() 方法的第二个参数 replacement 虽然不是正则表达式，但也是一种特殊的表达式，需要对 \\ 和 $ 进行转义，所以写的时候会比一般字符串表达式写多一层转义。","link":"/lang/java/other/string_replaceAll/"},{"title":"Java 反射调用有可变参数的方法","text":"Java 反射调用有可变参数的方法Java 反射经常会用到，但是在反射可变参数时，写法和平时有点不同。 以下面的类作为反射对象试验： 12345class Parameters { public int multi(Object... args) { return args.length; }} 一、普通调用12345new Parameters().multi(&quot;1&quot;); // 1new Parameters().multi(&quot;1&quot;, &quot;2&quot;); // 2new Parameters().multi(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;); // 4 很简单，传几个参数就是几个。 二、数组传参上面是传递的是简单的对象类型，换成数组会怎么样？ 12String[] args = new String[]{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;};new Parameters().multi(args); // 3 12Object[] args = new Object[]{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;};new Parameters().multi(args); // 4 如果传给可变参数的只是1个数组，那么这个数组不会被认为是1个参数，而是多个参数。 本质上，可变参数就是1个数组参数，传多个参数和只传1个数组参数，效果是一样的 可变参数只是 Java 语法糖，Java 会自动把参数数组拆分成多个参数 不过如果传的参数不止一个数组，就可以按正常逻辑处理： 12Object[] args = new Object[]{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;};new Parameters().multi(&quot;0&quot;, args); // 2 12Object[] args = new Object[]{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;};new Parameters().multi(args, &quot;5&quot;); // 2 由于已经明确传递了多个参数，所以第一个数组不再被认为是多个参数了。 三、错误的反射传参一般来说，反射传参是这样写的： 12Method method = Parameters.class.getDeclaredMethod(&quot;multi&quot;, Object[].class);method.invoke(new Parameters(), &quot;1&quot;, &quot;2&quot;, &quot;3&quot;); 这个本意是传递3个参数 {“1”, “2”, “3”} 给 multi 方法，但是实际上是不行的，会报错： 1java.lang.IllegalArgumentException: wrong number of arguments 这是为什么呢？ 原因是可变参数本质上就只是1个数组参数而已，也就是说可变参数方法只要1个数组参数而已。 从 getDeclaredMethod(&quot;multi&quot;, Object[].class) 这里也可以看出来，参数只有1个，也就是 Object[]。 而 method.invoke(object, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;) 调用实际上传给 multi 方法的参数是 3 个，而不是 1 个，所以会出现参数个数不匹配的错误。 但是，如果直接传递1个参数数组也是不行的： 123Method method = Parameters.class.getDeclaredMethod(&quot;multi&quot;, Object[].class);Object[] args = new Object[]{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;};method.invoke(new Parameters(), args); 这个也会报一样的错误，因为 method.invoke() 接收的也是可变参数，只传1个数组和上面的传多个参数是同样的效果。 四、正确的反射传参首先明确2件事： method.invoke() 接收的也是可变参数，只传1个数组会被认为是多个参数 可变参数本质上是接收1个参数数组 需要把1个数组参数传给 multi 方法，但是又不让 method.invoke() 把这个数组拆分成多个参数，怎么办呢？ 正确的做法是，把数组参数再包装一层： 1234Method method = Parameters.class.getDeclaredMethod(&quot;multi&quot;, Object[].class);String[] methodArgs = new String[]{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;};Object[] invokeArgs = new Object[]{methodArgs};method.invoke(new Parameters(), invokeArgs); invokeArgs 参数是给 method.invoke() 用的，methodArgs 参数是给 multi 方法用的。 invokeArgs 里面只有1个 methodArgs，这样就不会被认为是多个参数了，只会被认为是1个数组参数。 所以最终传给 multi 的就只有1个参数 methodArgs 了。 总结 可变参数只是 Java 语法糖，Java 会自动把参数数组拆分成多个参数 可变参数只是 Java 的语法糖，本质上和1个数组参数是一样的 传多个可变参数，和传1个数组参数是一样的效果 反射可变参数的方法时，要确保传给可变参数方法的最终参数是1个数组","link":"/lang/java/other/reflect_paramters/"},{"title":"Java 的格式化字符串","text":"Java 的格式化字符串一、格式化 Formatter 参考了 C 语言的 printf() 函数，但 Java 的格式化会更严格一些 同时定制化增加了 Java 语言的一些特性，使得格式化更适用于 Java 语言 二、格式化方法2.1 使用 Formatter 实例12Formatter formatter = new Formatter();formatter.format(&quot;%4$2s %3$2s %2$2s %1$2s&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) 2.2 使用 System 中的方法12345// outSystem.out.format(&quot;Local time: %tT&quot;, Calendar.getInstance());// errSystem.err.printf(&quot;Unable to open file '%1$s': %2$s&quot;, fileName, exception.getMessage()); 2.3 使用 String 中的静态方法1String s = String.format(&quot;Duke's Birthday: %1$tb %1$te, %1$tY&quot;, c); 2.4 格式化方法要素所有的格式化方法都有 2 个要素： format string：格式化字符串 argument list：参数列表 比如： 1String s = String.format(&quot;%4$2s %3$2s %2$2s %1$2s&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;); 其中， %4$2s %3$2s %2$2s %1$2s 是格式化字符串 &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot; 是参数列表 格式化字符串的写法是有固定语法的，不能随意写。 三、格式化语法参数类型可以分为几类： 通用：比如字符串 字符：比如字母 数值：比如整数和浮点数 日期时间：比如年月日，时分秒 无参类型：比如换行 对于不同的参数数据类型，格式化语法会稍微有点不一样。 3.1 通用、字符、数值语法格式： 1%[argument_index$][flags][width][.precision]conversion argument_index：参数索引，指定使用第几个参数，1$ 表示第1个参数，2$ 表示第2个参数 flags：标志，用于调整参数输出的格式，比如左对齐，前缀补零等 width：输出宽度，用于指定参数输出的最小字符数量 precision：对于数值型参数，用于指定精度；对于某些类型，用于表示输出的最大字符数量 conversion：转换符，单个字母，用于表示参数如何被格式化 举个例子： 12345(&quot;%4$2s&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) --&gt; &quot; d&quot;- 4$: argument_index，这里表示使用第 4 个参数- 2: width，这里表示输出字符数量最少为 2- s: conversion，这里表示以字符串形式输出参数，即 toString() 3.2 日期、时间语法格式： 1%[argument_index$][flags][width]conversion argument_index、flags、width 和上面的通用型含义一样 conversion：转换符，2 个字母，第一个字母是 t 或 T，用于表示参数如何被格式化 举个例子： 12345(&quot;%1$tY&quot;, new Date()) --&gt; 2023- 1$: argument_index，这里表示使用第 1 个参数- t: conversion，日期和时间转换符的固定前缀- Y: conversion，年份，最少 4 位整数表示，不足 4 位时前面补零 3.3 无参类型语法格式： 1%[flags][width]conversion flags、width 和上面的通用型含义一样 conversion：表示输出的内容，没有参数，不是占位符了 举个例子： 123(&quot;%d%%&quot;, 50) --&gt; &quot;50%&quot;- %: 表示输出 % 这个字符 四、转换符（conversion）4.1 转换符分类 类型 应用范围 适用参数类型 通用型 所有参数类型 字符型 可应用于 Unicode 字符展示的基本类型 包括 char、Character、byte、Byte、short、Short还有可能应用于 int、Integer 类型（满足 Character.isValidCodePoint） 数值型 可分为整型和浮点型 整型包括 byte、Byte、short、Short、int、Integer、long、Long、BigInteger浮点型包括 float、Float、double、Double、BigDecimal 日期时间 可应用于日期和时间 包括 long、Long、Calendar、Date、TemporalAccessor 百分比 特定字面量 % 只有 % 换行符 特定平台的换行符 比如 \\n、\\r\\n 4.2 转换符汇总 转换符 分类类型 描述 b/B 通用型 布尔值。null 的结果是 false布尔参数时等于 String.valueOf(arg)非布尔参数时等于 true h/H 通用型 哈希值。结果等于 Integer.toHexString(arg.hashCode()) s/S 通用型 字符串。如果参数实现了 Formattable 接口，那么输出就是 arg.formatTo() 的结果否则输出等于 arg.toString() c/C 字符型 Unicode 字符 d 整型 整数 o 整型 八进制整数 x/X 整型 十六进制整数 e/E 浮点型 科学计数法 f 浮点型 小数 g/G 浮点型 小数或者科学计数法，根据数据的实际情况动态决定使用哪种 a/A 浮点型 十六进制浮点数，带有效数和指数 t/T 日期时间 日期时间转换符的固定前缀 % 百分比 字面量 % n 换行符 特定平台的换行符 转换符大小写的格式化作用相同，仅仅是输出结果的大小写不一样。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* 布尔值 b/B */System.out.printf(&quot;null: %b, %B&quot;, null, null);// null: false, FALSE System.out.printf(&quot;bool: %b, %B&quot;, true, false);// bool: true, FALSE System.out.printf(&quot;other: %b, %B&quot;, 1, &quot;test&quot;);// other: true, TRUE /* 哈希值 h/H */System.out.printf(&quot;null: %h, %H&quot;, null, null);// null: null, NULL System.out.printf(&quot;hash: %h, %H&quot;, 12.0, &quot;false&quot;);// hash: 40280000, 5CB1923 /* 字符串 s/S */System.out.printf(&quot;null: %s, %S&quot;, null, null);// null: null, NULL System.out.printf(&quot;string: %s, %S&quot;, 123, &quot;string&quot;);// string: 123, STRING/* 字符 c/C */System.out.printf(&quot;null: %c, %C&quot;, null, null);// null: null, NULL System.out.printf(&quot;string: %c, %C&quot;, 36, 'a');// char: $, A /* 整数值 d/o/x/X */System.out.printf(&quot;null: %d&quot;, null);// null: null System.out.printf(&quot;10-int: %d&quot;, 36);// 10-int: 36 System.out.printf(&quot;8-int: %o&quot;, 40);// 8-int: 50 System.out.printf(&quot;16-int: %x, %X&quot;, 46, 47);// 16-int: 2e, 2F /* 浮点值 e/E/f/g/G/a/A */System.out.printf(&quot;null: %f&quot;, null);// null: null System.out.printf(&quot;scientific: %e, %E&quot;, 360000000000000.0, 0.00002);// scientific: 3.600000e+14, 2.000000E-05System.out.printf(&quot;float: %f, %f&quot;, 40.0f, 100.2);// float: 40.000000, 100.200000 System.out.printf(&quot;rounding: %g, %G&quot;, 0.0001, 0.00000000000001);// rounding: 0.000100000, 1.00000E-14System.out.printf(&quot;16-float: %a, %A %n&quot;, 0.0001, 0.00000000000001);// 16-float: 0x1.a36e2eb1c432dp-14, 0X1.6849B86A12B9BP-47 /* 日期时间 t/T */System.out.printf(&quot;null: %th&quot;, null);// null: null System.out.printf(&quot;year: %ty, %tY&quot;, new Date(), new Date());// year: 23, 2023 System.out.printf(&quot;month: %tM&quot;, new Date());// month: 09 System.out.printf(&quot;hour: %th, %tH&quot;, new Date(), new Date());// hour: 01System.out.printf(&quot;16-float: %s, %S&quot;, new Date(), new Date());// second: 1673025096, 36 /* 百分比 % */System.out.printf(&quot;percent: %%&quot;);// percent: % /* 换行符 n */System.out.printf(&quot;line separator: %n line separator&quot;);//line separator: // line separator 4.3 日期转换符 转换符 描述 示例 Y 4位数的年份 0092 y 2位数的年份 范围是 00 - 99 B 本地化的月份全称 “January”、”February” b 本地化的月份简称 “Jan”、”Feb” h 和 b 一样 m 2位数的月份，从01开始 范围是 01 - 13 A 本地化的周全称 “Sunday”、”Monday” a 本地化的周简称 “Sun”、”Mon” d 2位数的每月天数 范围是 01 - 31 e 每月天数 范围是 1 - 31 12345678910System.out.printf(&quot;year: %ty, %tY&quot;, new Date(), new Date());// year: 23, 2023 System.out.printf(&quot;month name: %tb, %tB, %th&quot;, new Date(), new Date(), new Date());// month name: 1月, 一月, 1月System.out.printf(&quot;month number: %tm&quot;, new Date());// month number: 01 System.out.printf(&quot;week: %ta, %tA&quot;, new Date(), new Date());// week: 周六, 星期六 System.out.printf(&quot;day: %td, %te&quot;, new Date(), new Date()); // day: 07, 7 4.4 时间转换符 转换符 描述 H 小时，24小时制，2位数，范围是 00 - 23 I（i的大写） 小时，12小时制，2位数，范围是 01 - 12 k 小时，24小时制，范围是 0 - 23 l（L的小写） 小时，12小时制，范围是 1 - 12 M 分钟，2位数，范围是 00 - 59 S 秒，2位数，范围是 00 - 60，60专门用于支持闰秒 L 毫秒，3位数，范围是 000 -999 N 纳秒，9位数，范围是 000000000 - 999999999 s 从 1970/01/01 00:00:00 开始的秒数，范围是 Long.MIN_VALUE/1000 - Long.MAX_VALUE/1000 Q 从 1970/01/01 00:00:00 开始的毫秒数，范围是 Long.MIN_VALUE - Long.MAX_VALUE p 特定语言的上午或者下午，比如 am，pm 123456789101112System.out.printf(&quot;hour: %tH, %tI, %tk, %tl&quot;, date, date, date, date);// hour: 21, 09, 21, 9 System.out.printf(&quot;minute: %tM&quot;, date);// minute: 33 System.out.printf(&quot;second: %ts, %tS&quot;, date, date);// second: 1673012005, 25 System.out.printf(&quot;millisecond: %tL, %tQ&quot;, date, date);// millisecond: 706, 1673012005706System.out.printf(&quot;nanosecond: %tN&quot;, date);// nanosecond: 706000000 System.out.printf(&quot;noon: %tp&quot;, date);// noon: 下午 上面是比较细的转换符，直接用的话写起来比较麻烦。 而且日期时间的输出还是很常用的，所以还提供了一些时间转换符的快捷方式： 转换符 描述 示例 R 表示24小制时分：%tH:%tM 范围是 00:00 - 23:59 T 表示24小制时分秒：%tH:%tM:%tS 范围是 00:00:00 - 23:59:59 D 表示日期的月日年：%tm/%td/%ty 比如 01/06/23 F 表示日期的年月日：%tY-%tm-%td 比如 2023-01-06 c 完整的时间日期：%ta %tb %td %tT %tZ %tY 比如 Sun Jul 20 16:17:00 EDT 1969 12345678910System.out.printf(&quot;HH:MM: %tR&quot;, new Date());// HH:MM: 01:38 System.out.printf(&quot;HH:MM:SS: %tT&quot;, new Date());// HH:MM:SS: 01:38:51 System.out.printf(&quot;mm/dd/yy: %tD&quot;, new Date());// mm/dd/yy: 01/07/23 System.out.printf(&quot;YYYY-mm-dd: %tF&quot;, new Date());// YYYY-mm-dd: 2023-01-07 System.out.printf(&quot;date time: %tc&quot;, new Date());// date time: 周六 1月 07 01:38:51 CST 2023 时间转换符的快捷方式就是用简单的1个字符替代多个转换符，简化代码，相当于缩写。 五、标志位（flags）标志位用于对输出格式进行一些调整。 标志 描述 示例 结果 - 左对齐 (“^%-5d^”, 15) ^15&nbsp;&nbsp;&nbsp;^ # 如果是浮点数则包含小数点，如果是16进制或8进制则添加0x或0 (“%#x”, 99) 0x63 + 给数值加上符号位，正数前加+，负数前加- (“%+d”, 99) +99 空格 在整数之前添加指定数量的空格 (“^% 4d^”, 99) ^&nbsp;&nbsp;99^ 0 在数字前面补0 (“%04d”, 99) 0099 , 以“,”对数字分组 (“%,d”, 999999999) 999,999,999 ( 使用括号包含负数 (“%(f”, -99.99) (99.99) 12345678910111213141516System.out.printf(&quot;left-justified: ^%5d^, ^%-5d^&quot;, 99, 99);// left-justified: ^ 99^, ^99 ^ System.out.printf(&quot;conversion-dependent: %o, %#o&quot;, 40, 40);// conversion-dependent: 50, 050 System.out.printf(&quot;conversion-dependent: %X, %#X&quot;, 47, 47);// conversion-dependent: 2F, 0X2F System.out.printf(&quot;sign: %d, %+d&quot;, 99, 99);// sign: 99, +99 System.out.printf(&quot;space: ^%d^, ^% 5d^&quot;, 99, 99);// space: ^99^, ^ 99^ System.out.printf(&quot;zero: ^%4d^, ^%04d^&quot;, 99, 99);// zero: ^ 99^, ^0099^ System.out.printf(&quot;grouping separators: %d, %,d&quot;, 123456789, 123456789);// grouping separators: 123456789, 123,456,789 System.out.printf(&quot;negative parentheses: %d, %(d&quot;, -99, -99);// negative parentheses: -99, (99) 六、宽度（width）宽度的含义： 表示输出字符数量的最小值 类型是整数，范围是 1 - Integer.MAX_VALUE 1234System.out.printf(&quot;width: ^%4d^&quot;, 99);// width: ^ 99^System.out.printf(&quot;width: %4s&quot;, &quot;123456789&quot;);// width: 123456789 因为输出字符数量最小是 4，因此在 99 之前补了2个空格，所以 (&quot;^%4d^&quot;, 99) 的结果是 ^ 99^。 七、精度（precision）精度对于不同类型的含义： 对于通用型，精度表示输出字符数量的最大值 对于浮点型，精度表示小数点后面的数字个数 对于字符型、整型、日期时间、百分比、换行符等，精度不支持 1234System.out.printf(&quot;general: %.6s&quot;, &quot;123456789&quot;);// general: 123456 System.out.printf(&quot;float: %.3f&quot;, 123.342235625345);// float: 123.342 参考 java.util.Formatter https://blog.csdn.net/lonely_fireworks/article/details/7962171/","link":"/lang/java/other/formatter/"},{"title":"各种 O 对象概念","text":"各种 O 对象一、各类对象的含义1.1 PO（persistant Object）、DO（Data Object） 与数据库表一一对应，由 DAO 层向上传输数据源对象 一个 DO/PO 对象对应数据库表的一条记录 DO/PO 的每个属性都对应的数据库表的列 只存在于数据库连接期间，连接关闭后，DO/PO 就消失了（一般都会将其转为其他 O 对象） 1.2 DTO（Data Transfer Object） 数据传输对象，用于在应用程序的各个子系统/服务间传输数据 一般是子系统/服务之间进行数据交流的传参 DTO 应该仅包括必要属性，用不到的不应该放它里面 1.3 BO（Business Object） 业务对象，封装了业务逻辑和业务数据的对象 与业务紧密相关，一般会包括对多个 PO 对象的处理 1.4 AO（Application Object） 应用对象，在 Web 层与 Service 层之间抽象的复用对象模型 极为贴近展示层，复用度不高 1.5 VO（View Object） 显示层对象，通常是 Web 向模板渲染引擎层传输的对象 VO 一般是给有界面展示的客户端的数据 VO 也是只包括必要属性，用不到的也不应该传 1.6 POJO（Plain Oridinary Java Object） 专指只有 setter/getter 的简单类 包括 DO/DTO/BO/VO 等 就是普通的 JavaBean 对象，理论上只有数据，没有逻辑处理 二、各类对象的区别1. PO 和 BO 的区别 PO 是简单的 Java 对象，没有业务逻辑，只有数据 BO 是将 PO 与业务逻辑结合起来的对象，是数据与操作的结合 2. DTO 和 VO 的区别 把前后端看成 2 个子系统，后端传给前端的数据对象就是 VO，前端传给后端的数据对象则是 DTO VO 实际上属于是 DTO 的一种，只是特指传给前端界面的数据对象 DTO 则是更广泛的定义，可代指各个独立子系统之间的数据传输对象，比如微服务之间 总结 参考 https://zhuanlan.zhihu.com/p/102389552 http://t.zoukankan.com/angel11288-p-06b95a05e8d6d042bf461cabd7532035.html https://www.bilibili.com/read/cv4956351/","link":"/other/object_concept/"},{"title":"264. 丑数2","text":"264. 丑数2一、题目描述给你一个整数 n ，请你找出并返回第 n 个 丑数 。 丑数 就是只包含质因数 2、3 和/或 5 的正整数。 输入：n = 10输出：12解释：[1, 2, 3, 4, 5, 6, 8, 9, 10, 12] 是由前 10 个丑数组成的序列。 提示： 1 &lt;= n &lt;= 1690 二、解题思路丑数是只包含 2、3、5 这 3 个质因素的数。 后面的丑数肯定是由前面的丑数计算得来的 后面的丑数 = min(前面的丑数 * 2/3/5) 前面所有的丑数，分别乘以 2/3/5，去重后，它们中的最小积就是下一个丑数。 比如说，前面的丑数列表是这样的： 1[1, 2, 3, 4, 5] 那么分别乘以 2/3/5 后，得到结果是： 12345678// 乘以2[2, 4, 6, 8, 10]// 乘以3[3, 6, 9, 12, 15]// 乘以5[5, 10, 15, 20, 25] 去掉之前的 [1, 2, 3, 4, 5]，这里面最小的就是 6，所以下一个丑数就是 6。 但是这种方式会有很多重复计算，比如前面出现过的 [2, 3, 5]，每次都要算一遍。 我们可以从比最后一个丑数大的位置开始，比如丑数列表是： 1[1, 2, 3, 4, 5, 6, 8, 10] 那么对于 2/3/5 这几种情况： 10 / 2 = 5，那么 2 可以从比 5 大的值开始计算，对应列表里的 6 10 / 3 = 3，那么 3 可以从比 3 大的值开始计算，对应列表里的 4 10 / 5 = 2，那么 5 可以从比 2 大的值开始计算，对应列表里的 3 那么它们下一个列表是： 12345678// 乘以2，从 6 开始[12, 16, 20]// 乘以3，从 4 开始[12, 15, 18, 24, 30]// 乘以5，从 3 开始[15, 20, 25, 30, 35] 前面的重复值没有了，但还是有很多不必要的计算，比如后面的 [16, 18, 20] 这些。 反正是求最小值，只需要乘以 2、乘以 3、乘以 5 的第一个值就可以了 所以上面实际上只需要 3 个数就够了： 12 (6 * 2) 12 (4 * 3) 15 (3 * 5) 这三个数中的最小值 12 就是下一个丑数。 那怎么快速找到 2 、3、5 的起始位置呢？ 可以用 3 个指针分别记录 2、3、5 下一次的起始位置 比如这次 3 个指针指向的元素是 [6, 4, 3]： 起始元素分别乘以 2、3、5 得到 [12, 12, 15]，最小值 12 就是下一个丑数 最后更新指针，往后移动 1 位 [8, 5, 3]（因为 2、3 的值相同，所以都移动了） 通过 3 指针的方式，可以避免计算前面无用的重复值，也能快速地算出下一个丑数。 三、复杂度分析 时间：O(n) 空间：O(n) 四、参考代码12345678910111213141516171819202122232425262728293031323334/** * 思路：3指针，分别指向2、3、5的下一个起始位置，下一个丑数肯定是从这 3 个数里面出来的 * &lt;p&gt; * 复杂度：时间 O(n) 空间 O(n) * &lt;p&gt; * 执行耗时:2 ms,击败了97.22% 的Java用户 * 内存消耗:40.9 MB,击败了36.82% 的Java用户 */private int nthUglyNumber(int n) { int[] nums = new int[n]; nums[0] = 1; int p2 = 0, p3 = 0, p5 = 0; for (int i = 1; i &lt; n; ) { // 下一个丑数 int next2 = nums[p2] * 2; int next3 = nums[p3] * 3; int next5 = nums[p5] * 5; int next = Math.min(next2, Math.min(next3, next5)); // 不用 else 是为了去掉重复的数字 if (next == next2) { p2++; } if (next == next3) { p3++; } if (next == next5) { p5++; } nums[i++] = next; } return nums[n - 1];}","link":"/practice/leetcode/math/264.NthUglyNumber/"},{"title":"854. 相似度为 K 的字符串","text":"854. 相似度为 K 的字符串一、题目描述对于某些非负整数 k ，如果交换 s1 中两个字母的位置恰好 k 次，能够使结果字符串等于 s2 ，则认为字符串 s1 和 s2 的 相似度为 k 。 给你两个字母异位词 s1 和 s2 ，返回 s1 和 s2 的相似度 k 的最小值。 输入：s1 = “ab”, s2 = “ba”输出：1 提示： 1 &lt;= s1.length &lt;= 20 s2.length == s1.length s1 和 s2 只包含集合 {‘a’, ‘b’, ‘c’, ‘d’, ‘e’, ‘f’} 中的小写字母 s2 是 s1 的一个字母异位词 二、解题思路查找交换的所有可能情况，可以采用回溯法。 每次交换，至少把 1 个字符换到正确的位置 这样子做的话，交换次数最多 n - 1 次。 因为 n - 1 次交换之后，前 n - 1 个字符都已经对上了，那最后一个肯定也对上了。 最优的交换是，交换后的 2 个字符的位置都是正确的 可利用最优交换进行快速剪枝。另外， 如果当前交换次数，比之前最小的交换次数还大了，此时可以直接剪枝 三、复杂度分析不分析时空复杂度。 四、参考代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657int ans = Integer.MAX_VALUE;private int kSimilarity(String s1, String s2) { backtrace(s1.toCharArray(), s2.toCharArray(), 0, 0); return ans;}/** * 思路：回溯法，每次换位都确保有 1 位能够在正确位置上，从左往右逐个换位 * &lt;p&gt; * 执行耗时:21 ms,击败了81.61% 的Java用户 * 内存消耗:39.1 MB,击败了98.85% 的Java用户 */private void backtrace(char[] s1, char[] s2, int index, int cnt) { // 快速剪枝，交换次数比最小值大了 if (cnt &gt;= ans) { return; } // 2 个字符串已经相等了 if (index &gt;= s1.length) { ans = cnt; return; } // 当前位相同，无需交换，进行下一步 if (s1[index] == s2[index]) { backtrace(s1, s2, index + 1, cnt); return; } int n = s1.length; for (int i = index + 1; i &lt; n; i++) { // 回溯交换，把 index 的字符换位到 2 者相等 if (s1[i] == s2[index] &amp;&amp; s1[i] != s2[i]) { swap(s1, index, i); backtrace(s1, s2, index + 1, cnt + 1); swap(s1, i, index); /* * 这个地方的剪枝非常重要 * 执行耗时:2 ms,击败了92.53% 的Java用户 * 内存消耗:39.2 MB,击败了93.10% 的Java用户 */ // 交换后 2 个位置都相等，已经是最优解 if (s1[index] == s2[i]) { break; } } }}private void swap(char[] sc, int i, int j) { char temp = sc[i]; sc[i] = sc[j]; sc[j] = temp;}","link":"/practice/leetcode/string/854.KSimilarity/"},{"title":"698. 划分为k个相等的子集","text":"698. 划分为k个相等的子集一、题目描述给定一个整数数组 nums 和一个正整数 k，找出是否有可能把这个数组分成 k 个非空子集，其总和都相等。 提示： 1 &lt;= k &lt;= len(nums) &lt;= 16 0 &lt; nums[i] &lt; 10000 每个元素的频率在 [1,4] 范围内 二、解题思路查找所有可能情况，可以采用回溯法。 回溯为了加快速度，还要加上快速剪枝和记忆搜索。 快速剪枝： 对数组进行排序，可以方便判断元素的前后大小 快速剪枝，只要当前 sum + nums[i] &gt; target，那么后面就不必遍历了 记忆搜索（状态去重）： 数组有 n 位数，所有总共有 2 ^ n 中不同的状态，但是题目限制了 1 &lt; n &lt; 16。 可以采用状态压缩的方式，用整数的低 16 位保存 n 位状态 压缩状态到整数表示以后，就能用数组 new boolean[1 &lt;&lt; n] 进行状态去重 总的处理过程如下： 验证数组总和，是否可以均分成 k 组 sum(nums) % k 验证均值 sum(nums) / k 的有效性，即判断它是否不小于数组所有值 状态压缩，回溯遍历所有情况 回溯过程中，快速剪枝 + 记忆去重 三、复杂度分析3.1 时间 O(n * 2^n)总共 2^n 种状态，每种状态进行 n 轮判断，验证可能性。 3.2 空间 O(2^n)记忆搜索需要 2^n 空间保存所有状态。 四、参考代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 搜索数组int[] nums;// 状态缓存boolean[] cache;// 目标值int target = 0;/** * 思路：状态压缩 + 记忆搜索 * &lt;p&gt; * 复杂度：O(n * 2^n) 空间 O(2^n) * &lt;p&gt; * 执行耗时:17 ms,击败了67.38% 的Java用户 * 内存消耗:40.9 MB,击败了30.37% 的Java用户 */private boolean canPartitionKSubsets(int[] nums, int k) { // 判断总和够不够均分 int sum = Arrays.stream(nums).sum(); if (sum % k != 0) { return false; } // 平均值 int avg = sum / k; // 排序，方便剪枝 Arrays.sort(nums); // 最大值比平均值大，不可能均分 int n = nums.length; if (avg &lt; nums[n - 1]) { return false; } // 状态压缩，用 n 位 1 表示 int state = (1 &lt;&lt; n) - 1; this.nums = nums; this.target = avg; this.cache = new boolean[state + 1]; Arrays.fill(this.cache, true); return dfs(state, 0);}/** * 递归遍历 * * @param state 状态 * @param sum 总和 * @return true/false */private boolean dfs(int state, int sum) { // 分配成功 if (state == 0) { return true; } // 记忆状态去重 if (!cache[state]) { return false; } int n = nums.length; for (int i = 0; i &lt; n; i++) { // num[i] 已被使用 boolean used = ((state &gt;&gt; i) &amp; 1) == 0; if (used) { continue; } // 快速剪枝，排序了后面的比前面大 if (nums[i] + sum &gt; target) { break; } // 设置第 i 位为 0，标记 num[i] 已被使用 int nextState = state ^ (1 &lt;&lt; i); // 加够一个 target 后，重新从 0 开始 int nextSum = (sum + nums[i]) % target; // 递归，验证下一个状态是否可行 if (dfs(nextState, nextSum)) { return true; } } // 状态记忆存储 cache[state] = false; return false;}","link":"/practice/leetcode/array/698.CanPartitionKSubsets/"},{"title":"922. 按奇偶排序数组 II","text":"922. 按奇偶排序数组 II一、题目描述给定一个非负整数数组A， A 中一半整数是奇数，一半整数是偶数。 对数组进行排序，以便： 当A[i] 为奇数时，i也是奇数； 当A[i]为偶数时，i 也是偶数。 你可以返回任何满足上述条件的数组作为答案。 二、解题思路利用双指针，偶数指针放偶数，奇数指针放奇数。 左指针从 1 ~ 2n - 1 右指针从 0 ~ 2n 三、复杂度分析 空间 O(n) 时间 O(n) 四、参考代码12345678910111213141516171819/** * 奇偶数排序 * @param nums 数组 * @return 排序后的数组 */public int[] sortArrayByParityII(int[] nums) { int[] n = new int[nums.length]; int ep = 0, op = 1; for (int num : nums) { if (num % 2 == 0) { n[ep] = num; ep += 2; } else { n[op] = num; op += 2; } } return n;}","link":"/practice/leetcode/array/922.SortArrayByParityII/"},{"title":"905. 按奇偶排序数组","text":"905. 按奇偶排序数组一、题目描述给定一个非负整数数组 A，返回一个数组，在该数组中， A 的所有偶数元素之后跟着所有奇数元素。 你可以返回满足此条件的任何数组作为答案。 二、解题思路利用左右指针，左指针放偶数，右指针放奇数。 左指针从 0 ~ n 右指针从 n ~ 0 三、复杂度分析 时间 O(n) 空间 O(n) 三、提交代码123456789101112131415161718/** * 奇偶数排序 * @param nums 数组 * @return 排序后的数组 */private int[] sortArrayByParity(int[] nums) { int[] n = new int[nums.length]; int lp = 0, rp = n.length - 1; int k = 0; while (k &lt; n.length) { if (nums[k] % 2 == 0) { n[lp++] = nums[k++]; } else { n[rp--] = nums[k++]; } } return n;}","link":"/practice/leetcode/array/905.SortArrayByParity/"},{"title":"896. 单调数列","text":"896. 单调数列一、题目描述如果数组是单调递增或单调递减的，那么它是单调的。 如果对于所有 i &lt;= j，A[i] &lt;= A[j]，那么数组 A 是单调递增的。 如果对于所有 i &lt;= j，A[i]&gt; = A[j]，那么数组 A 是单调递减的。 当给定的数组 A是单调数组时返回 true，否则返回 false。 二、解题思路先利用首尾2个元素判断递增还是递减。 然后遍历数组，如果发现和首尾元素的标记不一样，就说明不是单调的。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码1234567891011121314151617181920/** * 是否是单调数列 * @param nums 数组 * @return true/false */private boolean isMonotonic(int[] nums) { boolean flag = nums[0] &lt;= nums[nums.length - 1]; for (int i = 1; i &lt; nums.length; i++) { if (flag) { if (nums[i] &lt; nums[i - 1]) { return false; } } else { if (nums[i] &gt; nums[i - 1]) { return false; } } } return true;}","link":"/practice/leetcode/array/896.Monotonic/"},{"title":"746. 使用最小花费爬楼梯","text":"746. 使用最小花费爬楼梯一、题目描述数组的每个下标作为一个阶梯，第 i 个阶梯对应着一个非负数的体力花费值cost[i]（下标从 0 开始）。 每当你爬上一个阶梯你都要花费对应的体力值，一旦支付了相应的体力值，你就可以选择向上爬一个阶梯或者爬两个阶梯。 请你找出达到楼层顶部的最低花费。在开始时，你可以选择从下标为 0 或 1 的元素作为初始阶梯。 123输入：cost = [10, 15, 20]输出：15解释：最低花费是从 cost[1] 开始，然后走两步即可到阶梯顶，一共花费 15 。 123输入：cost = [1, 100, 1, 1, 1, 100, 1, 1, 100, 1]输出：6解释：最低花费方式是从 cost[0] 开始，逐个经过那些 1 ，跳过 cost[3] ，一共花费 6 。 二、解题思路假设此时要计算走到第i个阶梯的花费，那么有2种情况可以做到： 此时站在 i - 1 阶梯上，迈1步走上第i个阶梯，需要花费 cost[i - 1]; 此时站在 i - 2 阶梯上，迈2步走上第i个阶梯，需要花费 cost[i - 2]。 因此走到第i个阶梯的最小花费就是： 1minCost[i] = min(minCost[i - 1] + cost[i - 1], minCost[i - 2] + cost[i - 2]); 题目的要求是走过n个阶梯，并不是走到第n个阶梯。 也就是说，实际上应该是要走到第 n + 1 个阶梯上面，所以最终求的结果应该是 minCost[n + 1]。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码123456789101112131415161718/** * 使用最小花费爬楼梯 * * @param cost 数组 * @return 最小花费 */private int minCostClimbingStairs(int[] cost) { // 求走到第 n + 1 阶梯的花费 int[] minCost = new int[cost.length + 1]; for (int i = 0; i &lt; minCost.length; i++) { if (i &gt; 1) { minCost[i] = Math.min(minCost[i - 1] + cost[i - 1], minCost[i - 2] + cost[i - 2]); } else { minCost[i] = 0; } } return minCost[minCost.length - 1];} 优化空间，因为只用到了 minCost[i - 1] 和 minCost[i - 2]，所以直接用2个变量保存就行。 123456789101112131415/** * 使用最小花费爬楼梯 * * @param cost 数组 * @return 最小花费 */private int minCostClimbingStairs(int[] cost) { int minCost = 0, minCost1 = 0, minCost2 = 0; for (int i = 2; i &lt; cost.length + 1; i++) { minCost = Math.min(minCost1 + cost[i - 1], minCost2 + cost[i - 2]); minCost2 = minCost1; minCost1 = minCost; } return minCost;}","link":"/practice/leetcode/array/746.MinCostClimbingStairs/"},{"title":"724. 寻找数组的中心下标","text":"724. 寻找数组的中心下标一、题目描述给你一个整数数组nums，请编写一个能够返回数组 “中心下标” 的方法。 数组 中心下标 是数组的一个下标，其左侧所有元素相加的和等于右侧所有元素相加的和。 如果数组不存在中心下标，返回 -1 。 如果数组有多个中心下标，应该返回最靠近左边的那一个。 注意：中心下标可能出现在数组的两端。 nums 的长度范围为 [0, 10000]。 任何一个 nums[i] 将会是一个范围在 [-1000, 1000]的整数。 二、解题思路先算出整个数组的总和，然后利用一个指针，从左往右遍历数组。 在遍历的同时，计算左边的和 leftSum += nums[p - 1]，和右边的和 rightSum -= nums[i]。 当 leftSum == rightSum 时，就是中心下标。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码1234567891011121314151617181920212223242526/** * 寻找数组的中心下标 * * @param nums 数组 * @return 中心下标索引 */private int pivotIndex(int[] nums) { int result = -1; int leftSum = 0, rightSum = 0; for (int num : nums) { rightSum += num; } int p = 0; while (p &lt; nums.length) { if (p &gt; 0) { leftSum += nums[p - 1]; } rightSum -= nums[p]; if (leftSum == rightSum) { result = p; break; } p++; } return result;}","link":"/practice/leetcode/array/724.PivotIndex/"},{"title":"717. 1比特与2比特字符","text":"717. 1比特与2比特字符一、题目描述有两种特殊字符。 第一种字符可以用一比特0来表示。 第二种字符可以用两比特(10或11)来表示。 现给一个由若干比特组成的字符串。 问最后一个字符是否必定为一个一比特字符。 给定的字符串总是由0结束。 二、解题思路我的想法是，既然最后一个是0，而且要识别这个0是不是1bit，那么就从后面往前找，直到找到不符合2bit字符的情况为止。 前一个数字是0，那么00在一起，最后的0肯定是1bit； 前一个数字是1，再前一个也是1，也就是110，那么无法判断，继续往前； 前一个数字是1，再前一个是0，也就是010，那么后面的0肯定是属于前面的1的，肯定是2bit。 根据这样从后往前判断，就可以判断出来结果。 不过官方的解法更简洁，只要判断最后2个0之间的1的数量，就可以识别出最后一个0是不是1bit： 如果最后2个0之间的1数量是偶数，说明这些1都是11组合的，所以最后1个0肯定是1bit； 如果最后2个0之间的1数量是奇数，说明除了最后1个1以外，其他都是11组合，最后一个则是10组合，所以是2bit。 虽然原理上差不太多，不过官方解法确实简洁~~~ 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码1234567891011121314151617181920212223242526/** * 最后一个字符是否必定为一个一比特字符 * * @param bits 数组 * @return true/false */private boolean isOneBitCharacter(int[] bits) { if (bits.length &lt;= 0 || bits[bits.length - 1] != 0) { return false; } int rp = bits.length - 2; while (rp &gt;= 0) { if (bits[rp] == 0) { // 如果是00，那后面的0肯定是单独的0 return true; } if (rp - 1 &gt;= 0 &amp;&amp; bits[rp - 1] == 1) { // 前面是11，忽略它们并继续往前找 rp -= 2; } else { // 前面是01，那么后面的0肯定属于前面的1 return false; } } return true;} 官方解法： 1234567891011/** * 最后一个字符是否必定为一个一比特字符 * * @param bits 数组 * @return true/false */private boolean isOneBitCharacter(int[] bits) { int i = bits.length - 2; while (i &gt;= 0 &amp;&amp; bits[i] &gt; 0) i--; return (bits.length - i) % 2 == 0;}","link":"/practice/leetcode/array/717.OneBitCharacter/"},{"title":"697. 数组的度","text":"697. 数组的度一、题目描述给定一个非空且只包含非负数的整数数组nums，数组的度的定义是指数组里任一元素出现频数的最大值。 你的任务是在 nums 中找到与nums拥有相同大小的度的最短连续子数组，返回其长度。 二、解题思路需要计算数字的度，只能遍历一次数组来计算，可以用数组来保存次数，但是为了简单起见，还是直接用集合类吧。 得到数字的度数后，还需要知道最大度数，这个也顺便在计算数字的度数时一起更新了。 知道哪些数字有最大度数后，就剩下计算它们的最短子数组长度了： 这个子数组，实际上就是这个数字第一次和最后一次出现之间的子数组 所以还必须知道每个数字第一次和最后一次出现的位置，len = lastPos - firstPos + 1。 我一开始的思路是，得到最大度数和数字后，再逐个寻找这些数字的第一次和最后一次的位置，但是看了官方解答后，没想到可以在前面统计度数时，顺便吧前后出现的位置记录下来，有点意思啊~ 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码1234567891011121314151617181920212223242526272829303132333435363738/** * 找到与nums拥有相同大小的度的最短连续子数组，返回其长度 * * @param nums 数组 * @return 长度 */private int findShortestSubArray(int[] nums) { // 计算每个数的度数，以及最大度数 int maxCount = 0; Map&lt;Integer, int[]&gt; countMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) { int[] count = countMap.get(nums[i]); if (count == null) { count = new int[3]; count[1] = i; } count[0]++; count[2] = i; countMap.put(nums[i], count); if (count[0] &gt; maxCount) { maxCount = count[0]; } } // 计算最大度数数字的最短数组长度 int minLen = nums.length; for (Map.Entry&lt;Integer, int[]&gt; entry : countMap.entrySet()) { int[] count = entry.getValue(); if (count[0] == maxCount) { int len = count[2] - count[1] + 1; if (len &lt; minLen) { minLen = len; } } } return minLen;}","link":"/practice/leetcode/array/697.ShortestSubArray/"},{"title":"665. 非递减数列","text":"665. 非递减数列一、题目描述给你一个长度为n的整数数组，请你判断在 最多 改变1 个元素的情况下，该数组能否变成一个非递减数列。 我们是这样定义一个非递减数列的：对于数组中任意的i (0 &lt;= i &lt;= n-2)，总满足 nums[i] &lt;= nums[i + 1]。 二、解题思路既然是非递减数列，那么就从左到右遍历数组，维护一个前面遍历过的最大值 prev，当前值 nums[i]，下一个值 next。 若 nums[i] &lt; prev，因为要求是非递减的，那么 nums[i] 是一定要修正，至少要修正到 nums[i] = prev； 若 prev &lt;= nums[i] &lt;= next，属于正常情况，那么中值是不用修正的，直接更新 prev = nums[i]； 若 prev &lt;= nums[i] &amp;&amp; nums[i] &gt; next，也就是中值比两边值都大，这个时候就需要分成2种情况：一种是 prev &lt;= next，这时候只需要修正中值 nums[i] = prev 就行了；另一种是 prev &gt; next，这个时候修正中值是没办法满足非递减要求的，只能修正 next 的值。 同时，为了保证 prev 和 next 一直存在，就给数组左右两边分别添加了额外的最小最大值，即整数的最小最大值。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码1234567891011121314151617181920212223242526272829303132333435/** * 检查数组能否变成一个非递减数列 * @param nums 数组 * @return true/false */private boolean checkPossibility(int[] nums) { int fixCount = 0; int prev = Integer.MIN_VALUE; for (int i = 0; fixCount &lt;= 1 &amp;&amp; i &lt; nums.length; i++) { int next = i + 1 &lt; nums.length ? nums[i + 1] : Integer.MAX_VALUE; // 中值比前值小，肯定要修正 if (nums[i] &lt; prev) { // 修正为 nums[i] = prev fixCount++; continue; } // 中值在前后值之间，不用修正 if (nums[i] &lt;= next) { prev = nums[i]; continue; } // 中值最大，前值后值都比中值小 if (prev &lt;= next) { // 前值比后值小，修正中值 // 修正为 prev &lt;= nums[i] &lt;= next fixCount++; } else { // 前值比后值大，修正后值 prev = nums[i]; } } return fixCount &lt;= 1;}","link":"/practice/leetcode/array/665.CheckPossibility/"},{"title":"643. 子数组最大平均数 I","text":"643. 子数组最大平均数 I一、题目描述给定 n 个整数，找出平均数最大且长度为 k 的连续子数组，并输出该最大平均数。 二、解题思路因为是连续子数组，所以直接使用滑动窗口来计算就行。 下一个和 = 上一个和 - 窗口第1个元素 + 新元素 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码12345678910111213141516171819/** * 最大平均数 * @param nums 数组 * @param k 数量 * @return 最大平均数 */private double findMaxAverage(int[] nums, int k) { int maxSum = 0; for (int i = 0; i &lt; k; i++) { maxSum += nums[i]; } for (int i = k, sum = maxSum; i &lt; nums.length; i++) { sum = sum - nums[i - k] + nums[i]; if (sum &gt; maxSum) { maxSum = sum; } } return maxSum * 1.0 / k;}","link":"/practice/leetcode/array/643.MaxAverage/"},{"title":"628. 三个数的最大乘积","text":"628. 三个数的最大乘积一、题目描述给你一个整型数组 nums ，在数组中找出由三个数组成的最大乘积，并输出这个乘积。 3 &lt;= nums.length &lt;= 104 -1000 &lt;= nums[i] &lt;= 1000 二、解题思路2.1 思路1：排序先排序，然后再找最大值，可能的情况包括： 都是非负数，或者非正数，此时最大值只能是最后3个值相乘； 正数负数都有，那么最大乘积就只可能是2种情况：3非负、1非负2非正。 2.2 思路2（官方解法）：直接遍历思路1中实际用到的值包括：3个最大值和2个最小值。 直接遍历数组，拿到这些值，然后最大乘积就只能是2种情况： 3个最大值（3正或3负）; 1个最大值2个最小值（1正2负）。 三、复杂度分析1）思路1：排序 时间 O(nlogn) 空间 O(1) 2）思路2（官方解法）：直接遍历 时间 O(n) 空间 O(1) 四、参考代码1）思路1：排序 1234567891011121314151617181920/** * 三个数的最大乘积 * @param nums 数组 * @return 最大乘积 */private int maximumProduct2(int[] nums) { int result; Arrays.sort(nums); if (nums[0] &gt;= 0 || nums[nums.length - 1] &lt;= 0) { // 3非负，或3非正 result = nums[nums.length - 1] * nums[nums.length - 2] * nums[nums.length - 3]; } else { // 3非负，或1非负2非正 int r1 = nums[nums.length - 1] * nums[nums.length - 2] * nums[nums.length - 3]; // 1非负2非正 int r2 = nums[0] * nums[1] * nums[nums.length - 1]; result = Math.max(r1, r2); } return result;} 2）思路2：直接遍历 12345678910111213141516171819202122232425262728293031/** * 三个数的最大乘积 * @param nums 数组 * @return 最大乘积 */private int maximumProduct(int[] nums) { int max1 = Integer.MIN_VALUE, max2 = Integer.MIN_VALUE, max3 = Integer.MIN_VALUE; int min1 = Integer.MAX_VALUE, min2 = Integer.MAX_VALUE; for (int i = 0; i &lt; nums.length; i++) { int num = nums[i]; // 最大值 if (num &gt; max1) { max3 = max2; max2 = max1; max1 = num; } else if (num &gt; max2) { max3 = max2; max2 = num; } else if (num &gt; max3) { max3 = num; } // 最小值 if (num &lt; min1) { min2 = min1; min1 = num; } else if (num &lt; min2) { min2 = num; } } return Math.max(max1 * max2 * max3, max1 * min1 * min2);}","link":"/practice/leetcode/array/628.MaximumProduct/"},{"title":"605. 种花问题","text":"605. 种花问题一、题目描述假设有一个很长的花坛，一部分地块种植了花，另一部分却没有。 可是，花不能种植在相邻的地块上，它们会争夺水源，两者都会死去。 给你一个整数数组flowerbed 表示花坛，由若干 0 和 1 组成，其中 0 表示没种植花，1 表示种植了花。 另有一个数n ，能否在不打破种植规则的情况下种入n朵花？能则返回 true ，不能则返回 false。 二、解题思路遍历数组，除了2端的元素以外，只要有连续的3个为0的地方，就可以在中间的0那里种花。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码123456789101112131415161718192021222324252627282930313233/** * 种花问题 * @param flowerbed 数组 * @param n 数量 * @return true/false */private boolean canPlaceFlowers(int[] flowerbed, int n) { if (n &lt;= 0) { return true; } if (flowerbed.length &lt; 2 * n - 1) { return false; } int k = n; for (int i = 0; k &gt; 0 &amp;&amp; i &lt; flowerbed.length; i++) { // 当前不为空 if (flowerbed[i] != 0) { continue; } // 左边不为空 if (i - 1 &gt;= 0 &amp;&amp; flowerbed[i - 1] != 0) { continue; } // 右边不为空 if (i + 1 &lt; flowerbed.length &amp;&amp; flowerbed[i + 1] != 0) { continue; } // 两边都为空，可以种花 k--; i++; } return k &lt;= 0;}","link":"/practice/leetcode/array/605.PlaceFlowers/"},{"title":"561. 数组拆分 I","text":"561. 数组拆分 I一、题目描述给定长度为2n的整数数组 nums ，你的任务是将这些数分成 n 对。 例如 (a1, b1), (a2, b2), …, (an, bn) ，使得从 1 到n 的 min(ai, bi) 总和最大。 二、解题思路假设一个有序序列 a1 &lt;= a2 &lt;= a3 &lt;= a4 ... &lt;= an。 a1 是最小值，那它应该和谁一起组成数对呢？ 由于计算总和时取的是数对中的小值 min(a1, x)，而此时 a1 是最小值，也就是说，无论 x 是哪个，实际上计算时都会被抛弃。 为了能够实现最大和，我们就选个最小和和 a1 组合，那剩下的元素里，最小的就是 a2 了，所以得到第一个数对 (a1, a2)。 以此类推，最终得到的优数对组合就是 (a1, a2), (a3, a4), ... , (an-1, an)。 而此时的最大总和就是 a1 + a3 + a5 + ... + an-1。 三、复杂度分析 时间 O(nlogn) 空间 O(1) 四、参考代码1234567891011121314/** * 数对最小值的最大和 * * @param nums 数组 * @return 最大和 */private int arrayPairSum(int[] nums) { int sum = 0; Arrays.sort(nums); for (int i = 0; i &lt; nums.length; i += 2) { sum += nums[i]; } return sum;}","link":"/practice/leetcode/array/561.ArrayPairSum/"},{"title":"448. 找到所有数组中消失的数字","text":"448. 找到所有数组中消失的数字一、题目描述给你一个含 n 个整数的数组 nums ，其中 nums[i] 在区间 [1, n] 内。 请你找出所有在 [1, n] 范围内但没有出现在 nums 中的数字，并以数组的形式返回结果。 二、解题思路把数值 n 放到它应该在的位置 n - 1，最后再遍历一遍数组，如果 nums[i] != i + 1，就表明数字 i + 1 丢失了。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码1234567891011121314151617181920212223242526/** * 找到所有数组中消失的数字 * * @param nums 数组 * @return 消失的数字 */private List&lt;Integer&gt; findDisappearedNumbers(int[] nums) { List&lt;Integer&gt; result = new ArrayList&lt;&gt;(nums.length); int n = nums.length; for (int i = 0; i &lt; n; i++) { int t = nums[i] - 1; while (0 &lt;= t &amp;&amp; t &lt; n &amp;&amp; nums[t] != nums[i]) { // 循环交换到正确的位置 int temp = nums[t]; nums[t] = nums[i]; nums[i] = temp; t = nums[i] - 1; } } for (int i = 0; i &lt; n; i++) { if (nums[i] != i + 1) { result.add(i + 1); } } return result;}","link":"/practice/leetcode/array/448.DisappearedNumbers/"},{"title":"167. 两数之和 II - 输入有序数组","text":"167. 两数之和 II - 输入有序数组一、题目描述给定一个已按照 升序排列 的整数数组numbers ，请你从数组中找出两个数满足相加之和等于目标数target 。 函数应该以长度为 2 的整数数组的形式返回这两个数的下标值。numbers 的下标 从 1 开始计数 ，所以答案数组应当满足 1 &lt;= answer[0] &lt; answer[1] &lt;= numbers.length 。 你可以假设每个输入只对应唯一的答案，而且你不可以重复使用相同的元素。 二、解题思路因为是升序数组，并且找2个数的和等于某个值，所以可以从数组2头分别开始遍历，找到符合的值。 比如目标值是 t，此时选中左边 l，右边 r。 如果此时 l + r == t，直接满足条件； 如果 l + r &lt; t，需要增大2数之和，那就取 l 的下一个数； 如果 l + r &gt; t，需要减少2数之和，那就取 r 的前一个数。 为什么这种方式可以找到和为 t 的值呢？ 首先，如果发现此时 l + r &lt; t，那么就可以判定： l 左边的值 ll 比 l 小，所以 ll + r &lt; t，都不满足条件，排除. 其次，如果发现此时 l + r &gt; t，那么就可以判定： r 右边的值 rr 比 r 大，所以 l + rr &gt; t，都不满足条件，排除。 通过不断排除这2种情况的值，就能逐步找到和为指定值的2个数值。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码123456789101112131415161718192021222324252627/** * 升序数组中，两个数满足相加之和等于目标数 * @param numbers 升序数组 * @param target 目标和 * @return 两个数的索引 */private int[] twoSum(int[] numbers, int target) { int[] result = new int[2]; if (numbers.length &lt; 2) { return result; } int lp = 0, rp = numbers.length - 1; while (lp &lt; rp) { int sum = numbers[lp] + numbers[rp]; if (sum == target) { result[0] = lp + 1; result[1] = rp + 1; break; } if (sum &lt; target) { lp++; } else { rp--; } } return result;}","link":"/practice/leetcode/binary/167.TwoSum2/"},{"title":"36. 有效的数独","text":"36. 有效的数独一、题目描述请你判断一个9x9 的数独是否有效。只需要 根据以下规则 ，验证已经填入的数字是否有效即可。 数字1-9在每一行只能出现一次。 数字1-9在每一列只能出现一次。 数字1-9在每一个以粗实线分隔的3x3宫内只能出现一次。（请参考示例图） 数独部分空格内已填入了数字，空白格用’.’表示。 注意： 一个有效的数独（部分已被填充）不一定是可解的。 只需要根据以上规则，验证已经填入的数字是否有效即可。 二、解题思路按照题目的要求，按行、按列、按方格分别验证各种情况是否符合要求。 这样做的话，需要遍历3遍二维数组。 官方解法，只用遍历一次二维数组，遍历同时校验各个位置的有效性，时间和空间效率比我想得要高。 三、复杂度分析 时间 O(n^2) 空间 O(1) 四、参考代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 验证是否是有效的9x9数独 */private boolean isValidSudoku(char[][] board) { // 校验行 for (int i = 0; i &lt; board.length; i++) { if (!checkRangeValid(board, i, 0, 1, board[i].length)) { return false; } } // 校验列 for (int i = 0; i &lt; board[0].length; i++) { if (!checkRangeValid(board, 0, i, board.length, 1)) { return false; } } // 校验方格 for (int i = 0; i &lt; board.length; i += 3) { for (int j = 0; j &lt; board[0].length; j += 3) { if (!checkRangeValid(board, i, j, 3, 3)) { return false; } } } return true;}/** * 验证指定范围的有效性 */private boolean checkRangeValid(char[][] board, int x, int y, int rows, int cols) { boolean[] flags = new boolean[9]; Arrays.fill(flags, false); for (int i = 0; i &lt; rows; i++) { for (int j = 0; j &lt; cols; j++) { char ch = board[x + i][y + j]; if (ch == '.') { continue; } int index = ch - '1'; if (flags[index]) { return false; } flags[index] = true; } } return true;} 官方解法： 1234567891011121314151617181920212223/** * 官方解法，一次遍历 */private boolean isValidSudoku2(char[][] board) { int[][] rows = new int[9][9]; int[][] columns = new int[9][9]; int[][][] subboxes = new int[3][3][9]; for (int i = 0; i &lt; 9; i++) { for (int j = 0; j &lt; 9; j++) { char c = board[i][j]; if (c != '.') { int index = c - '0' - 1; rows[i][index]++; columns[j][index]++; subboxes[i / 3][j / 3][index]++; if (rows[i][index] &gt; 1 || columns[j][index] &gt; 1 || subboxes[i / 3][j / 3][index] &gt; 1) { return false; } } } } return true;}","link":"/practice/leetcode/array/36.ValidSudoku/"},{"title":"268. 丢失的数字","text":"268. 丢失的数字一、题目描述给定一个包含 [0, n] 中 n 个数的数组 nums ，找出 [0, n] 这个范围内没有出现在数组中的那个数。 二、解题思路2.1 思路1既然数值是在 [0, n] 之间，也就是说可以把正确的数值设到数组 num[i] 上。 比如此时 i = 0, nums[i] = 3 那么就知道了 3 是存在的，并把它交换到它应该在的位置。 12nums[0] = nums[3];nums[3] = 3; 通过这样把值设到正确的位置。 最后再遍历一遍数组，如果索引和值不相等，表示当前索引的值丢失了。 2.2 思路2（官方解法）异或操作中，同一个数值异或1次，得到的结果为 0。 比如 3 ^ 3 = 0。 根据这种现象，可以通过异或数组中的所有值： 10 ^ nums[0] ^ 1 ^ nums[1] ... ^ (n - 1) ^ nums[n - 1] ^ n 在这里面，正常值有2个，它们异或之后结果是 0，而丢失的数字只有一个，所以异或结果就是丢失的数字。 官方解法也太骚了，这还真想不到。。。 三、复杂度分析1）思路1 时间 O(n) 空间 O(1) 1）思路2 时间 O(n) 空间 O(1) 四、参考代码1）解法1 12345678910111213141516171819202122232425/** * 丢失的数字 * * @param nums 数组 * @return 丢失的数字 */private int missingNumber(int[] nums) { int n = nums.length; for (int i = 0; i &lt; n; i++) { int t = nums[i]; while (0 &lt;= t &amp;&amp; t &lt; n &amp;&amp; nums[t] != nums[i]) { // 一直交换到正确的位置 int temp = nums[t]; nums[t] = nums[i]; nums[i] = temp; t = nums[i]; } } for (int i = 0; i &lt; n; i++) { if (nums[i] != i) { return i; } } return n;} 2）解法2 12345678910111213/** * 丢失的数字（官方解法） * * @param nums 数组 * @return 丢失的数字 */private int missingNumber2(int[] nums) { int missing = nums.length; for (int i = 0; i &lt; nums.length; i++) { missing ^= i ^ nums[i]; } return missing;}","link":"/practice/leetcode/array/268.MissingNumber/"},{"title":"204. 计数质数","text":"204. 计数质数一、题目描述统计所有小于非负整数 n 的质数的数量。 二、解题思路如果 x 是质数，那么大于 x 的 x 的倍数 2x, 3x ,… 一定不是质数。 不过实际上，对于一个质数 x，应该直接从 x⋅x 开始标记，因为 2x, 3x, … 这些数一定在 x⋅x 之前就被其他数的倍数标记过了。 例如 2x 已经被 2 标记了，3x 已经被 3 标记了。 三、时间复杂度 时间 O(n) 空间 O(n) 四、参考代码12345678910111213141516171819202122232425262728/** * 统计所有小于非负整数 n 的质数的数量 * @param n 非负整数 * @return 质数数量 */public int countPrimes(int n) { if (n &lt;= 1) { return 0; } boolean[] bools = new boolean[n]; Arrays.fill(bools, true); bools[0] = bools[1] = false; for (int i = 2; i &lt; Math.sqrt(n); i++) { if (!bools[i]) { continue; } for (int sum = i * i; sum &lt; n; sum += i) { bools[sum] = false; } } int count = 0; for (int i = 2; i &lt; n; i++) { if (bools[i]) { count++; } } return count;}","link":"/practice/leetcode/array/204.PrimesCount/"},{"title":"169. 多数元素","text":"169. 多数元素一、题目描述给定一个大小为 n 的数组，找到其中的多数元素。多数元素是指在数组中出现次数 大于⌊ n/2 ⌋的元素。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。 二、解题思路投票法，相同值 +1，不同值 -1。 因为有一半元素以上是同一个值，所以最终投票结果肯定是超过半数的那个元素。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码12345678910111213141516171819202122232425/** * 寻找出现次数大于一半的元素 * * @param nums 数组 * @return 大于一半数量的元素 */private int majorityElement(int[] nums) { // 投票法，相同值+1，不同值-1 // 因为有一半元素以上是同一个值，所以最终投票结果肯定是超过半数的那个元素 int x = nums[0]; int count = 1; for (int i = 1; i &lt; nums.length; i++) { if (count == 0) { x = nums[i]; count++; continue; } if (x == nums[i]) { count++; } else { count--; } } return x;}","link":"/practice/leetcode/array/169.MajorityElement/"},{"title":"34. 在排序数组中查找元素的第一个和最后一个位置","text":"34. 在排序数组中查找元素的第一个和最后一个位置一、题目描述给定一个按照升序排列的整数数组 nums，和一个目标值 target。 找出给定目标值在数组中的开始位置和结束位置。 如果数组中不存在目标值 target，返回[-1, -1]。 二、解题思路既然是排序好的数组，那就用二分查找法来直接找到对应的位置。 需要定位开始的位置和结束的位置，因此我的想法是： 分别找到 nums[l] &gt;= target 和 nums[r] &gt;= target + 1 的第一个索引位置 它们的范围 [l, r - 1] 就是所求的结果。 三、复杂度分析 时间 O(logn) 空间 O(1) 四、参考代码12345678910111213141516171819202122232425262728293031323334353637383940/** * 搜索指定目标值的范围 * @param nums 数组 * @param target 目标值 * @return 索引范围 */public int[] searchRange(int[] nums, int target) { int[] result = new int[2]; result[0] = result[1] = -1; int lp = findIndex(nums, target, 0, nums.length); if (0 &lt;= lp &amp;&amp; lp &lt; nums.length &amp;&amp; nums[lp] == target) { result[0] = lp; result[1] = findIndex(nums, target + 1, lp, nums.length) - 1; } return result;}/** * 查找大于等于 target 的第一个位置 * @param nums 数组 * @param target 目标值 * @param start 起始位置 * @param end 结束位置，不包括 * @return 大于等于target的第一个位置，或-1，或end */private int findIndex(int[] nums, int target, int start, int end) { if (end &lt;= start) { return -1; } int lp = start, rp = end; while (lp &lt; rp) { int m = lp + ((rp - lp) &gt;&gt; 1); if (target &lt;= nums[m]) { rp = m; } else { lp = m + 1; } } return rp;}","link":"/practice/leetcode/binary/34.SearchRange/"},{"title":"33.搜索旋转排序数组","text":"33.搜索旋转排序数组一、题目描述整数数组 nums 按升序排列，数组中的值 互不相同 。 在传递给函数之前，nums 在预先未知的某个下标 k（0 &lt;= k &lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（下标 从 0 开始 计数）。 例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。 给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的下标，否则返回 -1 。 二、解题思路循环数组可以分为2个有序的数组，所以可以利用二分搜索法查找。 首先取中值，那么中值左右两边的数组： 肯定有一边是有序的，另一边可能是有序的，也可能是循环有序的 如果是位于有序数组内，直接使用二分法查找即可； 如果是位于另外的数组，则按照之前的方式继续递归。 三、复杂度分析 时间 O(logn) 空间 O(1) 四、参考代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 搜索旋转排序数组 * @param nums 数组 * @param target 目标值 * @return 目标值的索引 */private int search(int[] nums, int target) { return find(nums, target, 0, nums.length - 1);}/** * 二分查找 * @param nums 数组 * @param target 目标值 * @param start 起始索引 * @param end 结束索引 * @return 目标值索引 */private int find(int[] nums, int target, int start, int end) { if (end &lt; start) { return -1; } int mp = start + ((end - start) &gt;&gt; 1); if (nums[mp] == target) { return mp; } if (nums[mp] &gt;= nums[start]) { // 中值在左边的升序序列中 if (nums[start] &lt;= target &amp;&amp; target &lt; nums[mp]) { // 左边 return find(nums, target, start, mp - 1); } else { // 右边 return find(nums, target, mp + 1, end); } } else { // 中值在右边的升序序列中 if (nums[mp] &lt; target &amp;&amp; target &lt;= nums[end]) { // 右边 return find(nums, target, mp + 1, end); } else { // 左边 return find(nums, target, start, mp - 1); } }}","link":"/practice/leetcode/binary/33.RotateSearch/"},{"title":"31. 下一个排列","text":"31. 下一个排列一、题目描述实现获取 下一个排列 的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。 如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。 必须 原地 修改，只允许使用额外常数空间。 1 &lt;= nums.length &lt;= 100 0 &lt;= nums[i] &lt;= 100 二、解题思路2.1 个人想法我自己的想法是，既然是下一个比它大的排序值，那肯定是改变值的位置越靠后越好。 比如 123，改变2的值变成132，肯定比改变1的值变成213更贴近原值。 首先就是要找到最靠后的可以交换的值 什么样的值是可以改变的？ 既然是求下一个大值，那么这个改变值的后续序列中，肯定要有比改变值大的 比如 42531，改变值就是2，因为531的后面都没有比它们大的值，而2的后续值53比2大，这个时候改变2的值，就能获取比它更大的值。 后续序列中比改变值大的可能有多个，那应该改变哪个值呢？ 既然是下一个大值，那肯定是改变的越小越好 比如前面的 42531，2换成3的改变是最小的，因为3比2大，并且2和3最接近。 交换之后就可以了吗？ 实际还不行，交换后的值为 43521，但是可以发现，43125 &lt; 43521 所以除了交换值以外，还需要对后续的序列进行升序排序 总的步骤可以分为3步： 找到要改变的值，它的后续值中有比它大的值，比如前面说的2； 找到后续值中比它大的最小值，作为改变值即将交换的值，比如前面说的2和3； 对后续的序列进行升序排序。 2.2 官方解法官方的思路其实和我的差不多，但是比我的更精妙，时间复杂度也比我的低得多。 第一步，也是找出改变值，但是它不像我那样遍历寻找，而是倒序找到第一个逆序元素，也就是满足 nums[i] &lt; nums[i + 1]，num[i] 就是需要改变的值。为什么这样做？其实看前面的例子 42531，确实可以发现，2是满足 nums[i] &lt; nums[i + 1]，不得不说，官方的这个想法比我好多了~~ 第二步，找出需要交换的值，也就是比改变值大的最小值。官方的更直接，前面第一步找的就是第一个逆序元素，也就意味着，改变值之后的序列，是一个降序序列，从我前面的例子可以看出，2的后续序列531确实是降序的，所以只要从后往前找到第一个比2大的值，就是要最小的比2大的值，也就是3。 第三步，排序，因为前面知道了改变值的后续序列是降序的，而且交换之后，实际上也是降序的，如交换后43521，521依旧是降序的。所以只要把降序的521倒过来变成125，就是升序了，无需做排序操作（官方牛逼~~） 总之，虽然思路是差不多的，但是官方的精妙得多，时间复杂度比我低了整整一个等级~~~~ 三复杂度分析1）个人解法 时间 O(n^2) 空间 O(1) 2）官方解法 时间 O(n) 空间 O(1) 四、参考代码1）个人代码 1234567891011121314151617181920212223242526272829303132333435363738/** * 31. 下一个排列 * @param nums 数组 */private void nextPermutation(int[] nums) { for (int i = nums.length - 2; i &gt;= 0; i--) { int index = findMinMax(nums, nums[i], i + 1, nums.length); if (index &gt; -1) { int temp = nums[i]; nums[i] = nums[index]; nums[index] = temp; Arrays.sort(nums, i + 1, nums.length); return; } } Arrays.sort(nums);}/** * 查找比k大的最小值的索引 * @param nums 数组 * @param k 指定值 * @param start 起始索引 * @param end 结束索引 * @return 索引，或-1 */private int findMinMax(int[] nums, int k, int start, int end) { int maxIndex = -1; for (int i = start; i &lt; end; i++) { if (nums[i] &lt;= k) { continue; } if (maxIndex == -1 || nums[maxIndex] &gt; nums[i]) { maxIndex = i; } } return maxIndex;} 2）官方代码 123456789101112131415161718192021222324252627/** * 31. 下一个排列 * @param nums 数组 */private void nextPermutation(int[] nums) { // 寻找第一个逆序值 int index = nums.length - 2; while (index &gt;= 0 &amp;&amp; nums[index] &gt;= nums[index + 1]) { index--; } // 交换比逆序值大的最小值 for (int i = nums.length - 1; index &gt;= 0 &amp;&amp; i &gt; index; i--) { if (nums[i] &gt; nums[index]) { int temp = nums[i]; nums[i] = nums[index]; nums[index] = temp; break; } } // 后面这部分是降序的，倒过来转成升序 int lp = index + 1, rp = nums.length - 1; while (lp &lt; rp) { int temp = nums[lp]; nums[lp++] = nums[rp]; nums[rp--] = temp; }}","link":"/practice/leetcode/array/31.NextPermutation/"},{"title":"122. 买卖股票的最佳时机 II","text":"122. 买卖股票的最佳时机 II一、题目描述给定一个数组 prices ，其中prices[i] 是一支给定股票第 i 天的价格。 设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。 注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 二、解题思路想要获取最大收益，最好的情况就是在谷值买入，峰值卖出。 但是如果谷值和峰值都很多的情况下，这个时候该什么时候买入卖出呢？ 最优的情况是在相邻的谷值和峰值买入卖出，收益才能最大。 验证过程： 比如谷值是 a，峰值 b（b &gt; a，否则收益为负数），此时收益就是： 1b - a 假设 a，b之间还存在另外的峰值 c, 谷值 d，其中有 d &lt; c。 那么相邻谷值峰值买入卖出的收益是： 1c - a + b - d = b - a + c - d &gt; b - a 也就是说，如果在一对谷值峰值之间，还存在别的谷值峰值，那它们取得的收益就不是最大值。 因此，相邻谷值峰值买入卖出的情况下能够获取最大收益。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码12345678910111213141516/** * 最大收益 * * @param prices 价格数组 * @return 最大收益 */private int maxProfit(int[] prices) { int sumVal = 0, n = prices.length; for (int rp = 1; rp &lt; n; rp++) { if (prices[rp] &gt; prices[rp - 1]) { // 谷值到峰值之间的上升值 sumVal += prices[rp] - prices[rp - 1]; } } return sumVal;}","link":"/practice/leetcode/array/122.MaxProfit2/"},{"title":"121. 买卖股票的最佳时机","text":"121. 买卖股票的最佳时机一、题目描述给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。 你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。 设计一个算法来计算你所能获取的最大利润。 返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。 二、解题思路1、找到一个小值，然后从这个小值开始往右查找大值，并更新这期间的最大差值2、在查找大值的过程中，如果遇到一个更小值，则更新小值的位置，重新进行1步骤 12345678910111213141516171819 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 3 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 2 - 2 = 0 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 3 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 3 - 2 = 1 lp;rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 3 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 1 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 3 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 4 - 1 = 3 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 3 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 6 - 1 = 5 类似这种效果。 但是，后面的差值就不一定比前面的差值大。 举个例子，把上面的 3 改成 9： 123456789101112131415 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 9 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 9 - 2 = 7 lp;rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 9 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 7 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 9 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 7 &gt; 4 - 1 = 3 lp rp ___ ___ ___ ___ ___ ___ ___ | 2 | 2 | 9 | 1 | 4 | 5 | 6 | =&gt; maxDiffVal = 7 &gt; 6 - 1 = 5 这种情况下，最大值就是之前的差值，所以更新最大差值时需要和之前的比较过才行。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码123456789101112131415161718192021/** * 最大收益 * * @param prices 价格数组 * @return 最大收益 */private int maxProfit(int[] prices) { int maxDiffVal = 0; int lp = 0, n = prices.length; for (int rp = lp; rp &lt; n; rp++) { if (prices[rp] &lt; prices[lp]) { // 找到更小值，那后面的最大差值就和之前的最小值没关系了 // 后面就用最新的最小值来计算差值 lp = rp; } else if (prices[rp] - prices[lp] &gt; maxDiffVal) { // 找到更大值，更新最新的差值 maxDiffVal = prices[rp] - prices[lp]; } } return maxDiffVal;}","link":"/practice/leetcode/array/121.MaxProfit/"},{"title":"18. 四数之和","text":"18. 四数之和一、题目描述给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。 注意：答案中不可以包含重复的四元组。 0 &lt;= nums.length &lt;= 200 -109 &lt;= nums[i] &lt;= 109 -109 &lt;= target &lt;= 109 二、解题思路与三数之和类似，先排序，然后 把 a + b + c + d = target 变成三数之和 a + b + c = target - d 最后按照三数之和求值即可。 三、复杂度分析 时间 O(n^3) 空间 O(1) 四、参考代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * 四数之和 * @param nums 数组 * @param target 目标值 * @return 四元组列表 */private List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (nums.length &lt; 4) { return result; } Arrays.sort(nums); List&lt;Integer&gt; values = new ArrayList&lt;&gt;(4); for (int i = 0; i &lt; nums.length - 3; i++) { // 去重 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) { continue; } values.add(nums[i]); List&lt;List&lt;Integer&gt;&gt; sumList = threeSum(nums, target - nums[i], i + 1, nums.length - 1, values); if (sumList.size() &gt; 0) { result.addAll(sumList); } values.remove(values.size() - 1); } return result;}/** * 三数之和 * @param nums 数组 * @return 所有三元组 */private List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums, int target, int start, int end, List&lt;Integer&gt; values) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); for (int i = start; i &lt; nums.length - 2; i++) { // 去重 if (i &gt; start &amp;&amp; nums[i] == nums[i - 1]) { continue; } values.add(nums[i]); List&lt;List&lt;Integer&gt;&gt; sumList = twoSum(nums, target - nums[i], i + 1, nums.length - 1, values); if (sumList.size() &gt; 0) { result.addAll(sumList); } values.remove(values.size() - 1); } return result;}/** * 求2数之和 * @param nums 升序数组 * @param target 两数和 * @param start 起始地址 * @param end 结束地址 * @return 两数，或null */private List&lt;List&lt;Integer&gt;&gt; twoSum(int[] nums, int target, int start, int end, List&lt;Integer&gt; values) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); int lp = start, rp = end; int size = values.size() + 2; while (lp &lt; rp) { int temp = nums[lp] + nums[rp]; if (temp == target) { List&lt;Integer&gt; sumList = new ArrayList&lt;&gt;(size); sumList.addAll(values); sumList.add(nums[lp]); sumList.add(nums[rp]); result.add(sumList); // 去重 while (lp &lt; rp &amp;&amp; nums[lp] == nums[++lp]); while (lp &lt; rp &amp;&amp; nums[rp] == nums[--rp]); } else if (temp &lt; target) { lp++; } else { rp--; } } return result;}","link":"/practice/leetcode/array/18.FourSum/"},{"title":"15. 三数之和","text":"15. 三数之和一、题目描述给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。 注意：答案中不可以包含重复的三元组。 0 &lt;= nums.length &lt;= 3000 -105 &lt;= nums[i] &lt;= 105 二、解题思路3个数，如果直接使用3层循环的话，估计应该会超时，所以只能想其他办法。 a + b + c = 0 可以转成 b + c = -a，那么就相当于查找2数之和，这个就变得简单了 3元组去重的问题： 通过排序，保证每次的 a、b 不一样，那么 c 肯定不同，3元组也就不一样了 至于进一步的优化： 既然3个数相加等于0，那么肯定有一个数是非正数 对数组进行排序后，保证最小的那个数是非正数就行 三、复杂度分析 时间 O(n^2) 空间 O(1) 四、参考代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 三数之和 * @param nums 数组 * @return 所有三元组 */private List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (nums.length &lt; 3) { return result; } Arrays.sort(nums); if (nums[0] &gt; 0 || nums[nums.length - 1] &lt; 0) { return result; } for (int i = 0; i &lt; nums.length &amp;&amp; nums[i] &lt;= 0; i++) { List&lt;List&lt;Integer&gt;&gt; sumList = twoSum(nums, -nums[i], i + 1, nums.length - 1); if (sumList.size() &gt; 0) { result.addAll(sumList); } // 去重 while (i &lt; nums.length - 1 &amp;&amp; nums[i] == nums[i + 1]) { i++; } } return result;}/** * 求2数之和 * @param nums 升序数组 * @param sum 两数和 * @param start 起始地址 * @param end 结束地址 * @return 两数，或null */private List&lt;List&lt;Integer&gt;&gt; twoSum(int[] nums, int sum, int start, int end) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); int lp = start, rp = end; while (lp &lt; rp) { int temp = nums[lp] + nums[rp]; if (temp == sum) { List&lt;Integer&gt; sumList = new ArrayList&lt;&gt;(3); sumList.add(-sum); sumList.add(nums[lp]); sumList.add(nums[rp]); result.add(sumList); // 去重 while (lp &lt; rp &amp;&amp; nums[lp] == nums[++lp]); while (lp &lt; rp &amp;&amp; nums[rp] == nums[--rp]); } else if (temp &lt; sum) { lp++; } else { rp--; } } return result;}","link":"/practice/leetcode/array/15.ThreeSum/"},{"title":"16. 最接近的三数之和","text":"16. 最接近的三数之和一、题目描述给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和 假定每组输入只存在唯一答案。 3 &lt;= nums.length &lt;= 10^3 -10^3 &lt;= nums[i] &lt;= 10^3 -10^4 &lt;= target &lt;= 10^4 二、解题思路原理和求3数之和一样，把它转换成找2数之和，问题就变得稍微容易一些。 a + b + c = target 可以转成 b + c = target - a，那么就相当于查找2数之和 2数之和就快很多了。 三、复杂度分析 时间 O(n^2) 空间 O(1) 四、参考代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 最近的3数之和 * @param nums 数组 * @param target 目标值 * @return 3数之和 */private int threeSumClosest(int[] nums, int target) { int closestSum = 0; Arrays.sort(nums); for (int i = 0; i &lt; nums.length - 2; i++) { int sum = twoSumClosest(nums, target - nums[i], i + 1, nums.length - 1); sum += nums[i]; if (sum == target) { return sum; } // 取最接近的值 if (i == 0 || Math.abs(sum - target) &lt; Math.abs(closestSum - target)) { closestSum = sum; } } return closestSum;}/** * 最近的2数之和 * @param nums 排序数组 * @param target 目标值 * @param start 起始索引 * @param end 终止索引 * @return 2数之和 */private int twoSumClosest(int[] nums, int target, int start, int end) { int lp = start, rp = end; int sum = nums[lp] + nums[rp]; while (lp &lt; rp) { int temp = nums[lp] + nums[rp]; if (temp == target) { return target; } if (Math.abs(temp - target) &lt; Math.abs(sum - target)) { sum = temp; } if (temp &lt; target) { lp++; } else { rp--; } } return sum;}","link":"/practice/leetcode/array/16.ThreeSumClosest/"},{"title":"6186. 按位或最大的最小子数组长度","text":"6186. 按位或最大的最小子数组长度一、题目描述给你一个长度为 n 下标从 0 开始的数组 nums ，数组中所有数字均为非负整数。 对于 0 到 n - 1 之间的每一个下标 i ，你需要找出 nums 中一个 最小 非空子数组，它的起始位置为 i （包含这个位置），同时有 最大 的 按位或运算值 。 换言之，令 Bij 表示子数组 nums[i…j] 的按位或运算的结果，你需要找到一个起始位置为 i 的最小子数组，这个子数组的按位或运算的结果等于 max(Bik) ，其中 i &lt;= k &lt;= n - 1 。 一个数组的按位或运算值是这个数组里所有数字按位或运算的结果。 请你返回一个大小为 n 的整数数组 answer，其中 answer[i]是开始位置为 i ，按位或运算结果最大，且 最短 子数组的长度。 子数组 是数组里一段连续非空元素组成的序列。 示例： 输入：nums = [1,0,2,1,3]输出：[3,3,2,2,1]解释：任何位置开始，最大按位或运算的结果都是 3 。 下标 0 处，能得到结果 3 的最短子数组是 [1,0,2] 。 下标 1 处，能得到结果 3 的最短子数组是 [0,2,1] 。 下标 2 处，能得到结果 3 的最短子数组是 [2,1] 。 下标 3 处，能得到结果 3 的最短子数组是 [1,3] 。 下标 4 处，能得到结果 3 的最短子数组是 [3] 。所以我们返回 [3,3,2,2,1] 。 提示： n == nums.length 1 &lt;= n &lt;= 105 0 &lt;= nums[i] &lt;= 109 二、解题思路整数就 32 位，题目都是非负整数，所以或运算后最多也就是低 31 位全都是 1。 或运算结果越大，实际就是 31 位中 1 的数量越多 要是知道 31 位整数中每一位 1 出现的位置 indexes，那就能知道或运算达到最大值的地方。 或运算结果最大的最短子数组，就是： 从当前索引 i，到 32 位 1 索引最大值的区间 [i, max(indexes)] 题目限制了范围大于 0 小于 10^9，所以只需要低 30 位就够了。 三、复杂度分析 时间 O(n) 空间 O(1) 四、参考代码123456789101112131415161718192021222324private int[] smallestSubarrays(int[] nums) { // 整数低 30 位出现 1 的最小索引 int[] indexes = new int[30]; Arrays.fill(indexes, -1); int n = nums.length; int[] ans = new int[n]; for (int i = n - 1; i &gt;= 0; i--) { int maxIndex = i; for (int j = 0; j &lt; 30; j++) { int exist = (nums[i] &gt;&gt;&gt; j) &amp; 1; if (exist &gt; 0) { // 当前数字有第 j 位的 1 // 因为是求最短子数组，所以更新索引为更小值 indexes[j] = i; } else if (indexes[j] != -1) { // 找出 30 位 1 索引的最大值 maxIndex = Math.max(maxIndex, indexes[j]); } } ans[i] = maxIndex - i + 1; } return ans;}","link":"/practice/leetcode/bit/6186.SmallestSubarrays/"},{"title":"05_指令集和解释器","text":"指令集和解释器Java虚拟机顾名思义，就是一台虚拟的机器，而字节码（bytecode）就是运行在这台虚拟机器上的机器码。 一、字节码指令1.1 指令结构字节码中存放编码后的 Java 虚拟机指令： 每条指令都以一个单字节的操作码（opcode）开头。 由于只使用一字节表示操作码，Java 虚拟机最多只能支持 256 条指令。 到第八版为止，Java 虚拟机规范已经定义了205条指令，操作码分别是0(0x00)到 202(0xCA)、254(0xFE)和 255(0xFF)。 Java虚拟机使用的是变长指令，操作码后面可以跟零字节或多字节的操作数（operand）。 比如 0xB20002 这条指令，B2 表示该指令的操作码，0002 就表示操作数。 1.2 指令助记符为了便于记忆，Java虚拟机规范给每个操作码都指定了一个助记符（mnemonic）。 比如，操作码是 0x00 的助记符是 nop（no operation）。 操作数栈和局部变量表只存放数据的值（Slot），并不记录数据类型。 所以指令必须知道自己在操作什么类型的数据，即指令绑定了数据类型 例如，iadd 指令就是对 int 值进行加法操作；dstore 指令把操作数栈顶的double值弹出，存储到局部变量表中；areturn 从方法中返回引用值。 1.3 指令类型Java 虚拟机规范把已经定义的205条指令按用途分成了11类，分别是： 常量（constants）指令 加载（loads）指令 存储（stores）指令 操作数栈（stack）指令 数学（math）指令 转换（conversions）指令 比较（comparisons）指令 控制（control）指令 引用（references）指令 扩展（extended）指令 保留（reserved）指令 保留指令一共有3条。 其中1条是留给调试器的，用于实现断点，操作码是 202(0xCA)，助记符是 breakpoint； 另外2条留给 Java 虚拟机实现内部使用，操作码分别是 254(0xFE) 和 266(0xFF)，助记符是 impdep1 和 impdep2。 这3条保留指令不允许出现在class文件中。 二、指令运行2.1 指令循环虚拟机的运行过程，就是循环执行指令的过程，伪代码大致是这样的： 12345do { atomically calculate pc and fetch opcode at pc; if (operands) fetch operands; execute the action for the opcode;} while (there is more to do); 每次循环都包含三个部分： 计算pc 指令解码 指令执行 上面的伪代码转成 java 代码的话，大概是这样的： 12345678910while (true) { // 计算PC pc = calculatePC() // 指令解码 opcode = bytecode[pc] inst = createInst(opcode) inst.fetchOperands(bytecode) // 指令执行 inst.execute()} 2.2 指令接口根据上述的伪代码，创建指令接口 Instruction，作为所有指令实现的基本接口： 1234567public interface Instruction { void execute(Frame frame); void fetchOperands(ByteCodeReader reader);} 接口包括2个方法：取数（fetchOperands）和执行（execute）。 2.2 指令解码接下来就是怎么把字节码解析成指令接口了。 因为需要操作字节，所以定义字节码读取类 ByteCodeReader，用于读取字节码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ByteCodeReader { /** 字节码字节数组 */ private byte[] bytes; /** 字节缓冲读取 */ private ByteBuffer buf; public ByteCodeReader(byte[] bytes) { reset(bytes, 0); } public void reset(byte[] bytes, int position) { this.bytes = bytes; buf = ByteBuffer.wrap(bytes); buf.order(ByteOrder.BIG_ENDIAN); // 大端 buf.position(position); } public int getPosition() { return buf.position(); } public byte readByte() { return buf.get(); } public int readShort() { return buf.getShort(); } public int readInt() { return buf.getInt(); } public int readInt8() { return readByte(); } public Uint8 readUint8() { byte b = buf.get(); int val = 0x0FF &amp; b; return new Uint8(val); } public int readInt16() { return readShort(); } public Uint16 readUint16() { short s = buf.getShort(); int val = 0x0FFFF &amp; s; return new Uint16(val); } public Uint32 readUint32() { int i = buf.getInt(); long val = 0x0FFFFFFFFL &amp; i; return new Uint32(val); } public byte[] readBytes(Uint32 length) { int len = (int) length.value(); byte[] bytes = new byte[len]; buf.get(bytes); return bytes; } public void skipPadding() { while (getPosition() % 4 != 0) { readUint8(); } }} bytes 存放原始的字节码字节数组，buf 是 java 中的 ByteBuffer 类对象，可以对字节进行操作。 因为有些数据是占用不止1个机器字的，所以需要定义字节数组是大端，还是小端，这里设定是大端。 getPosition() 可用于获取当前读到的位置，这个主要是用于后面程序计数器 PC 的定位。 剩余的则是读取不同数据格式的方法，和 classfile 的读取差不多。 三、指令集3.1 抽象指令基类接口包括2个方法：取数（fetchOperands）和执行（execute）。 很多指令都具有相同的操作数类型，所以定义一些基类来方便实现。 有些指令是没有操作数的，定义一个无操作数基类 NoOperandsInstruction： 12345678910111213public class NoOperandsInstruction implements Instruction { @Override public void execute(Frame frame) { // 什么也不做 } @Override public void fetchOperands(ByteCodeReader reader) { // 什么也不做 }} 有些指令需要访问局部变量表，局部变量表索引是一个8位无符号整数，定义一个基类 Index8Instruction： 123456789101112131415public class Index8Instruction implements Instruction { protected int index; protected Uint8 source; @Override public void execute(Frame frame) { } @Override public void fetchOperands(ByteCodeReader reader) { source = reader.readUint8(); index = source.value(); }} 有些指令需要访问常量池，常量池索引是一个16位无符号整数，定义一个基类 Index16Instruction： 123456789101112131415public class Index16Instruction implements Instruction { protected int index; protected Uint16 source; @Override public void execute(Frame frame) { } @Override public void fetchOperands(ByteCodeReader reader) { source = reader.readUint16(); index = source.value(); }} 还有跳转指令，它的操作数是16位无符号整数，定义基类 BranchInstruction： 12345678910111213141516171819202122232425public class BranchInstruction implements Instruction { /** 16位有符号整数偏移 */ protected int offset; @Override public void execute(Frame frame) { } @Override public void fetchOperands(ByteCodeReader reader) { // 注意是16位有符号整数 offset = reader.readShort(); } /** * 指令跳转 * @param frame 栈帧 */ protected void branch(Frame frame) { int pc = frame.getThread().getPc(); frame.setNextPc(pc + offset); }} 3.2 常量（constants）指令常量指令，把常量推入操作数栈顶。 常量的来源有3个： 隐含在操作码 操作数 运行时常量池 下面是这几种常量来源的具体实现。 3.2.1 隐含在操作码的常量所谓的隐含在操作码里，实际上指令绑定了常量，在助记符里就能看出来常量值。 比如指令 iconst_3，就是整数常量3；iconst_m1 就是整数常量-1；dconst_1 就是双精度浮点数1。 这种隐含在操作码的指定，有15条： 123456789101112131415aconst_nulliconst_m1iconst_0iconst_1iconst_2iconst_3iconst_4iconst_5lconst_0lconst_1fconst_0fconst_1fconst_2dconst_0dconst_1 指令这些隐藏常量，是因为这些常量比较常用，懒得浪费1个字节去额外存储。 aconst_null 指令把 null 引用推入操作数栈顶： 12345678public class AConstNull extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().pushRef(null); }} iconst_m1 指令把 int 型 -1 推入操作数栈顶： 12345678public class IConstM1 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().pushInt(-1); }} dconst_0 指令把 double 型 0 推入操作数栈顶： 12345678public class DConst0 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().pushDouble(0.0); }} 其余常量指令代码都差不多，只是值不同，不再列出。 3.2.2 操作数常量有2个指令，是把操作数当作常量，放入操作数栈中： 12bipushsipush bipush 是从操作数中读取一个 byte 整数，放入操作数栈中： 123456789101112131415public class BIPush implements Instruction { private int val; @Override public void execute(Frame frame) { frame.getOpStack().pushInt(val); } @Override public void fetchOperands(ByteCodeReader reader) { // 注意是8位有符号整数 val = reader.readInt8(); }} sipush 是从操作数中读取一个 short 整数，放入操作数栈中； 123456789101112131415public class SIPush implements Instruction { private int val; @Override public void execute(Frame frame) { frame.getOpStack().pushInt(val); } @Override public void fetchOperands(ByteCodeReader reader) { // 注意是16位有符号整数 val = reader.readInt16(); }} 注意，bipush 和 sipush 的操作数都是有符号整数。 3.2.3 常量池常量还有几条指令，是从常量池中获取常量，放入操作数栈中： 123idcidcwidc2w idc 的操作数是8位无符号整数，用于获取 int、float 这些类型的常量： 12345678910111213141516public class IDC extends Index8Instruction { @Override public void execute(Frame frame) { OperandStack stack = frame.getOpStack(); ConstantPool cp = frame.getMethod().getClazz().getConstantPool(); Constant constant = cp.getConstant(index); if (constant instanceof IntegerConstant) { stack.pushInt(((IntegerConstant) constant).value()); } else if (constant instanceof FloatConstant) { stack.pushFloat(((FloatConstant) constant).value()); } else { System.out.println(&quot;Unsupported Type: &quot; + constant); } }} idcw 的操作数是16位无符号整数，用于获取 int、float 这些类型的常量： 12345678910111213141516public class IDCW extends Index16Instruction { @Override public void execute(Frame frame) { OperandStack stack = frame.getOpStack(); ConstantPool cp = frame.getMethod().getClazz().getConstantPool(); Constant constant = cp.getConstant(index); if (constant instanceof IntegerConstant) { stack.pushInt(((IntegerConstant) constant).value()); } else if (constant instanceof FloatConstant) { stack.pushFloat(((FloatConstant) constant).value()); } else { System.out.println(&quot;Unsupported Type: &quot; + constant); } }} idc2w 的操作数是16位无符号整数，用于获取 long、double 类型的常量： 12345678910111213141516public class IDC2W extends Index16Instruction { @Override public void execute(Frame frame) { OperandStack stack = frame.getOpStack(); ConstantPool cp = frame.getMethod().getClazz().getConstantPool(); Constant constant = cp.getConstant(index); if (constant instanceof LongConstant) { stack.pushLong(((LongConstant) constant).value()); } else if (constant instanceof DoubleConstant) { stack.pushDouble(((DoubleConstant) constant).value()); } else { throw new ClassFormatError(&quot;Constant: &quot; + constant); } }} idc、idcw 的作用差不多，只是操作数的范围不一样。 idc2w 是专门用于 long、double 这种双字类型的指令。 3.3 加载（loads）指令加载指令，负责从局部变量表获取变量，然后推入操作数栈顶。 加载指令共33条。 按照操作数类型分的话，可以分为6种： aload 系列指令：操作引用类型变量 dload 系列指令：操作 double 类型变量 fload 系列指令：操作 float 变量 iload 系列指令：操作 int 变量 lload 系列指令：操作 long 变量 xaload 系列指令：操作数组变量 实际上各个加载指令都差不多，只是操作数的类型不同。 从局部变量表中获取变量，需要指定变量索引，索引的来源有2个： 隐含在操作码中 操作数 这2种来源和前面的常量指令差不多。 这里给几个例子： iload_1 指令，把局部变量表中的 1 号整型变量，推入操作数栈中： 12345678public class ILoad1 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().pushInt(frame.getLocalVars().getInt(1)); }} dload_2 指令，把局部变量表中的 2 号 double 变量，推入操作数栈中： 12345678public class DLoad2 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().pushDouble(frame.getLocalVars().getDouble(2)); }} lload 指令，从操作数中获取索引 index，根据索引去局部变量表中加载第 index 号的 long 变量，推入操作数栈中： 123456789public class LLoad extends Index8Instruction { @Override public void execute(Frame frame) { // index 是 Index8Instruction 读取的8位无符号整数 frame.getOpStack().pushLong(frame.getLocalVars().getLong(index)); }} 类似的指令还有 iload、fload、dload、aload 等。 需要注意，long、double 类型实际上是会占用局部变量表和操作数栈的2个插槽 Slot 的，之前已经封装好了。 3.4 存储（stores）指令存储指令，负责从操作数栈中弹出变量，放入局部变量表中。 存储指令和加载指令是反过来操作的，所以指令都差不多，实现也就是反过来就行。 这里给几个例子： astore_0 指令，从操作数栈中弹出引用变量，放入局部变量表的 0 号位置： 12345678public class AStore0 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getLocalVars().setRef(0, frame.getOpStack().popRef()); }} fstore_2 指令，从操作数栈中弹出 float 变量，放入局部变量表的 2 号位置： 12345678public class FStore2 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getLocalVars().setFloat(2, frame.getOpStack().popFloat()); }} dstore 指令，在操作数中获取索引 index，从操作数栈中弹出 double 变量，放入局部变量表的 index 号位置： 123456789public class DStore extends Index8Instruction { @Override public void execute(Frame frame) { // index 是 Index8Instruction 读取的8位无符号整数 frame.getLocalVars().setDouble(index, frame.getOpStack().popDouble()); }} 其余指令实现都差不多，基本是和加载指令反过来而已。 3.5 操作数栈（stack）指令操作数栈指令，是直接对操作数栈中的数据进行操作。 共9条，包括： 弹出指令：pop 系列指令将栈顶变量弹出 复制指令：dup 系列指令复制栈顶变量 交换指令：swap 指令交换栈顶的两个变量 操作数栈指令，直接操作的是插槽 Slot，所以并不关系里面数据的类型。 因为只操作 Slot，所以需要给 OperandStack 增加2个操作 Slot 的方法： 123456789101112131415public class OperandStack { public void pushSlot(Slot slot) { slots[size].setSlot(slot); size++; } public Slot popSlot() { size--; Slot slot = slots[size]; Slot copySlot = new Slot(slot); slot.setSlot(null); return copySlot; }} 这里的弹出 Slot 和推入 Slot，实际上并不是直接替换 Slot 对象，而是改变了它里面的值。 这是为了保证 Slot 对象一直存在，用于占位，避免空指针异常。 3.5.1 弹出指令弹出指令包括 pop 和 pop2。 pop 指令用于弹出 int、float 等占用1个插槽位置的变量： 1234567public class Pop extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().popSlot(); }} pop2 指令用于弹出 long、double 等占用2个插槽位置的变量。 12345678public class Pop2 extends NoOperandsInstruction { @Override public void execute(Frame frame) { frame.getOpStack().popSlot(); frame.getOpStack().popSlot(); }} 3.5.2 复制指令复制指令，用于复制操作数栈的变量。 dup 指令是复制栈顶的单个变量： 123456789public class Dup extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot); frame.getOpStack().pushSlot(slot); }} dup2 指令是复制栈顶的2个变量： 123456789101112public class Dup2 extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot1 = frame.getOpStack().popSlot(); Slot slot2 = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); }} dupx1 指令是复制栈顶的单个变量，但复制变量不是推入栈顶，具体看实现： 123456789101112public class DupX1 extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot1 = frame.getOpStack().popSlot(); Slot slot2 = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot1); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); }} dupx2 指令是复制栈顶的单个变量，但复制变量不是推入栈顶，具体看实现： 12345678910111213public class DupX2 extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot1 = frame.getOpStack().popSlot(); Slot slot2 = frame.getOpStack().popSlot(); Slot slot3 = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot1); frame.getOpStack().pushSlot(slot3); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); }} dup2x1 指令是复制栈顶的2个变量，但复制变量不是推入栈顶，具体看实现： 1234567891011121314public class Dup2X1 extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot1 = frame.getOpStack().popSlot(); Slot slot2 = frame.getOpStack().popSlot(); Slot slot3 = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); frame.getOpStack().pushSlot(slot3); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); }} dup2x2 指令是复制栈顶的2个变量，但复制变量不是推入栈顶，具体看实现： 12345678910111213141516public class Dup2X2 extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot1 = frame.getOpStack().popSlot(); Slot slot2 = frame.getOpStack().popSlot(); Slot slot3 = frame.getOpStack().popSlot(); Slot slot4 = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); frame.getOpStack().pushSlot(slot4); frame.getOpStack().pushSlot(slot3); frame.getOpStack().pushSlot(slot2); frame.getOpStack().pushSlot(slot1); }} 除了 dup、dup2，其他几个指令还是挺麻烦的。 3.5.3 交换指令交换指令，负责交换操作数栈的2个变量。 只有1条指令 swap： 12345678910public class Swap extends NoOperandsInstruction { @Override public void execute(Frame frame) { Slot slot1 = frame.getOpStack().popSlot(); Slot slot2 = frame.getOpStack().popSlot(); frame.getOpStack().pushSlot(slot1); frame.getOpStack().pushSlot(slot2); }} 3.6 数学（math）指令数学指令，包括算术（加、减、乘、除）、位移、布尔、自增等基本指令。 共 37 条。 数学指令，都是先从操作数栈中弹出变量，执行数学运算后，再把结果推回操作数栈。 这里给几个例子： 算术指令，整数加法指令 idd： 12345678910public class IAdd extends NoOperandsInstruction { @Override public void execute(Frame frame) { int val1 = frame.getOpStack().popInt(); int val2 = frame.getOpStack().popInt(); int val = val2 + val1; frame.getOpStack().pushInt(val); }} 算术指令，double 类型减法指令 dsub： 12345678910public class DSub extends NoOperandsInstruction { @Override public void execute(Frame frame) { double val1 = frame.getOpStack().popDouble(); double val2 = frame.getOpStack().popDouble(); double val = val2 - val1; frame.getOpStack().pushDouble(val); }} 位移指令，int 整型左移指令 ishl： 12345678910public class IShl extends NoOperandsInstruction { @Override public void execute(Frame frame) { int val1 = frame.getOpStack().popInt(); int val2 = frame.getOpStack().popInt(); int val = val2 &lt;&lt; (val1 &amp; 0x1f); frame.getOpStack().pushInt(val); }} 位移指令，long 长整型无符号右移指令 lushr： 1234567891011public class LUShr extends NoOperandsInstruction { @Override public void execute(Frame frame) { // 注意位移操作数是一个int类型的 int val1 = frame.getOpStack().popInt(); long val2 = frame.getOpStack().popLong(); long val = val2 &gt;&gt;&gt; (val1 &amp; 0x3f); frame.getOpStack().pushLong(val); }} 布尔指令，int 整型按位或指令 or： 12345678910public class IOr extends NoOperandsInstruction { @Override public void execute(Frame frame) { int val1 = frame.getOpStack().popInt(); int val2 = frame.getOpStack().popInt(); int val = val2 | val1; frame.getOpStack().pushInt(val); }} 自增指令 iinc： 12345678910111213141516171819202122232425public class IInc implements Instruction { /** * 局部变量索引 */ private Uint8 index; /** * 常量 */ private int value; @Override public void execute(Frame frame) { int val = frame.getLocalVars().getInt(index.value()); val += value; frame.getLocalVars().setInt(index.value(), val); } @Override public void fetchOperands(ByteCodeReader reader) { index = reader.readUint8(); // 注意这是一个8位的有符号整数 value = reader.readInt8(); }} 数学指令还是比较简单的，不过像自增指令 iinc 就需要特别注意操作数类型。 3.7 转换（conversions）指令转换指令，是指对类型进行强制转换，比如 double 转 long，float 转 int 等。 共15条，这里暂时实现基本类型的转换。 引用类型的强制转换，会走 checkcast 指令，这里还没有办法实现。 这里给出几个例子： i2x 系列指令，i2l 是 int 转 long 类型： 12345678public class I2L extends NoOperandsInstruction { @Override public void execute(Frame frame) { long l = frame.getOpStack().popInt(); frame.getOpStack().pushLong(l); }} l2x 系列指令，l2d 是 long 转 double 类型： 123456789public class L2D extends NoOperandsInstruction { @Override public void execute(Frame frame) { long l = frame.getOpStack().popLong(); double d = (double) l; frame.getOpStack().pushDouble(d); }} f2x 系列指令，f2i 是 float 转 int 类型： 123456789public class F2I extends NoOperandsInstruction { @Override public void execute(Frame frame) { float f = frame.getOpStack().popFloat(); int i = (int) f; frame.getOpStack().pushInt(i); }} 转换类型没什么特别的，都比较简单。 3.8 比较（comparisons）指令比较指令，是比较变量的值，然后做出指定的操作。 共 19 条。 比较指令可分为2类： 比较后，结果推入操作数栈顶 比较后，根据结果跳转 比较指令主要用于实现 if-else、for、while 等语句。 3.8.1 结果推入操作数栈比较返回结果的指令有5条： 12345lcmpfcmpgfcmpldcmpgdcmpl lcmp 指令用于比较 long 变量，并将结果（int 类型的-1/0/1）推入操作数栈： 12345678910public class LCmp extends NoOperandsInstruction { @Override public void execute(Frame frame) { long v2 = frame.getOpStack().popLong(); long v1 = frame.getOpStack().popLong(); int v = CmpUtil.cmpLong(v1, v2); frame.getOpStack().pushInt(v); }} 由于浮点数计算有可能产生 NaN（Not a Number）值，所以比较两个浮点数时，除了大于、等于、小于之外，还有第4种结果：无法比较。 fcmpg 和 fcmpl 指令都是用于比较 float 变量，意义都差不多。 fcmpg 和 fcmpl 指令的区别就在于对第4种结果（无法比较）的定义。 两个 · 变量中至少有一个是 NaN 时，用 fcmpg 指令比较的结果是1，而用 fcmpl 指令比较的结果是-1。 12345678910public class FCmpg extends NoOperandsInstruction { @Override public void execute(Frame frame) { float v2 = frame.getOpStack().popFloat(); float v1 = frame.getOpStack().popFloat(); int v = CmpUtil.cmpFloat(v1, v2, true); frame.getOpStack().pushInt(v); }} 12345678910public class FCmpl extends NoOperandsInstruction { @Override public void execute(Frame frame) { float v2 = frame.getOpStack().popFloat(); float v1 = frame.getOpStack().popFloat(); int v = CmpUtil.cmpFloat(v1, v2, false); frame.getOpStack().pushInt(v); }} 上面几个命令有用到的工具类： 123456789101112131415161718192021public final class CmpUtil { public static int cmpLong(long v1, long v2) { return Long.compare(v1, v2); } public static int cmpFloat(float v1, float v2, boolean gFlag) { if (v1 &gt; v2) { return 1; } else if (v1 == v2) { return 0; } else if (v1 &lt; v2) { return -1; } else if (gFlag) { return 1; } else { return -1; } }} dcmpg 和 dcmpl 指令用来比较 double 变量，它们的意义和 fcmpg、fcmpl 指令一样，这里不再给出。 3.8.2 比较跳转比较跳转的指令有14条，可以分为2类： 单操作数指令：if&lt;cond&gt; 指令 双操作数指令：if_icmp&lt;cond&gt; 和 if_acmp&lt;cond&gt; 指令 单操作数 if&lt;cond&gt; 指令，是从栈顶弹出一个 int 整型变量和 0 进行比较： 123456ifeq: x == 0ifne: x != 0iflt: x &lt; 0ifle: x &lt;= 0ifgt: x &gt; 0ifge: x &gt;= 0 实现很简单，ifeq 指令： 1234567891011public class IfEq extends BranchInstruction { @Override public void execute(Frame frame) { int v1 = frame.getOpStack().popInt(); if (v1 == 0) { branch(frame); } }} ifle 指令： 1234567891011public class IfLe extends BranchInstruction { @Override public void execute(Frame frame) { int v1 = frame.getOpStack().popInt(); if (v1 &lt;= 0) { branch(frame); } }} 其他指令类似，不在举例。 双操作数指令 if_icmp&lt;cond&gt;，用于从栈顶弹出2个 int 整型变量进行比较，然后跳转： 123456if_icmpeq: if x1 == x2if_icmpne: if x1 != x2if_icmplt: if x1 &lt; x2if_icmple: if x1 &lt;= x2if_icmpgt: if x1 &gt; x2if_icmpge: if x1 &gt;= x2 if_icmpne 指令： 123456789101112public class IfICmpNe extends BranchInstruction { @Override public void execute(Frame frame) { int v2 = frame.getOpStack().popInt(); int v1 = frame.getOpStack().popInt(); if (v1 != v2) { branch(frame); } }} if_icmpgt 指令： 123456789101112public class IfICmpGt extends BranchInstruction { @Override public void execute(Frame frame) { int v2 = frame.getOpStack().popInt(); int v1 = frame.getOpStack().popInt(); if (v1 &gt; v2) { branch(frame); } }} 双操作数指令 if_acmp&lt;cond&gt;，也是从栈顶弹出2个变量，不过是引用变量，引用变量的比较只有2种情况： 12if_acmpeq: if x1 == x2if_acmpne: if x1 != x2 if_acmpeq 指令： 123456789101112public class IfACmpEq extends BranchInstruction { @Override public void execute(Frame frame) { Object v2 = frame.getOpStack().popRef(); Object v1 = frame.getOpStack().popRef(); if (v1 == v2) { branch(frame); } }} if_acmpne 指令： 123456789101112public class IfACmpNe extends BranchInstruction { @Override public void execute(Frame frame) { Object v2 = frame.getOpStack().popRef(); Object v1 = frame.getOpStack().popRef(); if (v1 != v2) { branch(frame); } }} 3.9 控制（control）指令控制指令，主要用于地址的直接跳转。 比如 return、goto、switch 等语句的实现。 包括的指令有： 12345678gototableswitchlookupswitchireturnlreturnfreturndreturnareturn return 系列指令等后面再实现。 goto 指令进行无条件跳转： 1234567public class Goto extends BranchInstruction { @Override public void execute(Frame frame) { branch(frame); }} tableswitch 指令和 lookupswitch 指令都是用于实现 switch 语句的： tableswitch 指令：case 值可以编码成一个索引表 lookupswitch 指令：case 值不可以编码成一个索引表 什么时候 case 值可以编码成一个索引表？比如下面这2个例子： 123456switch (i) { case 0: return 0; case 1: return 1; case 2: return 2; default: return -1;} 这种 case 值是大于等于 0 的值，可以作为索引，就会编译成 tableswitch 指令。 123456switch (i) { case -100: return -1; case 0: return 0; case 100: return 1; default: return -1;} 这种存在负数的值，就不能用作索引，就会编译成 lookupswitch 指令。 tableswitch 指令的实现是这样的： 1234567891011121314151617181920212223242526272829public class TableSwitch extends BranchInstruction { private int defaultOffset; private int low; private int high; private int[] jumpOffsets; @Override public void execute(Frame frame) { int index = frame.getOpStack().popInt(); if (index &gt;= low &amp;&amp; index &lt;= high) { offset = jumpOffsets[index - low]; } else { offset = defaultOffset; } branch(frame); } @Override public void fetchOperands(ByteCodeReader reader) { reader.skipPadding(); defaultOffset = reader.readInt(); low = reader.readInt(); high = reader.readInt(); int jumpOffsetsCount = high - low + 1; jumpOffsets = reader.readInts(jumpOffsetsCount); }} 其中，defaultOffset 就是 switch 语句中的 default 语句，而 low 和 high 则是对应的 case 语句的范围。 jumpOffsets 是一个索引表，里面存放 high - low + 1 个 int 值，对应各种 case 情况下，执行跳转所需的字节码偏移量。 tableswitch 指令的操作数是从栈中弹出的，作为偏移量地址，如果在 low 和 high 范围内，则说明是 case 语句，否则是 default 语句。 tableswitch 指令操作码的后面有 0~3 字节的 padding，这个是为了对齐地址用的，保证 defaultOffset 在字节码中的地址是4的倍数。 下面是 lookupswitch 指令的实现： 123456789101112131415161718192021222324252627public class LookupSwitch extends BranchInstruction { private int defaultOffset; private int npairs; private int[] matchOffsets; @Override public void execute(Frame frame) { int key = frame.getOpStack().popInt(); offset = defaultOffset; for (int i = 0; i &lt; npairs * 2; i += 2) { if (matchOffsets[i] == key) { offset = matchOffsets[i + 1]; break; } } branch(frame); } @Override public void fetchOperands(ByteCodeReader reader) { reader.skipPadding(); defaultOffset = reader.readInt(); npairs = reader.readInt(); matchOffsets = reader.readInts(npairs * 2); }} 其中，defaultOffset 也是默认的地址偏移量，npairs 表示有多少个 case 语句。 每个 case 语句都包括2部分内容：一个就是 case 的 key 值，比如前面的 100，一个是 case 代码的地址偏移量，表示跳转的偏移地址。 lookupswitch 指令的操作数也是从栈中弹出，作为 case 的 key 去比较，找到则跳转到 case 对应的偏移地址，否则跳到 default 语句。 lookupswitch 指令也有地址对齐的操作，和 tableswitch 指令作用一样。 3.10 引用（references）指令引用指令，是和字段访问、方法调用相关的指令。 这里暂不实现。 3.11 扩展（extended）指令扩展指令，是给一些操作数比较小的指令进行扩展。 扩展指令有3类： 123wideifnull 和 ifnonnullgoto_w 3.11.1 widewide 指令用于扩展操作索引的范围。 比如加载指令、存储指令等需要访问局部变量表的指令，索引用的都是 uint8 字节。 对于大部分方法来说，uint8 的大小已经足够满足了，但是不排除有些方法的局部变量表过大，所以才使用 wide 执行来扩展它们。 扩展的指令包括： 1234567891011120x15: iload0x16: lload0x17: fload0x18: dload0x19: aload0x36: istore0x37: lstore0x38: fstore0x39: dstore0x3a: astore0x84: iinc0xa9: ret wide 指令只是增加了索引宽度，并不改变子指令操作。 比如，原来的加载指令 iload 操作数是一个 uint8 字节的索引，在 wide 指令中则是 uint16 的双字节索引： 12345678public class WILoad extends Index16Instruction { @Override public void execute(Frame frame) { frame.getOpStack().pushInt(frame.getLocalVars().getInt(index)); }} 注意这里换成了 Index16Instruction 基类，使用的是2字节的索引。 同理，dstore 指令也换成了双操作数索引： 12345678public class WDStore extends Index16Instruction { @Override public void execute(Frame frame) { frame.getLocalVars().setDouble(index, frame.getOpStack().popDouble()); }} 自增指令 iinc 也是一样： 12345678910111213141516171819202122232425public class WIInc implements Instruction { /** * 局部变量索引 */ private Uint16 index; /** * 常量 */ private int value; @Override public void execute(Frame frame) { int val = frame.getLocalVars().getInt(index.value()); val += value; frame.getLocalVars().setInt(index.value(), val); } @Override public void fetchOperands(ByteCodeReader reader) { index = reader.readUint16(); // 注意这里是16位有符号整数 value = reader.readInt16(); }} 其他指令类似，不再列出。 3.11.2 ifnull 和 ifnonnul和前面的比较指令差不多，ifnull 和 ifnonnull 就是用于比较 null 值并跳转的： 1234567891011public class IfNull extends BranchInstruction { @Override public void execute(Frame frame) { Object v1 = frame.getOpStack().popRef(); if (v1 == null) { branch(frame); } }} 1234567891011public class IfNonNull extends BranchInstruction { @Override public void execute(Frame frame) { Object v1 = frame.getOpStack().popRef(); if (v1 != null) { branch(frame); } }} 3.11.3 goto_w前面的 goto 指令操作数是 int16 位有符号整数，goto_w 指令则是扩展成 int32 位有符号整数： 12345678910111213public class WGoto extends BranchInstruction { @Override public void execute(Frame frame) { branch(frame); } @Override public void fetchOperands(ByteCodeReader reader) { // 注意是32位有符号整数 offset = reader.readInt(); }} 3.12 保留（reserved）指令保留指令是留给虚拟机用的，这里暂时不实现。 四、解释器完成所有指令的解析之后，就可以实现一个简单的解释器，执行解析好的指令。 因为方法的调用，最后都会执行 return 语句，由于暂时未实现 return 语句，所以解释器目前只能执行一个方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Interpreter { public void interpret(MethodInfo methodInfo) { // 拿到方法的代码属性 CodeAttributeInfo codeAttr = methodInfo.getCodeAttributeInfo(); Uint16 maxLocals = codeAttr.getMaxLocals(); Uint16 maxStack = codeAttr.getMaxStack(); byte[] codes = codeAttr.getCodes(); // 创建一个栈帧测试 Thread thread = new Thread(); Frame frame = thread.newFrame(maxLocals.value(), maxStack.value()); thread.pushFrame(frame); // 解释执行代码 loop(thread, codes); } private void loop(Thread thread, byte[] codes) { Frame frame = thread.popFrame(); ByteCodeReader reader = new ByteCodeReader(codes); try { while (true) { // 程序计数器地址 int pc = frame.getNextPc(); thread.setPc(pc); reader.setPosition(pc); // 编译识别指令 int opcode = reader.readUint8().value(); Instruction instruction = InstructionFactory.newInstance(opcode); if (instruction == null) { break; } // 获取指定操作数 instruction.fetchOperands(reader); frame.setNextPc(reader.getPosition()); // 执行指令 instruction.execute(frame); } } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(&quot;Frame: &quot; + frame); } }} 解释器的逻辑很简单： 从指定方法中拿出 code 代码属性 根据指令集解析 code 代码的指令 执行解析好的指令 由于没有实现 return 指令，所以不能很好的看出结果，而且执行到最后肯定会报错。 这里通过捕获错误，并打印栈帧来查看结果。 getCodeAttributeInfo()、getMaxLocals() 这些都是 MethodInfo 新增的 get 方法，这里不多说。 InstructionFactory.newInstance(opcode) 是根据字节码生成对应的指令，实现差不多这样： 123456789101112131415161718public class InstructionFactory { public static Instruction newInstance(int opcode) { switch (opcode) { case 0x00: return new Nop(); case 0x01: return new AConstNull(); case 0x02: return new IConstM1(); case 0x03: . . . ... } }} 太长了，这里就不全列举出来了。 还需要改造一下 Jvm 类的代码，让他可以跑指定的方法，这里执行的是 main 方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Jvm { public static void main(String[] args) throws IOException { Cmd cmd = new Cmd(); cmd.printHelp(); String[] testArgs = new String[]{ &quot;com.wjd.cmd.Cmd&quot;, &quot;-classpath&quot;, &quot;D:\\\\Projects\\\\IdeaProjects\\\\self-jvm\\\\target\\\\test-classes;D:\\\\Projects\\\\IdeaProjects\\\\self-jvm\\\\target\\\\classes&quot; }; cmd.parse(testArgs); String userClassName = &quot;com\\\\wjd\\\\instructions\\\\InstructionsTest&quot;; Classpath classpath = new Classpath(cmd.getJreOption(), cmd.getCpOption()); ClassFile classFile = loadClass(userClassName, classpath); MethodInfo mainMethod = getMainMethod(classFile); if (mainMethod != null) { // 解释器执行，解释执行 main 方法 new Interpreter().interpret(mainMethod); } else { System.out.println(&quot;Not found main method!&quot;); } } /** * 加载类 */ public static ClassFile loadClass(String className, Classpath classpath) throws IOException { byte[] userClassBytes = classpath.readClass(className); ClassReader reader = new ClassReader(userClassBytes); return ClassFile.parse(reader); } /** * 获取类文件中的main方法 */ public static MethodInfo getMainMethod(ClassFile classFile) { for (MethodInfo m : classFile.getMethods()) if (&quot;main&quot;.equals(m.name()) &amp;&amp; &quot;([Ljava/lang/String;)V&quot;.equals(m.descriptor())) { return m; } return null; }} 改的内容就是找到测试类，拿出它的 main 方法，然后交给解释器 Interpreter 去解释执行。 五、单元测试测试类，就是要测试执行它的 main 方法： 1234567891011public class InstructionsTest { public static void main(String[] args) { int sum = 0; for (int i = 0; i &lt;= 100; i++) { sum += i; } System.out.println(sum); }} 测试应该会出现错误，在异常捕获里面，栈帧输出结果里面应该包含结果值 5050。 总结指令结构 字节码中存放编码后的 Java 虚拟机指令，每条指令都以一个单字节的操作码（opcode）开头 由于只使用一字节表示操作码，Java 虚拟机最多只能支持 256 条指令 Java 虚拟机使用的是变长指令，操作码后面可以跟零字节或多字节的操作数（operand） 比如 0xB20002 这条指令，B2 表示该指令的操作码，0002 就表示操作数 指令助记符 为了便于记忆，Java 虚拟机规范给每个操作码都指定了一个助记符（mnemonic） 比如，操作码是 0x00 的助记符是 nop（no operation） 操作数栈和局部变量表只存放数据的值（Slot），并不记录数据类型 指令必须知道自己在操作什么类型的数据，即指令绑定了数据类型 例如，iadd 指令就是对 int 值进行加法操作 指令类型Java 虚拟机规范把已经定义的205条指令按用途分成了11类，分别是： 常量（constants）指令 加载（loads）指令 存储（stores）指令 操作数栈（stack）指令 数学（math）指令 转换（conversions）指令 比较（comparisons）指令 控制（control）指令 引用（references）指令 扩展（extended）指令 保留（reserved）指令 保留指令： 1条是留给调试器的，用于实现断点，操作码是 202(0xCA)，助记符是 breakpoint 另外2条留给 Java 虚拟机实现内部使用，操作码分别是 254(0xFE) 和 266(0xFF)，助记符是 impdep1 和 impdep2","link":"/lang/java/jvm/selfjvm/05_instruction/"},{"title":"04_运行时数据区","text":"运行时数据区一、数据结构在运行Java程序时，Java虚拟机需要使用内存来存放各式各样的数据。Java虚拟机规范把这些内存区域叫作运行时数据区。 运行时数据区可以分为两类：一类是多线程共享的，另一类则是线程私有的。 多线程共享的运行时数据区需要在Java虚拟机启动时创建好，在Java虚拟机退出时销毁 线程私有的运行时数据区则在创建线程时才创建，线程退出时销毁 多线程共享的内存区域主要存放两类数据：类数据和类实例（也就是对象）： 类实例对象数据存放在堆（Heap）中 类数据存放在方法区（Method Area）中，类数据包括字段和方法信息、方法的字节码、运行时常量池等 线程私有的运行时数据区用于辅助执行Java字节码。每个线程都有自己的pc寄存器（Program Counter）和Java虚拟机栈（JVMStack）。 Java虚拟机栈又由栈帧（Stack Frame，后面简称帧）构成，帧中保存方法执行的状态，包括局部变量表（Local Variable）和操作数栈（Operand Stack）等。 二、数据类型Java虚拟机可以操作两类数据：基本类型（primitive type）和引用类型（reference type）。 基本类型的变量存放的就是数据本身，引用类型的变量存放的是对象引用，真正的对象数据是在堆里分配的。这里所说的变量包括类变量（静态字段）、实例变量（非静态字段）、数组元素、方法的参数和局部变量，等等。 基本类型可以进一步分为布尔类型（boolean type）和数字类型（numeric type），数字类型又可以分为整数类型（integral type）和浮点数类型（floating-point type）。 引用类型可以进一步分为3种：类类型、接口类型和数组类型。类类型引用指向类实例，数组类型引用指向数组实例，接口类型引用指向实现了该接口的类或数组实例。引用类型有一个特殊的值——null，表示该引用不指向任何对象。 三、线程线程都有自己的pc寄存器（Program Counter）和Java虚拟机栈（JVMStack）。 定义一个线程类，如下： 12345678910111213141516171819202122232425262728293031323334public class Thread { /** 最大栈深度 */ private static int maxStackSize = 1024; /** 程序计数器 */ private int pc; /** 虚拟机栈 */ private JvmStack stack; public Thread() { stack = new JvmStack(maxStackSize); } public int getPc() { return pc; } public void setPc(int pc) { this.pc = pc; } public void pushFrame(Frame frame) { stack.push(frame); } public Frame popFrame() { return stack.pop(); } public Frame currentFrame() { return stack.top(); }} 其中，JvmStack 是虚拟机栈，定义在后面给出。 四、虚拟机栈虚拟机栈就是一个栈结构，数据先入后出。虚拟机栈里面放的就是栈帧，表示每一个被调用的方法。 和堆一样，Java虚拟机规范对Java虚拟机栈的约束也相当宽松： Java虚拟机栈可以是连续的空间，也可以不连续；可以是固定大小，也可以在运行时动态扩展 如果Java虚拟机栈有大小限制，且执行线程所需的栈空间超出了这个限制，会导致StackOverflowError异常抛出 如果Java虚拟机栈可以动态扩展，但是内存已经耗尽，会导致OutOfMemoryError异常抛出 因此可以采用单向链表的形式来实现虚拟机栈，它的定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041public class JvmStack { /** 最大栈深度 */ private int maxSize; /** 当前栈深度 */ private int size; /** 栈顶对象 */ private Frame top; public JvmStack(int maxSize) { this.maxSize = maxSize; } public void push(Frame frame) { if (size &gt;= maxSize) { throw new StackOverflowError(&quot;jvm stack is overflow: &quot; + maxSize); } frame.setLower(top); top = frame; size++; } public Frame pop() { if (size == 0) { throw new IllegalStateException(&quot;jvm stack is empty!&quot;); } Frame val = top; top = top.getLower(); val.setLower(null); size--; return val; } public Frame top() { if (size == 0) { throw new IllegalStateException(&quot;jvm stack is empty!&quot;); } return top; }} 其中，栈帧 Frame 就作为单向链表的节点存在，栈顶就是单向链尾。 五、栈帧栈帧表示的一个方法调用，里面包括了执行方法所需要的局部变量表和操作数栈。 执行方法所需的局部变量表大小和操作数栈深度是由编译器预先计算好的，存储在 class 文件 method_info 结构的 Code 属性中。 栈帧的定义如下： 1234567891011121314151617181920212223public class Frame { /** 局部变量表 */ private LocalVars localvars; /** 操作数栈 */ private OperandStack operandStack; /** 指向下一个栈帧 */ private Frame lower; public Frame(int maxLocals, int maxStack) { localvars = new LocalVars(maxLocals); operandStack = new OperandStack(maxStack); } public Frame getLower() { return lower; } public void setLower(Frame lower) { this.lower = lower; } } 六、局部变量表局部变量表是按索引访问的，可以把它想象成一个数组。 根据Java虚拟机规范，这个数组的每个元素至少可以容纳一个 int 或引用值，两个连续的元素可以容纳一个 long 或 double 值。 为了能够同时容纳一个 int 和引用值，这里采用以下结构作为局部变量表的数组元素类型，同时增加了一些静态方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Slot { /** 索引 */ private long num; /** 引用 */ private Object ref; public Object getRef() { return ref; } public void setRef(Object ref) { this.ref = ref; } public static void setInt(Slot slot, int num) { slot.num = num; } public static int getInt(Slot slot) { return (int) slot.num; } public static void setFloat(Slot slot, float num) { int bits = Float.floatToIntBits(num); setInt(slot, bits); } public static float getFloat(Slot slot) { int bits = getInt(slot); return Float.intBitsToFloat(bits); } public static void setLong(Slot highSlot, Slot lowSlot, long num) { // long类型占用2个插槽 highSlot.num = num &gt;&gt;&gt; 32; lowSlot.num = num &amp; 0x0FFFFFFFFL; } public static long getLong(Slot highSlot, Slot lowSlot) { // long类型占用2个插槽 long lowerBits = lowSlot.num; long highBits = highSlot.num; long val = highBits &amp; 0x0FFFFFFFFL; val = (val &lt;&lt; 32) | (lowerBits &amp; 0x0FFFFFFFFL); return val; } public static void setDouble(Slot highSlot, Slot lowSlot, double num) { // 把double的bit转成long保存 long bits = Double.doubleToLongBits(num); setLong(highSlot, lowSlot, bits); } public static double getDouble(Slot highSlot, Slot lowSlot) { // 把long的bit解析成double long bits = getLong(highSlot, lowSlot); return Double.longBitsToDouble(bits); }} 然后局部变量表的定义则是这样的，实际就是对数组进行了一层封装，并提供了一些接口： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class LocalVars { /** 局部变量数组的最大大小 */ private static final int defaultMaxLocals = 65536; /** 局部变量表数组 */ private Slot[] slots; public LocalVars() { this(defaultMaxLocals); } public LocalVars(int maxLocals) { if (maxLocals &lt;= 0) { maxLocals = defaultMaxLocals; } // 一开始就把插槽初始化好 slots = new Slot[maxLocals]; for (int i = 0; i &lt; slots.length; i++) { slots[i] = new Slot(); } } public void setInt(int index, int num) { Slot.setInt(slots[index], num); } public int getInt(int index) { return Slot.getInt(slots[index]); } public void setFloat(int index, float num) { Slot.setFloat(slots[index], num); } public float getFloat(int index) { return Slot.getFloat(slots[index]); } public void setLong(int index, long num) { // long类型占用2个插槽 Slot.setLong(slots[index + 1], slots[index], num); } public long getLong(int index) { // long类型占用2个插槽 return Slot.getLong(slots[index + 1], slots[index]); } public void setDouble(int index, double num) { // double类型占用2个插槽 Slot.setDouble(slots[index + 1], slots[index], num); } public double getDouble(int index) { // double类型占用2个插槽 return Slot.getDouble(slots[index + 1], slots[index]); } public void setRef(int index, Object ref) { slots[index].setRef(ref); } public Object getRef(int index) { return slots[index].getRef(); }} 其中，long 和 double 这2种类型是占用了2个插槽的。 long 类型可以拆成2个 int 类型保存。 float 可以转成 int 类型保存，double 可以转成 long 类型保存。 七、操作数栈操作数栈和局部变量表类似，实际上操作数栈操作的数据，就是局部变量表里面的数据。 操作数栈的大小是编译器已经确定的，所以可以用 Slot[] 实现栈结构，其中栈顶就是 slots[size - 1]： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class OperandStack { /** 最大栈深度 */ private static final int defaultMaxStack = 65536; /** 操作数栈数组 */ private Slot[] slots; /** 当前栈大小 */ private int size; public OperandStack() { this(defaultMaxStack); } public OperandStack(int maxStack) { if (maxStack &lt;= 0) { maxStack = defaultMaxStack; } slots = new Slot[maxStack]; for (int i = 0; i &lt; slots.length; i++) { slots[i] = new Slot(); } } public void pushInt(int val) { Slot.setInt(slots[size], val); size++; } public int popInt() { size--; return Slot.getInt(slots[size]); } public void pushFloat(float val) { Slot.setFloat(slots[size], val); size++; } public float popFloat() { size--; return Slot.getFloat(slots[size]); } public void pushLong(long val) { // long类型占用2个插槽 Slot.setLong(slots[size + 1], slots[size], val); size += 2; } public long popLong() { // long类型占用2个插槽 size -= 2; return Slot.getLong(slots[size + 1], slots[size]); } public void pushDouble(double val) { // double类型占用2个插槽 Slot.setDouble(slots[size + 1], slots[size], val); size += 2; } public double popDouble() { // double类型占用2个插槽 size -= 2; return Slot.getDouble(slots[size + 1], slots[size]); } public void pushRef(Object ref) { slots[size].setRef(ref); size++; } public Object popRef() { size--; Object ref = slots[size].getRef(); slots[size].setRef(null); return ref; }} 操作数栈的实现和局部变量表的实现差不多，都是采用数组 Slot[]，所以操作数栈也需要对 long 和 double 进行特殊处理。 八、单元测试局部变量表测试： 12345678910111213141516171819202122public class LocalVarsTest { @Test public void testLocalVars() { LocalVars localVars = new LocalVars(100); localVars.setInt(0, 100); localVars.setInt(1, -100); localVars.setLog(2, 2997924580L); localVars.setLog(4, -2997924580L); localVars.setFloat(6, 3.1415926F); localVars.setDouble(7, 2.71828182845); localVars.setRef(9, this); System.out.println(localVars.getInt(0)); System.out.println(localVars.getInt(1)); System.out.println(localVars.getLong(2)); System.out.println(localVars.getLong(4)); System.out.println(localVars.getFloat(6)); System.out.println(localVars.getDouble(7)); System.out.println(localVars.getRef(9)); }} 操作数栈测试： 1234567891011121314151617181920212223242526public class OperandStackTest { @Test public void testOperandStack() { OperandStack stack = new OperandStack(100); stack.pushInt(100); stack.pushInt(-100); stack.pushLong(2997924580L); stack.pushLong(-2997924580L); stack.pushFloat(3.1415926F); stack.pushFloat(-3.1415926F); stack.pushDouble(2.71828182845); stack.pushDouble(-2.71828182845); stack.pushRef(this); System.out.println(stack.popRef()); System.out.println(stack.popDouble()); System.out.println(stack.popDouble()); System.out.println(stack.popFloat()); System.out.println(stack.popFloat()); System.out.println(stack.popLong()); System.out.println(stack.popLong()); System.out.println(stack.popInt()); System.out.println(stack.popInt()); }} 总结数据结构： 运行时数据区可以分为两类：一类是多线程共享的，另一类则是线程私有的 多线程共享的运行时数据区需要在Java虚拟机启动时创建好，在Java虚拟机退出时销毁 线程私有的运行时数据区则在创建线程时才创建，线程退出时销毁 多线程共享的内存区域主要存放两类数据：类数据和类实例（也就是对象） 类实例对象数据存放在堆（Heap）中 类数据存放在方法区（Method Area）中，类数据包括字段和方法信息、方法的字节码、运行时常量池等 数据类型： Java虚拟机可以操作两类数据：基本类型（primitive type）和引用类型（reference type） 基本类型的变量存放的就是数据本身，引用类型的变量存放的是对象引用，真正的对象数据是在堆里分配的 基本类型可以进一步分为布尔类型（boolean type）和数字类型（numeric type），数字类型又可以分为整数类型（integral type）和浮点数类型（floating-point type） 引用类型可以进一步分为3种：类类型、接口类型和数组类型。类类型引用指向类实例，数组类型引用指向数组实例，接口类型引用指向实现了该接口的类或数组实例 线程结构： 线程都有自己的pc寄存器（Program Counter）和Java虚拟机栈（JVMStack） 虚拟机栈就是一个栈结构，数据先入后出。虚拟机栈里面放的就是栈帧，表示每一个被调用的方法 Java虚拟机规范对虚拟机栈的约束相当宽松： Java虚拟机栈可以是连续的空间，也可以不连续；可以是固定大小，也可以在运行时动态扩展 如果Java虚拟机栈有大小限制，且执行线程所需的栈空间超出了这个限制，会导致StackOverflowError异常抛出 如果Java虚拟机栈可以动态扩展，但是内存已经耗尽，会导致OutOfMemoryError异常抛出 局部变量表是按索引访问的，可以把它想象成一个数组 根据Java虚拟机规范，局部变量表的每个元素至少可以容纳一个 int 或引用值，两个连续的元素可以容纳一个 long 或 double 值 操作数栈的大小是编译器已经确定的 操作数栈实际操作的数据就是局部变量表里面的数据","link":"/lang/java/jvm/selfjvm/04_runtimedata/"},{"title":"02_操作符","text":"操作符Java 中的操作符有很多，大概可以分成以下几种： 关系操作符：&gt;、&lt;、&gt;=、&lt;=、==、!= 逻辑操作符：!、&amp;、|、&amp;&amp;、|| 条件操作符：?: 算术操作符：-、++、–、+、-、*、/、% 位操作符：~、&amp;、|、^、&lt;&lt;、&gt;&gt;、&gt;&gt;&gt; 赋值操作符：=、+=、-=、*=、/=、&amp;=、|=、^=、&lt;&lt;=、&gt;&gt;=、&gt;&gt;&gt;= 一、操作符优先级当一个表达式存在多个操作符时，操作符的优先级就决定了各部分的计算顺序。 Java 中操作符的优先级共分为 14 级，其中 1 级最高，14 级最低。在表达式中操作符优先级高的优先执行。 下面是各种操作符的优先级和结合性： 优先级 操作符 结合性 1 ()、[]、{} 从左至右 2 !、+、-、~、++、– 从右至左 3 *、/、% 从左至右 4 +、- 从左至右 5 &lt;&lt;、&gt;&gt;、&gt;&gt;&gt; 从左至右 6 &lt;、&lt;=、&gt;、&gt;=、instanceof 从左至右 7 ==、!= 从左至右 8 &amp; 从左至右 9 ^ 从左至右 10 | 从左至右 11 &amp;&amp; 从左至右 12 || 从左至右 13 ?: 从右至左 14 =、+=、-=、*=、/=、&amp;=、|=、^=、~=、&lt;&lt;=、&gt;&gt;=、&gt;&gt;&gt;= 从右至左 比如说，下面的表达式： 1--a &gt; 0 || ++b &lt;= 1 &amp;&amp; c * d &gt; 100 然后根据表中的优先级，它的实际计算顺序应该是这样的： 先计算a的自减，即 --a 再计算 --a &gt; 0 的结果 再计算b的自增，即 ++b 接着计算 ++b &lt;= 1 的结果 然后计算c、d的乘法，即 c * d 再计算 c * d &gt; 100 的结果 由于 &amp;&amp; 优先级比 || 高，所以再接着是计算 ++b &lt;= 1 &amp;&amp; c * d &gt; 100 的结果 最后则是将2的结果和7的结果进行逻辑或（||）运算，即计算 --a &gt; 0 || ++b &lt;= 1 &amp;&amp; c * d &gt; 100 的结果 实际上，不建议直接写这种混合了多种优先级的表达式，因为一旦混合在一起后，就很难识别它们的优先级了。 对于复杂的表达式，一般建议按照以下操作去修改，方便理解： 尽量不要在一个表达式中混合使用多种不同优先级的操作符 不要写过于复杂的表达式，而是建议把它分成几个简单表达式 不要过多地依赖操作符的优先级来控制表达式的执行顺序，尽量使用小括号 () 来控制表达式的执行顺序 就比如上面的表达式，为了方便理解，可以给它加上小括号： 1((--a) &gt; 0) || ((++b) &lt;= 1 &amp;&amp; (c * d) &gt; 100) 虽然小括号不是必须的，但是加上之后，表达式理解起来反而更加容易了，很简单就能识别出各个部分的优先级。 二、关系操作符关系操作符是用于计算操作数之间的关系，其结果是一个布尔值，即 true 或 false。 关系操作符包括以下几个： 运算符 含义 例子 &gt; 大于 a &gt; b &lt; 小于 a &lt; b &gt;= 大于等于 a &gt;= b &lt;= 小于等于 a &lt;= b == 等于 a == b != 不等于 a != b 这个关系运算，和平时数学里的值比较差不多，需要注意的有几个地方： 等于操作符（==、!=）可以作用于所有基本数据类型 其他的大小比较操作符（&gt;、&lt;、&gt;=、&lt;=）能作用于除布尔基本类型外的其他基本数据类型。因为布尔值只有 true 和 false 这2种，不存在大小关系，没有意义 特别注意，等于操作符（==、!=）作用在基本数据类型和对象上时的效果是不一样的： 作用在基本数据类型上，比较的就是数据的真实值 作用在对象上，实际比较的是对象的引用地址，而不是对象的值 举个栗子来说： 1234567int a = 10;int b = 10;boolean c = a == b; // c = true，因为a和b都是基本数据类型，它们的值是相等的Integer d = 1000;Integer e = 1000;boolean f = d == e; // f = false，因为d和e都是对象，==比较的是对象引用地址，而不是对象的值 d和e都是对象，== 比较的是对象引用地址，而不是对象的值，所以表达式 d == e 的返回值是 false。因为 d 和 e 是2个对象，虽然这2个对象的数值是相等的，但是它们的引用地址是不同的。 再举个栗子，如果同时对比基本数据类型和包装类型对象的话： 123int a = 1000;Integer b = 1000;boolean c = a == b; // c = true 最终c的结果为true，说明了在对基本数据类型和包装类型进行比较时，包装类型对象会自动拆箱成基本数据类型，然后再比较2个基本数据类型的值。 所以，判断操作数的关系时，需要注意： 比较对象的值，一般不用 ==，而是用 equals() 方法 比较基本数据类型的值，equals() 方法用不了，直接用 == 简单来说，不要用 == 和 != 去判断对象就对了。 还有，不要将等于操作符（==、!=）作用在浮点数（float、double）上，由于计算机内存放的浮点数与实际的实数存在着一定的误差，如果对浮点数进行 ==（相等）或 !=（不相等）的比较，容易产生错误结果。 三、逻辑操作符逻辑操作符是对布尔类型变量/布尔表达式进行运算，其运算结果也是布尔类型值，即 true 或 false。 注意，逻辑操作符只能操作布尔值（布尔变量、关系表达式）。 逻辑操作符包括以下几个： 运算符 含义 例子 ! 逻辑非 !a &amp;&amp; 逻辑与 a &amp;&amp; b || 逻辑或 a || b &amp; 与 a &amp; b | 或 a | b 本来 &amp; 和 | 不算在逻辑操作符内的，不过它也能用来进行逻辑判断，所以姑且放在这里。 逻辑运算符的作用是，把各部分的运算关系表达式连接起来，组成一个复杂的逻辑表达式。 比如说： 1boolean b = a &gt; 0 &amp;&amp; b &lt; 0 || !(c &lt; 0); 通过逻辑操作符将 a &gt; 0、b &lt; 0、c &lt; 0 这几个简单连接成了一个复杂的逻辑表达式。 逻辑操作符 &amp;&amp;、|| 具有“短路”现象，即一旦能够明确整个表达式的值，就不再计算表达式剩余的部分了。 举个栗子： 1boolean a = 1 &lt; 2 &amp;&amp; 3 &lt; 4 || 5 &gt; 6; // a = true 这条表达式，它是这样计算的： 首先计算 1 &lt; 2，结果是 true； 其次计算 3 &lt; 4，结果是 true； 发现后面是逻辑或运算，此时前面的表达式 1 &lt; 2 &amp;&amp; 3 &lt; 4 的结果已经是 true 了，所以就明确肯定整条表达式的值必然是 true（因为 true 逻辑或任何值，结果都是 true），这个时候就不再计算表达式剩余部分 5 &gt; 6 的值了，而是直接返回 true 给 a。 表达式计算只计算到 1 &lt; 2 &amp;&amp; 3 &lt; 4 就返回了，后面的 5 &gt; 6 无需计算。这种行为就是“短路”现象，通过提前返回结果，减少表达式的判断，优化性能。 不过，&amp; 和 | 就没有“短路”操作了，它会执行完整个表达式，所以一般情况下，不会在逻辑表达式中用 &amp; 和 |，因为它们没有短路优化，但是结果却与 &amp;&amp; 和 || 是一样的。 一般建议，不要用 &amp; 和 | 来做逻辑判断，这2个操作符主要还是用在位操作上。 四、条件操作符条件操作符一个三元运算符，表示 if-then-else 行为： 运算符 含义 例子 ?: if-then-else a &gt; 0 ? b : c 举个例子： 12int a = 10; // a = 10int b = a &gt; 0 ? a + 1 : a - 1; // b = 11 条件操作符就是一个判断语句，还是比较好理解的： 首先判断 a &gt; 0； 若 a &gt; 0 为 true，则执行 ? 后的语句，即 a + 1; 若 a &gt; 0 为 false，则执行 : 后的语句，即 a - 1。 条件操作符和平时写的条件判断 if-else 差不多，相当于它的简写形式。 五、算术操作符Java 中的算术操作符主要用来对数值类型数据进行算术运算。 按照算术运算中涉及的操作数量，可以分为一元运算符和二元运算符。 5.1 一元运算符一元运算符包括以下几个： 运算符 含义 例子 - 一元减，取反符号 -a + 一元加 +a – 自减一 a–、–a ++ 自增一 a++、++a 一元减号 - 用于转变数据的符号，比如正变负，负变正。一元加号 + 只是为了与一元减号相对应，实际作用不大。不过它们有一个特点： 一元运算符 -、+ 会先将小整数类型（byte、char、short）提升为 int 类型，再执行运算 实际应用效果就类似下面这样子： 12345int a = 10; // a = 10int b = -a; // b = -10byte c = 10; // c(byte) = 10short d = (short) +c; // d(short) = 10，+号会自动提升操作数类型为int，所以这里需要强制转换为shortshort e = (short) -c; // e(short) = 10，-号会自动提升操作数类型为int，所以这里需要强制转换为short 自增操作符可分为前缀式（--a）和后缀式（a--），前缀式是先计算，再返回值；而后缀式则是先返回值，再计算： 1234int a = 10; // a = 10int b = 20; // b = 20int c = --a; // c = 9，a = 9，先计算自减--，再返回值int d = b--; // d = 20，b = 19，先返回值，再计算自减-- 在表达式中使用前缀式和后缀式时，需要特别注意它们的返回值，要清楚知道表达式的返回值是多少。 不过一般建议使用小括号把它们括起来，这样就无需过多在意前后缀表达式的返回值了。 5.2 二元运算符二元运算符包括以下几个： 运算符 含义 例子 + 加 a + b - 减 a - b * 乘 a * b / 除 a / b % 取余 a % b 这个就是平时的基本数学运算，理解起来很简单。 有点不同的就是，Java 中的整数除法会直接去掉小数位来取整，而不是常见的四舍五入。 12345int a = 10; // a = 10int b = a / 3; // b = 3，会直接去掉小数位int c = -10; // c = -10int d = c / 3; // d = -3，会直接去掉小数位 注意整数除法是直接去掉小数位数据，既不是向上/向下取整，也不是四舍五入。 另外，二元运算符也会导致小整数类型（byte、char、short）提升为 int 类型： 12345short a = 10;a = (short) (a + 1); // a 会先提升为 int 类型，再执行运算a = (short) (a * 2); // a 会先提升为 int 类型，再执行运算short b = --a; // 注意，自增/自减不会提升为 int 类型，或者说底层已经帮我们转好类型了 一般来说，只要是涉及到数学运算的，小整数类型（byte、char、short）都会先提升为 int 类型，再运算。 当然，除了自增（++）和自减（--）以外。 六、位操作符位操作符是直接对整数类型的位进行操作，类型包括 long，int，short，char 和 byte。 注意，位操作只对整数起作用，浮点数 float 和 double 不能进行位操作（因为它们是按 IEEE754 标准保存的，位运算的意义不是很大）。 按照意义，位操作符可分为2种： 按位运算符：对2个操作数对应的位执行布尔代数操作 移位运算符：直接对操作数的位移动，并用0/1补充移动后空出来的位 下面分别介绍2种操作符类型。 6.1 按位运算符按位运算符包括以下几个： 运算符 含义 例子 &amp; 按位与（AND） a &amp; b | 按位或（OR） a | b ^ 按位异或（XOR） a ^ b ~ 按位取反（NOT） ~a 按位运算符是直接对位进行操作的，比如： 123int a = 10;int b = -20;int c = a ^ b; 它的一个实际运算过程是这样的，会按照操作数的每一个位进行布尔运算： 1234 00000000000000000000000000001010 // a = 10^ 11111111111111111111111111101100 // b = -20------------------------------------- 11111111111111111111111111100110 // c = -26 注意，布尔类型也可以进行按位运算，但是只能执行 &amp;、|、^ 这3种操作，而没有按位取反 ~ 操作。 至于没有按位取反操作的原因，可能有以下几个： 布尔类型只有 true 和 false 这2个值，而布尔类型的位数是不确定的，在这种情况下执行按位取反，有可能会出现非布尔类型值 假设布尔类型是8位，其中 10000000 表示 true，00000001 表示 false，在这种情况下按位取反的话，true 取反后的值并不是 false，而且也不是布尔类型值了 除非布尔类型只有1位，它的按位取反才显得正常，因为只有1位的话，就肯定只会有2个值，取反后肯定是相反值，也就不会出现非布尔类型值了 还有可能是为了避免和逻辑非（!）混淆，因为布尔值只有2个，所以从理论上来说，按位取反（~）和逻辑非（!）的结果是一样的 综上，由于某些原因，布尔类型并没有按位取反（~）的操作。 6.2 移位运算符移位运算符包括以下几个： 运算符 含义 例子 &lt;&lt; 左移（高位移除、低位补0） a &lt;&lt; 1 &gt;&gt; 有符号右移（高位补符号位、低位移除） a &gt;&gt; 2 &gt;&gt;&gt; 无符号右移（高位补0、低位移除） a &gt;&gt;&gt; 3 有符号右移和无符号右移，区别就在于高位的补充是什么值。举2个例子： 12345# b = a &gt;&gt; 2&gt;&gt; 11111111111111111111111111110110 // a = -10------------------------------------- 11111111111111111111111111111101 // b = a &gt;&gt; 2 12345# b = a &gt;&gt;&gt; 2&gt;&gt;&gt; 11111111111111111111111111110110 // a = -10------------------------------------- 00111111111111111111111111111101 // b = a &gt;&gt;&gt; 2 有符号右移（&gt;&gt;），高位会补充符号位（负数补 1，其他补 0），无符号右移（&gt;&gt;&gt;）高位统一补 0。 另外，移位操作还有几个特点： 小整数类型 byte、char、short 执行移位操作前，会先提升为 int 类型，再进行移位 int 移位只取操作数的低 5 位数值（2 的 5 次方是 32，也就是 int 的位数） long 移位只取操作数的低 6 位数值（2 的 6 次方是 64，也就是 long 的位数） 也就是说，小整数类型进行移位操作会出现这种情况： 12short a = 10;a = (short) (a &gt;&gt; 1); // 返回值要强制类型转换 因为移位操作会把 short 提升为 int，所以最后的运算结果需要强制类型转换。 至于移位操作数的值超出 int 或 long 的位数时，就需要特殊处理： 12int a = 10; // a = 1010int b = a &lt;&lt; 55; // b = 101000000000000000000000000, 55 = 110111 这种情况，55 明显超出了 int 的 32 位，所以它实际上移位的数值是 55（110111） 的低 5 位，也就是 23（10111），也就是 a &lt;&lt; 55 等价于 a &lt;&lt; 23。 同样地，如果移位操作数是负数，也是取低5位（long 取低6位）： 12int a = 10; // a = 1010int b = a &lt;&lt; -55; // b = 1010000000000, -55 = 11111111111111111111111111001001 55 的低 5 位是 9（1001），所以 a &lt;&lt; -55 等价于 a &lt;&lt; 9。 截取低位来运算，是为了避免移位超出类型的位数，徒做无用功。 七、赋值操作符赋值操作符就比较简单了，就是给变量赋值。 赋值操作符包括以下几个： 运算符 含义 例子 = 直接赋值 a = 1 += 先加，再赋值 a += 2 -= 先减，再赋值 a -= 3 *= 先乘，再赋值 a *= 3 /= 先除，再赋值 a /= 3 &amp;= 先按位与，再赋值 a &amp;= 3 |= 先按位或，再赋值 a |= 3 ^= 先按位异或，再赋值 a ^= 3 &lt;&lt;= 先左移位，再赋值 a &lt;&lt;= 3 &gt;&gt;= 先有符号右移位，再赋值 a &gt;&gt;= 3 &gt;&gt;&gt;= 先无符号右移位，再赋值 a &gt;&gt;&gt;= 3 除了赋值操作符 = 以外，其他的都是复合操作符，也就是赋值操作和运算操作联合在一起形成的。 除了一元操作符（--、++、~），凡是运算相关的操作符（不包括关系、逻辑、条件），基本上都能和 = 联合形成复合操作符。 不过这种复合操作符的优先级是比较低的（和 = 的优先级一样），举个例子来说： 1a *= 1 + 2; 正常来说，乘法 * 优先级肯定比加法 + 高的，但实际上的它却等价于： 1a = a * (1 + 2); 所以说，复合操作符的优先级比较低，和直接赋值 = 优先级一样。 总结操作符种类： 关系操作符：&gt;、&lt;、&gt;=、&lt;=、==、!= 逻辑操作符：!、&amp;、|、&amp;&amp;、|| 条件操作符：?: 算术操作符：-、++、–、+、-、*、/、% 位操作符：~、&amp;、|、^、&lt;&lt;、&gt;&gt;、&gt;&gt;&gt; 赋值操作符：=、+=、-=、*=、/=、&amp;=、|=、^=、&lt;&lt;=、&gt;&gt;=、&gt;&gt;&gt;= 操作符优先级： 操作符的优先级共分为 14 级，其中 1 级最高，14 级最低 尽量不要在一个表达式中混合使用多种不同优先级的操作符 不要写过于复杂的表达式，而是建议把它分成几个简单表达式 不要过多地依赖操作符的优先级来控制表达式的执行顺序，尽量使用小括号 () 来控制表达式的执行顺序 关系操作符： 等于操作符（==、!=）可以作用于所有基本数据类型 其他的大小比较操作符（&gt;、&lt;、&gt;=、&lt;=）能作用于除布尔基本类型外的其他基本数据类型。因为布尔值只有 true 和 false 这2种，不存在大小关系，没有意义 作用在基本数据类型上，比较的就是数据的真实值 作用在对象上，实际比较的是对象的引用地址，而不是对象的值 比较对象的值，一般不用 ==，而是用 equals() 方法 比较基本数据类型的值，equals() 方法用不了，直接用 == 逻辑操作符： 逻辑操作符 &amp;&amp;、|| 具有“短路”现象，即一旦能够明确整个表达式的值，就不再计算表达式剩余的部分了 &amp; 和 | 就没有“短路”操作了，它会执行完整个表达式 一般建议，不要用 &amp; 和 | 来做逻辑判断，这2个操作符主要还是用在位操作上 条件操作符： 条件操作符和平时写的条件判断 if-else 差不多，相当于它的简写形式 算术操作符： 按照算术运算中涉及的操作数量，可以分为一元运算符和二元运算符 自增操作符可分为前缀式（--a）和后缀式（a--），前缀式是先计算，再返回值；而后缀式则是先返回值，再计算 注意整数除法是直接去掉小数位数据，既不是向上/向下取整，也不是四舍五入 一般来说，凡是涉及到数学运算的，小整数类型（byte、char、short）都会先提升为 int 类型，再运算 位操作符： 位操作符是直接对整数类型的位进行操作，类型包括 long，int，short，char 和 byte 位操作只对整数起作用，浮点数 float 和 double 不能进行位操作（因为它们是按 IEEE754 标准保存的，位运算的意义不是很大） 按照意义，位操作符可分为2种： 按位运算符：对2个操作数对应的位执行布尔代数操作 移位运算符：直接对操作数的位移动，并用0/1补充移动后空出来的位 布尔类型也可以进行按位运算，但是只能执行 &amp;、|、^ 这3种操作，而没有按位取反 ~ 操作 小整数类型 byte、char、short 执行移位操作前，会先提升为 int 类型，再进行移位 int 移位只取操作数的低 5 位数值（2 的 5 次方是 32，也就是 int 的位数） long 移位只取操作数的低 6 位数值（2 的 6 次方是 64，也就是 long 的位数） 赋值操作符： 除了赋值操作符 = 以外，其他的都是复合操作符，也就是赋值操作和运算操作联合在一起形成的 除了一元操作符（--、++、~），凡是运算相关的操作符（不包括关系、逻辑、条件），基本上都能和 = 联合形成复合操作符 复合操作符的优先级是比较低的（和 = 的优先级一样）","link":"/lang/java/core/basic/02_operators/"},{"title":"01_基本类型","text":"基本类型一、类型大小在 Java 中，通过 new 生成的对象数据是存储在“堆”中，而基本类型则是直接把“值”保存在栈中。 Java 中每种基本类型所占用的存储空间大小都是确定的，不会随着机器硬件架构变化而变化。 存储空间大小不变性，为Java的可移植性提供了很大的帮助 Java 中各种基本类型的空间大小如下： 基本类型 包装器类型 大小（bit） 最小值 最大值 boolean Boolean - - - byte Byte 8 -128 +127 char Character 16 Unicode 0 Unicode $ 2 ^ 16 - 1 $ short Short 16 $ -2 ^ 15 $ $ 2 ^ 15 - 1 $ int Integer 32 $ -2 ^ 31 $ $ 2 ^ 31 - 1 $ long Long 64 $ -2 ^ 63 $ $ 2 ^ 63 - 1 $ float Float 32 IEEE754 IEEE754 double Double 64 IEEE754 IEEE754 void Void - - - 在 Java 中，基本类型有以下几个特点： 所有数值类型都是有正负号的，不存在无符号数值类型 boolean 类型的存储大小没有明确规定，仅定义为能够取字面值 true 和 false 基本类型都有对应的包装器类型 Java SE5 中的自动包箱功能可以自动将基本类型转换为包装器类型。 二、类型转换在适当的时候，Java 会把一种数据类型转换为另一种数据类型，这个就称为类型转换。 例如，执行以下语句时，编译器会适当地转换数据类型来完成操作： 12int a = 10;double d = a + 1.0; // 此处a会自动转换为double类型 但是，有时候不能自动进行转换，则需要手动强制转换类型，例如： 12long j = 100;int i = (int) j + 10; // 这种必须显式地进行强制类型转换 对于类型转换，有如下几个特点： 布尔基本类型（boolean）不允许进行任何类型转换 除布尔基本类型外，其他基本类型之间可以任意转换，不过进行转换时可能会丢失部分信息 没有血缘关系（继承）的“类”之间不允许进行类型转换 比较特殊的就是布尔基本类型（boolean），它不允许进行任何的类型转换。例如： 123boolean b = true;int i = (int) b; // 不允许转换b = (boolean) i; // 不允许转换 这2种转换操作，在 Java 中都是不允许的，编译器也不会通过这些语句。 根据转换的实际情况，可以分为2种转换类型： 窄化转换（narrowing conversion）：将大数据类型转换为小数据类型了，可能会丢失部分信息，比如 long 转换为 int，int 转换为 short 等 扩展转换（widening conversion）：将小数据类型转换为大数据类型，不会丢失任何信息，比如 short 转换为 int，int 转换为 long 等 对于窄化转换，必须显式地进行强制类型转换，否则编译器会直接报错。而对于扩展转换，则不必显式地进行类型转换，它会自动转换。 对于窄化转换，它是怎么转换的呢？是直接截取？还是舍入？举个例子来看一下： 1234567long t = 0x0FF0FF00F0F0F0F0L;System.out.println(t);System.out.println(Long.toBinaryString(t));int i = (int) t;System.out.println(i);System.out.println(Integer.toBinaryString(i)); 12341148698284486881520111111110000111111110000000011110000111100001111000011110000-25264513611110000111100001111000011110000 很明显，long 窄化转换为 int，它是直接进行的截尾操作。也就是说，64位的 long 窄化转换为32位的 int 时，是直接截取的 long 的低32位。 类似地，其他大类型转换为小类型时，也是直接截取的低位数。 还需要注意的一点就是，窄化转换后，数值符号可能会发生变化，比如从正数变负数，或者从负数变正数，因为它是直接截尾转换的。 而对于扩展转换，它的实际情况如何呢？也举个例子： 1234567int i = 0xF0F0F0F0;System.out.println(i);System.out.println(Integer.toBinaryString(i));long t = i;System.out.println(t);System.out.println(Long.toBinaryString(t)); 1234-25264513611110000111100001111000011110000-2526451361111111111111111111111111111111111110000111100001111000011110000 可以看到，扩展转换的数据信息是不会丢失的，它是用符号位进行扩充来填补高位，从而保持了数值的符号不变。 总之，扩展转换是不需要关心的，主要还是大数据类型转小数据类型的窄化转换，它可能会导致部分信息丢失，需要特别留意。 三、高精度数值类型另外，除了上面的基本数据类型，Java还提供了2种高精度数值类型： BigInteger：支持任意精度的整数 BigDecimal：支持任意精度的定点数 这2种类型分别对应的是 int 和 float 基本类型，它们所能执行的操作相似。 也就是说，int 和 float 能做的事，都可以用 BigInteger 和 BigDecimal 来做，而且精度更高。 但是 BigInteger 和 BigDecimal 毕竟不是基本类型，而是一种对象类型，所以运算速度会比较慢。 实际上基本类型也是用精度换取了速度。 总结基本类型： 在 Java 中，通过 new 生成的对象数据是存储在“堆”中，而基本类型则是直接把“值”保存在栈中 Java 中每种基本类型所占用的存储空间大小都是确定的，不会随着机器硬件架构变化而变化。 存储空间大小不变性，为Java的可移植性提供了很大的帮助 所有数值类型都是有正负号的，不存在无符号数值类型 boolean 类型的存储大小没有明确规定，仅定义为能够取字面值 true 和 false 基本类型都有对应的包装器类型 Java SE5 中的自动包箱功能可以自动将基本类型转换为包装器类型 类型转换： 根据转换的实际情况，可以分为2种转换类型： 窄化转换（narrowing conversion）：将大数据类型转换为小数据类型了，可能会丢失部分信息，比如 long 转换为 int，int 转换为 short 等 扩展转换（widening conversion）：将小数据类型转换为大数据类型，不会丢失任何信息，比如 short 转换为 int，int 转换为 long 等 对于窄化转换，必须显式地进行强制类型转换，否则编译器会直接报错。而对于扩展转换，则不必显式地进行类型转换，它会自动转换 窄化转换，采用的是截尾实现，也就是截取大数据类型的低位 窄化转换后，数值符号可能会发生变化，比如从正数变负数，或者从负数变正数","link":"/lang/java/core/basic/01_types/"},{"title":"03_解析class文件","text":"解析class文件Java 虚拟机规范中所指的 class 文件，并非特指位于磁盘中的 .class 文件，而是泛指任何格式符合规范的 class 数据。它实际上可以通过网络下载，从数据库加载，甚至是在运行中直接生成等方式来获取 class 文件。 构成 class 文件的基本数据单位是字节，可以把整个 class 文件当成一个字节流来处理 数据由连续多个字节构成，这些数据在 class 文件中以大端（big-endian）方式存储 为了描述 class 文件格式，Java 虚拟机规范定义了 u1、u2 和 u4 三种数据类型来表示1、2和4字节无符号整数。 相同类型的多条数据一般按表（table）的形式存储在 class 文件中 表由表头和表项（item）构成，表头是 u2 或 u4 整数 整个 class 文件被描述为一个 ClassFile 结构，如下： 123456789101112131415161718ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];} 一、前期准备1.1 自定义数据类型Java 虚拟机规范定义了 u1、u2 和 u4 三种数据类型来表示1、2和4字节无符号整数。 但是 Java 中都是有符号整数，没有无符号整数，所以这里先定义几种无符号整数类型，实际上它们是由更大范围的整数值来保存的： 12345678910111213141516171819202122232425262728293031323334353637/** * 8比特无符号整数 */public class Uint8 { private int val; public Uint8(int val) { this.val = val; }}/** * 16比特无符号整数 */public class Uint16 { private int val; public Uint16(int val) { this.val = val; }}/** * 32比特无符号整数 */public class Uint32 { private long val; public Uint32(long val) { this.val = val; }} 使用自定义类型的原因是，方便在定义 ClassFile 类时，各个成员变量的类型能更清晰一些，不然都是 int、long 这些类型的话，都不知道 ClassFile 中实际保存的字节数量。 这样增加自定义类型后，下面的 ClassFile 结构就稍微好看一点了： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class ClassFile { /** * 魔数 */ private Uint32 magic; /** * 次版本号 */ private Uint16 minorVersion; /** * 主版本号 */ private Uint16 majorVersion; /** * 常量池常量数量 */ private Uint16 constantCount; /** * 常量池 */ private ConstantPoolInfo constantPool; /** * 类访问标志 */ private Uint16 accessFlags; /** * 类名 */ private Uint16 className; /** * 父类名 */ private Uint16 superClassName; /** * 接口数量 */ private Uint16 interfaceCount; /** * 接口定义 */ private Uint16[] interfaces; /** * 字段数量 */ private Uint16 fieldCount; /** * 字段定义 */ private FieldInfo[] fields; /** * 方法数量 */ private Uint16 methodCount; /** * 方法定义 */ private MethodInfo[] methods; /** * 属性数量 */ private Uint16 attributesCount; /** * 属性定义 */ private AttributeInfo[] attributes;} 1.2 类型数据读取现在是把 class 文件当成字节流来处理，但是如果直接操作字节是很不方便的。而且前面增加了自定义数据类型，把数据读出来后，还要再转成对应的数据类型，相当麻烦。 所以定义了一个工具类 ClassReader 来帮助读取数据： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class ClassReader { private ByteBuffer buf; private int offset; ClassReader (byte[] bytes) { buf = ByteBuffer.wrap(bytes); buf.order(ByteOrder.BIG_ENDIAN); // 大端 offset = 0; } public int readInt() { return buf.getInt(); } public long readLong() { return buf.getLong(); } public float readFloat() { return buf.getFloat(); } public double readDouble() { return buf.getDouble(); } public Uint8 readUint8() { int val = buf.get(); return new Uint8(val); } public Uint16 readUint16() { short s = buf.getShort(); int val = 0x0FFFF &amp; s; return new Uint16(val); } public Uint32 readUint32() { int i = buf.getInt(); long val = 0x0FFFFFFFFL &amp; i; return new Uint32(val); } public Uint16[] readUint16s(Uint16 length) { Uint16[] table = new Uint16[length.value()]; for (int i = 0; i &lt; table.length; i++) { table[i] = readUint16(); } return table; } public byte[] readBytes(int length) { byte[] bytes = new byte[length]; buf.get(bytes); offset += length; return bytes; }} 工具类底层是用 ByteBuffer 来实现的，它提供了很多有用的方法来读取指定类型的数据，基本上可以直接使用。 二、类文件数据结构2.1 魔数很多文件格式都会规定满足该格式的文件必须以某几个固定字节开头，这几个字节主要起标识作用，叫作魔数（magic number）。 class 文件的魔数是 0xCAFEBABE。 1magic = reader.readUint32(); Java 虚拟机规范规定，如果加载的 class 文件不符合要求的格式，Java 虚拟机实现就抛出 java.lang.ClassFormatError 异常。 2.2 版本号魔数之后是 class 文件的次版本号和主版本号，都是u2类型。 12minorVersion = reader.readUint16();majorVersion = reader.readUint16(); 次版本号只在 J2SE 1.2 之前用过，从1.2开始基本上就没什么用了（都是0）。 主版本号在 J2SE 1.2 之前是45，从1.2开始，每次有大的 Java 版本发布，都会加1。 Java 版本 class 文件版本号 JDK 1.0.2 45.0 ~ 45.3 JDK 1.1 45.0 ~ 45.65535 J2SE 1.2 46.0 J2SE 1.3 47.0 J2SE 1.4 48.0 Java SE 5.0 49.0 Java SE 6 50.0 Java SE 7 51.0 Java SE 8 52.0 特定的 Java 虚拟机实现只能支持版本号在某个范围内的 class 文件。 例如，Java 8 支持版本号为 45.0 ~ 52.0 的 class 文件。 如果版本号不在支持的范围内，Java 虚拟机实现就抛出 java.lang.UnsupportedClassVersionError 异常。 2.3 类访问标志类访问标志，这是一个16位的 bitmask，用于指出 class 文件定义的是类还是接口，访问级别是 public 还是 private 等。 1accessFlags = reader.readUint16(); 2.4 类和超类类访问标志之后是两个u2类型的常量池索引，分别给出类名和超类名。 12className = reader.readUint16();superClassName = reader.readUint16(); class 文件存储的类名类似完全限定名，但是把点（.）换成了斜线（/），这种名字叫作二进制名（binary names）。 比如，java.lang.Object 在 class 文件中存储的名称为 java/lang/Object。 每个类都要有名字，所以 className 必须是有效的常量池索引。 除 java.lang.Object 之外，其他类都有超类，所以除了 Object.class 以外，其他 class 文件中的 superClassName 必须是有效的常量池索引。 而 java.lang.Object 的 class 文件中，superClassName 的值是0。 2.5 类接口类和超类索引后面是接口索引表，表中存放的也是常量池索引，给出该类实现的所有接口的名字。 12interfaceCount = reader.readUint16();interfaces = reader.readUint16s(interfaceCount); 2.6 字段、方法接口索引表之后是字段表和方法表，分别存储字段和方法信息。字段和方法的基本结构大致相同，差别仅在于属性表。 1234567field_info { u2 access_flags; u2 name_index; u2 descriptor_index; u2 attributes_count; attribute_info attributes[attributes_count];} 和类一样，字段和方法也有自己的访问标志。 访问标志之后是一个常量池索引，给出字段名或方法名。 然后又是一个常量池索引，给出字段或方法的描述符。 最后是属性表。 字段和方法的结构基本一致，所以它们的解析过程也差不多： 123456789101112131415// 成员变量fieldCount = reader.readUint16();fields = new FieldInfo[fieldCount.value()];for (int i = 0; i &lt; fields.length; i++) { fields[i] = new FieldInfo(); fields[i].readFrom(reader);}// 成员方法methodCount = reader.readUint16();methods = new MethodInfo[methodCount.value()];for (int i = 0; i &lt; methods.length; i++) { methods[i] = new MethodInfo(); methods[i].readFrom(reader);} 三、常量池常量池里面存放着各式各样的常量信息，包括数字和字符串常量、类和接口名、字段和方法名等等。 常量池实际上也是一个表。表头给出的常量池大小比实际大1。 假设表头给出的值是n，那么常量池的实际大小是n–1。也就是说，常量池的有效的常量池索引是1~n–1。0是无效索引，表示不指向任何常量。 CONSTANT_Long_info 和 CONSTANT_Double_info 各占两个位置。也就是说，如果常量池中存在这两种常量，实际的常量数量比n–1还要少，而且1~n–1的某些数也会变成无效索引。 123456789101112constantCount = reader.readUint16();constantPool = new ConstantInfo[constantCount.value()];// 常量池的索引从1开始for (int i = 1; i &lt; constantPool.length; i++) { constantPool[i] = readConstantInfo(reader); // 双字类型（即8字节）占2个位置 if (constantPool[i] instanceof LongConstantInfo || constantPool[i] instanceof DoubleConstantInfo) { constantPool[++i] = null; }} 常量的第一个字节是 tag 值，用于指明常量的类型。 Java 虚拟机规范定义了14种常量，各个常量值对应的 tag 如下： 123456789101112131415161718192021public class Constant { public static final int ConstantUtf8 = 1; // Java 1.0.2 public static final int ConstantInteger = 3; // Java 1.0.2 public static final int ConstantFloat = 4; // Java 1.0.2 public static final int ConstantLong = 5; // Java 1.0.2 public static final int ConstantDouble = 6; // Java 1.0.2 public static final int ConstantClass = 7; // Java 1.0.2 public static final int ConstantString = 8; // Java 1.0.2 public static final int ConstantFieldRef = 9; // Java 1.0.2 public static final int ConstantMethodRef = 10; // Java 1.0.2 public static final int ConstantInterfaceMethodRef = 11; // Java 1.0.2 public static final int ConstantNameAndType = 12; // Java 1.0.2 public static final int ConstantMethodHandle = 15; // Java 7 public static final int ConstantMethodType = 16; // Java 7 public static final int ConstantInvokeDynamic = 18; // Java 7 public static final int ConstantModule = 19; // Java 9 public static final int ConstantPackage = 20; // Java 9 public static final int ConstantDynamic = 17; // Java 11} 按照结构，常量池的常量可以分为2种，一种是存放有数据的字面常量，一种是存放索引的引用常量。 像整数、浮点数、UTF8字节等，都属于字面常量；而像字符串、类型、方法等都是引用常量。 就比如，整数常量的结构是这样的： 1234CONSTANT_Integer_info { 3 (u1 tag); 101 (u4 Integer);} 整数常量的 u4 Integer 的值 101 就是这个整数常量的值，也就是它是直接保存数据的。 而字符串常量的结构是这样的： 1234CONSTANT_String_info { 8 (u1 tag); 34 (u2 string_index);} 字符串常量里面的 string_index 就只是一个索引，指向了另外的常量，并不直接保存数据。 下面分别详细介绍这些常量的结构定义。 3.1 字面常量字面常量，和 Java 中的基本类型概念差不多，是实际拥有数据的常量。 3.1.1 CONSTANT_Utf8CONSTANT_Utf8 是一个变长的数据结构，里面存放的是 MUTF-8 编码的字符串，结构如下： 12345CONSTANT_Utf8_info { u1 tag; u2 length; u1 bytes[length];} tag 等于 1。 length 是它的长度，u2 是2个字节，所以它的最大值为 65536。 这也就意味着，Java 中允许的最大字符串长度为 65536 字节。也就是能够放 65536 个 ASCII 字符，或者 65536/3 个中文字符。 它的读取比较直接，按照字节长度读取即可： 1234public void readFrom(ClassReader reader) { length = reader.readUint16(); val = reader.readBytes(length);} 3.1.2 CONSTANT_IntegerCONSTANT_Integer 是整型常量，使用4字节存储数值，结构如下： 1234CONSTANT_Integer_info { u1 tag; u4 bytes;} tag 等于 3。 整型常量，对应的就是 Java 中的 Integer 整型，所以直接按照读取 Integer 的方式读取即可。 刚好 ByteBuffer 也提供了相应的基本类型读取方法： 123public int readInt() { return buf.getInt();} 所以在解析整型常量时，可以直接解析： 123public void readFrom(ClassReader reader) { val = reader.readInt();} 3.1.3 CONSTANT_FloatCONSTANT_Float 是 IEEE754 单精度浮点数常量，使用4字节存储数值，结构如下： 1234CONSTANT_Float_info { u1 tag; u4 bytes;} tag 等于 4。 单精度浮点数常量，对应的就是 Java 中的 Float 单精度浮点数。 ByteBuffer 也提供了相应的读取方法： 123public float readFloat() { return buf.getFloat();} 然后就可以直接解析浮点数了： 123public void readFrom(ClassReader reader) { val = reader.readFloat();} 3.1.4 CONSTANT_LongCONSTANT_Long 是8字节长整型常量，结构如下： 12345CONSTANT_Long_info { u1 tag; u4 high_bytes; u4 low_bytes;} tag 等于 5。 注意，在长整型常量定义中，8字节是被拆分成高位4字节和低位4字节来存放的。 长整型常量，对应的就是 Java 中的 Long 长整型。 ByteBuffer 也提供了相应的读取方法： 123public long readLong() { return buf.getLong();} 直接解析即可： 123public void readFrom(ClassReader reader) { val = reader.readLong();} 3.1.5 CONSTANT_DoubleCONSTANT_Double 是 IEEE754 双精度浮点数常量，使用8字节存储数值，结构如下： 12345CONSTANT_Double_info { u1 tag; u4 high_bytes; u4 low_bytes;} tag 等于 6。 注意，在双精度浮点数常量定义中，8字节也是被拆分成高位4字节和低位4字节来存放的。 双精度浮点数常量，对应的是 Java 中的 Double 双精度浮点数。 ByteBuffer 也提供了相应的读取方法： 123public double readDouble() { return buf.getDouble();} 直接解析即可： 123public void readFrom(ClassReader reader) { val = reader.readDouble();} 3.2 引用常量引用常量比较简单，它们不直接保存数据，只保存了索引，所以结构上可能会比字面常量稍微复杂一些。 下面简单介绍其中几种常见的引用常量。 3.2.1 CONSTANT_StringCONSTANT_String_info 常量表示 java.lang.String 字面量，结构如下： 1234CONSTANT_String_info { u1 tag; u2 string_index;} tag 等于 8。 string_index 是常量池索引，指向一个 CONSTANT_Utf8_info 常量。 3.2.2 CONSTANT_ClassCONSTANT_Class 常量表示类或者接口的符号引用，结构如下： 1234CONSTANT_Class_info { u1 tag; u2 name_index;} tag 等于 7。 name_index 是常量池索引，指向一个 CONSTANT_Utf8_info 常量。 3.2.3 CONSTANT_FieldrefCONSTANT_Fieldref_info 表示字段符号引用，结构如下： 12345CONSTANT_Fieldref_info { u1 tag; u2 class_index; u2 name_and_type_index;} tag 等于 9。 class_index 是所在类索引，指向一个 CONSTANT_Class_info 常量。 name_and_type_index 是名称和类型定义索引，指向一个 CONSTANT_NameAndType_info 常量。 3.2.4 CONSTANT_MethodrefCONSTANT_Methodref_info 表示普通（非接口）方法符号引用，结构如下： 12345CONSTANT_Methodref_info { u1 tag; u2 class_index; u2 name_and_type_index;} tag 等于 10。 class_index 是所在类索引，指向一个 CONSTANT_Class_info 常量。 name_and_type_index 是名称和类型定义索引，指向一个 CONSTANT_NameAndType_info 常量。 3.2.5 CONSTANT_InterfaceMethodrefCONSTANT_InterfaceMethodref_info 表示接口方法符号引用，结构如下： 12345CONSTANT_InterfaceMethodref_info { u1 tag; u2 class_index; u2 name_and_type_index;} tag 等于 11。 class_index 是所在接口索引，指向一个 CONSTANT_Class_info 常量。 name_and_type_index 是名称和类型定义索引，指向一个 CONSTANT_NameAndType_info 常量。 3.2.6 CONSTANT_NameAndTypeCONSTANT_NameAndType_info 给出字段或方法的名称和描述符，结构如下： 12345CONSTANT_NameAndType_info { u1 tag; u2 name_index; u2 descriptor_index;} tag 等于 12。 name_index 是名称索引，指向一个 CONSTANT_Utf8_info 常量。 descriptor_index 是字段或方法的描述符索引，也是指向一个 CONSTANT_Utf8_info 常量。 CONSTANT_Class_info 和 CONSTANT_NameAndType_info 加在一起可以唯一确定一个字段或者方法。 描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值。 不过这里的描述符，不是常见的完整的字段或者函数定义，而是一种缩写形式，它的规则有以下几个： 类型描述符 基本类型byte、short、char、int、long、float和double的描述符是单个字母，分别对应B、S、C、I、J、F和D（注意，long的描述符是J而不是L） 引用类型的描述符是“L + 类的完全限定名 + 分号” 数组类型的描述符是“[ + 数组元素类型描述符” 字段描述符 字段描述符就是字段类型的描述符 方法描述符 方法描述符是“（分号分隔的参数类型描述符）+ 返回值类型描述符”，其中void返回值由单个字母V表示 这里直接举几个例子来说明： 描述符 类型 B byte S short Ljava/lang/Object; java.lang.Object [I int[] [[Ljava/lang/String; String[][] ()V void method() (Ljava/lang/String;)Ljava/lang/String; String method(String) ([JJ)J long method(long[], long) (Ljava/lang/String;Ljava/lang/String;)V void method(String, String) 为了减少描述符在 ClassFile 文件中占用的空间，它只保留了必要的属性，一些不必要的属性如方法名称，并没有直接保存在描述符中。 Java语言支持方法重载（override），不同的方法可以有相同的名字，只要参数列表不同即可。这就是为什么CONSTANT_NameAndType_info结构要同时包含名称和描述符的原因。 那么字段呢？Java是不能定义多个同名字段的，哪怕它们的类型各不相同。这只是Java语法的限制而已，从class文件的层面来看，是完全可以支持这点的。 小结常量池中的常量分为两类：字面量（literal）和符号引用（symbolic reference）。 字面量包括数字常量和字符串常量，符号引用包括类和接口名、字段和方法信息等。 除了字面量，其他引用常量都是通过索引直接或间接指向 CONSTANT_Utf8_info 常量。 四、属性表属性表可谓是个大杂烩，里面存储了各式各样的信息，如方法的字节码等。 常量是由Java虚拟机规范严格定义的，共有14种。但属性是可以扩展的，不同的虚拟机实现可以定义自己的属性类型。 由于这个原因，Java虚拟机规范没有使用tag，而是使用属性名来区别不同的属性。 属性数据放在属性名之后的u1表中，这样Java虚拟机实现就可以跳过自己无法识别的属性。 属性的结构定义如下： 12345attribute_info { u2 attribute_name_index; u4 attribute_length; u1 info[attribute_length];} 属性表中存放的属性名实际上并不是编码后的字符串，而是常量池索引 attribute_name_index，指向常量池中的 CONSTANT_Utf8_info 常量。 按照这个定义，定义了一个属性接口： 123public interface AttributeInfo { void readFrom(ClassReader reader);} 具体属性只要实现 readFrom 方法即可。 4.1 属性类型Java虚拟机规范预定义了23种属性，按照用途可以分为三组： 实现Java虚拟机所必需的，共有5种 Java类库所必需的，共有12种 提供给工具使用，共有6种，这组属性是可选的 属性名 所在位置 分组 增加版本 ConstantValue field_info 1 1.0.2 Code meghod_info 1 1.0.2 Exceptions method_info 1 1.0.2 SourceFile ClassFile 3 1.0.2 LineNumberTable Code 3 1.0.2 LocalVariableTable Code 3 1.0.2 InnerClasses ClassFile 2 1.1 Synthetic ClassFile,field_info,method_info 2 1.1 Deprecated ClassFile,field_info,method_info 3 1.1 EnclosingMethod ClassFile 2 5.0 Signature ClassFile,field_info,method_info 2 5.0 SourceDebugExtension ClassFile 3 5.0 LocalVariableTypeTable Code 3 5.0 RunttimeVisibleAnnotations ClassFile,field_info,method_info 2 5.0 RunttimeInvisibleAnnotations ClassFile,field_info,method_info 2 5.0 RunttimeVisibleParameterAnnotations method_info 2 5.0 RunttimeInvisibleParameterAnnotations method_info 2 5.0 AnnotationDefault method_info 2 5.0 StackMapTable Code 1 6 BootstrapMethods ClassFile 1 7 RunttimeVisibleTypeAnnotations ClassFile,field_info,method_info,Code 2 8 RunttimeInvisibleTypeAnnotations ClassFile,field_info,method_info,Code 2 8 MethodParameters method_info 2 8 4.2 属性定义4.2.1 Deprecated和Synthetic属性Deprecated 是最简单的两种属性之一，仅起标记作用，不包含任何数据。 它的结构定义如下： 1234Deprecated_attribute { u2 attribute_name_index; u4 attribute_length;} 由于不包含任何数据，所以attribute_length的值必须是0。 Deprecated 属性用于指出类、接口、字段或方法已经不建议使用，编译器等工具可以根据Deprecated属性输出警告信息。 J2SE 5.0之前,可以使用 Javadoc 提供的 @deprecated 标签指示编译器给类、接口、字段或方法添加 Deprecated 属性。 从J2SE 5.0开始，可以使用 @Deprecated 注解。 Deprecated 属性不包含数据，所以它的 readFrom 实现为空就行了： 123@Overridepublic void readFrom(ClassReader reader) {} 4.2.2 SyntheticSynthetic 是最简单的两种属性之一，仅起标记作用，不包含任何数据。 它的结构定义如下： 1234Synthetic_attribute { u2 attribute_name_index; u4 attribute_length;} Synthetic 属性用来标记源文件中不存在、由编译器生成的类成员，引入 Synthetic 属性主要是为了支持嵌套类和嵌套接口。 Synthetic 属性不包含数据，所以它的 readFrom 也是为空： 123@Overridepublic void readFrom(ClassReader reader) {} 4.2.3 SourceFileSourceFile 是可选定长属性，只会出现在 ClassFile 结构中，用于指出源文件名。 其结构定义如下： 12345SourceFile_attribute { u2 attribute_name_index; u4 attribute_length; u2 sourcefile_index;} attribute_length 的值必须是2。 sourcefile_index 是常量池索引，指向一个 CONSTANT_Utf8_info 常量。 SourceFile 属性读取很简单，直接读就行了： 12345@Overridepublic void readFrom(ClassReader reader) { length = reader.readUint32(); nameIndex = reader.readUint16();} 4.2.4 ConstantValueConstantValue 是定长属性，只会出现在 field_info 结构中，用于表示常量表达式的值。 其结构定义如下： 12345ConstantValue_attribute { u2 attribute_name_index; u4 attribute_length; u2 constantvalue_index;} attribute_length 的值必须是2。 constantvalue_index 是常量池索引，指向某一个类型定义，但具体指向哪种常量因字段类型而异。 ConstantValue 属性读取也很简单，也是直接读就行了： 12345@Overridepublic void readFrom(ClassReader reader) { length = reader.readUint32(); constantIndex = reader.readUint16();} 4.2.5 CodeCode 是变长属性，只存在于 method_info 结构中。Code 属性中存放字节码等方法相关信息。 其结构定义如下： 12345678910111213141516Code_attribute { u2 attribute_name_index; u4 attribute_length; u2 max_stack; u2 max_locals; u4 code_length; u1 code[code_length]; u2 exception_table_length; { u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; } exception_table[exception_table_length]; u2 attributes_count; attribute_info attributes[attributes_count];} max_stack 给出操作数栈的最大深度；max_locals给出局部变量表大小； 接着是字节码，存在u1表中；最后是异常处理表和属性表。 Code 属性结构相对复杂一些，有几层结构，读取起来有点麻烦： 123456789101112131415161718192021222324@Overridepublic void readFrom(ClassReader reader) { length = reader.readUint32(); maxStack = reader.readUint16(); maxLocals = reader.readUint16(); codeLength = reader.readUint32(); codes = reader.readBytes(codeLength); exceptionLength = reader.readUint16(); exceptionEntries = new ExceptionTableEntry[exceptionLength.value()]; for (int i = 0; i &lt; exceptionEntries.length; i++) { exceptionEntries[i] = readExceptionEntry(reader); } attributeInfoTable = new AttributeInfoTable(); attributeInfoTable.readFrom(reader);}private ExceptionTableEntry readExceptionEntry(ClassReader reader) { ExceptionTableEntry entry = new ExceptionTableEntry(); entry.setStartPC(reader.readUint16()); entry.setEndPC(reader.readUint16()); entry.setHandlerPC(reader.readUint16()); entry.setCatchPC(reader.readUint16()); return entry;} 4.2.6 ExceptionsExceptions 是变长属性，记录方法抛出的异常表。 其结构定义如下： 123456Exceptions_attribute { u2 attribute_name_index; u4 attribute_length; u2 number_of_exceptions; u2 exception_index_table[number_of_exceptions];} Exceptions 属性简单，直接读取即可： 123456@Overridepublic void readFrom(ClassReader reader) { length = reader.readUint32(); numberOfExceptions = reader.readUint16(); exceptionIndexTable = reader.readUint16s(numberOfExceptions);} 4.2.7 LineNumberTableLineNumberTable 属性表存放方法的行号信息。 结构定义如下： 12345678LineNumberTable_attribute { u2 attribute_name_index; u4 attribute_length; u2 line_number_table_length; { u2 start_pc; u2 line_number; } line_number_table[line_number_table_length];} LineNumberTable 属性表不算复杂，可以直接读取： 12345678910111213141516 @Overridepublic void readFrom(ClassReader reader) { length = reader.readUint32(); lineNumberLength = reader.readUint16(); lineNumberEntries = new LineNumberTableEntry[lineNumberLength.value()]; for (int i = 0; i &lt; lineNumberEntries.length; i++) { lineNumberEntries[i] = readLineNumberTableEntry(reader); }}private LineNumberTableEntry readLineNumberTableEntry(ClassReader reader) { LineNumberTableEntry entry = new LineNumberTableEntry(); entry.setStartPC(reader.readUint16()); entry.setLineNumber(reader.readUint16()); return entry;} 小结相对于常量来说，属性的结构要稍微复杂一些，毕竟是可以扩展的，不像常量池常量那样基本都是固定的。 虽然属性的机构稍微复杂一些，但是层次还是比较清晰的。 五、单元测试123456789101112131415161718192021222324public class ClassFileStructureTest { private byte bt = 1; private boolean b = false; private char c = 'A'; private short s = 2; private int i = 3; private long l = 4L; private float f = 5.0F; private double d = 6.0; private String str = &quot;test&quot;; public static void main(String[] args) { short s = -10; int i = s; int ii = s &amp; 0xFFFF; long ss = 0L; long si = ss | i; for (int j = 0; j &lt; 4; j++) { } System.out.println(&quot;Class File Test&quot; + i + &quot; &quot; + ii + &quot; &quot; + si); }} 123456789101112131415161718192021public class ClassFileTest { @Test public void getClassName() throws IOException { String jreOption = null; String cpOption = &quot;C:\\\\IdeaProjects\\\\self-jvm\\\\target;C:\\\\IdeaProjects\\\\self-jvm\\\\target\\\\classes&quot;; String bootClassName = &quot;java\\\\lang\\\\Object&quot;; String userClassName = &quot;com\\\\wjd\\\\classfile\\\\ClassFileStructureTest&quot;; Classpath classpath = new Classpath(jreOption, cpOption); byte[] bootClassBytes = classpath.readClass(bootClassName); ClassReader bootReader = new ClassReader(bootClassBytes); ClassFile bootClassFile = ClassFile.parse(bootReader); assertEquals(&quot;Class name error&quot;, &quot;java/lang/Object&quot;, bootClassFile.getClassName()); byte[] userClassBytes = classpath.readClass(userClassName); ClassReader userReader = new ClassReader(userClassBytes); ClassFile userClassFile = ClassFile.parse(userReader); assertEquals(&quot;Class name error&quot;, &quot;com/wjd/classfile/ClassFileStructureTest&quot;, userClassFile.getClassName()); }} 总结class 文件： Java 虚拟机规范中所指的 class 文件，并非特指位于磁盘中的 .class 文件，而是泛指任何格式符合规范的 class 数据。它实际上可以通过网络下载，从数据库加载，甚至是在运行中直接生成等方式来获取 class 文件 构成 class 文件的基本数据单位是字节，可以把整个 class 文件当成一个字节流来处理 数据由连续多个字节构成，这些数据在 class 文件中以大端（big-endian）方式存储 为了描述 class 文件格式，Java 虚拟机规范定义了 u1、u2 和 u4 三种数据类型来表示1、2和4字节无符号整数 相同类型的多条数据一般按表（table）的形式存储在 class 文件中 表由表头和表项（item）构成，表头是 u2 或 u4 整数 常量池： 常量池里面存放着各式各样的常量信息，包括数字和字符串常量、类和接口名、字段和方法名等等 常量池实际上也是一个表。表头给出的常量池大小比实际大1 假设表头给出的值是n，那么常量池的实际大小是n–1。也就是说，常量池的有效的常量池索引是1~n–1。0是无效索引，表示不指向任何常量 long 和 double 各占两个位置。也就是说，如果常量池中存在这两种常量，实际的常量数量比n–1还要少，而且1~n–1的某些数也会变成无效索引 按照结构，常量池的常量可以分为2种，一种是存放有数据的字面常量（literal），一种是存放索引的符号引用常量（symbolic reference） 字面量包括数字常量和字符串常量，符号引用包括类和接口名、字段和方法信息等 像整数、浮点数、UTF8字节等，都属于字面常量，直接存放数据 而像字符串、类型、方法等都是引用常量，不直接存放数据，只保存指向数据的索引 除了字面量，其他引用常量都是通过索引直接或间接指向 CONSTANT_Utf8_info 常量 属性： Java虚拟机规范没有使用tag，而是使用属性名来区别不同的属性 常量是由Java虚拟机规范严格定义的，共有14种。但属性是可以扩展的，不同的虚拟机实现可以定义自己的属性类型","link":"/lang/java/jvm/selfjvm/03_classfile/"},{"title":"02_查找class文件","text":"查找class文件加载允许一个类，必须把它相关的依赖类也加载进来，比如父类、成员类等。 Java虚拟机规范并没有规定去哪里寻找类，所以不同虚拟机可以采用不同的方法。 一、类加载路径Oracle的Java虚拟机是根据类路径（classpath）来搜索类，按照搜索顺序可分为3类： 启动类路径（bootstrasp classpath）：默认目录是 jre\\lib，即Java标准库（大部分在rt.jar里）所在位置 扩展类路径（extension classpath）：默认目录是 jre\\lib\\ext，即Java扩展机制的类所在位置 用户类路径（user classpath）：默认当前目录，即自己实现的类、以及第三方类库所在位置 可以通过参数 -Xbootclasspath 来修改启动类路径。 可以设置环境变量 CLASSPATH 来修改用户类路径，也可以使用参数 -classpath/-cp 来设置用户类路径。 123java -cp path\\classes ...java -cp path\\lib1.jar ...java -cp path\\lib2.zip ... -classpath/-cp 既可以使用目录，也可以指向 jar 文件或者 zip 文件，可以同时指定多个目录或文件。 指定多个路径，需要分隔符分开，不同操作系统的分隔符不一样，在 windows 下是分号 ;，在类 Unix 下是冒号 :。 1java -cp path\\classes;path\\lib1.jar;path\\lib2.zip ... 从 Java 6 开始，还可以使用通配符（*）指定某个目录下的所有 jar 文件（注意，不会递归子目录的 jar 文件）： 1java -cp path\\classes;path\\lib\\* ... 二、类文件查找2.1 添加jre参数首先在命令行 Cmd 类中增加一个非标准参数 Xjre，表示 jre 所在的目录路径。 1234options.addOption(Option.builder(&quot;Xjre&quot;) .hasArg().desc(&quot;jre directory&quot;) .type(String.class) .build()); 1private String jreOption; 1234// jre路径if (line.hasOption(&quot;Xjre&quot;)) { jreOption = line.getOptionValue(&quot;Xjre&quot;);} 2.2 查找入口类其次，要实现不同类加载路径的入口类，接口定义如下： 123456789101112131415public interface Entry { /** * 读取class文件 * @param className class的完整名称（java/lang/Object） * @return 文件字节 */ byte[] readClass(String className) throws IOException; /** * 路径 * @return 路径 */ String string();} 然后有4种入口实现，分别对应上面几种类加载路径的写法： DirEntry：查找 class 的目录 ZipEntry：查找 class 的 zip 或 jar 文件 CompositeEntry：多种查找路径的组合，比如目录，或 zip，或 jar WildcardEntry：通配符路径，指定某个目录下的所有子 zip 或 jar 文件 各自的实现代码如下： 1234567891011121314151617181920212223242526272829/** * 目录入口 */public class DirEntry implements Entry { /** * 目录绝对路径 */ private String absPath; public DirEntry(String path) { this.absPath = Paths.get(path).toAbsolutePath().toString(); } @Override public byte[] readClass(String className) throws IOException { Path path = Paths.get(absPath, className); if (Files.exists(path)) { System.out.println(className + &quot; found in &quot; + string()); return Files.readAllBytes(path); } return null; } @Override public String string() { return absPath; }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * zip或jar入口 */public class ZipEntry implements Entry { /** * 文件绝对路径 */ private String absPath; public ZipEntry(String path) { this.absPath = Paths.get(path).toAbsolutePath().toString(); } @Override public byte[] readClass(String className) throws IOException { try (FileInputStream fis = new FileInputStream(absPath); BufferedInputStream buf = new BufferedInputStream(fis); ArchiveInputStream in = new ArchiveStreamFactory().createArchiveInputStream(buf)) { ArchiveEntry entry; while ((entry = in.getNextEntry()) != null) { if (!in.canReadEntryData(entry)) { continue; } // 转成路径格式一样的才能对比得上完整名称 String entryPath = Paths.get(entry.getName()).toString(); if (entryPath.equals(className)) { System.out.println(className + &quot; found in &quot; + string()); ByteArrayOutputStream out = new ByteArrayOutputStream(); IOUtils.copy(in, out); return out.toByteArray(); } } } catch (ArchiveException e) { e.printStackTrace(); } return null; } @Override public String string() { return absPath; }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 组合入口 */public class CompositeEntry implements Entry { /** * 路径选项 */ private String pathOptions; /** * 子入口列表 */ private List&lt;Entry&gt; entries; public CompositeEntry(String pathOptions) { this.pathOptions = pathOptions; this.initEntries(); } @Override public byte[] readClass(String className) throws IOException { if (entries == null) { return null; } for (Entry e : entries) { byte[] bytes = e.readClass(className); if (bytes != null) { return bytes; } } return null; } @Override public String string() { if (entries == null) { return pathOptions; } StringBuilder sb = new StringBuilder(); sb.append(&quot;CompositeEntry [&quot;); for (Entry e : entries) { sb.append(e.string()).append(&quot;, &quot;); } sb.delete(sb.length() - 2, sb.length()); sb.append(&quot;]&quot;); return sb.toString(); } /** * 初始化Entries列表 */ private void initEntries() { String[] paths = pathOptions.split(File.pathSeparator); entries = new ArrayList&lt;&gt;(paths.length); for (String path : paths) { entries.add(EntryFactory.newEntry(path)); } System.out.println(string()); }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 通配符入口 */public class WildcardEntry implements Entry { /** * 绝对路径 */ private String absPath; /** * 子入口列表 */ private List&lt;Entry&gt; entries; public WildcardEntry(String path) { // 去掉后面的通配符 String p = path.substring(0, path.length() - 1); this.absPath = Paths.get(p).toAbsolutePath().toString(); initEntries(); } @Override public byte[] readClass(String className) throws IOException { if (entries == null) { return null; } for (Entry e : entries) { byte[] bytes = e.readClass(className); if (bytes != null) { return bytes; } } return null; } @Override public String string() { if (entries == null) { return absPath; } StringBuilder sb = new StringBuilder(); sb.append(&quot;WildcardEntry [&quot;); for (Entry e : entries) { sb.append(e.string()).append(&quot;, &quot;); } sb.delete(sb.length() - 2, sb.length()); sb.append(&quot;]&quot;); return sb.toString(); } /** * 初始化Entries列表 */ private void initEntries() { File dir = new File(absPath); if (!dir.isDirectory()) { return; } // 获取目录下所有的zip或jar文件 File[] files = dir.listFiles((dir1, name) -&gt; { String lowerName = name.toLowerCase(); return lowerName.endsWith(&quot;.zip&quot;) || lowerName.endsWith(&quot;.jar&quot;); }); if (files == null) { return; } // 生成所有子入口实例 entries = new ArrayList&lt;&gt;(files.length); for (File file : files) { String filePath = file.getAbsolutePath(); entries.add(EntryFactory.newEntry(filePath)); } System.out.println(string()); }} 2.3 类查找实现查找入口搞定后，接下来就是真正的类查找实现了。 首先，对命令行参数进行解析，包括设置 jre 目录、启动类路径、用户类路径等，并创建对应的入口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112/** * 类路径 */public class Classpath { /** * 启动类路径 */ private Entry bootEntry; /** * 扩展类路径 */ private Entry extEntry; /** * 用户类路径 */ private Entry userEntry; /** * 启动路径选项 */ private String jreOption; /** * 用户类路径选项 */ private String cpOptions; public Classpath(String jreOption, String cpOptions) { this.jreOption = jreOption; this.cpOptions = cpOptions; initOptions(); } /** * classpath */ public String string() { return cpOptions; } /** * 初始化选项 */ private void initOptions() { parseBootAndExtClasspath(); parseUserClasspath(); } /** * 解析启动类路径和扩展类路径 */ private void parseBootAndExtClasspath() { String jrePath = getJrePath(); // 启动类路径（jre/lib/*） Path bootPath = Paths.get(jrePath, &quot;lib&quot;); String bootDir = bootPath.toAbsolutePath() + File.separator + &quot;*&quot;; bootEntry = EntryFactory.newEntry(bootDir); // 扩展类路径（jre/lib/ext/*） Path extPath = Paths.get(jrePath, &quot;lib&quot;, &quot;ext&quot;); String extDir = extPath.toAbsolutePath() + File.separator + &quot;*&quot;; extEntry = EntryFactory.newEntry(extDir); } /** * 解析用户类路径 */ private void parseUserClasspath() { if (cpOptions == null || &quot;&quot;.equals(cpOptions)) { return; } // 用户类路径（-classpath/-cp） userEntry = EntryFactory.newEntry(cpOptions); } /** * 获取jre文件夹路径 * * @return jre文件夹路径 */ private String getJrePath() { Path path; // 用户自定义路径 if (jreOption != null) { path = Paths.get(jreOption); if (Files.exists(path)) { return path.toString(); } } // 系统环境变量 String jdkPath = System.getenv(&quot;JAVA_HOME&quot;); if (jdkPath != null) { path = Paths.get(jdkPath, &quot;jre&quot;); if (Files.exists(path)) { return path.toString(); } } // 最后尝试在当前路径下寻找jre目录 path = Paths.get(&quot;.&quot;, &quot;jre&quot;); if (Files.exists(path)) { return path.toString(); } // 找不到jre的路径 throw new IllegalStateException(&quot;Can not found jre folder!&quot;); }} 然后，就是实际的类查找流程实现了，它是按照 启动类路径 -&gt; 扩展类路径 -&gt; 用户类路径 去查找的： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 类路径 */public class Classpath { /** * 读取class文件 * * @param className class的完整名称（java/lang/Object） * @return 文件字节 */ public byte[] readClass(String className) throws IOException { byte[] bytes = null; // 转换成文件路径 String classPath = Paths.get(className).toString(); String classFileName = classPath + &quot;.class&quot;; // 启动类加载 if (bootEntry != null) { bytes = bootEntry.readClass(classFileName); } // 扩展类加载 if (bytes == null &amp;&amp; extEntry != null) { bytes = extEntry.readClass(classFileName); } // 用户类加载 if (bytes == null &amp;&amp; userEntry != null) { bytes = userEntry.readClass(classFileName); } if (bytes == null) { System.out.println(&quot;not found class &quot; + className); } return bytes; }} 另外，创建入口实例的方法统一放到了一个工厂类里面，为了方便查看和修改： 123456789101112131415161718192021222324252627282930public class EntryFactory { /** * 根据参数生成指定的Entry类 * * @param entryOption 选项参数 * @return 具体的Entry实例 */ public static Entry newEntry(String entryOption) { // 多选项路径 if (entryOption.contains(File.pathSeparator)) { return new CompositeEntry(entryOption); } // 通配符路径 if (entryOption.endsWith(&quot;*&quot;)) { return new WildcardEntry(entryOption); } // zip或者jar String lowName = entryOption.toLowerCase(); if (lowName.endsWith(&quot;.zip&quot;) || lowName.endsWith(&quot;.jar&quot;)) { return new ZipEntry(entryOption); } // 文件夹路径 return new DirEntry(entryOption); }} 完整的类查找代码差不多就是这样了，后面就是要测试实际的效果了。 2.4 单元测试下面就是单元测试的代码： 12345678910111213public class ClasspathTest { @Test public void readClass() throws IOException { String jreOption = null; String cpOption = &quot;C:\\\\IdeaProjects\\\\self-jvm\\\\target;C:\\\\IdeaProjects\\\\self-jvm\\\\target\\\\classes&quot;; String bootClassName = &quot;java\\\\lang\\\\Object&quot;; String userClassName = &quot;com\\\\wjd\\\\cmd\\\\Cmd&quot;; Classpath classpath = new Classpath(jreOption, cpOption); Assert.assertNotNull(&quot;Object is null&quot;, classpath.readClass(bootClassName)); Assert.assertNotNull(&quot;Cmd is null&quot;, classpath.readClass(userClassName)); }} 它的输出结果如下： 123456789WildcardEntry [D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\charsets.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\deploy.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\javaws.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\jce.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\jfr.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\jfxswt.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\jsse.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\management-agent.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\plugin.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\resources.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\rt.jar]WildcardEntry [D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\access-bridge-64.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\cldrdata.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\dnsns.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\jaccess.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\jfxrt.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\localedata.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\nashorn.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\sunec.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\sunjce_provider.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\sunmscapi.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\sunpkcs11.jar, D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\ext\\zipfs.jar]CompositeEntry [C:\\IdeaProjects\\self-jvm\\target, C:\\IdeaProjects\\self-jvm\\target\\classes]java\\lang\\Object.class found in D:\\Program Files\\JDK\\jdk1.8.0_25_x64\\jre\\lib\\rt.jarcom\\wjd\\cmd\\Cmd.class found in C:\\IdeaProjects\\self-jvm\\target\\classes 看起来，实际加载的包和最后查找到的类路径都是对的。 总结 Oracle的Java虚拟机是根据类路径（classpath）来搜索类，按照搜索顺序可分为3类： 启动类路径（bootstrasp classpath）：默认目录是 jre\\lib，即Java标准库（大部分在rt.jar里）所在位置 扩展类路径（extension classpath）：默认目录是 jre\\lib\\ext，即Java扩展机制的类所在位置 用户类路径（user classpath）：默认当前目录，即自己实现的类、以及第三方类库所在位置 -classpath/-cp 既可以使用目录，也可以指向 jar 文件或者 zip 文件，可以同时指定多个目录或文件。 指定多个路径，需要分隔符分开，不同操作系统的分隔符不一样，在 windows 下是分号 ;，在类 Unix 下是冒号 : 从 Java 6 开始，还可以使用通配符（*）指定某个目录下的所有 jar 文件（注意，不会递归子目录的 jar 文件） 具体代码实现，有4种入口类，分别对应几种类加载路径的写法： DirEntry：查找 class 的目录 ZipEntry：查找 class 的 zip 或 jar 文件 CompositeEntry：多种查找路径的组合，比如目录，或 zip，或 jar WildcardEntry：通配符路径，指定某个目录下的所有子 zip 或 jar 文件 ps：上面的代码实现，为了简单，有些地方没做参数校验，默认传入参数的格式都是正确的（好吧。。实际是我懒得写了，先把功能实现了再说~~）","link":"/lang/java/jvm/selfjvm/02_classpath/"},{"title":"01_命令行工具","text":"命令行工具Java虚拟机启动时，需要指定类启动应用程序。 但是Java虚拟机规范中并没有明确规定，怎么指定类启动应用程序，也就是主类（包含main方法的类）。 Oracle的虚拟机实现是通过 java 命令来启动的，主类名由命令函参数指定。 1234java [-options] class [args]java [-options] -jar jarfile [args]javaw [-options] class [args]javaw [-options] -jar jarfile [args] class：主类名 jarfile：jar包文件名 args：main() 方法参数 标准选项比较稳定，不会轻易变动 非标准选项以 -X 开头，很有可能在未来版本中发生变更 非标准选项中的高级选项，以 -XX 开头 一、编写命令行工具目前主要添加几个命令参数： -help -version -classpath 另外，启动程序主类名也是参数之一，并且必须放在所有参数中的第一位。 1234private boolean helpFlag = false;private boolean versionFlag = false;private String cpOption = null;private String mainClass = null; 命令行参数的生成和解析，采用了 Apache 的一个 commons-cli 命令行工具包。 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class Cmd { private final static Options options; static { options = new Options(); options.addOption(new Option(&quot;help&quot;, false, &quot;print help message&quot;)); options.addOption(new Option(&quot;?&quot;, false, &quot;print help message&quot;)); options.addOption(new Option(&quot;version&quot;, false, &quot;print version and exit&quot;)); options.addOption(Option.builder(&quot;classpath&quot;) .hasArg().desc(&quot;classpath&quot;) .type(String.class) .build()); options.addOption(Option.builder(&quot;cp&quot;) .hasArg().desc(&quot;classpath&quot;) .type(String.class) .build()); } private boolean helpFlag = false; private boolean versionFlag = false; private String cpOption = null; private String mainClass = null; private String[] args = null; /** * 解析命令行参数 * @param args 命令行参数 */ public void parse(String[] args) { try { // 解析命令行参数 CommandLineParser parser = new DefaultParser(); CommandLine line = parser.parse(options, args); this.args = Arrays.copyOfRange(args, 1, args.length); // 打印帮助信息 if (line.hasOption(&quot;help&quot;) || line.hasOption(&quot;?&quot;)) { helpFlag = true; printHelp(); } // 版本信息 if (line.hasOption(&quot;version&quot;)) { versionFlag = true; System.out.println(&quot;version 0.0.1&quot;); } // 启动程序主类名 if (args.length &gt; 0) { mainClass = args[0]; } // classpath路径 if (line.hasOption(&quot;classpath&quot;)) { cpOption = line.getOptionValue(&quot;classpath&quot;); } else if (line.hasOption(&quot;cp&quot;)) { cpOption = line.getOptionValue(&quot;cp&quot;); } // 打印所有参数 System.out.println(&quot;helpFlag = &quot; + helpFlag); System.out.println(&quot;versionFlag = &quot; + versionFlag); System.out.println(&quot;mainClass = &quot; + mainClass); System.out.println(&quot;classpath = &quot; + cpOption); } catch (ParseException e) { e.printStackTrace(); } } /** * 打印命令行帮助信息 */ public void printHelp() { HelpFormatter formatter = new HelpFormatter(); formatter.printHelp(&quot;self-jvm&quot;, options); }} 二、添加测试类测试类代码如下： 123456789101112131415public class CmdTest { @Test public void parse() { String[] args = new String[]{ &quot;com.wjd.cmd.Cmd&quot;, &quot;-classpath&quot;, &quot;/projects&quot; }; Cmd cmd = new Cmd(); cmd.parse(args); } @Test public void printHelp() { Cmd cmd = new Cmd(); cmd.printHelp(); }} 测试的打印结果大概是这样子的： 12345678910111213# parsehelpFlag = falseversionFlag = falsemainClass = com.wjd.cmd.Cmdclasspath = /projects# printHelpusage: self-jvm -? print help message -classpath &lt;arg&gt; classpath -cp &lt;arg&gt; classpath -help print help message -version print version and exit","link":"/lang/java/jvm/selfjvm/01_cmd/"},{"title":"Stack","text":"Stack一、定义12public class Stack&lt;E&gt; extends Vector&lt;E&gt; {} Stack 继承自 Vector 类，因此拥有 Vector 的所有特性。 二、原理Stack 除了增加几个栈特用的方法以外，其他的和 Vector 都一样，而增加的这几个方法，内部实际上也是调用的 Vector 的方法。 12345678910111213141516171819public E push(E item) { addElement(item); return item;}public synchronized E pop() { E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj;}public synchronized E peek() { int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1);} 和 Vector 的保持一致，Stack 添加的方法也加上了同步锁 synchronized，避免并发问题。 不过 push 方法并没有加上同步锁，这个倒是有点出乎意料，或许是因为它内部调用的方法 addElement 已经加锁的原因吧。","link":"/lang/java/source/jdk8/collection/Stack/"},{"title":"Vector","text":"Vector一、定义1234public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { } 定义上和 ArrayList 一样，继承同一个父类和实现相同的接口。 二、实现原理 实际上，Vector 和 ArrayList 的实现代码基本一致，底层数据结构都是数组，而且接口方法的实现代码都差不多。 目前来说，也就发现了 Vector 和 ArrayList 的几点区别。 2.1 同步锁第1点是同步锁的区别，Vector 的大部分方法都使用了 synchronized 来加锁，用于避免并发访问和修改： 123456public synchronized E get(int index) { if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);} 而 ArrayList 的方法都是没有 synchronized 加持的，也就是完全不考虑并发同步的问题。所以一般情况下，ArrayList 相比于 Vector 在取数存数上的效率会高一些。 2.2 迭代器ArrayList 使用的当前最常用的迭代器接口 Iterator。 而 Vector 则是以前的旧枚举迭代器 Enumeration： 123456789101112131415161718public Enumeration&lt;E&gt; elements() { return new Enumeration&lt;E&gt;() { int count = 0; public boolean hasMoreElements() { return count &lt; elementCount; } public E nextElement() { synchronized (Vector.this) { if (count &lt; elementCount) { return elementData(count++); } } throw new NoSuchElementException(&quot;Vector Enumeration&quot;); } };} 也不是说 Iterator 就比 Enumeration 好。只是 Iterator 相比于 Enumeration，不仅增加了 remove 方法，而且 接口方法名称也更精简。 在使用体验上，Iterator 确实会更好用一些。","link":"/lang/java/source/jdk8/collection/Vector/"},{"title":"PriorityQueue","text":"PriorityQueue一、定义12345678910111213public class PriorityQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements java.io.Serializable { public PriorityQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) { // Note: This restriction of at least one is not actually needed, // but continues for 1.5 compatibility if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.queue = new Object[initialCapacity]; this.comparator = comparator; }} 从名称就可以看出来，这是个优先队列，也就是按照从小到大（或从大到小）排序的队列。 继承的类就是队列 Queue 的模板实现类 AbstractQueue。 二、实现2.1 数据结构既然是有顺序的队列，那么它的底层数据结构是什么样的呢？ 其实还是数组~~ 123transient Object[] queue; // non-private to simplify nested class accessprivate int size = 0; 学过数据结构的话，应该知道，数组也可以用于表示树结构。就比如数组： 1[1, 2, 3, 4, 5, 6, 7, 8, 9] 就可以表示下面的完全二叉树： 1234567 1 / \\ 2 3 / \\ / \\ 4 5 6 7 / \\8 9 假如当前索引是 k，那么父节点索引就是 (k - 1) / 2，2个子节点索引分别是 (k * 2) + 1 和 (k * 2) + 2。 用例子来说，假如当前索引是 1，那么父节点索引就是 (1 - 1) / 2 = 0，子节点索引是 (1 * 2) + 1 = 3 和 (1 * 2) + 2 = 4。 完全二叉树在数据结构中，常用于表示堆（当然，完全多叉树也可以）。 堆也是可以有序的，一般可以分为最大值堆和最小值堆： 最小值堆，父节点都不比子节点的值大； 最大值堆，父节点都不比子节点的值小。 例如上面的例子 [1, 2, 3, 4, 5, 6, 7, 8, 9]，就是最小值堆。 优先队列 PriorityQueue 实际上也是用有序堆来实现的。 不过具体是最小值堆，还是最大值堆，就得看优先队列的比较器函数是什么了。 2.2 扩容机制底层结构是数组，那也就是和 ArrayList 一样，当元素增多时，就需要进行扩容。 优先队列 PriorityQueue 的扩容机制，基本和 ArrayList 差不多，只有些许区别： 1234567891011private void grow(int minCapacity) { int oldCapacity = queue.length; // Double size if small; else grow by 50% int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); queue = Arrays.copyOf(queue, newCapacity);} 优先队列 PriorityQueue 对容量比较小的情况进行了特别处理，其他则和 ArrayList 一样： 当队列容量还比较小（&lt; 64）时，就直接扩容 1 倍（oldCapacity + 2）； 否则就扩容 0.5 倍（oldCapacity &gt;&gt; 1）。 举2个列子说明： 当 queue.length 是 9 时，因为 9 &lt; 64，所以扩容 1 倍，新容量就是 9 + (9 + 2) = 20。 当 queue.length 是 70 时，因为 70 &gt; 64，所以扩容 0.5 倍，新容量就是 70 + (70 / 2) = 105。 2.3 堆操作从数组变成堆的实现，和数据结构里的方法差不多。 堆的构造，一般是从数组的最后一个非叶子节点开始，到根节点为止，一直执行下沉操作，就能够完成： 1234private void heapify() { for (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--) siftDown(i, (E) queue[i]);} 简单说一下下沉函数 siftDown 的实现吧： 12345678910111213141516171819202122232425262728293031323334353637383940414243private void siftDown(int k, E x) { if (comparator != null) siftDownUsingComparator(k, x); else siftDownComparable(k, x);}@SuppressWarnings(&quot;unchecked&quot;)private void siftDownComparable(int k, E x) { Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; int half = size &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) { int child = (k &lt;&lt; 1) + 1; // assume left child is least Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) c = queue[child = right]; if (key.compareTo((E) c) &lt;= 0) break; queue[k] = c; k = child; } queue[k] = key;}@SuppressWarnings(&quot;unchecked&quot;)private void siftDownUsingComparator(int k, E x) { int half = size &gt;&gt;&gt; 1; while (k &lt; half) { int child = (k &lt;&lt; 1) + 1; Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c; k = child; } queue[k] = x;} 下沉 siftDown 可以分为2种情况，一种是有自定义的比较器，一种是用默认的比较。 下沉 siftDown 就是一直往下替换当前节点，直到成为叶子节点，或子节点都比节点小（或大）时才结束。 比如，当前需要下沉的节点是 9： 1234567891011121314151617181920212223 1 / \\ 9 2 / \\ / \\ 3 4 5 6 / \\7 8 1 / \\ 3 2 / \\ / \\ 9 4 5 6 下沉，交换 9 &lt;==&gt; 3 / \\7 8 1 / \\ 3 2 / \\ / \\ 7 4 5 6 下沉，交换 9 &lt;==&gt; 7 / \\9 8 至于上浮 siftUp 和下沉的 siftDown 代码差不多： 123456private void siftUp(int k, E x) { if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x);} 只是逻辑反过来而已，比如需要上浮的节点是 2： 1234567891011121314151617181920212223 1 / \\ 3 4 / \\ / \\ 5 6 7 8 / \\9 2 1 / \\ 3 4 / \\ / \\ 2 6 7 8 上浮，交换 2 &lt;==&gt; 5 / \\9 5 1 / \\ 2 4 / \\ / \\ 3 6 7 8 上浮，交换 2 &lt;==&gt; 3 / \\9 5 2.4 集合操作优先队列的增删查改稍微麻烦一些，因为它是一个有序的堆，因此在增删元素时，会引起堆结构发生变化。 1）查询 查找没什么好说的，因为底层结构是数组，所以直接遍历数组查询就行： 12345678910111213141516public E peek() { return (size == 0) ? null : (E) queue[0];}public boolean contains(Object o) { return indexOf(o) != -1;}private int indexOf(Object o) { if (o != null) { for (int i = 0; i &lt; size; i++) if (o.equals(queue[i])) return i; } return -1;} 2）添加 不过，添加元素时，总是先添加到队列数组的末尾，再利用上浮 siftUp 来调整堆结构，算是有点小麻烦： 123456789101112131415161718public boolean add(E e) { return offer(e);}public boolean offer(E e) { if (e == null) throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1); size = i + 1; if (i == 0) queue[0] = e; else siftUp(i, e); return true;} 3）删除 而删除则是更麻烦一些，删除时，会把删除元素和数组末尾的元素交换，再执行下沉 siftDown 或上浮 siftUp 操作，也就是说，删除时是不确定是要下沉，还是上浮的。而添加是明确的只会上浮（因为添加总是在末尾）： 12345678910111213141516171819202122232425262728293031public E poll() { if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0]; E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x); return result;}private E `removeAt` (int i) { // assert i &gt;= 0 &amp;&amp; i &lt; size; modCount++; int s = --size; if (s == i) // removed last element queue[i] = null; else { E moved = (E) queue[s]; queue[s] = null; siftDown(i, moved); if (queue[i] == moved) { siftUp(i, moved); if (queue[i] != moved) return moved; } } return null;} 删除元素的话，也可以分为几种情况： 删除队列头，移除后，这个只要执行下沉操作； 删除末尾元素，直接移除，不需要额外的操作； 删除中间的元素，可能下沉，也可能上浮。 删除比添加会稍微复杂一点，不过也还好，毕竟都是堆的基本操作。 这里举2个栗子，简单说明一下什么时候需要下沉？什么时候需要上浮？ 栗1，删除节点 2，这种情况就会下沉： 12345678910111213141516171819202122232425262728293031 1 / \\ 2 4 / \\ / \\ 3 6 7 8 需要删除2 / \\9 5 1 / \\ 5 4 / \\ / \\ 3 6 7 8 和末尾元素交换，2 &lt;==&gt; 5 / \\9 2 1 / \\ 5 4 / \\ / \\ 3 6 7 8 删除末尾元素 /9 1 / \\ 3 4 / \\ / \\ 5 6 7 8 下沉，交换 5 &lt;==&gt; 3 /9 栗2，删除节点 8，这种情况就会上浮： 12345678910111213141516171819202122232425262728293031 1 / \\ 2 7 / \\ / \\ 3 4 8 9 需要删除8 / \\5 6 1 / \\ 2 7 / \\ / \\ 3 4 6 9 和末尾元素交换，8 &lt;==&gt; 6 / \\5 8 1 / \\ 2 7 / \\ / \\ 3 4 6 9 删除末尾元素 /5 1 / \\ 2 6 / \\ / \\ 3 4 7 9 上浮，交换 6 &lt;==&gt; 7 /5 一般情况下，删除元素时， 删除元素的是和末尾元素位于同一侧的子树，肯定会执行下沉操作； 删除元素的是和末尾元素位于不同侧的子树，有可能会执行上浮操作，也可能是执行下沉操作； 因为同侧子树，祖先节点肯定比末尾节点要小，所以交换后肯定是执行下沉操作的。而不同侧的子树，交换后是有可能祖先节点比末尾节点大的，所以有可能执行上浮操作（注意是可能）。 另外，为什么这里的 removeAt 需要返回值？而且还是只返回执行了上浮 siftUp 的值？有什么特殊的意义嘛？这个原因到后面迭代器那里再说~~ 2.5 迭代器首先明确一点，优先队列的迭代是按照底层数组顺序遍历的，并不是按大小顺序。 也就是说，迭代遍历出来的顺序，并不是有序的，这点必须要搞清楚。 12345678910111213141516private final class Itr implements Iterator&lt;E&gt; { public E next() { if (expectedModCount != modCount) throw new ConcurrentModificationException(); if (cursor &lt; size) return (E) queue[lastRet = cursor++]; // 按照数组顺序遍历所有元素 if (forgetMeNot != null) { lastRet = -1; lastRetElt = forgetMeNot.poll(); if (lastRetElt != null) return lastRetElt; } throw new NoSuchElementException(); }} 其实优先队列的迭代器，如果只是简单遍历访问的话，倒也没什么问题。 关键是迭代时，是可以删除元素的，而优先队列的元素是有序的，如果在迭代期间移除元素，就会引起堆的数据结构发生变化，那后面还能正常迭代下去嘛？或者说是怎么实现，数据结构变化后依旧可以正常遍历？ 先确认一下，迭代删除时，是否会影响后续的遍历？ 举个栗子吧，比如当前访问的元素是 8，下一个迭代元素是 9（next()）： 1234567 1 / \\ 2 7 / \\ / \\ 3 4 8 9 要删除8 / \\5 6 假如此时删除当前元素 8，那么堆结构就会变成： 1234567 1 / \\ 2 6 / \\ / \\ 3 4 7 9 6还没遍历到，但是已经被移到前面遍历过的位置了 /5 那么问题就来了，6 还能不能遍历到呢？毕竟下一个待遍历的元素是 7，迭代器是不可能回到前面再遍历 6 的，所以 6 已经无法被遍历到了，那要怎么处理这种情况呢？ 为了解决这个问题，优先队列 PriorityQueue 的迭代器里就加上一个成员变量 forgetMeNot，用于保存这种发生移动后，正常迭代遍历无法访问到的元素： 12345678910111213141516171819202122232425262728293031323334353637private final class Itr implements Iterator&lt;E&gt; { /** * A queue of elements that were moved from the unvisited portion of * the heap into the visited portion as a result of &quot;unlucky&quot; element * removals during the iteration. (Unlucky element removals are those * that require a siftup instead of a siftdown.) We must visit all of * the elements in this list to complete the iteration. We do this * after we've completed the &quot;normal&quot; iteration. * * We expect that most iterations, even those involving removals, * will not need to store elements in this field. */ private ArrayDeque&lt;E&gt; forgetMeNot = null; public void remove() { if (expectedModCount != modCount) throw new ConcurrentModificationException(); if (lastRet != -1) { E moved = PriorityQueue.this.removeAt(lastRet); lastRet = -1; if (moved == null) cursor--; else { if (forgetMeNot == null) forgetMeNot = new ArrayDeque&lt;&gt;(); forgetMeNot.add(moved); } } else if (lastRetElt != null) { PriorityQueue.this.removeEq(lastRetElt); lastRetElt = null; } else { throw new IllegalStateException(); } expectedModCount = modCount; }} 实际上，只有发生上浮 siftUp 时，才会导致元素无法被遍历到，因此前面的 removeAt 方法只返回了上浮 siftUp 情况下的移动节点，其实就是专门为这个迭代器准备的。 如果 removeAt 的返回值不为 null，就说明发生了上浮 siftUp，那么就需要添加到 forgetMeNot。 另外，forgetMeNot 中的元素，需要等到正常的迭代遍历走完以后，才会遍历到素（看上面next()的代码）。 也就是说，删除元素后，实际上会影响到遍历的顺序。用个栗子说明一下： 123456789101112131415161718192021 1 / \\ 2 7 / \\ / \\ 3 4 8 9 删除8 / \\5 6 1 / \\ 2 6 / \\ / \\ 3 4 7 9 删除8之后，此时再删除9 /5 1 / \\ 2 5 / \\ / \\ 3 4 7 6 删除9之后的结构 删除2次之后，forgetMeNot 里面应该包含2个元素 [6, 5]，这个时候迭代顺序就发生变化了： 12345// 正常的遍历顺序1 2 7 3 4 8 9 5 6// 删除后的遍历顺序1 2 7 3 4 8 9 6 5 可以看到，删除后可能会影响实际遍历的顺序。 其实我有一点不明白的是，删除时删除元素交换的始终都是末尾元素，它本来就是最后遍历的，而 forgetMeNot 保存的就是移动的元素，实际上也就是末尾元素，所以 forgetMeNot 是倒着放入末尾元素的，为什么不是用 Stack ，而是用队列 ArrayDeque 呢？ 这点还没有搞明白，还是说反正都是遍历，顺序什么的都不是啥大问题？？","link":"/lang/java/source/jdk8/collection/PriorityQueue/"},{"title":"Hashtable","text":"Hashtable一、定义1234public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable {} Hashtable 继承了旧的父类 Dictionary，和新的接口 Map。 二、实现 2.1 数据结构HashTable 底层是采用“数组 + 链表”的结构实现的： 12345678910private transient Entry&lt;?,?&gt;[] table;private transient int count;private static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Entry&lt;K,V&gt; next;} 通过 key 的 hash 映射到数组table上，找到位置后，再将不同的 key 链接到链表上： 123456789数组（4） ___ ___ ___ | 0 | -&gt; | 4 | -&gt; | 8 | --链表 ___ ___ | 1 | -&gt; | 5 | --链表 ___ | 2 | --链表 ___ ___ ____ | 3 | -&gt; | 7 | -&gt; | 11 | --链表 2.2 集合操作1）添加元素 知道了数据结构，实际上就很容易理解怎么添加一个元素了： 12345678910111213141516171819private void addEntry(int hash, K key, V value, int index) { modCount++; Entry&lt;?,?&gt; tab[] = table; if (count &gt;= threshold) { // 扩容 rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; } // 添加新元素 @SuppressWarnings(&quot;unchecked&quot;) Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++;} 扩容代码那里暂时忽略，后面再解释，直接看后面几行代码： 12Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index];tab[index] = new Entry&lt;&gt;(hash, key, value, e); 举个例子说明这2行代码的意义，假设当前数据结构如下： 123456789数组（4） ___ | 4 | ___ | | ___ | | ___| 3 | 这个时候添加 0，此时 0 还不在集合里，0 % 4 = 0，所以应该要放入 table[0] 中，但是此时 table[0] 已经有 4 了，所以就需要追加到链表上。 那么按照上面的2行代码，最终结果如下： 123456789数组（4） ___ ___ | 0 | -&gt; | 4 | ___ | | ___ | | ___| 3 | 注意，添加元素时，是插入到链表头部的，而不是链表尾部。 至于为什么倒着插入，我想应该是如果每次都插到尾部的话，就得遍历一次链表，代价有点高~~ 2）删除元素 1234567891011121314151617181920212223public synchronized V remove(Object key) { Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(&quot;unchecked&quot;) Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)tab[index]; for(Entry&lt;K,V&gt; prev = null ; e != null ; prev = e, e = e.next) { if ((e.hash == hash) &amp;&amp; e.key.equals(key)) { modCount++; if (prev != null) { prev.next = e.next; } else { // 删除数组元素 tab[index] = e.next; } count--; V oldValue = e.value; e.value = null; return oldValue; } } return null;} 删除没什么好说的，直接删就是了，唯一需要注意的就是，如果删除的是数组上的节点，就需要更新它的值： 123456789数组（4） ___ ___ | 0 | -&gt; | 4 | ___ | | ___ | | ___| 3 | 比如删除 0，就需要把 4 设置到数组里： 123456789数组（4） ___ | 4 | ___ | | ___ | | ___| 3 | 2.2 扩容机制HashTable 是采用“数组 + 链表”的结构实现的，理论上链表可以无限长。 但是如果链表太长了，就会导致查询变得很慢，这个要怎么解决呢？ 这个时候就需要扩容了，把过长的链表拆分，变成短链表。那要怎么拆分？ 数据是通过“数组 + 链表”保存的，在维持元素数量不变的情况下，想要链表变短，那就只能增长数组长度。 其实，HashTable 的扩容规则就是这样的，通过增长数组容量，以重新调整链表的结构，缩短链表的长度。 1）负载因子 那还有一个问题，就是，多长的链表才算是太长？或者说，什么时候才需要重新调整数组容量？ 在 HashTable 中，使用了负载因子来表示需要重构数组的时机： 12// 负载因子private float loadFactor; 为了了解负载因子的作用，先解释一下负载的意义。 举个例子说明，比如当前结构如下： 123456789数组（4） ___ ___ | 0 | -&gt; | 4 | ___ | 1 | ___ | | ___ ___ ____ | 3 | -&gt; | 7 | -&gt; | 11 | 那么，此时的数组容量是 4，元素数量是 6，因此实际负载就是 6 / 4 = 1.5。 也就是说，负载其实表示的是当前数据结构的负载情况，数值越高，表示保存的数据越多。 因此，负载因子相当于一个阈值，当负载超过这个阈值时，就表示当前数据已经很满了，需要对数组进行扩容了。 再举个例子，假设当前 HashTable 的负载因子是 0.8，此时的数据结构如下： 123456789数组（4） ___ ___ | 0 | -&gt; | 4 | ___ | | ___ | | ___| 3 | 此时的负载是 4 / 3 = 0.75 &lt; 0.8，暂时不需要扩容。 如果我再添加一个元素 1 之后： 123456789数组（4） ___ ___ | 0 | -&gt; | 4 | ___ | 1 | ___ | | ___| 3 | 此时的负载是 4 / 4 = 1 &gt; 0.8，这个时候就需要扩容了。 还有，HashTable 中为了避免经常计算负载，就添加了另一个变量阈值，来维护需要扩容的数量阈值： 12// 阈值private int threshold; 它实际就是由数组容量和负载因子算出来的： 1threshold = table.length * loadFactor 当元素数量大于这个阈值时，就需要扩容： 123if (count &gt;= threshold) { // 扩容} 但实际上，阈值 threshold 并不是一个必要的变量，只是为了减少负载的计算（除法计算），而添加的。 2）扩容规则 好了，既然知道了扩容的时机，那就说一下扩容的规则吧，究竟要扩容多少才好呢？ HashTable 和其他集合类差不多，具体如下： 1234567int newCapacity = (oldCapacity &lt;&lt; 1) + 1;if (newCapacity - MAX_ARRAY_SIZE &gt; 0) { if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE;} 除去溢出判断，一般情况下其实就是 2倍 + 1： 1新数组容量 = 旧数组容量 * 2 + 1 3）扩容实现 先上代码，后面再解释： 12345678910111213141516171819202122232425262728293031protected void rehash() { int oldCapacity = table.length; Entry&lt;?,?&gt;[] oldMap = table; // 计算扩容后新的数组容量 int newCapacity = (oldCapacity &lt;&lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) { if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE; } Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; modCount++; // 计算新的阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; for (int i = oldCapacity ; i-- &gt; 0 ;) { for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) { Entry&lt;K,V&gt; e = old; old = old.next; // 重新分配数组的链表 int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; } }} 举例子说明，假设 HashTable 的负载因子是 0.75，阈值 threshold = 4 * 0.75 = 3，此时的数据结构如下： 123456789数组（4） ___ ___ | 0 | -&gt; | 4 | ___ | | ___ | | ___| 3 | 此时元素数量是 3 &gt;= threshold，表示要扩容了，但是暂时还不需要扩容，因为实际上的扩容，是在下一次添加元素的时候。比如当下次再添加一个元素 1 时，添加前会先扩容： 1新数组容量 = 4 * 2 + 1 = 9 好了，现在就开始重新分配数据了： 12345678910111213141516171819旧数组（4） 新数组（9） ___ ___ ___ | 0 | -&gt; | 4 | | | ___ ___ | | | | ___ ___ | | | | ___ ___ | 3 | | | ___ | | ___ | | ___ | | ___ | | ___ | | 首先是 3（为什么是3？仔细看看上面的代码，遍历是从 table.length - 1 倒着开始的），3 % 9 = 3，所以它的新位置就在新数组索引 3 那里： 12345678910111213141516171819旧数组（4） 新数组（9） ___ ___ ___ | 0 | -&gt; | 4 | | | ___ ___ | | | | ___ ___ | | | | ___ ___ | 3 | | 3 | ___ | | ___ | | ___ | | ___ | | ___ | | 接着是 0，0 % 9 = 0，所以它的新位置就在新数组索引 0 那里： 12345678910111213141516171819旧数组（4） 新数组（9） ___ ___ ___ | 0 | -&gt; | 4 | | 0 | ___ ___ | | | | ___ ___ | | | | ___ ___ | 3 | | 3 | ___ | | ___ | | ___ | | ___ | | ___ | | 最后是 4，4 % 9 = 4，所以它的新位置就在新数组索引 4 那里： 12345678910111213141516171819旧数组（4） 新数组（9） ___ ___ ___ | 0 | -&gt; | 4 | | 0 | ___ ___ | | | | ___ ___ | | | | ___ ___ | 3 | | 3 | ___ | 4 | ___ | | ___ | | ___ | | ___ | | 至此，扩容重新分配就完成了。 其实可以看到，链表 0 被拆分了，就是通过这种扩容方式，来减短链表的长度，提高查询效率。 差点忘了，还要把新增元素1加进去： 12345678910111213141516171819数组（9） ___ | 0 | ___ | 1 | ___ | | ___ | 3 | ___ | 4 | ___ | | ___ | | ___ | | ___ | | 这样才算是圆满结束了~~ 等等！！其实还有个比较有趣的地方，那就是分配后的链表元素顺序，怎么说？ 还是直接举例子吧，下面这种结构，重新分配后是怎么样的呢： 123456789数组（4） ___ ___ ____ | 0 | -&gt; | 4 | -&gt; | 12 | ___ | | ___ | | ___| | 过程就不说了，直接给结果吧： 12345678910111213141516171819数组（9） ____ ___ | 12 | -&gt; | 0 | ___ | | ___ | | ___ | | ___ | 4 | ___ | | ___ | | ___ | | ___ | | 咦？0 和 12 的顺序变了！是的，没错，实际上确实是这样，仔细看看重新分配的代码： 123int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity;e.next = (Entry&lt;K,V&gt;)newMap[index];newMap[index] = e; 实际上重新分配时，和添加元素时一样，元素是倒着插入的，都是为了提高效率。","link":"/lang/java/source/jdk8/collection/Hashtable/"},{"title":"LinkedList","text":"LinkedList一、定义12345public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable{} LinkedList 和 ArrayList 的定义有一些区别，LinkedList 是继承于 AbstractSequentialList 的，而 ArrayList 是直接继承于 AbstractList。 LinkedList 的继承链多了一层 AbstractSequentialList。 另外，LinkedList 还实现了另外一个双向队列的接口 Deque，表示 LinkedList 能够双向访问元素。 二、原理2.1 数据结构底层的数据存储是采用双向链表来实现的，至于链表节点类型，是一个静态内部类 Node，有2个引用分别指向前一个和后一个节点： 1234567891011private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; }} 2.2 集合操作LinkedList 的集合操作不外乎增删查改，底层数据结构是链表，实际上这些操作就是链表的操作。 首先看一下查询，既然是链表，那么就有链头和链尾，在 LinkedList 内分别用2个成员变量表示，获取表头和表尾还是比较简单的： 12345678910111213public E getFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;}public E getLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;} 至于查找链表中间的节点，没有别的办法，必须需要遍历链表才行： 12345678910111213141516171819202122public E get(int index) { checkElementIndex(index); return node(index).item;}Node&lt;E&gt; node(int index) { // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) { // 链表前半段 Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { // 链表后半段 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; }} 不过在查找时进行了一些优化，因为 LinkedList 是一个双向链表，所以可以从两边任意一边开始搜索。 搜索指定索引的元素时，如果小于长度的一半，就从表头正向查找；如果大于长度的一半，就从表尾逆向查找。 接下来是添加和删除，其实都是链表的基本操作： 12345678910111213141516171819202122232425262728293031323334353637public void add(int index, E element) { checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));}void linkLast(E e) { final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;}void linkBefore(E e, Node&lt;E&gt; succ) { // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 建立后链 succ.prev = newNode; // 建立前链 if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;} 添加元素也没什么特别的，一般就是追加和插入指定位置。追加的话，直接链接到表尾就行；至于插入，则先需要需要前面的搜索，找到插入的位置，再执行插入，会多耗费一些。所以专门针对这2种情况分别进行了处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public boolean remove(Object o) { if (o == null) { for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (x.item == null) { unlink(x); return true; } } } else { for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (o.equals(x.item)) { unlink(x); return true; } } } return false;}E unlink(Node&lt;E&gt; x) { // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // 解开前链 if (prev == null) { first = next; } else { prev.next = next; x.prev = null; } // 解开后链 if (next == null) { last = prev; } else { next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element;} 删除元素也一样，添加元素是插入时建立节点链接，删除实际就是解除某个节点的链接。所以操作上都差不多。 最后是更新，这个更简单了,先查找到需要更新的元素，然后直接就可以更新： 1234567public E set(int index, E element) { checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;} 总的来说，增删查改这几个操作，也就查找有点看头，其他的都是链表的基本操作。 2.3 迭代器LinkedList 是一个双向链表，所以它的迭代器也一样，可以双向遍历，然后我就发现了一个有意思的地方。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private class ListItr implements ListIterator&lt;E&gt; { private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) { // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; } public E next() { checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; } public E previous() { checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; } public void remove() { checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; }} 有意思的是迭代器中的2个成员变量 next 和 lastReturned。 在 next() 方法中可以看到，一般情况下， next 和 lastReturned 是指向不同的元素的，next 正常是 lastReturned 的下一个元素： 12lastReturned = next;next = next.next; 但是如果执行过 previous() 方法，它们的指向就发生变化了： 1lastReturned = next = (next == null) ? last : next.prev; 这个时候，next 和 lastReturned 都指向同一个元素，也就是当前 next 的前一个元素。 由于 next() 和 previous() 的不同情况，其他方法在处理时，也需要考虑这两种情况，就比如上面的 remove() 方法： 123456if (next == lastReturned) // previous()的情况 next = lastNext;else // next()的情况 nextIndex--; 一开始看到这里，貌似是有点别扭的，因为感觉代码写起来有点不太统一。 后来仔细相想想，可能是因为只用了 next 变量来遍历，如果再加上一个 previous 变量可能会更好理解： 12345678910111213141516171819202122232425262728private class ListItr implements ListIterator&lt;E&gt; { public E next() { checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); // 添加previous指向前一个元素 lastReturned = previous = next; next = next.next; nextIndex++; return lastReturned.item; } public E previous() { checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); // 添加previous指向前一个元素 lastReturned = next = previous; previous = previous.prev; nextIndex--; return lastReturned.item; }} 这样貌似好理解一些，不过多了一个变量 previous，维护起来可能麻烦一些吧？所以源码实现并没有添加？ 由于 LinkedList 是双向的，所以也还有另一个迭代器，逆向迭代器： 123456789101112private class DescendingIterator implements Iterator&lt;E&gt; { private final ListItr itr = new ListItr(size()); public boolean hasNext() { return itr.hasPrevious(); } public E next() { return itr.previous(); } public void remove() { itr.remove(); }} 不过在实现上，实际是直接用的正向迭代器，在它外面包装了一层，真正遍历时就调用正向迭代器中相反的接口。","link":"/lang/java/source/jdk8/collection/LinkedList/"},{"title":"ArrayList","text":"ArrayList一、定义123public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { ... } 有个地方没搞明白，按理说抽象类 AbstractList 已经包含了接口 List，为何还需要再次实现这个接口呢？ 难道是担心抽象类 AbstractList 有可能会修改，不再实现接口 List？ 二、实现原理ArrayList 底层实现是用数组 elementData 来保存集合元素的，并且数组的类型是 Object： 12// 没有设为private的原因是为了让内部类可以访问该属性transient Object[] elementData; 2.1 最大容量ArrayList 内置数组的最大容量是： 1234/** * The maximum size of array to allocate. Some VMs reserve some header words in an array. Attempts to allocate larger arrays may result in OutOfMemoryError: Requested array size exceeds VM limit */MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 为什么需要 -8 呢？按照源码的备注来看，是因为有些 JVM 在数组的实现上，会保留一些字节作为数组头，用于标记数组的相关信息。可能是“长度”“类型”之类的信息（具体我也没了解）。 2.2 扩容机制虽然底层实现是数组，但是集合列表 ArrayList 是可扩容的，它的扩容方法是： 12345678910111213141516private void grow(int minCapacity) { // 首先在当前基础上是增长1/2容量 int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 判断增长1/2后是否满足容量要求 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 新容量-数组最大值 &gt; 0，则扩充为大容量数组 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 复制数组到更大的内存 elementData = Arrays.copyOf(elementData, newCapacity);} 扩容可以分为3步： 正常情况下，每次扩容增长当前数组容量的 1/2。 扩容1/2后仍小于最小容量，则使用最小容量； 若最小容量值大于数组最大值，则使用大数组容量。 举几个例子说明： 例1：假如当前的数组容量是 oldCapacity = 16，minCapacity = 23，那么按照扩容机制的第1条规则： 1newCapacity = 16 + 16 / 2 = 24 满足要求，因此最终扩容后的数组容量是 24。 例2：假如当前的数组容量是 oldCapacity = 16，minCapacity = 30，那么按照扩容机制的第2条规则： 1234567// 第1条规则newCapacity = 16 + 16 / 2 = 24// 第2条规则if (newCapacity - 30 &lt; 0) { newCapacity = 30} 那么此时按照第2条规则，最终扩容后的数组容量是 30。 例3：假如当前的数组容量是 oldCapacity = 16，minCapacity = Integer.MAX_VALUE - 4，那么按照扩容机制的第3条规则： 1234567891011121314minCapacity = Integer.MAX_VALUE - 4// 第1条规则newCapacity = 16 + 16 / 2 = 24// 第2条规则if (newCapacity - minCapacity &lt; 0) { newCapacity = minCapacity}// 第3条规则if (newCapacity - MAX_ARRAY_SIZE &gt; 0) { newCapacity = hugeCapacity(minCapacity);} 此时扩充后的数组容量由方法 hugeCapacity(minCapacity) 计算，而这个方法的定义如下： 1234567private static int hugeCapacity(int minCapacity) { if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;} 也就是说，当 minCapacity 值介于 MAX_ARRAY_SIZE 和 Integer.MAX_VALUE 之间时，返回 Integer.MAX_VALUE；否则返回默认的数组最大值 MAX_ARRAY_SIZE。 虽然这3条规则的代码看起来比较简单，但是实际上它还考虑到了溢出的问题。 2.3 集合操作集合的操作，不外乎增删查改，由于底层是数组实现，因此对于查询和更新，可以直接根据数组的索引来访问即可，很简单（当然，这中间还会进行索引范围的检查，但也不是难事）。 至于添加和删除，这就涉及到了数组的移动。如果插入到数组中间，就需要把插入位置后面的数组元素都往后移动，才能插入；而删除中间的某个元素，也需要把该元素之后的数组元素往前移动。 实际上操作也不复杂，举个插入的例子。首先是插入函数的定义： 1234567891011121314public void add(int index, E element) { // 检查索引的范围 rangeCheckForAdd(index); // 保证数组空间足够，不够就扩容 ensureCapacityInternal(size + 1); // 把插入位置后的元素往后移动 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 插入新元素 elementData[index] = element; size++;} 原理比较简单，和平时自己用把数据插入到数组时的操作差不多，只是多了一些索引范围和扩容的校验。 删除的原理也差不多，不过有一个比较有意思的就是，如果同一个对象保存在集合中不止一个位置，那么在删除的时候，只会删除第一个出现的位置： 12345678910111213141516public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false;} 可以看到，删除元素时，只要找到第一个就把它删除，至于后面是否还有这个元素，就不再管了。 2.4 子列表子列表本来觉得没什么特别的东西，后来仔细一看，还真发现了一些华点。 1）子列表构造函数的参数 子列表构造函数的参数有啥特别的？先上源代码： 12345678SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) { this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount;} fromIndex 和 toIndex 很容易理解，就是子集合的索引范围；parent 也很清楚，就是子集合的父集合； 但是 offset 是干啥用的，不是已经有 fromIndex 和 toIndex 了吗？需要这个参数吗？ 看到后面才发现，原来是为了嵌套子列表，也就是子列表再获取子列表的情况： ArrayList -&gt; SubList -&gt; SubList -&gt; ... 就类似这种层层嵌套的结构。 子列表的子列表函数如下： 1234public List&lt;E&gt; subList(int fromIndex, int toIndex) { subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, offset, fromIndex, toIndex);} 这个时候 offset 的作用就体现出来了。 2）内部类 SubList 与 ArrayList 的关系 在源码里可以看到，SubList 里经常会访问 ArrayList 的变量，主要包括 modCount 和 elementData。 但是考虑到嵌套子列表的情况，它里面是怎么访问到相当于祖先级别的 ArrayList 呢？ 貌似还挺简单的，直接使用 ArrayList.this 就可以访问到外部类的成员（但是我以前还真不知道这种操作，所以特地记下来，哈哈哈~~）： 12345ArrayList.this.modCountArrayList.this.elementDataArrayList.this.set(offset + lastRet, e) 由于内部类占用了 this，为了和外部类区分开来，就加上了外部类的类名前缀 ArrayList.this。","link":"/lang/java/source/jdk8/collection/ArrayList/"},{"title":"ArrayDeque","text":"ArrayDeque一、定义123public class ArrayDeque&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Deque&lt;E&gt;, Cloneable, Serializable { } ArrayDeque 实现了 Deque 接口，是一个数组实现的双向队列。 二、原理2.1 数据结构ArrayDeque 底层数据存储结构是数组： 12345678// 队列存储数组transient Object[] elements;// 队列头transient int head;// 队列尾transient int tail; 在用数组实现队列时，为充分利用起数组的空间，是采用的环形存放来实现的，例如： 12 ___ ___ ___ ___ ___ ___ ___ ___| 5 | 6 | | | 1 | 2 | 3 | 4 | 就类似这样，数组是循环存放队列数据的，队头 head 指向 1 的位置，而队尾则指向 6 之后的位置（注意不是指向 6，而是下一个）。 2.2 扩容机制虽然是数组实现，但是实际上和 ArrayList 这种一样，会随着队列元素的增多而自动扩容。 ArrayDeque 的底层数组 elements 的长度始终是 2的倍数，就是说，elements 的扩容增长也必须遵守这个规则。 首先，在初始化队列时，如果提供了初始容量，但是这个初试容量不满足 2的倍数，那就会对它进行修正： 12345678910111213141516private void allocateElements(int numElements) { int initialCapacity = MIN_INITIAL_CAPACITY; if (numElements &gt;= initialCapacity) { initialCapacity = numElements; initialCapacity |= (initialCapacity &gt;&gt;&gt; 1); initialCapacity |= (initialCapacity &gt;&gt;&gt; 2); initialCapacity |= (initialCapacity &gt;&gt;&gt; 4); initialCapacity |= (initialCapacity &gt;&gt;&gt; 8); initialCapacity |= (initialCapacity &gt;&gt;&gt; 16); initialCapacity++; if (initialCapacity &lt; 0) // Too many elements, must back off initialCapacity &gt;&gt;&gt;= 1;// Good luck allocating 2 ^ 30 elements } elements = new Object[initialCapacity];} 比如说，在实例化队列时，传入参数 numElements = 9，但是因为9不是 2的倍数，所以会对它进行修正，这个时候满足条件的最小值是16，因此初始容量实际上是16。 注意一点，如果 numElements &lt; MIN_INITIAL_CAPACITY，也就是小于最小容量（实际上就是8）时，就直接取最小容量。 实际扩容时，也要保持数组容量是 2的倍数，所以扩容时是直接是 以2倍增长 的。 123456789101112131415private void doubleCapacity() { assert head == tail; int p = head; int n = elements.length; int r = n - p; // number of elements to the right of p int newCapacity = n &lt;&lt; 1; if (newCapacity &lt; 0) throw new IllegalStateException(&quot;Sorry, deque too big&quot;); Object[] a = new Object[newCapacity]; System.arraycopy(elements, p, a, 0, r); System.arraycopy(elements, 0, a, r, p); elements = a; head = 0; tail = n;} 也就是说，如果当前容量是16，那么下一次扩容后，容量就应该是32了。 至于为什么数组容量一定要是 2的倍数，我估计可能和性能有关： 1） 计算机对于2倍数计算是很快的，直接通过移位操作（n &lt;&lt; 1）就可以实现； 2）采用数组循环时，经常需要执行取模，如果容量是2的倍数，那么取模就可以用掩码（head = (head - 1) &amp; (elements.length - 1)）来实现，相对而言会更高效一些。 2.3 集合操作由于底层是数组，实际上增删查改都很简单。 1）添加元素 123456789101112131415public void addFirst(E e) { if (e == null) throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e; if (head == tail) doubleCapacity();}public void addLast(E e) { if (e == null) throw new NullPointerException(); elements[tail] = e; if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head) doubleCapacity();} 由于是双向队列，添加元素可以分为追加队头，或者追加队尾。两种实现代码都差不多，添加元素之后还需要验证是否数组已满，满了的话，就要进行扩容。 2）删除元素 删除元素会稍微麻烦一些，毕竟是数组，当删除中间的元素时，需要移动一部分数组元素。 由于数组是循环存放的，所以实际上会分为2种情况： 1、head &lt; tail 正常型 12 ___ ___ ___ ___ ___ ___ ___ ___| | 1 | 2 | 3 | 4 | 5 | 6 | | 2、tail &lt; head 环绕型 12 ___ ___ ___ ___ ___ ___ ___ ___| 5 | 6 | | | 1 | 2 | 3 | 4 | 根据删除的位置，处理不同的情况就可以了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344private boolean delete(int i) { checkInvariants(); final Object[] elements = this.elements; final int mask = elements.length - 1; final int h = head; final int t = tail; final int front = (i - h) &amp; mask; final int back = (t - i) &amp; mask; // Invariant: head &lt;= i &lt; tail mod circularity if (front &gt;= ((t - h) &amp; mask)) throw new ConcurrentModificationException(); // 最少元素移动优化 if (front &lt; back) { // 左边元素少 if (h &lt;= i) { // 正常型 System.arraycopy(elements, h, elements, h + 1, front); } else { // 环绕型 System.arraycopy(elements, 0, elements, 1, i); elements[0] = elements[mask]; System.arraycopy(elements, h, elements, h + 1, mask - h); } elements[h] = null; head = (h + 1) &amp; mask; return false; } else { // 右边元素少 if (i &lt; t) { // 正常型 System.arraycopy(elements, i + 1, elements, i, back); tail = t - 1; } else { // 环绕型 System.arraycopy(elements, i + 1, elements, i, mask - i); elements[mask] = elements[0]; System.arraycopy(elements, 1, elements, 0, t); tail = (t - 1) &amp; mask; } return true; }} 代码实现虽然有点长，不过原理其实也很简单。 代码实现中，为了减少数组元素的移动，对移动进行了优化，移动时采用最少元素移动原则。 1234567891011final int h = head;final int t = tail;final int front = (i - h) &amp; mask;final int back = (t - i) &amp; mask;if (front &lt; back) { // 左边元素少 // 移动左边的元素} else { // 右边元素少 // 移动右边的元素} 比如，要删除元素 3： 12 ___ ___ ___ ___ ___ ___ ___ ___| | 1 | 2 | 3 | 4 | 5 | 6 | | 这个时候，3 左边的元素数量是 2，右边元素数量是 3，那么在删除 3 之后，就会移动左边的元素： 12 ___ ___ ___ ___ ___ ___ ___ ___| | | 1 | 2 | 4 | 5 | 6 | | 当然，对于环绕型数组的删除，原理是一样的，只是代码处理上会稍微麻烦一些。 比如，要删除元素 4： 12 ___ ___ ___ ___ ___ ___ ___ ___| 5 | 6 | | | 1 | 2 | 3 | 4 | 这个时候右边元素比较少，所以移动右边的： 12 ___ ___ ___ ___ ___ ___ ___ ___| 6 | | | | 1 | 2 | 3 | 5 | 反正不管怎么样，删除时总是移动元素少的一边。","link":"/lang/java/source/jdk8/collection/ArrayDeque/"},{"title":"AbstractQueue","text":"AbstractQueue一、定义12345public abstract class AbstractQueue&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Queue&lt;E&gt; { } AbstractQueue 只是一个抽取类，其目的主要是为接口 Queue 的一些方法提供了基础的实现模板。 二、实现AbstractQueue 只是一个模板类，可以为子类在实现接口 Queue 时提供一些通用代码，减少子类实现时的代码量。 比如： 1234567891011121314public boolean add(E e) { if (offer(e)) return true; else throw new IllegalStateException(&quot;Queue full&quot;);}public E remove() { E x = poll(); if (x != null) return x; else throw new NoSuchElementException();} 类似这种常用方法，AbstractQueue 直接就实现了，避免子类每次都要自己实现的麻烦。 从代码上来说，AbstractQueue 没有什么特殊的代码，都是一些通用的基础代码。 总之，AbstractQueue 就是提供了一个简易实现模板，减少子类在实现接口 Queue 时的代码，提高效率。","link":"/lang/java/source/jdk8/collection/AbstractQueue/"},{"title":"AbstractSet","text":"AbstractSet一、定义12public abstract class AbstractSet&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Set&lt;E&gt; {} AbstractSet 提供了接口 Set 的模板实现，也就是提供了 Set 中某些方法的实现，减少实现 Set 接口时的代码。 二、实现 主要实现了几个方法： 1）equals 1234567891011121314151617public boolean equals(Object o) { if (o == this) return true; if (!(o instanceof Set)) return false; Collection&lt;?&gt; c = (Collection&lt;?&gt;) o; if (c.size() != size()) return false; try { return containsAll(c); } catch (ClassCastException unused) { return false; } catch (NullPointerException unused) { return false; }} 比较两个集合是是否相等： 是否是自己 是否是Set集合 大小size是否相等 2个集合内的元素是否全等 根据第4条规则，只要集合内的元素全等，就表明两个集合是相等的。 但是有些集合是有序的，也就是说，如果一个有序集合和一个无序集合比较，是有可能相等的，因为第4条规则并不会判断集合内元素的顺序。 当然，如果子类重写了 equals 方法，那就另外说了。 2）hashCode 12345678910public int hashCode() { int h = 0; Iterator&lt;E&gt; i = iterator(); while (i.hasNext()) { E obj = i.next(); if (obj != null) h += obj.hashCode(); } return h;} 集合 Set 的 hashCode 就等于集合内所有元素的 hashCode 的总和。 3）removeAll 1234567891011121314151617public boolean removeAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c); boolean modified = false; if (size() &gt; c.size()) { for (Iterator&lt;?&gt; i = c.iterator(); i.hasNext(); ) modified |= remove(i.next()); } else { for (Iterator&lt;?&gt; i = iterator(); i.hasNext(); ) { if (c.contains(i.next())) { i.remove(); modified = true; } } } return modified;} 删除时，遍历集合数量较少的那个： 12345if (size() &gt; c.size()) { // 另一个集合元素数量少} else { // 当前集合元素数量少}","link":"/lang/java/source/jdk8/collection/AbstractSet/"},{"title":"AbstractMap","text":"AbstractMap一、定义12public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; {} AbstractMap 就是接口 Map 的模板实现类，提供一些已经实现好的方法，后续子类继承时就不用重复写了。 二、实现2.1 entrySet实际上，AbstractMap 里面的方法实现都是依赖 entrySet() 方法来实现的，具体看看代码吧： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public int size() { return entrySet().size();}public V get(Object key) { Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (key==null) { while (i.hasNext()) { Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) return e.getValue(); } } else { while (i.hasNext()) { Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) return e.getValue(); } } return null;}public V remove(Object key) { Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); Entry&lt;K,V&gt; correctEntry = null; if (key==null) { while (correctEntry==null &amp;&amp; i.hasNext()) { Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) correctEntry = e; } } else { while (correctEntry==null &amp;&amp; i.hasNext()) { Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) correctEntry = e; } } V oldValue = null; if (correctEntry !=null) { oldValue = correctEntry.getValue(); i.remove(); } return oldValue;}public void clear() { entrySet().clear();} 其余实现方法也差不多是这样的，都是通过 entrySet() 来实现，这里就不多贴代码了。 所以，子类只要再实现 entrySet()，基本上就可以正常使用了。 当然，如果需要其他代码优化之类的，再重写就好。 2.2 Entry在 AbstractMap 中，还提供了2个接口 Entry 的实现类 SimpleEntry 和 SimpleImmutableEntry。 一个是可修改的 SimpleEntry； 一个是不可修改的 SimpleImmutableEntry。 这2个 Entry 实现类，代码其实都差不多，下面分别看一下这2个实现类的代码： 123456789101112131415161718192021222324252627282930313233public static class SimpleEntry&lt;K,V&gt; implements Entry&lt;K,V&gt;, java.io.Serializable { private final K key; private V value; public K getKey() { return key; } public V getValue() { return value; } public V setValue(V value) { V oldValue = this.value; this.value = value; return oldValue; } public boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; return eq(key, e.getKey()) &amp;&amp; eq(value, e.getValue()); } public int hashCode() { return (key == null ? 0 : key.hashCode()) ^ (value == null ? 0 : value.hashCode()); }} 而 SimpleImmutableEntry 和 SimpleEntry 唯一的区别就是 setValue 方法。SimpleEntry 可以用 setValue 方法，而 SimpleImmutableEntry 使用 setValue 方法则会抛异常。： 12345678910111213141516171819202122232425262728293031public static class SimpleEntry&lt;K,V&gt; implements Entry&lt;K,V&gt;, java.io.Serializable { private final K key; private V value; public K getKey() { return key; } public V getValue() { return value; } public V setValue(V value) { throw new UnsupportedOperationException(); } public boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; return eq(key, e.getKey()) &amp;&amp; eq(value, e.getValue()); } public int hashCode() { return (key == null ? 0 : key.hashCode()) ^ (value == null ? 0 : value.hashCode()); }} 其中这里面的 eq 就是一个内部私有静态方法： 123private static boolean eq(Object o1, Object o2) { return o1 == null ? o2 == null : o1.equals(o2);}","link":"/lang/java/source/jdk8/collection/AbstractMap/"},{"title":"AbstractList","text":"AbstractList一、定义AbstractList 是一个抽象类，是一个 List。 123public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; { ...} 二、属性在 AbstractList 中，有一个特殊的属性 modCount，用于统计列表被修改的次数（例如删除、添加等）。 1protected transient int modCount = 0; modCount 属性的作用是为了在并发修改列表时，能够快速失败（fail-fast）并抛出并发异常。例如多个线程同时修改列表时，就有可能对正在访问列表元素的线程造成影响，modCount 属性可用于判断当前列表是否是异常状态。 二、方法一般的实现方法没什么特别的，只要了解其中一些有趣的实现。 2.1 indexOf 和 lastIndexOf从 indexOf 的实现代码可以看出，List 是允许放置 null 元素的。 1234567891011121314public int indexOf(Object o) { ListIterator&lt;E&gt; it = listIterator(); if (o==null) { // 列表中的元素有可能是null while (it.hasNext()) if (it.next()==null) return it.previousIndex(); } else { while (it.hasNext()) if (o.equals(it.next())) return it.previousIndex(); } return -1;} 根据 indexOf() 和 lastIndexOf() 的实现效果，有不同的返回值： 使用 indexOf() 方法查询 null 时，会返回列表中第一个出现的 null 元素 使用 lastIndexOf() 方法查询 null 时，会返回列表中最后一个出现的 null 元素 2.2 hashCode对于一个列表集合而言，它的 hashCode 是根据列表集合中的所有元素计算得到的： 123456public int hashCode() { int hashCode = 1; for (E e : this) hashCode = 31*hashCode + (e==null ? 0 : e.hashCode()); return hashCode;} 也就是说，对于每个空列表对象（也就是 size() 等于 0），它的 hashCode 值始终是 1。 另外，即使两个列表包含的元素一样，但只要元素的排列顺序不同，它的 hashCode 也是不同的。 2.3 Itr 和 ListItr2.3.1 定义Itr 和 ListItr 是迭代器的两个实现。 Itr 是普通的迭代器实现，可以单向访问列表元素;ListItr 是列表专门的迭代器实现，可以用于双向访问列表元素。 123private class Itr implements Iterator&lt;E&gt; { ...} ListItr 本质上是在 Itr 的基础上进行了扩展，使得可以双向访问集合元素。 123456789101112131415161718private class ListItr extends Itr implements ListIterator&lt;E&gt; { public boolean hasPrevious() { ... } public E previous() { ... } public int nextIndex() { ... } public int previousIndex() { ... }} 2.3.2 属性 expectedModCount在 Itr 和 ListItr 两个迭代器中，有一个特殊的属性 expectedModCount，可以用于检测列表并发修改。 在前面说过，AbstractList 中有一个属性 modCount 用于记录列表的修改次数。而 expectedModCount 则是记录列表在正常情况下的修改次数，当 modCount ！= expectedModCount 时，就认为列表发生了并发修改。 expectedModCount 的值是在迭代器初始化时初始化的，初始值就是列表此时的修改次数 modCount。 1int expectedModCount = modCount; 在使用迭代器访问元素时，都会先检测列表是否发生了并发修改，如果发生了并发修改，迭代器则会抛出异常。 12345678910public E next() { // 迭代获取元素之前，都会验证列表是否发生了并发修改 checkForComodification(); ...}final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException();} expectedModCount 的值并不是一成不变的，因为迭代器可以进行 remove 等修改列表的操作，因此在迭代中使用了这些方法后，还需要再次同步列表的 modCount。 12345678910111213141516public void remove() { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { AbstractList.this.remove(lastRet); if (lastRet &lt; cursor) cursor--; lastRet = -1; // 在迭代中修改后，同步列表中的修改次数，防止抛出并发异常 expectedModCount = modCount; } catch (IndexOutOfBoundsException e) { throw new ConcurrentModificationException(); }} 2.4 SubList 和 RandomAccessSubList2.4.1 SubListSubList 是 AbstractList 的内部子类，用于返回 AbstractList 的子列表。 123456789101112131415161718192021222324class SubList&lt;E&gt; extends AbstractList&lt;E&gt; { // 子列表的原始列表 private final AbstractList&lt;E&gt; l; // 子列表在原始列表的偏移量 private final int offset; // 子列表的长度 private int size; SubList(AbstractList&lt;E&gt; list, int fromIndex, int toIndex) { if (fromIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;fromIndex = &quot; + fromIndex); if (toIndex &gt; list.size()) throw new IndexOutOfBoundsException(&quot;toIndex = &quot; + toIndex); if (fromIndex &gt; toIndex) throw new IllegalArgumentException(&quot;fromIndex(&quot; + fromIndex + &quot;) &gt; toIndex(&quot; + toIndex + &quot;)&quot;); l = list; offset = fromIndex; size = toIndex - fromIndex; this.modCount = l.modCount; }} 从代码可以直接看出，子列表 SubList 实际上只是一个代理，它实际返回的还是原始列表的元素。 12345public E get(int index) { rangeCheck(index); checkForComodification(); return l.get(index+offset);} 另外，由于子列表是共用原始列表的元素，因此还需要考虑并发的问题，和迭代器同样地，是通过检测列表的修改次数来检测的。因为 SubList继承自 AbstractList，所以在子列表中，和 expectedModCount 相同功能的属性就是 modCount。 1234private void checkForComodification() { if (this.modCount != l.modCount) throw new ConcurrentModificationException();} 2.4.2 RandomAccessSubListRandomAccessSubList 也是一个子列表，继承自 SubList，它的含义是可以随机访问元素的子列表。 123456789class RandomAccessSubList&lt;E&gt; extends SubList&lt;E&gt; implements RandomAccess { RandomAccessSubList(AbstractList&lt;E&gt; list, int fromIndex, int toIndex) { super(list, fromIndex, toIndex); } public List&lt;E&gt; subList(int fromIndex, int toIndex) { return new RandomAccessSubList&lt;&gt;(this, fromIndex, toIndex); }} 但是实际上，由于 SubList 已经实现了随机访问的功能，因此 RandomAccessSubList 并没有再进行任何其他的扩展，只是单纯继承了 SubList，并实现了 RandomAccess 接口而已。","link":"/lang/java/source/jdk8/collection/AbstractList/"},{"title":"注解@Enumerated","text":"@Enumerated@Enumerated 是JDK中 javax.persistence 包下的注解，用在持久化实体类属性或字段上，表示该属性或字段应该按照枚举类型 Enum 来持久化。例如： 1234public enum Gender { MALE, FEMALE;} 12345678@Entitypublic class Person { @Column @Enumerated private Gender gender; // 省略其他属性方法，后面也是} 属性或字段按照枚举类型来持久化时，可以分为两种情况：原始类型和字符串类型。 枚举持久化类型可以在 javax.persistence.EnumType 类中找到，其中 ORDINAL 表示原始类型；STRING 表示字符串类型。例如字符串类型的写法如下： 123456@Entitypublic class Person { @Column @Enumerated(EnumType.STRING) private Gender gender;} 如果没有特别指定类型，枚举属性或字段默认按照 ORDINAL 来持久化。 1. 原始类型ORDINAL 表示将枚举类按照其原始类型，也就是整数，来持久化。比如： 123456@Entitypublic class Person { @Column @Enumerated(EnumType.ORDINAL) private Gender gender;} 如果按照上述的代码执行，枚举字段 gender 将被转成数据库的整型字段（以Mysql为例）： 12JAVA &lt;---&gt; Mysqlgender &lt;---&gt; int(11) 也就是当 Person 对象被持久化到数据库时，枚举字段 gender 的值将按照其整数值来保存。 123Gender &lt;---&gt; MysqlMALE &lt;---&gt; 0FEMALE &lt;---&gt; 1 2. 字符串类型STRING 表示将枚举类按照字符串类型持久化。 123456@Entitypublic class Person { @Column @Enumerated(EnumType.STRING) private Gender gender;} 如果按照上述的代码执行，枚举字段 gender 将被转成数据库的字符串字段（以Mysql为例）： 12JAVA &lt;---&gt; Mysqlgender &lt;---&gt; varchar(255) 当 Person 对象被持久化到数据库时，枚举字段 gender 的值不再按照原始整数来保存，而是将按照其字符串值来保存。 123Gender &lt;---&gt; MysqlMALE &lt;---&gt; MALEFEMALE &lt;---&gt; FEMALE 3. 总结总的来说，@Enumerated 注解是用来标识枚举字段是按照什么方式来持久化的，也就是保存到数据库的数据类型： @Enumerated(EnumType.ORDINAL) 就是保存枚举字段的的整数值（序号）； @Enumerated(EnumType.STRING) 就是保存枚举字段的字符串值。 另外，不指定类型的 @Enumerated 等于 @Enumerated(EnumType.ORDINAL) 。","link":"/lang/java/other/enumerated/"},{"title":"JSON数据格式","text":"JSONJSON 是一种数据格式，不是一种编程语言。一般用于Web服务的前后端的数据交流格式。 一、类型JSON 的语法可以有3种类型的值： 简单值：包括字符串、数值、布尔值和 null（但是不支持 Javascript 中的 undefined） 对象：表示一组无序的键值对 数组：表示一组有序的值的列表 二、与 Jsvacript 的区别 Javascript 是一种编程语言，JSON只是一种数据格式 JSON 没有变量声明，也没有末尾的分号; JSON 字符串必须使用双引号（单引号会导致语法错误） Javascript 的语法： 1234var object = { name: 'Zhangsan'， age: 20} JSON 的语法： 1234{ &quot;name&quot;: &quot;Zhangsan&quot;, &quot;age&quot;: 20} 三、解析与序列化JSON 数据是 Web 服务中数据交换的格式，因此它可以与 Javascript 对象相互转换。 早期的浏览器，一般使用 eval() 函数来解析、解释 JSON 字符串并返回 Javascript 对象或数组。 ECMAScript 5 对解析 JSON 的行为进行来规范，定义了全局对象 JSON。 JSON 对象有两个方法：stringify() 和 parse()。其中 stringify() 用于将 Javascript 对象或数组序列化成 JSON 字符串，parse() 方法用于将 JSON 字符串解析成 avascript 对象或数组。 3.1 序列化JSON 序列化负责将 Javascript 对象或数组序列化成 JSON 字符串，实现这个功能的方法是 JSON.stringify()。 stringify 方法的参数有3个： 需要序列化的 Javascript 对象 过滤器，可以是数组，也可以是函数 JSON 字符串的缩进值，可以是数值，也可以是字符串 例如： 1234567var jsonObj = { name: 'Zhangsan', age: 20};// Javascript 对象序列化var jsonText = JSON.stringify(jsonObj); 则 jsonText 的值为： 1{&quot;name&quot;:&quot;Zhangsan&quot;,&quot;age&quot;:20} 3.1.1 过滤器使用 stringify 的第2个参数，可以自定义过滤序列化的结果。 过滤器参数可以有2种格式：数组和函数。 1）如果过滤器参数是数组，那么 stringify 序列化的结果只会返回包含在数组中的属性： 1234567var jsonObj = { name: 'Zhangsan', age: 20};// 过滤器是数组var jsonText = JSON.stringify(jsonObj, ['name']); 则 jsonText 的值为： 1{&quot;name&quot;:&quot;Zhangsan&quot;} 2）如果过滤器参数是函数，该函数会接收2个参数：属性（键）名和属性值。 函数返回值就是对应属性（键）名的值，如果函数返回值是 undefined，那么相应的属性会被忽略： 123456789101112var jsonObj = { name: 'Zhangsan', age: 20};// 过滤器是函数var jsonText = JSON.stringify(jsonObj, function (key, value) { if (key === 'name') { return value; } return undefined;}); 则 jsonText 的值为： 1{&quot;name&quot;:&quot;Zhangsan&quot;} 3.1.2 缩进默认情况下，JSON.stringify() 输出的 JSON 字符串是不包含任何空格字符或缩进的： 1234567var jsonObj = { name: 'Zhangsan', age: 20};// Javascript 对象序列化var jsonText = JSON.stringify(jsonObj); 则 jsonText 的值为： 1{&quot;name&quot;:&quot;Zhangsan&quot;,&quot;age&quot;:20} 使用 stringify 方法的第3个参数，可以控制序列化结果中的缩进和空白符。 缩进参数可以有2种格式：数值和字符串。 1）如果缩进参数是数值，表示的是每个缩进级别的空格数： 1234567var jsonObj = { name: 'Zhangsan', age: 20};// Javascript 对象序列化var jsonText = JSON.stringify(jsonObj, null, 4); 则 jsonText 的值为（缩进空格数为4）： 1234{ &quot;name&quot;: &quot;Zhangsan&quot;, &quot;age&quot;: 20} 只要传入了有效的缩进参数值，结果字符串也会包含换行符（因为只缩进不换行意义不大）。 最大缩进格数为10，所有大于10的值都会自动转换为10。 2）如果缩进参数是字符串，则这个字符串将会被用作缩进字符（不再使用空格）： 1234567var jsonObj = { name: 'Zhangsan', age: 20};// Javascript 对象序列化var jsonText = JSON.stringify(jsonObj, null, '----'); 则 jsonText 的值为（缩进字符不再是空格）： 1234{----&quot;name&quot;: &quot;Zhangsan&quot;,----&quot;age&quot;: 20} 缩进字符最大长度也不能超过10，如果字符长度超过了10，就会被截取成10个字符。 3.1.3 toJSON有时候，JSON.stringify() 还不能满足自定义序列化的需求，因此可以给对象定义 toJSON 方法，返回自定义的 JSON 数据格式。 12345678910var jsonObj = { name: 'Zhangsan', age: 20, toJSON: function () { return {&quot;sex&quot;: &quot;female&quot;}; }};// Javascript 对象序列化var jsonText = JSON.stringify(jsonObj); 则 jsonText 的值为（缩进字符不再是空格）： 1{&quot;sex&quot;: &quot;female&quot;} 3.1.4 序列化顺序 如果存在 toJSON 方法，返回该方法的返回值，否则，返回对象本身 如果提供了第2个参数，对第1步返回的值进行过滤 对第2步返回的每个值进行序列化 如果提供了第3个参数，执行相应的格式化 3.2 解析JSON 解析负责将 JSON 字符串解析成 Javascript 对象，实现这个功能的方法是 JSON.parse()。 parse 方法的参数有2个： 需要解析的 JSON 字符串 还原函数，和过滤器函数类似 例如： 1234var jsonText = '{&quot;name&quot;:&quot;Zhangsan&quot;,&quot;age&quot;:20}';// JSON 数据解析var jsonObj = JSON.parse(jsonText); 则 jsonObj 的值为： 1234{ name: &quot;Zhangsan&quot;, age: 20,} 3.2.1 还原函数还原函数和过滤器函数类似，也是接收2个参数：属性（键）名和属性值。 还原函数的返回值将作为属性（键）名的值，如果函数返回 undefined，表示从结果中删除相应的键。 123456789var jsonText = '{&quot;name&quot;:&quot;Zhangsan&quot;,&quot;age&quot;:20}';// JSON 数据解析，增加还原函数var jsonObj = JSON.parse(jsonText, function (key, value) { if (key === 'name') { return value; } return undefined;}); 则 jsonObj 的值为： 123{ name: &quot;Zhangsan&quot;}","link":"/lang/js/json_data/"},{"title":"js如何处理错误","text":"错误处理在 Javascript 中，处理异常的方式一般有两种： try-catch 语句捕获异常 onerror 事件捕获异常 一、try-catch 语句 try-catch 语句是 Javascript 中处理异常的一种标准方式，基本语法如下： 12345try { // 可能会导致错误的代码} catch (error) { // 在错误发生时处理} 对于 catch 捕获的异常对象 error，在不同浏览器中它包含的信息可能不太一样。一般来说，error 中通用的属性仅包括 message，也就是说，在跨浏览器编写代码时，最好只使用 message 属性。 123456try { // 可能会导致错误的代码} catch (error) { // 跨浏览器的通用属性仅有 message alert(error.message);} 实际上，try-catch 语句还包括了 finally 块，用于表示 finally 块内的语句一定会执行。 无论代码怎么处理，下述代码最后返回的结果始终是 finally 块的 0： 12345678910try { // 其他代码 return 1;} catch (error) { // 错误处理代码 return -1;} finally { // 其他代码 return 0;} 另外需要注意的是，如果代码中包含了 finally 语句，那么 try 块和 catch 块内的 return 语句都将会被忽略，下述代码返回的既不是 1 也不是 -1,实际返回的是 finally 的代码结果，但是由于 finally 块内没有 return 语句，因此会默认返回 undefined： 12345678910try { // 其他代码 return 1;} catch (error) { // 错误处理代码 return -1;} finally { // 其他代码 // 实际上这里会返回 undefined} 因此在使用 finally 块时，需要注意它的返回值。 还有一点需要说的就是，IE7 以前的版本有一个 bug，如果没有 catch 语句，finally 也不会执行。因此在写 IE7 以前版本的代码时，使用 finally 语句时必须要先写 catch 语句。 1.1 错误类型ECMA-262 定义了7种错误类型： Error EvalError RangeError ReferenceError SyntaxError TypeError URIError 1.1.1 ErrorError 是基类型，其他错误类型均继承自该类型。 1.1.2 EvalErrorEvalError 会在使用 eval() 函数时发生异常而被抛出，比如如果没有把 eval 当作函数来调用： 123// 这些会抛出异常new eval();eval = 1; 1.1.3 RangeErrorRangeError 会在数值超出相应范围时触发。比如数组的大小超出了范围： 123// 非法范围会抛出异常var arr1 = new Array(-10);var arr2 = new Array(Number.MAX_VALUE); 1.1.4 ReferenceErrorReferenceError 会在访问不存在的变量时触发，比如把未声明的变量用来赋值： 12// firstname 未定义时会抛出异常var name = firstname; 1.1.5 SyntaxErrorSyntaxError 一般是因为语法错误引起，比如将语法错误的字符串传进 eval 中执行时： 12// 语法错误异常eval(&quot;a ++ b&quot;); 1.1.6 TypeErrorTypeError 会在变量中保存着意外的类型，或者在访问不存在的方法时触发。比如传给函数的参数类型与预期的类型不相符： 1alert(&quot;name&quot; in true); 1.1.7 URIErrorURIError 一般会在使用 encodeURI() 或 decodeURI()，而 URI 格式不正确时触发。不过这两个方法的容错率比较高，不容易触发这个错误。 1.2 throw 抛出异常与 try-catch 语句相配的还有一个 throw 操作符，用于抛出自定义错误。 使用 throw 抛出错误时，必须指定一个错误值，但是这个错误值的类型没有要求，可以是任意类型： 1234throw 123;throw &quot;123&quot;throw false;throw { name: 'zhangsan'} 但是一般来说，抛出 Error 错误类型会更好一些，因为这样会比较方便 catch 处理该异常信息。 12throw new EvalError(&quot;eval error!&quot;);throw new TypeError(&quot;type error!&quot;); 也可以自定义错误，利用原型链继承 Error 来创建自定义的错误类型： 12345678function CustomError (message) { this.name = &quot;CustomError&quot;; this.message = message;}CustomError.prototype = new Error();throw new CustomError(&quot;custom error!&quot;); 二、onerror 事件任何没有通过 try-catch 语句处理的错误都会触发 window 对象的 error 事件（Opera、Safari 浏览器不支持 error 事件）。 在任何 Web 浏览器中，onerror 事件处理程序都不会创建 event 对象，只会接收3个参数： 错误信息 错误所在的 URL 错误所在行号 只要发生错误，无论是不是浏览器生成的，都会触发 error 事件。","link":"/lang/js/error/"},{"title":"事件的监听以及处理","text":"事件事件，是文档或浏览器窗口中发生的一些特定的交互瞬间。 下面分别介绍事件中的几个重要特性： 事件流 事件处理程序 事件对象 一、事件流事件流是用于描述页面接收事件的顺序。 根据事件的捕获顺序不同，事件流分为2种： 事件冒泡流 事件捕获流 1.1 事件冒泡事件冒泡，是指事件由最具体的元素（即最底层的节点）接收，然后逐级向上传播到较为不具体的节点（即最顶层的节点，文档），属于由下向上传播事件。 12345&lt;html&gt; &lt;body&gt; &lt;div id=&quot;myDiv&quot;&gt;Click&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 如果点击了页面中的 div 元素，那么这个 click 事件会按照以下顺序传播： &lt;div&gt; &lt;body&gt; &lt;html&gt; document 所有浏览器都支持事件冒泡。 1.2 事件捕获事件冒泡，是指事件由较不具体的元素（即最顶层的节点，文档）接收，然后逐级向下传播到最不具体的节点（即最底层的节点），属于由上到下传播事件。 12345&lt;html&gt; &lt;body&gt; &lt;div id=&quot;myDiv&quot;&gt;Click&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 如果点击了页面中的 div 元素，那么这个 click 事件会按照以下顺序传播： document &lt;html&gt; &lt;body&gt; &lt;div&gt; 老版本的浏览器不支持事件捕获。 1.3 DOM 事件流“DOM2级事件”规定的事件流包括3个阶段：事件捕获阶段、处于目标阶段、事件冒泡阶段。 12345&lt;html&gt; &lt;body&gt; &lt;div id=&quot;myDiv&quot;&gt;Click&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 以 div 的点击事件为例，事件流的顺序是： document（捕获） &lt;html&gt;（捕获） &lt;body&gt;（捕获） &lt;div&gt;（目标、冒泡） &lt;body&gt;（冒泡） &lt;html&gt;（冒泡） document（冒泡） 另外，在 DOM 事件流中，实际目标接收事件的时候不是处于捕获阶段，而是属于冒泡阶段。 也就是说，实际上只分为2个阶段：事件捕获阶段、事件冒泡阶段（包括处于目标阶段）。 二、事件处理程序事件是用户或浏览器自身执行的某种动作，而事件处理程序就是响应某个事件的函数。 一般情况下，事件处理程序的名字以on开头，具体形式为“on” + 事件名。 例如 click 事件的事件处理程序就是 onclick，load 事件的事件处理程序就是onload。 为事件指定事件处理程序的方式有几种： HTML事件处理程序 DOM0级事件处理程序 DOM2级事件处理程序 IE事件处理程序 2.1 HTML事件处理程序某个元素支持的每种事件，都可以使用一个与相应事件处理程序同名的HTML特性来执行： 1&lt;div onclick=&quot;alert('click')&quot;&gt;&lt;/div&gt; 例如 div 的click事件就可以用onclick来指定事件处理程序。 以这种方式来指定事件处理程序，有一些特别的性质： 会创建一个封装着元素属性值的函数； 事件处理程序的this值等于当前事件的目标元素； 事件处理函数中有一个局部变量事件对象event，不需要自己定义，也不需要从函数的参数列表获取。 123456789&lt;script&gt; function handleClick (event) { alert(event.type) // }&lt;/script&gt;&lt;div value=&quot;Click&quot; onclick=&quot;alert(this.value)&quot;&gt;&lt;/div&gt;&lt;!-- event 属性不需要定义，也不需要从参数列表中拿 --&gt;&lt;div onclick=&quot;handleClick(event)&quot;&gt;&lt;/div&gt; 这样指定事件处理程序实际上会创建一个函数来执行指定的事件代码，差不多类似于以下代码： 1234567function () { alert(this.value)}function () { handleClick(event)} 但是这种指定的方式也有一些缺点： 存在时差问题。由于事件处理程序是直接绑定在HTML元素上面的，因此有可能在HTML元素渲染时就触发了事件处理程序，但是当时的事件处理程序有可能还不具备执行条件，从而导致执行出现异常； 在不同的浏览器中，事件处理程序的作用域链有可能存在一些差异，从而导致不同的结果； HTML与Javascript代码紧密耦合，不方便后续的维护。 2.2 DOM0 级事件处理程序由于用 HTML 来指定事件处理程序，会使得 HTML 代码和 Javascript 代码耦合，并且不好维护。 因此为了处理这种情况，可以只使用 Javascript 来指定事件处理程序，这样不仅简单，在跨浏览器上兼容也比较容易。 每个 DOM 元素（包括 window 和 document）都有自己的事件处理程序属性，通常都是全部小写，例如 onclick。把事件处理程序属性设置为一个函数，就可以指定事件处理程序： 1234var btn = document.getElementById(&quot;myBtn&quot;);btn.onclick = function () { alert(&quot;Click&quot;);} 这种方式称为 DOM0 级方法指定事件处理程序。 这种方式有几个特点： 事件处理程序中的 this 表示当前元素； 事件处理程序会在事件流的冒泡阶段被处理。 删除 DOM0 级方法指定的事件处理程序也很简单，直接赋值为 null 就可以了： 12// 删除事件处理程序btn.onclick = null; 2.3 DOM2 级事件处理程序DOM0 级方式指定事件处理程序时，只能指定一个事件处理程序，当需要多个处理程序对同一个对象的同一个事件进行处理时，没有办法做到。 因此在 DOM2 级中，添加了2个方法，用于处理指定和删除事件处理程序的操作： addEventListener() removeEventListener() 所有 DOM 节点都包含这2个方法，这2个方法都接收3个参数： 要处理的事件名，比如 onclick 指定的事件处理函数 一个布尔值，true 表示在捕获阶段调用事件处理函数，false 表示在冒泡阶段调用事件处理函数。 以这种方式来指定事件处理程序，有几个特点： 可以添加多个事件处理程序； 事件处理函数中的 this 表示当前元素； 移除事件处理程序时，必现传入和添加处理程序时使用的参数相同。也就是说，如果添加的事件处理程序是匿名函数，将无法对它进行移除。 123456789101112131415var btn = document.getElementById(&quot;myBtn&quot;);var handler = function () { alert(this.id);};// 添加匿名函数，意味着无法移除btn.addEventListener(&quot;click&quot;, function () { alert(&quot;Click&quot;);}, false);// 可以添加多个事件处理程序，按添加顺序执行btn.addEventListener(&quot;click&quot;, handler, false);// 移除事件处理时，传入的参数必须和添加时相同btn.removeEventListener(&quot;click&quot;, handler, false); 2.4 IE 事件处理程序和 DOM 中不同的是，IE 并没有实现 addEventListener 和 removeEventListener，而是另外实现了和这2个方法功能相近的方法： attachEvent() detachEvent() IE 的事件处理和 DOM2 的事件处理有几点区别： IE8 以前只支持事件冒泡，所以 attachEvent 添加的事件处理只能在冒泡阶段被执行； attachEvent 的事件参数是 onclick，而 addEventListener 的事件参数是 click，没有加上 on； attachEvent 的事件处理函数的作用域是全局作用域，而 addEventListener 的则是所属元素的作用域； attachEvent 添加的事件处理程序是按添加顺序反序执行的，而 addEventListener 是按添加顺序执行的。 12345678910111213141516var btn = document.getElementById(&quot;myBtn&quot;);var handler = function () { alert(this.id);};// 注意这里是 onclick，而不是 DOM 的 clickbtn.attachEvent(&quot;onclick&quot;, function () { // 在全局作用域下运行 alert(this === window); // true}); // 没有第3个参数，事件处理只会在冒泡阶段执行// 也可以添加多个事件处理程序，按添加顺序反序执行btn.attachEvent(&quot;onclick&quot;, handler);// 移除事件处理时，传入的参数必须和添加时相同btn.detachEvent(&quot;onclick&quot;, handler); ps：需要特别注意的就是，使用attachEvent绑定的事件处理程序的作用域比较特殊，它的this并不是代表当前所属元素。 2.5 跨浏览器事件处理程序针对不同的浏览器，可以写出跨浏览器的方式处理事件。 跨浏览器事件处理只需要处理冒泡阶段，因为有些浏览器版本是不支持捕获事件的。 1234567891011121314151617181920var EventUtil = { addHandler: function (element, type, handler) { if (element.addEventListener) { element.addEventListener(type, handler, false); } else if (element.attachEvent) { element.attachEvent(&quot;on&quot; + type, handler); } else { element[&quot;on&quot; + type] = handler; } }, removeHandler: function (element, type, handler) { if (element.removeEventListener) { element.removeEventListener(type, handler, false); } else if (element.detachEvent) { element.detachEvent(&quot;on&quot; + type, handler); } else { element[&quot;on&quot; + type] = null; } }} 三、事件对象在触发 DOM 上的某个事件时，都会产生一个事件对象 event，这个对象包含着所有与事件有关的信息。 事件对象包括导致事件的元素、事件类型以及其他相关信息。 所有浏览器都支持事件对象，但是不同浏览器有不同的实现。 针对不同的浏览器，事件对象 event 也有不同的实现： DOM 中的事件对象 IE 中的事件对象 3.1 DOM 中的事件对象对于不同的绑定事件处理程序的方式，获取事件对象的方式也不一样。 1）HTML 事件处理程序 12&lt;!-- click --&gt;&lt;div onclick=&quot;alert(event.type)&quot;&gt;&lt;/div&gt; 在 HTML 指定事件程序这种方法中，事件对象 event 是保存在变量 event 中的，可以直接拿到。 2）DOM0/DOM2 级事件处理程序 1234567891011var btn = document.getElementById(&quot;myBtn&quot;);// 标准 DOM0 级btn.onclick = function (event) { alert(event.type); // &quot;click&quot;}// 标准 DOM2 级btn.addEventListener(&quot;click&quot;, function (event) { alert(event.type); // &quot;click&quot;}, false); 对于 DOM2/DOM2 级指定事件处理程序的方式，event 对象可以直接在事件处理程序的参数中获取。 DOM 中的事件对象有一些特殊的属性和方法： 属性/方法 说明 bubbles 表明事件是否可以冒泡 cancelable 表明是否可以取消事件的默认行为 currentTarget 当前事件处理程序绑定的元素 defaultPrevented 为 true 表示已经调用过 preventDefault() 了 eventPhase 当前事件流阶段。1表示捕获阶段，2表示“处于目标”，3表示冒泡阶段 target 触发事件的元素 type 事件类型 preventDefault() 取消默认的事件行为。只有 cancelable=true 时才能生效 stopPropagation() 取消事件的进一步捕获或冒泡。只有 bubbles=true 时才能生效 stopImmediatePropagation() 取消事件的进一步捕获或冒泡，同时阻止任何事件处理程序被调用 3.1.1 target在事件处理程序内部，this 始终等于 currentTarget，而 target 则只是事件的目标对象（即触发事件的元素）。 123456789101112131415161718var btn = document.getElementById(&quot;myBtn&quot;);// 触发事件的元素的事件处理btn.onclick = function (event) { alert(event.currentTarget === this); // true alert(event.target === this); // true}// 捕获/冒泡阶段的事件处理document.body.onclick = function (event) { // currentTarget 执行的是当前事件处理程序的绑定元素 alert(event.currentTarget === this); // true alert(event.currentTarget === document.body); // true // target 始终指向的是触发事件的元素 alert(event.target === this); // false alert(event.target === btn); // true} 3.1.2 preventDefault()为了阻止事件的默认行为，可以使用 preventDefault() 方法，但是要使用这个方法，必须确保 cancelable=true 才行，否则方法不会生效。 默认行为指的是 dom 元素的默认动作，比如 &lt;a hrtf=&quot;&quot;&gt; 元素的默认行为就是在 click 触发时导航到 href 指定的 URL。使用 preventDefault() 可以阻止其跳转。 1234var link = document.getElementById(&quot;myLink&quot;);link.onclick = function (event) { event.preventDefault();} 3.1.3 stopPropagation()为了阻止事件继续在事件流里传播，可以使用 stopPropagation() 方法，但是使用这个方法前，要确保 bubbles=true 才行，否则方法不会生效。 1234567891011var btn = document.getElementById(&quot;myBtn&quot;);// 触发事件的元素的事件处理btn.onclick = function (event) { alert(&quot;btn click&quot;);}// 捕获/冒泡阶段的事件处理document.body.onclick = function (event) { alert(&quot;doc click&quot;);} 正常情况下，由于事件的冒泡，当点击按钮时，会弹出2个警告框。 因此为了避免这种情况，可以使用 stopPropagation() 方法来阻止事件进一步传播： 1234567891011121314var btn = document.getElementById(&quot;myBtn&quot;);// 触发事件的元素的事件处理btn.onclick = function (event) { alert(&quot;btn click&quot;); // 阻止事件继续传播 event.stopPropagation();}// 捕获/冒泡阶段的事件处理document.body.onclick = function (event) { alert(&quot;doc click&quot;);} 这个时候，点击按钮时，只会弹出1个警告框。 但是 stopPropagation() 还存在一个问题，它只能阻止事件的冒泡，但是不能阻止同级事件处理程序的执行。前面说过，一个事件可以绑定多个事件处理程序，stopPropagation() 是没有阻止当前目标元素的其他事件处理程序的： 123456789101112131415var btn = document.getElementById(&quot;myBtn&quot;);var handler1 = function () { alert(&quot;handler1&quot;); // 阻止事件继续传播 event.stopPropagation();};var handler2 = function () { alert(&quot;handler2&quot;);};// 可以添加多个事件处理程序，按添加顺序执行btn.addEventListener(&quot;click&quot;, handler1, false);btn.addEventListener(&quot;click&quot;, handler2, false); 这个时候点击按钮，依旧会弹出2个警告框，因为stopPropagation()只是阻止了事件冒泡，但是同级事件处理程序还是会执行的。 所以在 DOM3 中，添加了一个新的方法stopImmediatePropagation()，它可以阻止后续的所有事件处理程序执行，包括同级别的事件处理程序。 3.2 IE 中的事件对象IE 中的事件对象获取方式有些不同，它取决于在IE中指定事件处理程序的方法。例如： 在IE中使用DOM0级方法添加事件处理程序时，event 事件对象是作为 window 对象的一个属性存在的； 但是在 IE 中使用 attachEvent() 添加事件处理程序时，event 对象是作为事件处理函数的参数存在的。 123456789101112var btn = document.getElementById(&quot;myBtn&quot;);// IE 下的 DOM0 级btn.onclick = function () { var event = window.event; alert(event.type); // &quot;click&quot;}// IE 下的 DOM2 级btn.attachEvent(&quot;onclick&quot;, function (event) { alert(event.type); // &quot;click&quot;}); IE 中的事件对象有一些特殊的属性和方法： 属性/方法 说明 cancelBubble 用于是否取消事件冒泡，与stopPropagation()作用相同 returnValue 用于是否取消事件的默认行为，与preventDefault()作用相同 srcElement 当前事件处理程序绑定的元素，与target属性相同 type 事件类型 3.2.1 srcElement事件处理程序的作用域是由指定它的方式来确定的，因此在写代码时需要特别注意，最好还是使用event.srcElement来替代``this`来作为当前目标对象。 12345678910111213var btn = document.getElementById(&quot;myBtn&quot;);// IE 下的 DOM0 级btn.onclick = function () { var event = window.event; alert(event.srcElement === this); // true}// IE 下的 DOM2 级btn.attachEvent(&quot;onclick&quot;, function (event) { alert(event.srcElement === this); // false alert(window === this); // true}); 3.3.2 retrunValueIE 中取消事件默认行为的方法是使用returnValue=false，与preventDefault()作用相同： 12345var link = document.getElementById(&quot;myLink&quot;);link.onclick = function () { var event = window.event; event.returnValue = false;} 和标准 DOM 不同的是，IE 中没有方法确定事件是否可以被取消。 3.2.3 cancelBubbleIE 中阻止事件冒泡的方法是使用cancelBubble=true，与stopPropagation()作用相同： 123456789101112131415var btn = document.getElementById(&quot;myBtn&quot;);// 触发事件的元素的事件处理btn.onclick = function () {var event = window.event; alert(&quot;btn click&quot;); // 阻止事件继续传播 event.cancelBubble = true;}// 捕获/冒泡阶段的事件处理document.body.onclick = function (event) { alert(&quot;doc click&quot;);} 点击按钮，只会弹出一个警告框。 3.3 跨浏览器的事件对象12345678910111213141516171819202122232425262728293031323334353637383940var EventUtil = { addHandler: function (element, type, handler) { if (element.addEventListener) { element.addEventListener(type, handler, false); } else if (element.attachEvent) { element.attachEvent(&quot;on&quot; + type, handler); } else { element[&quot;on&quot; + type] = handler; } }, removeHandler: function (element, type, handler) { if (element.removeEventListener) { element.removeEventListener(type, handler, false); } else if (element.detachEvent) { element.detachEvent(&quot;on&quot; + type, handler); } else { element[&quot;on&quot; + type] = null; } }, getEvent: function (event) { return event ? event : window.event; }, getTarget: function (event) { return event.target || event.srcElement; }, preventDefault: function (event) { if (event.preventDefault) { event.preventDefault(); } else { event.returnValue = false; } }, stopPropagation: function (event) { if (event.stopPropagation) { event.stopPropagation(); } else { event.cancelBubble = true; } }}","link":"/lang/js/events/"},{"title":"浏览器中的BOM对象","text":"BOMBOM 是指浏览器对象模型。 主要用于开发人员控制浏览器显示的界面以外的部分，例如浏览器窗口的位置、浏览器的地址信息、浏览历史界面的前进后退等。 一、windowwindow 对象是 BOM 的核心对象，表示浏览器的一个实例。 1.1 全局声明window 既是访问浏览器窗口的接口，也是 ECMAScript 的全局对象（Global）。 直接在全局作用域声明的变量、函数等都会变成 window 对象的属性和方法： 1234567891011&lt;script&gt; var name = 'zhangsan' function getName() { return this.name } alert(name) // zhangsan alert(getName()) // zhangsan alert(window.name) // zhangsan alert(window.getName()) // zhangsan&lt;/script&gt; 虽然定义全局变量会直接归到 window 中，但是还是和直接在 window 中定义的属性有点不同。 全局变量不能使用 delete 删除变量，但是在 window 中定义的属性是可以的： 123456789101112131415&lt;script&gt; var name = 'zhangsan' window.age = 12 alert(window.name) // zhangsan alter(window.age) // 12 // 删除无用 delete window.name alter(window.name) // zhangsan // 可以删除 delete window.age alter(window.age) // undefined&lt;/script&gt; 产生这种情况的原因是，全局声明的变量，虽然被归到 window 中，但是它的一个特性值 [[Configurable]] 默认会被设为 false，导致全局声明的变量没有办法使用 delete 进行删除。 1.2 窗口和框架框架，一般指的是 HTML 中的 &lt;frame&gt; 标签所表述的元素。 每个框架都类似于一个浏览窗口，因此每个框架都有自己的 window 对象。 框架的 window 对象会保存在父框架或父窗口的 window.frames 中。 一般情况下框架的 window 对象都会有一个 name 属性。 123456789&lt;html&gt; &lt;frameset&gt; &lt;frame src=&quot;top.html&quot;, name=&quot;topFrame&quot;&gt; &lt;frameset&gt; &lt;frame src=&quot;bottom-left.html&quot;, name=&quot;bottomLeftFrame&quot;&gt; &lt;frame src=&quot;bottom-right.html&quot;, name=&quot;bottomRightFrame&quot;&gt; &lt;/frameset&gt; &lt;/frameset&gt;&lt;/html&gt; 对于当前的 window 而言，window.frames 将会包含3个 window 对象，分别是框架 topFrame、bottomLeftFrame 和 bottomRightFrame 的 window 对象。 可以通过 window.frames[1] 或者 window.frames['bottomLeftFrame'] 来访问指定的框架 window 对象。 1.2.1 toptop（window.top）对象始终指向最高（最外）层的框架，也就是浏览器窗口。 1.2.2 parentparent（window.parent）对象指的是当前框架的直接上层框架（父框架）。 在没有框架的情况下，parent === top。 加入上述代码中的 top.html 文件如下： 123456&lt;html&gt; &lt;frameset&gt; &lt;frame src=&quot;topInnerLeft.html&quot;, name=&quot;topInnerLeftFrame&quot;&gt; &lt;frame src=&quot;topInnerRight.html&quot;, name=&quot;topInnerRightFrame&quot;&gt; &lt;/frameset&gt;&lt;/html&gt; 那么对于框架 topInnerLeftFrame 的 window 对象而言，它的 window.parent 指的就是框架 topFrame 的 window 对象。 1.2.3 selfself（window.self）指的是 window 对象本身。 引入 self 只是为了和 top、parent 对应，貌似没什么特别作用。 1.3 窗口位置窗口位置指的是浏览器窗口在屏幕上的位置信息。不同浏览器提供的位置属性不一样。 IE、Safari、Opera 和 Chrome 都提供 screenLeft 和 screenRight，分用于表示窗口相对于屏幕的左边和上边的位置。 FireFox、Safari、Chrome 提供 screenX 和 screenY ，对应相同的位置信息。 跨浏览器获取浏览器窗口的位置信息，可以用以下代码： 12var leftPos = (typeof window.screenLeft == 'number') ? window.screenLeft : window.screenX;var topPos = (typeof window.screenTop == 'number') ? window.screenTop : window.screenY; 移动窗口位置，可以使用 moveTo 和 moveBy 方法，moveTo 是移动到指定的位置， moveBy 是移动的方向距离。 12345// 将窗口移动到(100, 200)window.moveTo(100, 200)// 将窗口向右移动100，向下移动200window.moveBy(100, 200) 不过这两个方法有可能被浏览器禁用，因此最好不要使用。 1.4 窗口大小IE9+、Firefox、Safari、Opera 和 Chrome 提供了4个属性来获取窗口的大小：innerWidth、innerHeight、outerWidth、outerHeight，不过不同浏览器返回的值不太相同。有些是返回浏览器窗口本身的大小，有些是返回视口（viewport）的大小。 获取视口大小的代码如下： 123456789101112var pageWidth = window.innerWidthvar pageHeight = window.innerHeightif (typeof pageWidth != 'number') { if (document.compatMode == 'CSS1Compat') { pageWidth = document.documentElement.clientWidth pageHeight = document.documentElement.clientHeight } else { pageWidth = document.body.clientWidth pageHeight = document.body.clientHeight }} 使用 resizeTo 和 resizeBy 可以改变浏览器窗口的大小。resizeTo 是指定改变后浏览器窗口的大小，resizeBy 是指定改变窗口的宽高差值。 12345// 将窗口大小改变为(100, 200)window.resizeTo(100, 200)// 将窗口宽度减少100，高度减少200window.resizeBy(100, 200) 不过这两个方法也有可能被浏览器禁用，因此也是最好不要使用。 1.5 导航和打开窗口window.open() 方法可以导航到特定的 URL，也可以打开一个新的浏览器窗口。 接收的参数可以有4个： URL：要加载的URL 窗口目标：指定打开窗口的位置，是在当前窗口打开，还是新窗口打开 特性字符串：指定打开窗口的相关信息，例如窗口的高度、宽度等 标志位：用于标识新页面是否设置为浏览器历史记录中的当前加载页面 第二个参数的可选值有： _self：当前框架或窗口打开 _parent：父框架或父窗口打开 _top：当前浏览器窗口打开 _blank：新的浏览器窗口打开 frameName：指定的框架打开，不存在该框架时，新窗口打开 12// 等同于&lt;a href=&quot;http://ww.baidu.com&quot;, target=&quot;topFrame&quot;&gt;window.open('http://www.baidu.com', 'topFrame') 上述代码会在 topFrame 框架中加载新页面，如果框架不存在，则会新窗口打开。 1.5.1 窗口引用window.open() 方法会返回一个指向新窗口的引用，该引用和 window 对象差不多。 1234var newWin = window.open('http://www.baidu.com', 'topFrame')newWin.moveTo(100, 200)newWin.resizeTo(100,200)newWin.close() 同时，新打开窗口也拥有一个属性 opener 指向创建它的原始窗口对象： 12var newWin = window.open('http://www.baidu.com', 'topFrame')alert(newWin.opener == window) // true 1.5.2 窗口屏蔽大多数浏览器有内置的弹出窗口屏蔽程序，因此 window.open() 有可能返回 null。因此使用 window.open() 时，最好封装在一个 try-catch 块中： 1234567891011121314var blocked = falsetry { var newWin = window.open('http://www.baidu.com', '_blank') if (newWin == null) { blocked = true }} catch (ex) { blocked = true}if (blocked) { alert('open window was blocked')} 1.6 locationlocation（window.location）对象提供了当前窗口中加载的文档的有关信息，还有导航功能。 另外，在 window 和 document 中，有 window.location == document.location。 location 对象中包含的属性有： href：当前加载页面的完整 URL，如 http://www.baidu.com procotol：页面使用的协议，如 http:、https: host：服务器名称以及端口，如 www.baidu.com:80 hostname：服务器名称，不包括端口，如 www.baidu.com port：端口号，如 80 pathname：URL 路径，如 /uers/info search：URL 查询字符串，如 ?age=12&amp;&amp;city=guangzhou hash：URL 中的散列值，如 #content 1.6.1 位置操作直接改变 location 代表的值，就可以直接打开新的 URL： 1234// 这几种方式效果是一样的window.location = 'http://www.baidu.com'location.href = 'http://www.baidu.com'location.assign('http://www.baidu.com') 也可以单独修改 location 里面的属性： 1234567891011// http://www.baidu.com:80/users/window.location// http://www.baidu.com:80/users/#contentlocation.hash = '#content'// http://www.baidu.com:80/another/location.pathname = 'another'// http://www.baidu.com:8080/users/location.port = '8080' 使用上述的修改方式，会在浏览器的历史记录中生成一条新的记录，因此用户通过单击“后退”按钮后可以返回到上一个页面。 1.6.2 相关方法使用 location.repalce() 方法可以禁用这种行为，它会导航到一个新的页面，但是不会在浏览器历史记录中生成新的记录。 12// 不会生成新的历史记录，因此跳转后无法回到前一个页面location.replace('http://www.baidu.com') 使用 location.reload() 方法可以重新加载当前显示的页面。 12345// 有可能从缓存中加载location.reload()// 强制从服务器加载location.reload(true) 1.7 navigatornavigator（window.navigator） 对象用于识别客户端浏览器的类型等信息。 主要实现属性包括（还有很多属性没列出来）： appCodeName：浏览器名称 appName：完整的浏览器名称 appVersion：浏览器的版本 cookieEnabled：表示 cookie 是否启用 mimeTypes：在浏览器中注册的MIME类型数组 platform：浏览器所在的系统平台 plugins：浏览器安装的插件 userAgent：浏览器的用户代理字符串 navigator 对象主要提供来比较多来`客户端浏览器的相关信息，不同的浏览器实现还不一样。 1.8 screenscreen（window.screen）对象用来表明客户端的一些属性，包括浏览器窗口外部的显示器的信息，例如像素宽度和高度。 其中包含的属性有： height：屏幕的像素高度 width：·屏幕的像素宽度 left：当前屏幕距左边的像素距离 top：当前屏幕距上边的像素距离 colorDepth：用于表示颜色的位数 screen 对象不常用，而且在涉及移动设备时，使用前还需要进行相应的调整。 1.9 historyhistory（window.history）对象用于保存用户上网的历史记录，从打开窗口的那一刻算起。 history 是 window 的属性，因此不同的浏览器窗口、标签页、框架等都有自己的 history 对象。 出于安全考虑，history 对象不能看到用户浏览过的 URL，只能指导历史记录条数等一些信息。 使用 go() 方法可以在历史记录中进行任意的跳转，可以向前或者向后。 12345// 后退一页history.go(-1)// 前进两页history.go(2) go() 还可以使用字符串，表示跳转到包含该字符串的记录，因此有可能是前进，也可能是后退： 12// 跳到最近的 baidu.com 页面history.go('baidu.com') 使用简写的 forward() 和 back() 可以用来替代 go(1) 和 go(-1)： 12345// 前进一页history.forward()// 后退一页history.back()","link":"/lang/js/bom/"},{"title":"HTML中的DOM对象","text":"DOMDOM（文档对象模型）是针对 HTML 和 XML 文档的一个API。 主流浏览器都完成了 DOM1 级的实现 IE 的 DOM 对象都是以 COM 对象的形式存在，和原始的 DOM 对象行为并不一致 一、节点层次DOM 可以将 HTML 或 XML 文档描绘成一个由多层节点构成的结构，简单点说，就是一个树结构。 1.1 文档节点文档节点是每个文档的根节点。 文档节点不直接表现在文档定义中，是一个内置的节点。 1.2 文档元素文档元素是文档的最外层元素，文档中的所有其他元素都包含在文档元素中。 每个文档只能有一个文档元素。 在 HTML 页面中，文档元素始终是 &lt;html&gt; 元素。 1.3 节点结构以 HTML 文档为例，结构如下： 1234567|-- Document |-- html |-- head |-- title |-- body |-- p |-- div 其中，Document 是文档节点，它在 HTML 文档中是没有定义的；html 是文档元素，所有其他的元素都在它里面。 二、节点类型2.1 Node 类型Node 在 DOM1级定义中，是一个接口，由 DOM 中的所有节点类型实现。 在 JavaScript 中，Node 接口是作为 Node 类型实现的。 JavaScript 中的所有节点类型都继承自 Node 类型 每个节点都有一个 nodeType 属性，用于表明节点的类型 除 IE 外，其他浏览器均可以访问 Node 类型（IE 没有公开它的 Node 类型的构造函数） 2.1.1 公共属性(1) nodeType 每个节点都有一个 nodeType 属性，用于表明节点的类型。节点类型总共有12种（括号内的是它的常量值）： 123456789101112- Node.ELEMENT_NODE(1)- Node.ATTRIBUTE_NODE(2)- Node.TEXT_NODE(3)- Node.CDATA_SECTION_NODE(4)- Node.ENTITY_REFERENCE_NODE(5)- Node.ENTITY_NODE(6)- Node.PROCESSING_INSTRUCTION_NODE(7)- Node.COMMENT_NODE(8)- Node.DOCUMENT_NODE(9)- Node.DOCUMENT_TYPE_NODE(10)- Node.DOCUMENT_FRAGMENT_NODE(11)- Node.NOTATION_NODE(12) 需要说明的是，并不是所有 Web 浏览器都支持全部的节点类型。 由于 IE 无法访问 Node 类型，因此在判断节点类型时，为了确保浏览器兼容性，最好将 nodeType 与数值作比较： 123456789// IE 下无效if (node.nodeType === Node.ELEMENT_NODE) { ...}// 适用于所有浏览器if (node.nodeType === 1) { ...} (2) nodeName 和 nodeValue 这两个值取决于节点的类型，有可能取值为 null。 在 Node.ELEMENT_NODE 元素类型中，nodeName 始终保存的是元素的标签名，而 nodeValue 的值则始终是 null。 (3) childNodes 每个节点都有一个 childNodes 属性，用于保存它的子节点。 childNodes 是一个 NodeList 对象，是一种类数组对象（不是数组），其中保存着一组有序的节点。 NodeList 对象是一个动态查询的结果，也就是说，当 DOM 结构发生变化时，它能够实时更新数据。 12345678// 获取 NodeList 对象的长度var length = node.childNodes.length// 使用类似数组的[]下标访问var firstChild = node.childNodes[0]// 使用 item() 方法访问var lastChild = node.childNodes.item(length - 1) 需要说明的是，虽然所有节点都继承自 Node 类型，但并不是每种节点都有子节点。 (4) 其他属性 parentNode：父节点 previousSibling：同级节点的前一个节点 nextSibling：同级节点的下一个节点 firstChild：第一个子节点 lastChild：最后一个子节点 ownerDocument：节点所在的文档 2.1.2 公共方法(1) appendChild appendChild() 方法用于向 childNodes 列表末尾追加一个节点。 如果追加的节点已经在 childNodes 中，则会将该节点移动到 childNodes 列表的末尾。 12345678// 追加到末尾var newNode = parentNode.appendChild(newChildNode)alert(newNode === parentNode.lastChild) // true// 移动到末尾var firstChild = parentNode.firstChildvar moveNode = parentNode.appendChild(firstChild)alert(moveNode === parentNode.lastChild) // true (2) insertBefore insertBefore() 方法用于在 childNodes 列表的某个位置中插入一个节点。 1234567// 插入到末尾var newNode = parentNode.insertBefore(newChildNode, null)alert(newNode === parentNode.lastChild) // true// 插入后成为第一个节点var insertNode = parentNode.insertBefore(newChildNode, parentNode.firstChild)alert(insertNode === parentNode.firstChild) // true (3) replaceChild replaceChild() 方法用于将旧节点替换成新节点，实际上是做了一个删除节点操作和插入节点操作。 123// 替换指定的子节点var replaceNode = parentNode.replaceChild(newChildNode, parentNode.firstChild)alert(replaceNode === parentNode.firstChild) (4) removeChild removeChild() 方法用于移除子节点。 12// 移除第一个子节点var removeNode = parentNode.removeChild(parentNode.firstChild) (5) 其他方法 cloneNode：用于创建调用节点的副本，cloneNode(true) 为深复制，cloneNode(false) 为浅复制。 normalize：用于处理后代的文本节点，后代中如果存在空的文本节点，则删除它；如果出现相邻的文本节点，则合并它们。 2.2 Document 类型Document 类型用于表示文档，可以是 HTML 页面或者基于 XML 的文档。 在浏览器中，document 对象是 HTMLDocument（继承自 Document 类型）的一个实例，表示整个 HTML 页面 document 对象是 window 对象的一个属性，可作全局对象访问 具有的特征包括： nodeName 的值为 #document nodeValue 的值为 null parentNode 的值为 null ownerDocument 的值为 null (1) 文档子节点 DOM 标准规定 Documnet 节点的子节点可以是： DocumentType（最多一个） Element（最多一个） ProcessingInstruction Comment document 对象拥有两个内置的访问其子节点的快捷方式，一个是 documentElement，另一个是 body。 document.documentElement 可以直接访问文档的 &lt;html&gt; 元素（因为文档最多只会有一个 Element 元素） 作为 HTMLDocument 的实例，document.body 还可以直接访问文档的 &lt;body&gt; 元素 其他子节点属性： DocumentType：document.doctype 用来表示文档类型子节点，但是由于浏览器对 document.doctype 的支持不一致，因此这个属性的用处不大 Comment：理论上出现在 &lt;html&gt; 外面的注释，都属于 document 的子节点，但是不同浏览器对于这种注释的处理也存在差异，因此文档注释的意义也不大 (2) 文档信息 title：document.title 表示文档标题元素 &lt;title&gt; ，修改 document.title 的值会直接改变 &lt;title&gt; 元素。 URL：document.URL 表示当前页面的完整 URL（即地址栏显示的 URL） domain：document.domain 表示页面的域名，与 URL 相关联 referer：document.refreer 表示来源页面的 URL（即跳转到当前页面的上一个页面 URL） 1234567891011// 修改页面标题document.title = '新标题'// http://www.baidu.com/var url = document.URL// www.baidu.comvar domain = document.domain// http://www.google.com/var referer = document.refreer 在 URL、domain、referer 中，只有 domain 可以修改，其他两个都是只读属性。 domain 只能设置成 URL 的子域名，不能修改为 URL 中不包含的域 修改为子域名之后，不能再修改回原域名（即修改只能收缩，不能扩张） 1234567891011121314// http://www.baidu.com/var url = document.URL// www.baidu.comvar domain = document.domain// 可以从父域名修改为子域名document.domain = 'baidu.com'// 不可以修改为 URL 不包含的域名document.domain = 'google.com' // 出错// 修改为子域名以后，不可以再修改回原域名document.domain = 'www.baidu.com' // 出错 domain 的限制来源于跨域安全：来自不同子域的页面不能通过 Javascript 通信。也就是说，如果一个页面包含了一个内嵌框架，而且内嵌框架的域名和页面的域名不同，那它们之间就不能互相访问对方的 Javascript 对象。 123456789101112&lt;!-- 假设当前页面来自 http://wwww.baidu.com/outer.html --&gt;&lt;html&gt; &lt;body&gt; &lt;frameset&gt; &lt;frame src=&quot;http://www.google.com/inner.html&quot;, name=&quot;innerFrame&quot;&gt; &lt;/frameset&gt; &lt;script&gt; // 由于页面和内置框架不同域名，因此会受到跨域安全的限制 // 导致在这里无法正常访问内嵌框架的 Javascript 对象 &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 想要通过 Javascript 实现跨域访问，可以使用 window.postMessage() 方法。 (3) 特征检测 由于 DOM 分为多个级别，也包含多个部分，因此在使用某些特征功能之前，需要检测一下浏览器是否实现来该功能。 document.implemetation 属性提供了浏览器实现的相应信息和功能，其中 DOM1 级规定了一个方法 hasFeature() 用于检测 DOM 功能以及版本： 1var hasXmlDom = document.implementation.hasFeature('XML', '1.0') 需要注意的是，hasFeature() 方法判断可能存在错误，因为功能是由浏览器负责实现的，但它未必完全按照 DOM 规范来实现，因此即使是在 hasFeature() 返回 true情况下，也未必能正确使用该功能，所以除了使用 hasFeature() 以外，应该还要加上能力检测。 (4) 查找元素 Document 类型查找元素的方法有，搜索的范围是整个文档： getElementById：通过元素的 ID 获取，区分大小写。如果文档中有多个相同 ID 的元素，则返回第一次出现的元素 getElementsByTagName：通过元素的标签名获取，返回的是包含0个或多个元素的 NodeList 12345678// 按照 ID 获取var myDiv = document.getElementById('divId')// 按照标签获取var images = document.getElementsByTagName('img')// 获取所有元素var allElements = document.getElementsByTagName('*') 另外，对于 HTMLDocument 类型而言，还有另外的方法： getElementsByName：通过元素的name特性获取，返回的是包含0个或多个元素的 NodeList getElementsByName() 方法常用在获取同一组单选按钮的值： 12// 按照name属性获取var radios = document.getElementsByName('radioName') 另外，文档为常用的元素提供了快捷方式，可以免去我们自己查找： document.anchors：文档中所有带有 name 特性的 &lt;a&gt; 元素 document.links：文档中所有带有 href 特性的 &lt;a&gt; 元素 document.applets：文档中所有的 &lt;applet&gt; 元素（不建议使用） document.forms：文档中所有的 &lt;form&gt; 元素 document.images：文档中所有的 &lt;img&gt; 元素 (5) 文档写入 document 对象可以直接将输出流写入网页中，主要的方法有几个： write：写入字符串 writeln：写入字符串，并在末尾添加一个换行符（\\n） open：打开输出流 close：关闭输出流 需要注意的是，在文档加载期间使用 write() 和 writeln() 是不需要使用 open() 和 close() 方法的。 12345678&lt;html&gt; &lt;body&gt; &lt;script&gt; // 处于文档加载期间，不需要使用 open() 和 close() 方法 document.write('Hello world!'); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 12345678910111213&lt;html&gt; &lt;body&gt; &lt;button onclick=&quot;btnClick()&quot;&gt;&lt;/button&gt; &lt;script&gt; function btnClick () { // 文档加载完毕，需要使用 open() 和 close() 方法 document.open(); document.write('Hello world!'); document.close(); } &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 2.3 Element 类型元素 Element 类型用于表示 XML 或 HTML 元素，具有的特征包括： nodeType 的值为 1 nodeName 的值为元素的标签名 nodeValue 的值为 null parentNode 可能是 Document 或 Element 访问元素的标签名可以使用 nodeName 或 tagName，在 Element 类型中这两个是相等的。 在 HTMl 中，标签名始终是全部大写表示 在 XML 中，标签名则始终和源代码中保持一致 因此在判断标签名时，最好转换一下大小写： 123if (element.tagName.toUpperCase() === 'DIV') { ...} (1) HTML 元素 所有 HTML 元素都由 HTMLElement 类型表示，而 HTMLElement 继承自 Element，并添加了一些属性： id：元素的唯一标识符 title：元素的附加说明信息，一般用于工具提示条显示 lang：元素内容的语言代码，少用 dir：语言的方向，少用 className：元素的 class 特征，即元素的 CSS 类（class 是 ECMAScript 保留字，所以用 className 表示） (2) 元素特性 特性是用于给出元素及其内容的附加信息。 12&lt;!-- id、class、title、align、data-custom-attr 等称为元素特性 --&gt;&lt;div id=&quot;myDiv&quot; class=&quot;my-cls&quot; title=&quot;my-title&quot; align=&quot;left&quot; data-custom-attr=&quot;custom attribution&quot;&gt;&lt;/div&gt; 操作特性的 DOM 方法有几个： getAttribute：获取特性 setAttribute：设置特性 removeAttribute：删除特性 1234567891011121314var myDiv = document.getElementById('myDiv')// 设置特性myDiv.setAttribute('id', 'new_id')myDiv.setAttribute('class', 'new-my-cls')myDiv.setAttribute('title', 'New title')// 获取特性alert(myDiv.getAttribute('id')) // &quot;new_id&quot;alert(myDiv.getAttribute('class')) // &quot;new-my-cls&quot;alert(myDiv.getAttribute('title')) // &quot;New title&quot;// 移除特性myDiv.removeAttribute('class') (3) 元素属性 通过元素属性还可以访问元素特性，元素特性与元素属性的关系如下： 元素的特性可以通过 DOM 元素对象的属性访问 只有公认的（非自定义的）特性才会以属性的形式添加到 DOM 对象中（如 id、title 等） 通过属性获取得到的特性是经过解析的，是一个对象 123456789// element.id、element.className、element.title 等称为元素属性var myDiv = document.getElementById('myDiv')alert(myDiv.id) // &quot;myDiv&quot;alert(myDiv.className) // &quot;my-cls&quot;（class 是保留字的原因）alert(myDiv.title) // &quot;my-title&quot;// 自定义特性不会以属性的形式直接显示alert(myDiv['data-custom-attr']) // undefined（IE除外）alert(myDiv.getAttribute('data-custom-attr')) // &quot;custom attribution&quot; 有两类特性，它们虽然有对应属性名，但是属性值和通过 getAttribute() 拿到的特性值不同，属性值是经过解析的对象，而特性值是未经解析的字符串。这两类特性分别是样式 style，事件处理程序（onclick 等）。 1&lt;div id=&quot;myDiv&quot; style=&quot;height:100px;&quot; onclick=&quot;btnClick&quot;&gt;&lt;/div&gt; 123456789var myDiv = document.getElementById('myDiv')// 会直接得到原始的字符串alert(myDiv.getAttribute('style')) // &quot;height:100px;&quot;alert(myDiv.getAttribute('onclick')) // &quot;btnClick&quot;// 会得到解析过的对象/方法alert(myDiv.style) // objectalert(myDiv.onclick) // function 另外，Element 类型还有一个属性 attributes 用于保存元素所有的元素特性。element.attributes 属性包含一个 NamedNodeMap，是一个“动态”的集合，能够动态实时获取元素的所有特征。 (4) 创建元素 使用 document.createElement() 可以创建新元素，创建的同时，也为新元素设置了 ownerDocument 属性。 1234var newDiv = document.createElement('div')// 新元素需要添加到文档树中，才会在页面上显示document.body.appendChild(newDiv) (5) 查找元素 元素支持 getElementsByTagName() 方法，搜索起点为当前元素，范围是当前元素的子元素。 123// 查找指定元素下面的图片var myDiv = document.getElementById('myDiv')var images = myDiv.getElementsByTagName('img') 2.4 Text 类型文本节点由 Text 类型表示，包含的是纯文本内容，不能包含 HTML 代码，具有的特征： nodeType 的值为 3 nodeName 的值为 “#text” nodeValue 的值为节点所包含的文本 parentNode 是一个 Element 不支持（没有）子节点 文本节点的文本可以通过 nodeValue 或 data 属性获取，它们是相同的。 默认情况下，每个可以包含内容的元素最多只能有一个文本节点，而且必须确实有内容存在 修改文本时，字符串会经过 HTML （或 XML）编码（例如大于号、小于号等被转义成其他字符串） 如果两个文本节点是相邻的同胞节点，那它们的文本就会连起来显示，并且不会存在任何空格 12// 显示结果是 &quot;&amp;lt;p&amp;gt;New text content&amp;lt;/p&amp;gt;&quot;textNode.nodeValue = &quot;&lt;p&gt;New text content&lt;/p&gt;&quot; (1) 创建文本节点 创建文本节点使用 document.createTextNode() 方法，方法接收文本作为参数，创建节点的同时，也会设置节点的 ownerDocument 属性。 1var newTextNode = document.createTextNode('Hello world!') 需要注意的是，和设值一样，创建时的参数文本也会经过 HTML （或 XML）编码。 默认情况下，元素只有一个文本节点，但是通过 Javascript 可以为元素创建多个文本子节点： 1234567var myDiv = document.getElementById('myDiv')var newTextNode1 = document.createTextNode('Hello')var newTextNode2 = document.createTextNode(' world!')myDiv.appendChild(newTextNode1)myDiv.appendChild(newTextNode2) (2) 规范化文本 前面说过，如果两个节点是相邻的同胞节点，它们的文本会连起来显示，但是这样会导致分不清哪个字符串是哪个文本节点的，因此为了合并相邻的同胞文本节点，DOM 提供了一个方法 normalize()，用于合并相邻的文本节点。 12345678910var myDiv = document.getElementById('myDiv')var newTextNode1 = document.createTextNode('Hello')var newTextNode2 = document.createTextNode(' world!')myDiv.appendChild(newTextNode1)myDiv.appendChild(newTextNode2)// 合并同胞文本节点myDiv.normalize() (3) 分割文本 Text类型除了可以合并以外，还可以进行分割：splitText()。这个方法会将1个文本节点分割成2个： 123456789var myDiv = document.getElementById('myDiv')var newTextNode = document.createTextNode('Hello world!')myDiv.appendChild(newTextNode)var splitNode = myDiv.firstChild.splitText(5)alert(myDiv.firstChild.nodeValue) // &quot;Hello&quot;alert(splitNode.nodeValue) // &quot; world!&quot;alert(myDiv.childNodes.length) // 2 2.5 Comment 类型Comment 类型用于表示注释，与 Text 类型类似，具有特征如下： nodeType 的值为 8 nodeName 的值为 “#comment” nodeValue 的值是注释的内容 不支持（没有）子节点 Comment 类型和 Text 类型继承自相同的基类，因此拥有除了 splitText() 方法以外的所有字符串操作方法。 创建注释节点可以通过使用 document.createComment()，参数是注释内容： 1var comment = document.createComment('new comment') 2.6 CDATASection 类型CDATASection 类型只针对基于 XML 的文档，表示的是 CDATA 区域。具有的特征如下： nodeType 的值为4 nodeName 的值为 “#cdata-section” nodeValue 的值是 CDATA 区域的内容 不支持（没有）子节点 与 Comment 类型类似，CDATASection 类型继承自 Text 类型，因此拥有除了 splitText() 方法以外的所有字符串操作方法。 CDATA 区域只会出现在 XML 文档中，因此浏览器一般会把 CDATA 区域错误解析为 Comment 或 Element。 在 XML 文档中创建 CDATA 区域，可以使用 document.createCDATASection() 方法，参数是区域的内容。 2.7 DocumentType 类型DocumentType 类型包含着与文档的 doctype 有关的所有信息。具有的特征包括： nodeType 的值为 10 nodeName 的值为 doctype 的名称 nodeValue 的值为 null parentNode 为 Document 不支持（没有）子节点 在 DOM1 级中，DocumentType 对象不能动态创建，只能通过文档解析的方式创建。支持 DocumentType 的浏览器会将生成的 DoocumentType 对象保存在 document.doctype 中。 2.8 DocumentFragment 类型DocumentFragment 类型表示文档片段，是一种“轻量级”的文档，可以包含和控制部分节点，但是不像完整文档那样占用额外的资源。在所有的节点类型中，只有 DocumentFragment 类型在文档中没有对应的标记。具有的特征包括： nodeType 的值为 11 nodeName 的值为 “#document-fragment” nodeValue 的值为 null parentNode 的值为 null 文档片段不能直接添加到文档中，但是可以把文档片段中的节点添加到文档中。因此文档片段相当于一个节点临时仓库，可以将临时生成的节点保存在文档片段中，最后再将生成的节点都添加到文档中。 创建文档片段可以使用 document.createDocumentFragment() 方法： 1var fragment = document.createDocumentFragment() 如果将文档中的节点添加到文档片段中，该节点就会从文档树中移除（也就是浏览器看不到了） 将文档片段的子节点添加到文档中，节点会从文档片段中移除，但是文档片段不会添加到文档树上 文档片段有类似于缓存的作用，可以用于避免浏览器反复渲染新信息 1234567891011var ul document.createElement('ul')// 可以暂时保存到文档片段中，避免浏览器多次渲染新节点var li = nullvar fragment = document.createDocumentFragment()for (var i = 0; i &lt; 5; i++) { li = document.createElement('li') fragment.appendChild(li)}ul.appendChild(fragment) 2.9 Attr 类型元素的特性在 DOM 中以 Attr 类型来表示。在所有浏览器中，都可以访问 Attr 类型的构造器和原型。从技术角度讲，特性就是存在于元素的 attributes 属性中的节点。具有的特征包括： ndoeType 的值为 2 nodeName 的值就是特性的名称 nodeValue 的值是特性的值 parentNode 的值为 null 在 HTML 中不支持（没有）子节点 在 XML 中可以有 Text 或者 EntityReference 子节点 创建 Attr 节点可以使用 document.createAttribute() 方法，Attr 节点创建完成后，还需要使用 setAttribute() 方法来将属性值设到元素中： 123456var myDiv = document.getElementById('myDiv')var attr = document.createAttribute('align')attr.value = 'left'myDiv.setAttribute(attr) 但是在开发中，直接使用 setAttribute() 方法会更加直接一些： 12var myDiv = document.getElementById('myDiv')myDiv.setAttribute('align', 'left')","link":"/lang/js/dom/"},{"title":"对象变化侦测原理（三）","text":"三、Array 数组侦测数组 Array 虽然也是属于对象类型，但还是存在一些差别，它没办法像 Object 对象那样，通过 setter/getter 的方式来监听属性的变化，因此对于 Array 而言，需要用到另外一套变化侦测方案。 3.1 如何追踪变化我们知道，Array 数组有很多个内置方法可以改变数组的值，比如 push,pop,shift等，这些方法都可以改变数组的内容，所以可以尝试通过监听这些方法的调用，来达到监听数组变化的目的。 但是，这些方法都是内置方法，而且 js 中并没有提供接口给我们覆盖，因此要如何修改这些方法，以达到我们需要的效果呢？ 答案是，原型方法覆盖。 方法覆盖的方式可以分为2种：自定义同名私有方法，数组对象原型覆盖。 1、自定义同名私有方法 比如说，我们通过给数组对象添加同名的私有方法，就可以覆盖数组的内置方法。 假设数组对象 arr 本身自带有内置方法 push，我们可以通过添加同名私有方法 arr.push 来覆盖它： 1234arr.push = function (...args) { // 里面再调回数组的内置方法 Array.prototype.push.apply(arr, args)} 通过利用私有方法调用优先级的方式，就可以实现内置方法的代理。 每当我们调用 push 方法时，效果依旧和原来的一样，只不过实际上调用的是被我们包装代理过后的方法。 2、数组对象原型覆盖 除了使用私有方法覆盖的方式以外，还可以通过覆盖数组对象原型 Array.prototype 来实现。 我们都知道，在调用方法时，会优先从当前对象中查找该方法，如果没有，则会继续往上查找对象的原型中有没有该方法，然后这样一直向上，直到找到对应的方法为止，因此我们可以通过覆盖原型对象来实现方法代理。 比如说，数组对象 arr 在调用方法 push 时，会先查找本身有没有这个方法，如果没有，它就会去找原型 Array.prototype 中有没有该方法，这个时候找到了，就可以顺利调用 push 方法了。 假设这个时候，我把 arr 的原型换掉，换成我们自己封装过的，那么在数组对象向上寻找方法时，就会去我们换过的原型中查找方法： 12345678var arr = []// 覆盖原型对象arr.__proto__ = { push: function (...args) { // 里面再调回数组的内置方法 Array.prototype.push.apply(arr, args); }} 利用这种原型对象替换的方式，也可以实现内置方法的代理。 3.2 方法拦截器方法拦截器就是前面介绍的2种代理方式，其实对于这2种代理方式，Vue 中都有相应的实现。 首先，需要代理的方法是能够修改数组对象的方法，包括7个方法：push、pop、shift、unshift、splice、sort、reverse。 其实，我们再构造拦截方法，具体看 Vue 的代码实现： 12345678910111213141516171819202122232425262728293031// 创建一个和原始数组原型一样的对象const arrayProto = Array.prototypeexport const arrayMethods = Object.create(arrayProto)// 需要拦截的方法const methodsToPatch = [ 'push', 'pop', 'shift', 'unshift', 'splice', 'sort', 'reverse']// 实现方法拦截methodsToPatch.forEach(function (method) { const original = arrayProto[method] Object.defineProperty(arrayMethods, method, { value: function mutator (...args) { // 里面再调回原始的方法 const result = original.apply(this, args) // 后面还可以做其他事情 // ... return result }, enumerable: false, writable: true, configurable: true })}) 通过这种方法，我们就可以拦截数组对象的方法调用。 然后，将构造好的拦截方法设置到数组对象上： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 是否支持 `__proto__` 属性const hasProto = '__proto__' in {}// 需要拦截的方法名称集合const arrayKeys = Object.getOwnPropertyNames(arrayMethods)class Observer { constructor (value) { this.value = value if (Array.isArray(value)) { // 数组的方法拦截处理 if (hasProto) { // 原型替换 protoAugment(value, arrayMethods) } else { // 自定义私有方法 copyAugment(value, arrayMethods, arrayKeys) } } else { this.walk(value) } }}/** * 替换原型拦截代理 */function protoAugment (target, src) { target.__proto__ = src}/** * 自定义私有方法拦截代理 */function copyAugment (target, src, keys) { for (let i = 0, l = keys.length; i &lt; l; i++) { const key = keys[i] Object.defineProperty(target, key, { value: src[key], enumerable: false, writable: true, configurable: true }) }} 为什么需要2种实现方式呢？只用自定义私有方法不就可以实现了吗？ 其实是 Vue 优先使用原型替换来实现拦截，但是由于原型属性 __proto__ 在 ES6 之前并不属于官方标准属性，也就是说，通过 __proto__ 访问原型的方式并不是所有浏览器都支持！！！ 所以，当浏览器不支持 __proto__ 时，就使用自定义方法拦截的方式实现。 3.3 收集依赖既然方法拦截已经实现了，那么接下来就应该要实现依赖收集了。 依旧是按3步走：在哪里收集依赖、收集到哪里、什么时候触发依赖。 在哪里收集依赖 这个其实和 Objec 对象一样，数组对象的依赖也是在 getter 中收集的。 举个例子： 123var obj = { arr: [1, 2, 3]} 一般而言，访问数组对象实际上都是通过访问另外一个对象的属性来得到的，例如这里的 obj.arr。 也就是说，在收集 obj.arr 属性的依赖时，可以顺便收集数组的依赖，记住，是顺便收集~~。 因此，Array 数组对象的依赖收集，也是在 defineReactive 中收集的： 12345678910111213141516171819202122232425262728function defineReactive (obj, key, val) { // 递归子属性 if (typeof val === 'object') { new Observer(val) } let dep = new Dep() Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { // 收集对象属性的依赖 dep.depend() // 如果val是数组，则顺便收集数组的依赖 if (Array.isArray(val)) { // 这里收集数组依赖 } return val }, set: function reactiveSetter (newVal) { if (newVal === val) { return } val = newVal // 触发依赖 dep.notify() } })} 所以，在收集值为数组对象依赖时，实际上收集了2次依赖，一次是对象属性 obj.arr 的依赖），一次是属性对应的数组值 [1, 2, 3] 的依赖。 综上，Array 数组对象的依赖是在 getter 中收集，而依赖的触发则是在方法拦截器中。 收集到哪里 Array 数组对象依赖收集起来的地方，和 Object 对象的稍微有点不同。 原因在于，Object 对象的依赖收集和依赖触发，都是放在同一个作用域内的，也就是 getter/setter 方法，因此依赖只要保存在收集和触发的方法都能访问到的地方即可，在代码中也就是在 defineReactive 方法内。 而 Array 数组对象的话，依赖收集是在 getter 方法中，依赖触发则是在方法拦截器中，需要保证它们俩都能访问到依赖才行。 其实也很简单，只要找到它们的公共父作用域即可，而数组对象本身就可以满足这个条件。 为了能够让收集和触发访问到依赖对象，我们可以将依赖对象保存到数组对象中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class Observer { constructor (value) { this.value = value // 把依赖对象保存在数组对象中，这样两边都可以访问 this.value.dep = new Dep() if (Array.isArray(value)) { // 数组的方法拦截处理 if (hasProto) { // 原型替换 protoAugment(value, arrayMethods) } else { // 自定义私有方法 copyAugment(value, arrayMethods, arrayKeys) } } else { this.walk(value) } }}function defineReactive (obj, key, val) { // 递归子属性 let childOb if (typeof val === 'object') { childOb = new Observer(val) // 修改 } let dep = new Dep(); Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { // 收集对象属性的依赖 dep.depend(); // 如果有子对象/子数组 if (childOb &amp;&amp; childOb.value.dep) { // 修改 childOb.value.dep.depend() } return val }, set: function reactiveSetter (newVal) { if (newVal === val) { return } val = newVal; // 触发依赖 dep.notify(); } })}// 方法拦截methodsToPatch.forEach(function (method) { const original = arrayProto[method] Object.defineProperty(arrayMethods, method, { value: function mutator (...args) { // 里面再调回原始的方法 const result = original.apply(this, args) // 前面已经把依赖保存到数组的属性中，可以直接调用 if (this.dep) { // 修改 this.dep.notify() } return result }, enumerable: false, writable: true, configurable: true })}) 虽然这种方式也可以使得收集和触发都能访问到 dep 依赖对象，但是感觉不是很优雅，代码中直接在 value 上赋值了 value.dep 属性，这样很容易造成冲突。 所以 Vue 使用了另外一种方式，不是直接在 value 上添加属性 value.dep，而是在 value 上加了一个私有属性 __ob__，表示观察者 Observer。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Observer { constructor (value) { this.value = value this.dep = new Dep() // 修改，直接把依赖放在观察者下 this.value.__ob__ = this // 修改，保存到 value.__ob__ 中 if (Array.isArray(value)) { // 数组的方法拦截处理 if (hasProto) { // 原型替换 protoAugment(value, arrayMethods) } else { // 自定义私有方法 copyAugment(value, arrayMethods, arrayKeys) } } else { this.walk(value) } }}function defineReactive (obj, key, val) { // 递归子属性 let childOb if (typeof val === 'object') { childOb = new Observer(val) } let dep = new Dep(); Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { // 收集对象属性的依赖 dep.depend(); // 如果有子对象/子数组 if (childOb) { childOb.dep.depend() // 修改 } return val }, set: function reactiveSetter (newVal) { if (newVal === val) { return } val = newVal; // 触发依赖 dep.notify(); } })}// 方法拦截methodsToPatch.forEach(function (method) { const original = arrayProto[method] Object.defineProperty(arrayMethods, method, { value: function mutator (...args) { // 里面再调回原始的方法 const result = original.apply(this, args) // 先获取观察者，再得到依赖 const ob = this.__ob__ // 修改 if (ob) { ob.dep.notify() } return result }, enumerable: false, writable: true, configurable: true })}) 3.4 存在问题数组的变化侦测存在的问题，其实很明显。从上面的介绍可知，数组的变化侦测是通过代理数组的原型方法来实现的，所以只要是不经过代理方法调用的，都不会被侦测到。 比如： 12arr[2] = '0';arr.length = 0; 类似这种直接修改数组的值，就不会被变化侦测检测到。","link":"/framework/vuejs/dection03/"},{"title":"对象变化侦测原理（二）","text":"二、Object 变化侦测变化侦测指的是，当运行时的状态发生变化时，应用程序可以知道哪个状态发生了变化，并作出相应的动作。 变化侦测的方式可以分为2种：一种是“推（push）”，一种是“拉（pull）”。 Vue 的变化侦测就属于“推，当状态发生变化时，它就会通知相应的依赖对象进行更新。 2.1 追踪变化 前面说过，Object 的属性可以分为2种：数据属性和访问属性。 Vue 就是通过利用访问属性的 setter 和 getter 函数来追踪对象的变化的。 每当对象属性被读取时，getter 函数就会被触发；每当对象属性更新时，setter 函数就会被触发。 1234567891011121314151617var isStateChange = false;Object.defineProperty(objProxy, 'access', { get: function () { return obj.data; }, set: function (val) { obj.data = val; isStateChange = true; }})objProxy.accessalert(isStateChange) // falseobjProxy.access = '111'alert(isStateChange) // true 2.2 收集依赖知道了如何监听对象的变化，但是应该如何收集依赖呢？也就是说当状态发生变化后，该向谁通知状态变更呢？ 收集依赖需要分为3步：要收集什么？什么时候收集？收集到哪里？ 1、要收集什么？ 哪些算是依赖？其实就是用到了对象属性的地方就是依赖。比如说： 123&lt;template&gt; &lt;div&gt;{{ obj.name }}&lt;/div&gt;&lt;/template&gt; 对于上述模板，它调用了 name 属性，也就是对 obj.name 产生了依赖，当 obj.name 发生变化时，就需要通知模板进行重新渲染。 对于这种调用了对象属性的地方，都是需要收集起来的。 2、什么时候收集？ 前面已经说过了，Vue 是通过利用访问属性的 setter 和 getter 函数来进行侦听变化的。 因此收集原理也很简单，在 getter 中收集依赖，在 setter 中触发依赖。 1234567891011121314151617var isStateChange = false;Object.defineProperty(objProxy, 'access', { get: function () { return obj.data; }, set: function (val) { obj.data = val; isStateChange = true; }})objProxy.accessalert(isStateChange) // falseobjProxy.access = '111'alert(isStateChange) // true 3、收集到哪里？ 对于这个，可以简单地为每一个属性创建一个局部变量 dep 来保存。 假设依赖对象是一个函数，并且保存在 window.target 中，那么依赖的收集和通知实现可以如下所示： 1234567891011121314151617181920212223function defineReactive (obj, key, val) { let dep = []; // 保存依赖的地方 Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { // 收集依赖 // 假设依赖对象保存在 window.target 中 dep.push(window.target); return val }, set: function reactiveSetter (newVal) { if (newVal === val) { return } // 触发依赖 for (let i = 0; i &lt; dep.length; i++) { dep[i](newVal, val) } val = newVal; } })} 按照这种实现方式，每个对象属性都拥有自己的依赖收集器 dep。 当然，实际的 dep 并不是那么简单的一个数组，为了减低代码的耦合性，Vue 中把它实现为一个类 Dep，下面是它的简单实现： 1234567891011121314151617181920212223242526272829303132333435363738class Dep { constructor () { // 依赖，订阅者 this.subs = [] } addSub (sub) { this.subs.push(sub) } removeSub (sub) { remove(this.subs, sub) } depend () { // 假设依赖对象保存在 window.target 中 if (window.target) { this.addSub(window.target) } } notify () { const subs = this.subs.slice() for (let i = 0, l = subd.length; i &lt; l; i++) { // 通知依赖（订阅者）更新 subs[i].update() } }}function remove (arr, item) { if (arr.length) { const index = arr.indexOf(item) if (index &gt; -1) { return arr.splice(index, 1) } }} 根据新的 dep，修改 defineReactive 实现： 1234567891011121314151617181920function defineReactive (obj, key, val) { let dep = new Dep(); // 修改1 Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { // 收集依赖 dep.depend(); // 修改2 return val }, set: function reactiveSetter (newVal) { if (newVal === val) { return } val = newVal; // 触发依赖 dep.notify(); // 修改3 } })} 至此，收集依赖的工作基本完成了。 等等，还有一件重要的事，究竟什么是依赖呢？它到底从哪来的？虽然在前面的代码里，假设依赖是一个函数，并且已经设置到了 window.target 中， 但是并没有具体说明它是从哪里来的，是什么时候设置到 window.target 的。下面详细说明一下它。 依赖对象 前面说过，依赖实际上是用到对象属性的地方，但是用到对象属性的地方太多了，而且类型可能不一样，环境也不一样。这个时候为了能够统一处理依赖对象，需要将其抽象成一个依赖对象，这个依赖对象就称为观察者 Watcher，它就像是一直在观察对象属性的变化一样，当对象属性发生变化后，它就可以通过“观察”发现，从而进行相应的动作。 在 Vue 中，Watcher 是一个中介对象，当数据发生变化时，会通知到观察者 Watcher，然后 Watcher 再通知其他地方。 123456789101112131415161718192021222324252627class Watcher { constructor (vm, expOrFn, cb) { this.vm = vm; if (typeof expOrFn === 'function') { this.getter = expOrFn; } else { this.getter = parsePath(expOrFn); } this.cb = cb; this.value = this.get(); } get () { // 先把this设置到window.target中，然后再读取对象属性 window.target = this; // 这时候被读到的对象属性就会把当前this收集到它的依赖集合里面 let value = this.getter.call(this.vm, this.vm); window.target = undefined; return value; } update () { const oldValue = this.value; this.value = this.get(); this.cb(this.vm, this.value, oldValue); }} 收集依赖的过程实际上就在 getter 函数被调用的时候，那么 getter 函数具体是什么呢？也就是 parsePath 的实现是怎么样的呢？ 其实 parsePath 的参数 path 是类似 a.b.c 这样的形式，如果用过 Vue 的话，就应该知道 Vue 中可以利用 vm.$watch('a,b.c', function(){}) 这种形式来监听对象属性的变化。 12345678910function parsePath (path) { const segments = path.split('.') return function (obj) { for (let i = 0; i &lt; segments.length; i++) { if (!obj) return obj = obj[segments[i]] } return obj }} 实际原理很简单，parsePath 只是按照分隔符 . 来逐层地访问对象属性。 而前面说过，当读取对象的访问属性时，会触发依赖收集。所以当 getter 函数执行时，它其实就是在读取对象的访问属性，这个时候就会触发依赖收集的逻辑。 2.3 监测所有属性对于每个属性，如果需要监测它的变化，必须经过 defineReactive 来处理，这样它才能像访问属性那样收集依赖，实现响应式侦听。 为了提高代码的封装，Vue 中封装了一个监听类 Observer 类，用于监听对象的所有属性。 类 Observer 的作用就是将对象的所有属性都转换成访问属性，通过访问属性的 setter 和 getter 来实现变化追踪： 12345678910111213141516171819202122232425262728293031323334353637383940class Observer { constructor (value) { this.value = value if (!Array.isArray(value)) { this.walk(value) } } walk (obj) { const keys = Object.keys(obj) for (let i = 0; i &lt; keys.length; i++) { defineReactive(obj, keys[i]) } }}function defineReactive (obj, key, val) { // 递归子属性 if (typeof val === 'object') { new Observer(val) } let dep = new Dep(); Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { // 收集依赖 dep.depend(); return val }, set: function reactiveSetter (newVal) { if (newVal === val) { return } val = newVal; // 触发依赖 dep.notify(); } })} 类 Observer 的实现原理很简单，就是把所有属性都遍历一遍，利用 defineReactive 将属性都转成可追踪的访问属性。 2.4 存在问题Object 类型数据的变化侦听，其原理是通过访问属性 setter/getter 方法来实现的。 但是这种方式还存在一些问题，比如添加新属性、删除新属性时，setter/getter 是不会触发的，这些情况就没办法追踪属性的变化了。 1234567891011121314151617181920var isStateChange = false;Object.defineProperty(objProxy, 'access', { get: function () { isStateChange = true; return obj.data; }, set: function (val) { obj.data = val; isStateChange = true; }})// 删除属性不会触发set/getdelete objProxy.accessalert(isStateChange) // false// 新增属性也不会触发set/getobjProxy.name = 'newProp'alert(isStateChange) // false setter/getter 只能跟踪属性值是否发生修改，但是没办法侦测到新增属性和删除属性。","link":"/framework/vuejs/dection02/"},{"title":"对象变化侦测原理（一）","text":"变化侦测原理一、对象属性对于 js 对象的属性，可以分为2种：数据属性和访问属性。 1.1 数据属性数据属性就是普通的对象属性值，可以读入和写入值。 例如，下述的属性 data 就是数据属性： 1234var obj = {};obj.data = 'data';alert(obj.data) // &quot;data&quot; 对于数据属性，它有4个特性： [[Configureable]]：表示能否通过 delete 删除属性从而重新定义属性，能否修改属性的特性，或者能否把属性修改为访问属性。 [[Enumerable]]：表示能否通过 for-in 循环返回属性。 [[Writable]]：表示能否修改数据的值。 [[Value]]：这个属性的值。 这些属性特性一般是不能通过一般的方式获取到，需要通过使用方法 Object.getOwnPropertyDescriptor(obj, key)来获取特性值。以上面的代码为例： 1Object.getOwnPropertyDescriptor(obj, 'data') 123456{ configurable: true, enumerable: true, writable: true, value: &quot;data&quot;} 通过一般设置的对象属性，默认都是数据属性，而除了 value 特性以外，其他特性的值都是默认为 true。 如果需要修改特性的值，必须使用方法 Object.defineProperty(obj, key, option)来修改。 123Object.defineProperty(obj, 'data', { writable: false}) 再查看属性的特性，此时 writable 特性的值就已经发生变化了。 1Object.getOwnPropertyDescriptor(obj, 'data') 123456{ configurable: true, enumerable: true, writable: false, value: &quot;data&quot;} writable=false 表示属性不能修改，因此修改属性值是不生效的。 123alert(obj.data) // &quot;data&quot;obj.data = &quot;123&quot; // 此时修改的话也不生效alert(obj.data) // &quot;data&quot; 可以多次调用 Object.defineProperty 来修改属性特性。 接下来看一下特性 configurable 的作用： 123Object.defineProperty(obj, 'data', { configurable: false}) configurable=false 表示属性无法通过 delete 删除，再重新定义属性。 123alert(obj.data) // &quot;data&quot;delete obj.data // 无法删除alert(obj.data) // &quot;data&quot; 而且，还有一个比较重要的点，那就是一旦把 configurable 设置为 false 之后，就不能再把它重新恢复为 true 了。 12345678Object.defineProperty(obj, 'data', { configurable: false})// 设置失败，抛出错误Object.defineProperty(obj, 'data', { configurable: true}) 1.2 访问属性访问属性不包括数据，实际上是通过一对函数 setter 和 getter 进行属性的读取访问和设置。 访问属性不能通过一般的对象属性进行定义，必须使用 Object.defineProperty(obj, key, option) 进行定义。 1234567891011121314151617// 数据属性var obj = {};obj.data = 'data';// 访问属性var objProxy = {};Object.defineProperty(objProxy, 'access', { get: function () { return obj.data; }, set: function (val) { obj.data = val; }})alert(obj.data) // &quot;data&quot;alert(objProxy.access) // &quot;data&quot; 属性 access 就是所谓的访问属性，它和一般的数据属性 data 一样，它也有 4 个特性： [[Configureable]]：表示能否通过 delete 删除属性从而重新定义属性，能否修改属性的特性，或者能否把属性修改为访问属性。 [[Enumerable]]：表示能否通过 for-in 循环返回属性。 [[Get]]：在读取属性时调用的函数。 [[Set]]：在设置属性时调用的函数。 其中特性 Configureable 和 Enumerable 和数据属性中的是一样的。 获取属性特性的值也和数据属性的一样，通过方法 Object.getOwnPropertyDescriptor(obj, key) 来获取： 1Object.getOwnPropertyDescriptor(objProxy, 'access') 123456{ configurable: true, enumerable: true, get: [function ()], set: [function ()]} 访问属性比较特别，可以通过在访问函数 setter 和 getter中做一些中间操作，获得其他的效果： 12345678910111213141516171819202122var readTimes = 0var writeTimes = 0Object.defineProperty(objProxy, 'access', { get: function () { readTimes++; return obj.data; }, set: function (val) { writeTimes++; obj.data = val; }})objProxy.accessobjProxy.accessalert(readTimes) // 2alert(writeTimes) // 0objProxy.access = '111'alert(readTimes) // 2alert(writeTimes) // 1 这种利用访问函数的方式，其实就是 Vue 定义响应式属性所用的方法，通过利用访问属性的 setter 和 getter 来收集和通知属性发生了变更，就可以实现响应式属性。 也许，访问属性叫访问方法更好，虽然操作上和数据属性类似，但是它本身并不算一个属性，只是通过方法 setter 和 getter 进行了定义，然后拿的还是其他数据属性的值。 定义 setter 和 getter 实际上就是在定义 objProxy.access= 和 objProxy.access。调用 objProxy.access 就是在调用 getter 函数，调用 objProxy.access= 就是在调用 setter 函数。","link":"/framework/vuejs/dection01/"},{"title":"格式《代码整洁之道》","text":"格式1. 垂直格式 短的源文件比长的源文件会更好，一般在200行~500行之间为好 源文件的结构应该是从上往下展开，顶部是高层次概念，底下是实现细节，可以简单理解为 public 放在前，private 放在后 每组代码应该是完整的一条思路，不同组代码之间应该用空白行隔开 相关代码应该靠近，避免把相关的概念放到不同文件中，即避免过度使用 protected 变量声明应该尽可能靠近其使用位置 实体变量应该在类的顶部声明 函数调用应该放在一起，也就是被调用者在调用者的下面，保持程序的顺序性 概念相关的代码应该放在一起，相关性越强，彼此之间的距离就应该越短 2. 水平格式 代码行尽量短小，控制在120个字符以内最好 操作符左/右加上空格，例如 =、+、-、？等左右都应该加上空格，而 , 则是右边加空格 函数名和左括号不加空格 1234567// 声明时不要加空格public void print() { ...}// 调用时不要加空格print(); 函数参数之间用逗号和空格隔开，可以明显区分参数 1234// 参数之间加上空格分隔public void print (String prefix, String name) { ...} 有时为了强调运算符之间的关系，使用空格或括号分隔 123456789// 1. 这种方式也可以，但是会被格式化工具清理掉public double calc (double a, double b, double c) { return b*b - 4*a*c;}// 2. 所以建议用括号分隔不同的计算，明确区分public double calc (double a, double b, double c) { return (b * b) - (4 * a * c);} 不建议使用对齐的变量声明 123456789public class User { // 有人喜欢把变量名对齐， // 但是格式化工具会把排版清理掉，所以不建议这样写 private String firstName; private String lastName; private int age; private boolean sex; private String address;} 即使是单条语句，判断语句 if，while，以及函数都应该用大括号 {} 将代码包起来 12345678910111213// 不建议这么写if (a &gt; 10) return a;// 应该用大括号if (a &gt; 10) { return a;}// 即使这样也应该用大括号while (isTrue()) { ;} 不要违反缩进规则，特别是 if，while 和短函数 1234567// 有人会这么写if (a &gt; 10) { reurn a };// 建议缩进if (a &gt; 10) { return a;}","link":"/book/clean_code/formatter/"},{"title":"函数《代码整洁之道》","text":"注释1. 注释的作用 为了弥补代码表达某种意图时不够清晰的一种手段 2. 注释的缺点 需要写注释，就说明代码很糟糕，代码不能够清晰表达它的意思 注释会随着时间变得腐烂，离其描述的代码越来越远，甚至变得全部是错误的，因为程序员往往不能坚持维护注释 3. 好注释 不需要写注释就是最好的注释，由代码自己来阐述自己的意义 1File tempDirectory = FileUtils.getTempDirectory(); 法律信息类型的注释，例如版权及著作权声明 12345678910111213141516/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the &quot;License&quot;); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ 提供有用信息的注释，凡是能够根据注释去理解代码所代表的含义的信息，都可以称为有用信息，这个范围比较广 123456789101112public static boolean contentEquals(final File file1, final File file2) throws IOException { final boolean file1Exists = file1.exists(); if (file1Exists != file2.exists()) { return false; } if (!file1Exists) { // two not existing files are equal return true; } ...} 对意图解释的注释，用于解释当前代码这么做的原因，往往是因为代码中进行了特殊处理，例如性能优化，特例处理等 123456789if (!directory.mkdirs()) { // Double-check that some other thread or process hasn't made // the directory in the background if (!directory.isDirectory()) { final String message = &quot;Unable to create directory &quot; + directory; throw new IOException(message); }} 阐释型注释，这类注释一般是由于代码结构和含义比较难以理解，因而专门进行介绍，例如算法，多参数函数等 1234567891011121314151617/* * Implementation notes. * * This map usually acts as a binned (bucketed) hash table, but * when bins get too large, they are transformed into bins of * TreeNodes, each structured similarly to those in * java.util.TreeMap. Most methods try to use normal bins, but * relay to TreeNode methods when applicable (simply by checking * instanceof a node). Bins of TreeNodes may be traversed and * used like any others, but additionally support faster lookup * when overpopulated. However, since the vast majority of bins in * normal use are not overpopulated, checking for existence of * tree bins may be delayed in the course of table methods. * * ... * */ 警示型注释，用于警告其他程序员不要随便修改此处的代码，或者这里的代码会产生什么后果 1234// SimpleDateFormat is not thread safe,// so need to create each instance independentlySimpleDateFormat df = new SimpleDateFormat(&quot;yyyy/MM/dd&quot;);... TODO 列表注释，一般是由于某些原因暂时还没有做的留空，或者为了以后方便扩展留下的空门 Javadoc 文档注释，用于介绍代码整体结构，提供公共 API 方便别人调用的注释 1234567891011121314151617/** * An object that maps keys to values. A map cannot contain duplicate keys; * each key can map to at most one value. * * &lt;p&gt;This interface takes the place of the &lt;tt&gt;Dictionary&lt;/tt&gt; class, which * was a totally abstract class rather than an interface. * * &lt;p&gt;The &lt;tt&gt;Map&lt;/tt&gt; interface provides three &lt;i&gt;collection views&lt;/i&gt;, which * allow a map's contents to be viewed as a set of keys, collection of values, * or set of key-value mappings. The &lt;i&gt;order&lt;/i&gt; of a map is defined as * the order in which the iterators on the map's collection views return their * elements. Some map implementations, like the &lt;tt&gt;TreeMap&lt;/tt&gt; class, make * specific guarantees as to their order; others, like the &lt;tt&gt;HashMap&lt;/tt&gt; * class, do not. * * ... */ 4. 坏注释 不明确的注释，这类注释介绍不清楚，说不清楚代码的含义 12// Calculatedouble value = money * 50 + 100; 多余的注释，代码本身就很明确，不需要进行多余的注释说明 12345// check nullif (file == null) { // return if null return;} 误导性的注释，有些注释表达不精确，什么具有误导性，注释的内容和代码存在差异 循规式注释，一成不变地遵循每个函数或每个变量都要有注释的规矩，会使得代码中充满注释，结构变得散乱 日志式注释，把注释当成日志在写，每次修改都在注释中添加修改日志。这是旧代码的写法，因为现在已经有代码版本控制系统，不再需要这种写法 1234567/** * Changes log * * 2020-04-01: Fixed bug ... * 2020-05-01: Add a ... * ... */ 废话注释，像讲故事一样，天马行空，不够简洁，大部分内容都和代码毫无关系 位置标记注释，就是用于特别标记某个代码位置的注释，没有特别价值尽量少用 123// **************** Start ************** //...// **************** End ************** // 结束括号的标记注释，一般是为了识别每个括号的意义，实际上这类注释没有必要，除非是深层嵌套结构 123456789if (length &gt; 0) { int i = 0; while (i &lt; length) { if (i == 2) { ... } // if ... } // while} // if 归属或署名，由于当前已经有代码版本控制系统，已经不需要这种注释了 1// Add by xxx at 2020/04/01 注释的代码，其他程序员可能不敢随便删除注释的代码，因为它们可能还有用处。但是现在已经有了代码版本控制系统，代码可以找回，不需要留着被注释掉的代码 5. 注释优化 尽量用函数或变量来替换注释 1234// Check is validateif (length &gt; 0 &amp;&amp; str != null &amp;&amp; str.indexOf(&quot;s&quot;) &gt;= 0) { ...} 可以使用变量进行替换： 1234boolean isValid = length &gt; 0 &amp;&amp; str != null &amp;&amp; str.indexOf(&quot;s&quot;) &gt;= 0;if (isValid) { ...} 提炼废话较多的注释，将不相关的注释内容去掉 短函数不需要太多描述，选择一个好的函数名会比注释来的好","link":"/book/clean_code/annotation/"},{"title":"函数《代码整洁之道》","text":"函数1. 短小 函数在保证完整性的情况下，越短越好 每个函数都应该一目了然 长度为 20 行最佳 2. 只做一件事 每个函数应该保证只做一件事 要判断函数是否只做了一件事，可以看是否还能再拆出一个函数 一件事是指在同一抽象层次上完成的动作 3. 每个函数一个抽象层级 抽象层级类似于动作的抽象程度，例如 getData 和 data.push(item) 就属于不同的层次，getData 属于高层级别，而 data.push(item) 已经是属于比较低级别，因为它深入到了数据操作的底层 函数调用一般是高级别调用低级别，这样一层一层深入，是一种自顶向下的规则 如果出现同级别的函数调用，那可能是还有隐含的低层次还未抽象出来 4. switch 语句 switch 天生是做多件事的，因此无法满足只做一件事的要求 switch 难以写出较为短小的语句 可以利用抽象工厂的方式，将 switch 抽象到父类中，利用多态来隐藏 switch 语句 5. 使用描述性的名称 好的函数名称可以清晰地说明函数的作用 不要害怕长名称，长而具有描述性的名称，比短而令人费解的名称要好 长而具有描述性的名称，也比描述性的长注释要好 命名应该保持一致，使用与模块名一致的短语、名词或动词 6. 函数参数 函数参数不要多，0个最好，1个比较好，2个还行，3个以上基本不考虑 不要使用输出参数（不是输出值），而应该使用返回值，输出参数已经是以前旧代码的写法了。例如有返回值 StringBuffer transform(StringBuffer in) 会比输出参数 void transform(StringBuffer in) 更好一些 不建议使用标识参数（即 bool 参数），因为违反了一个函数只做一件事的原则，解决方法是拆分成两个函数 3个及以上的参数，应该考虑将其封装成类，从而减少参数数量 7. 分隔指令与查询 函数要么做修改对象的状态，要么返回对象的有关信息，二者不可兼得。例如 boolean set(String attr, String value) 就属于既修改来对象的状态，又返回了有关信息 正确的做法是将指令与查询分开，即利用 set 和 get 来实现 8. 使用异常替代返回错误码 返回错误码轻微违反了指令与查询分隔的规则 返回错误码容易导致多层次的嵌套，因为主流程代码需要根据不同的返回错误码进行不同的错误处理 使用异常替代返回错误码，可以将错误处理代码和主流程代码分离开来 将 try/catch 块抽取出来，单独作为一个函数，因为它容易导致函数结构混乱 使用异常替代错误码，可以使用新异常类从基本异常类中派生出来 9. 消除重复代码 重复代码是影响代码整洁性的罪魁祸首之一 要尽量清除掉代码中的重复代码 10. 反复调整 不要想着一开始就把函数写好，都是反复重构的 将函数的功能实现后，再根据基本原则对代码，对代码进行修改调整 最好给函数加上测试用例，调整完成后要保证函数都能通过测试","link":"/book/clean_code/method/"},{"title":"有意义的命名《代码整洁之道》","text":"有意义的命名1. 名副其实 变量、函数或类的名称应该能够准确地说明它的意义，比如它存在的意义，它做什么事，以及它应该怎么用。 一旦发现好的命名，就应该换掉旧的名称（当然要确定修改的难易程度）。 2. 避免误导 避免使用与本意相悖的词语，例如变量名 userList，如果不是 List 类型的变量，就不应该用这种命名。 提防使用区别很小的名称，因为很容易拼写错误。 避免使用误导性比较大的字母，例如 0，O，1，l，因为变量之间的区别只是这些字母的话，看错的可能性比较高。 3. 做有意义的区分 名称不同，那么其意义应该也不同才对。 不要使用数字序列作为名称的区分，会让人搞不清楚用途，例如 a1，a2。 多余的废话是冗余的区分，例如 getProduct 和 getProductData 这种就让人比较疑惑，意思区别不大。 4. 使用可读性好的名称 名称中的单词应该是可读的词语，或者公认的常见缩写，不要自造词语，例如 modymdhms 和 modifinationTimestamp。 5. 使用可搜索的名称 名称长短应该与其作用域大小相对应，长名称要优于短名称。 单字母名字应仅用于短方法中的本地变量，例如 i，j。 对于在代码中多次使用的变量或者常量，应该为其定义便于搜索的名称。例如数字常量 7，可以在代码中定义为 DAYS_PER_WEEK，这会比 7 好找得多。 6. 避免使用编码 不要添加成员前缀（或后缀），例如类成员 m_name 和 name，前后缀是以前旧代码所使用的，现在已经废弃了。 不要使用前导字母 I 来编码区分接口和实现，使用 impl 来标识实现类或许更好。 7. 别用俗语 不要使用俗语或典故作为名称，因为别人有可能不了解这方面的知识。 8. 每个概念对应一个词 给每个抽象概念都选定一个词，并且一以贯之。例如获取这个概念，fetch，get，retrieve 等都可以拿来使用，但是不要在代码中混杂着写，这里用 fetch，那边用 get，除非有明确说明，否则这很容易会让人受到误导。 9. 别用双关语 避免将同一单词用于不用的目的。例如 add 方法，在这个类中用来表示将两个数加起来，而在另一个类中则表示将对象放入集合中。因此可以修改第二个方法名称为 append 来作出区分。 10. 添加有意义的语境 如果语境不够清晰，可以为变量加上前缀。假如成员变量 state 在当前上下文中不是很明确时，因为 state 有可能在多个类中都存在。因此可以为其加上前缀 addrState，这样就能表明 state 是属于 Address 类了。 不要添加没用的语境。例如为每个名称都加上 app 的前缀，如 appUser，appAddress，这根本就是毫无意义的冗余。","link":"/book/clean_code/meaningful_naming/"},{"title":"人的精力","text":"人的精力 摘自：https://zhuanlan.zhihu.com/p/266759994 一、人的精力是有限的人的精力是有限的，做任何有益于自身成长的事情，都需要耗费大量的精力，这也就要求人要有节制地使用这一无形资本。 曾经有很长的一段时间我不明白为什么每当我参加一些人数众多，气氛热闹，互动频繁的活动时就会情绪低落，即使是参加大型同学聚会，面对大家欢快的讨论，我也多少有些拘谨。直到很久以后，我才明白这种性格特质叫：内向。而内向意味着个体在独处或面对有限的对象时精力充沛，而却对超出自我界限的对象则感到茫然无助，乃至疲惫不堪。 二、精力的损失 有很多人喜欢抱怨“无聊”，“无聊”其实就是精力不济的一种标志。在这种状态下，你几乎不可能做任何“有意义”的事情——比如高效率的工作、学习。你只能做一些娱乐性较高看似放松的事情，比如吃零食，上网，看肥皂剧，玩游戏等等。但在这一过程中，你内心的斗志实质上是被逐渐消磨的。随着时间逐渐拉长，你的精力愈发的懈怠，往往会坠入更深的无聊之中。 追究到底，人的精力是有限的，即使是“无聊”的事情，也会耗费精力。所以，当你发现自己很“无聊”时，就不应该再用“无聊”的事来打发时间，这样只会让自己陷入更“无聊”的无限死循环。 想要打破这个循环，就要从根本上了解自己的精力状况，合理的分配和使用精力。 三、精力与体力体力是一个非常重要的存在，它可以说是精力存在的保证，乃至来源。 体力是一个人健康程度的象征，如果不够健康的话，自然会常受各种因素影响，没有办法把注意力集中到做有益的事情上去。 体力和精力都是一种可快速恢复的，弹性十足且通过训练可以显着提高的能量，尤其对于那些已经进行过训练的人而言。而当人因体育锻炼而精神焕发的时候，他的精力也随之反弹，而且这一过程经常性并不随着体力值的降低而呈正相关。 你是不是有过这样一种体验：有时候你经过一天的奔波，体力运动，你反而感到精力旺盛，异常兴奋，甚至不能快速睡着。也许这种特例并不能说明体力值降低时人们的精力甚至能随之增长，但它也说明了运动的重要性。 显而易见的是，如果你一整天甚至更长的时间都待在家里，那你恐怕根本没法保持精力旺盛。 四、保护精力4.1 避免关注于己无关/没有意义的事情有太多的人每天把注意力放在与自己完全无关的事情上，以此消磨自己的意志、精力和时间，原因只是因为他们很“无聊”，不得不说这是一种恶劣的恶性循环。 4.2 避免情绪的波动没有什么比强烈的情绪更能直接损耗一个人的精力。如果是强烈的快乐和兴奋还好，但如果是强烈的负面情绪，则会直接让一个人的精力陷入瘫痪。 4.3 保持生活的平衡保持生活的平衡包括两部分，身体的平衡和心理的平衡。 身体的平衡要求人们对自己的摄入、睡眠、运动保持掌控，对需要身体的任何情况应对自如。 心理平衡则是同理，它是在“避免情绪波动”之上的一个范畴。这是一个很玄乎的状态，很难用文字表达出来。但当你处于这种状态时，则会时常感觉到平和、富足，而如果这种状态鲜有出现，则应该努力往这个方向靠拢。 4.4 不要在精力充沛的时候做一些损害精力的事情错误的放松方式是一种恶性循环，你会在不知不觉之中毁掉自己良好的状态和之前的努力。不要在精力充沛的时间做一些“无聊”的事来消耗自己的精力。 五、获取精力获取精力其实是和保护精力不受损害对应的概念，但它更侧重于我们要去做什么，而不是不去做什么。 5.1 保持规律而充足的睡眠保持规律而充足的睡眠是如此的重要，重要到那些即使在生活其他方面一团糟的人经过睡眠的修复，也能快速的恢复到一个不错的状态。 大多数人晚睡的原因都不是什么正经的事儿，将注意力集中在没有必要的事情上让人疲惫，睡前刷新网页，玩手机更是会直接损害睡眠质量……何必呢？看看书，保持沉静，安稳睡去，你的七到八个小时睡眠时间绝对不会在白天辜负你。 至于睡眠时间，最好的一种莫过于每天早晨在一个准确的时间起床，并长期坚持。 5.2 培养正确的爱好有些爱好就是比其他爱好要更好，比如阅读、观影、写作、摄影、画画，等等。这些爱好会让你感到开心，愉悦，幸福，满足，起到一些其他爱好无法满足的作用。 有些看起来并不怎么有意义的爱好会因人而异产生完全不同的效果。如果你做了而使自己获得了真正的放松——比如狂欢之后感到情绪被宣泄（换到我只会感觉到空虚）。归根结底还是要弄清自己真正适合做的是什么。 5.3 保持活动谨记：生命是一种流动中的形式，一个不动的人是很难有活力的。 六、训练精力任何事情都需要训练，运动员要训练肌肉记忆，做学问的要训练神经突触，蓄养精力也是同样的道理。将做有意义的事情时的精力上限提高并不仅仅意味着下次再做这件事情的时候能坚持的时间更长，而是意味着即使你只做一定的时间，你的效率也会大为增强。 比如，每天坚持读一个小时的书，或运动一个小时，而当一个小时之后，就可以休息一小会儿或看些轻松的东西。 在逐步的训练中，做某件事的精力值逐步提高了，而因为其趣味性也不断增强，你做其他相较之“不重要”的事情的时间也就缩短了。你的生活将变得更有意义，更加充实，对自我的成长帮助也越大。 七、分配精力7.1 不要一次性做完乐意的事人的精力是有限的，如果一大早就把自己乐意做的事情都做完了，难的不想做的事留在后面，那么后面的时间里，你整个人都会感到非常疲惫、倦怠。 而且很多人经常用错误的方法去放松自己，也就是做更“无聊”的事，周而复始，很多人的生活就会呈现出一种下滑的状态。 所以，合理分配自己的精力，保持充足的精神，是相当重要的，这样可以避免自己去做“无聊”的事情来打发时间。 7.2 交叉进行耗费和恢复精力的事情把一些乐意做的事和不想做的事交叉来做，这样两者都能够完成，并且还可以持续保持状态。 为了做那些我们需要耗费很大精力去完成的事情——比如工作——我们需要做充足的准备，留出足够的空档，并在其后对自己进行恢复。 在除了学习和工作以外的其他时间，分配同样重要。如果你决定每天晚上回家的时间是自己的充电时间——看书，看电影，写作——那你就不可以让自己回家的时候已经感到难受和疲惫。你可以将事情挪到其他时间去做，可以在下班后先做一些让自己兴奋的事情，可以通过训练让自己在某些事情上如鱼得水……不管怎样，你总要找到办法让自己每天的生活更加均衡，而不是完成中间的某一个部分之后就做不了别的事情了。 结语要知道，我们所有人都会老去，而我们中的几乎所有人都会比自己想像之中更早的老去，而老去时最常见的语言莫过于“精力有限”，“心有余而力不足”。 等到这一能量无可救药离我们远去的时候，我们应该有让自己骄傲的珍惜。到时候你才不会后悔的说，当我在还有机会发挥潜能的时候，却让财富从我的生命中偷偷流走。","link":"/life/human_energy/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/hello-world/"}],"tags":[{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"其他","slug":"其他","link":"/tags/%E5%85%B6%E4%BB%96/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","link":"/tags/%E6%8E%92%E5%BA%8F/"},{"name":"冒泡排序","slug":"冒泡排序","link":"/tags/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/"},{"name":"插入排序","slug":"插入排序","link":"/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"},{"name":"二分插入排序","slug":"二分插入排序","link":"/tags/%E4%BA%8C%E5%88%86%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"},{"name":"二分法","slug":"二分法","link":"/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"},{"name":"计数排序","slug":"计数排序","link":"/tags/%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F/"},{"name":"桶排序","slug":"桶排序","link":"/tags/%E6%A1%B6%E6%8E%92%E5%BA%8F/"},{"name":"堆排序","slug":"堆排序","link":"/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"name":"归并排序","slug":"归并排序","link":"/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"name":"快速排序","slug":"快速排序","link":"/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"选择排序","slug":"选择排序","link":"/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"},{"name":"基数排序","slug":"基数排序","link":"/tags/%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/"},{"name":"希尔排序","slug":"希尔排序","link":"/tags/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"name":"代码规范","slug":"代码规范","link":"/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"},{"name":"《代码整洁之道》","slug":"《代码整洁之道》","link":"/tags/%E3%80%8A%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E3%80%8B/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"堆","slug":"堆","link":"/tags/%E5%A0%86/"},{"name":"索引堆","slug":"索引堆","link":"/tags/%E7%B4%A2%E5%BC%95%E5%A0%86/"},{"name":"斜堆","slug":"斜堆","link":"/tags/%E6%96%9C%E5%A0%86/"},{"name":"左倾堆","slug":"左倾堆","link":"/tags/%E5%B7%A6%E5%80%BE%E5%A0%86/"},{"name":"并查集","slug":"并查集","link":"/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"设计原则","slug":"设计原则","link":"/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"登录","slug":"登录","link":"/tags/%E7%99%BB%E5%BD%95/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"临界区","slug":"临界区","link":"/tags/%E4%B8%B4%E7%95%8C%E5%8C%BA/"},{"name":"信号量","slug":"信号量","link":"/tags/%E4%BF%A1%E5%8F%B7%E9%87%8F/"},{"name":"管程","slug":"管程","link":"/tags/%E7%AE%A1%E7%A8%8B/"},{"name":"启动","slug":"启动","link":"/tags/%E5%90%AF%E5%8A%A8/"},{"name":"内核版本","slug":"内核版本","link":"/tags/%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC/"},{"name":"BF 算法","slug":"BF-算法","link":"/tags/BF-%E7%AE%97%E6%B3%95/"},{"name":"KMP 算法","slug":"KMP-算法","link":"/tags/KMP-%E7%AE%97%E6%B3%95/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"jar","slug":"jar","link":"/tags/jar/"},{"name":"字符串","slug":"字符串","link":"/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"格式化","slug":"格式化","link":"/tags/%E6%A0%BC%E5%BC%8F%E5%8C%96/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"native","slug":"native","link":"/tags/native/"},{"name":"本地方法","slug":"本地方法","link":"/tags/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"可变参数","slug":"可变参数","link":"/tags/%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/"},{"name":"实战","slug":"实战","link":"/tags/%E5%AE%9E%E6%88%98/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"状态压缩","slug":"状态压缩","link":"/tags/%E7%8A%B6%E6%80%81%E5%8E%8B%E7%BC%A9/"},{"name":"记忆化搜索","slug":"记忆化搜索","link":"/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/"},{"name":"回溯","slug":"回溯","link":"/tags/%E5%9B%9E%E6%BA%AF/"},{"name":"剪枝","slug":"剪枝","link":"/tags/%E5%89%AA%E6%9E%9D/"},{"name":"数组","slug":"数组","link":"/tags/%E6%95%B0%E7%BB%84/"},{"name":"三指针","slug":"三指针","link":"/tags/%E4%B8%89%E6%8C%87%E9%92%88/"},{"name":"基础知识","slug":"基础知识","link":"/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"集合","slug":"集合","link":"/tags/%E9%9B%86%E5%90%88/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"散列表","slug":"散列表","link":"/tags/%E6%95%A3%E5%88%97%E8%A1%A8/"},{"name":"树状数组","slug":"树状数组","link":"/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"},{"name":"跳表","slug":"跳表","link":"/tags/%E8%B7%B3%E8%A1%A8/"},{"name":"B-树","slug":"B-树","link":"/tags/B-%E6%A0%91/"},{"name":"红黑树","slug":"红黑树","link":"/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"线段树","slug":"线段树","link":"/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"},{"name":"B+树","slug":"B-树","link":"/tags/B-%E6%A0%91/"}],"categories":[{"name":"方法论","slug":"方法论","link":"/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/"},{"name":"设计模式","slug":"方法论/设计模式","link":"/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"生活感想","slug":"生活感想","link":"/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%83%B3/"},{"name":"面向对象","slug":"方法论/面向对象","link":"/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"排序算法","slug":"数据结构与算法/排序算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"查找算法","slug":"数据结构与算法/查找算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"},{"name":"代码规范","slug":"方法论/代码规范","link":"/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"},{"name":"数据结构","slug":"数据结构与算法/数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"设计原则","slug":"方法论/设计原则","link":"/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"},{"name":"编程语言","slug":"编程语言","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"字符串匹配","slug":"数据结构与算法/字符串匹配","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"name":"实战训练","slug":"数据结构与算法/实战训练","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%AE%9E%E6%88%98%E8%AE%AD%E7%BB%83/"},{"name":"Java","slug":"编程语言/Java","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"},{"name":"Vue","slug":"编程语言/Vue","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Vue/"},{"name":"JavaScript","slug":"编程语言/JavaScript","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/JavaScript/"},{"name":"基础","slug":"操作系统/基础","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%9F%BA%E7%A1%80/"},{"name":"Linux","slug":"操作系统/Linux","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/"}],"pages":[{"title":"标签","text":"","link":"/tags/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"资源","text":"","link":"/resources/index.html"},{"title":"关于","text":"","link":"/about/index.html"}]}